{
 "awd_id": "1064688",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "TC: Medium: Semantics and Enforcement of Privacy Policies: Information Use and Purpose",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Fen Zhao",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 1197126.0,
 "awd_amount": 1197126.0,
 "awd_min_amd_letter_date": "2011-04-12",
 "awd_max_amd_letter_date": "2013-08-12",
 "awd_abstract_narration": "Organizations, such as hospitals, financial institutions, and universities, that collect and use personal information are required to comply with privacy regulations, such as the Health Insurance Portability and Accountability Act (HIPAA), the Gramm-Leach-Bliley Act (GLBA), and the Family Educational Rights and Privacy Act (FERPA). Similarly, to ensure customer trust, web services companies, such as Google, Facebook, Yahoo!, and Amazon, publish privacy policies stating what they will do with the information they keep about customers' individual behaviors. These policies impose constraints on disclosure (or transmission) of personal information, articulate obligations (e.g., notifying customers about privacy breaches), and identify purposes for which personal information may or may not be used. Prior work has focused on formalisms for disclosure and obligations, but no such foundation has been developed for information use for specified purposes.\r\n\r\nIntellectual Merit. This project addresses the central problem of developing a formal semantics that explains what it means to use information for a set of purposes, a logic for specifying such policies, and algorithmic methods for their enforcement. It advances the state of knowledge in the field of privacy by providing a foundation for a concept that is commonly used in practice, but has not been the subject of careful scientific study. The project also investigates the interaction of this concept with the previously studied concepts of disclosure and obligation, thereby enabling a more comprehensive understanding of privacy.  The formal semantics the project develops is novel and draws on insights from prior work on philosophical theories of causation and intentions, and from the computer science literature on formal methods, information flow, and planning. The model is validated through user studies and its application through case studies in the healthcare domain. \r\n\r\nBroader Impacts. The project addresses a problem of significant and growing importance to society. It initiates a new direction in providing foundations for privacy by studying the concept of information use for a purpose. This concept appears in privacy policies published by organizations in sectors as diverse as finance, web services, healthcare, insurance, education, and government - the cornerstones of modern society. The semantic foundation serves as the basis for developing practical tools to support the enforcement of such policies in such organizations.  The project provides opportunities for engaging graduate and undergraduate students. The PIs plan to integrate the research results into their existing security and privacy courses, and, for wider dissemination, leverage outreach programs in Carnegie Mellon's Computer Science Department and CyLab aimed at K-12, women, persons with disabilities, and underrepresented minorities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Jeannette",
   "pi_last_name": "Wing",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Jeannette M Wing",
   "pi_email_addr": "WING@COLUMBIA.EDU",
   "nsf_id": "000142080",
   "pi_start_date": "2011-04-12",
   "pi_end_date": "2013-03-05"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anupam",
   "pi_last_name": "Datta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anupam Datta",
   "pi_email_addr": "danupam@andrew.cmu.edu",
   "nsf_id": "000501887",
   "pi_start_date": "2013-08-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Anupam",
   "pi_last_name": "Datta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anupam Datta",
   "pi_email_addr": "danupam@andrew.cmu.edu",
   "nsf_id": "000501887",
   "pi_start_date": "2011-04-12",
   "pi_end_date": "2013-03-05"
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7795",
   "pgm_ref_txt": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 293651.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 624322.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 279153.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project addresses the problem of precisely defining and enforcing a class of privacy properties that restrict information use for certain purposes.</p>\n<p>The intellectual merit of the project lies in outcomes that provide precise definitions of what it means to use information for a purpose and algorithms and tools for auditing logs and programs for compliance with such policies. Specifically, the project provides a semantics of purpose restrictions that relates it to planning -- an action is for a purpose if it is part of plan for achieving the purpose, and information is used for a purpose if it affects the planning process. These insights enable the design of audit algorithms based on well-known planning methods from artificial intelligence. Another set of outcomes involves a theory of information flow experiments that support discovering personal information use in black box web services, such as Google's advertising system.&nbsp;</p>\n<p>The broader impact of the project includes a tool chain for privacy compliance that was built jointly with collaborators at Microsoft Research and is now deployed on their production system. Another significant outcome is a rigorous study of the Google advertising system that discovered the use of personal information in ways that raise significant concerns about privacy and fairness.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/06/2017<br>\n\t\t\t\t\tModified by: Anupam&nbsp;Datta</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project addresses the problem of precisely defining and enforcing a class of privacy properties that restrict information use for certain purposes.\n\nThe intellectual merit of the project lies in outcomes that provide precise definitions of what it means to use information for a purpose and algorithms and tools for auditing logs and programs for compliance with such policies. Specifically, the project provides a semantics of purpose restrictions that relates it to planning -- an action is for a purpose if it is part of plan for achieving the purpose, and information is used for a purpose if it affects the planning process. These insights enable the design of audit algorithms based on well-known planning methods from artificial intelligence. Another set of outcomes involves a theory of information flow experiments that support discovering personal information use in black box web services, such as Google's advertising system. \n\nThe broader impact of the project includes a tool chain for privacy compliance that was built jointly with collaborators at Microsoft Research and is now deployed on their production system. Another significant outcome is a rigorous study of the Google advertising system that discovered the use of personal information in ways that raise significant concerns about privacy and fairness.\n\n\t\t\t\t\tLast Modified: 09/06/2017\n\n\t\t\t\t\tSubmitted by: Anupam Datta"
 }
}