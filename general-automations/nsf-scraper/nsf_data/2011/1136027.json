{
 "awd_id": "1136027",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Medium: Collaborative Research: Holistic Design Methodology for Automated Implementation of Human-in-the-Loop Cyber-Physical Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Corman",
 "awd_eff_date": "2011-09-15",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 1250000.0,
 "awd_amount": 1266000.0,
 "awd_min_amd_letter_date": "2011-08-30",
 "awd_max_amd_letter_date": "2014-06-05",
 "awd_abstract_narration": "This project develops a framework for design automation of cyber-physical systems to augment human interaction with complex systems that integrate across computational and physical environments. As a design driver, the project develops a Body/Brain Computer Interface (BBCI) for the population of functionally locked-in individuals, who are unable to interact with the physical world through movement and speech. The BBCI will enable communication with other humans through expressive language generation and interaction with the environment through robotic manipulators. \r\n\r\nUtilizing advances in system-level design, this project develops a holistic framework for design and implementation of heterogeneous human-in-the-loop cyber-physical systems composed of physically distributed, networked components. It will advance BBCI technology by incorporating context aware inference and learning of task-specific human intent estimation in applications involving semi-autonomous robotic actuators and an efficient wireless communication framework.\r\n\r\nThe results of this project are expected to significantly speed up the design of complex cyber-physical systems. By accelerating the path from idea to prototype, this work shortens the time frame of and cost of development for assistive technology to improve the quality-of-life for functionally locked-in individuals. This project establishes an open prototyping platform and a design framework for rapid exploration of other novel human-in-the-loop applications. The open platform will foster undergraduate involvement in cyber-physical systems research, building confidence and expertise. In addition, new activities at the Museum of Science in Boston will engage visitors to experiment with systematic design principles in context of a brain computer interface application, while offering learning opportunities about basic brain functions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gunar",
   "pi_last_name": "Schirner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gunar Schirner",
   "pi_email_addr": "schirner@ece.neu.edu",
   "nsf_id": "000552705",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Deniz",
   "pi_last_name": "Erdogmus",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Deniz Erdogmus",
   "pi_email_addr": "erdogmus@ece.neu.edu",
   "nsf_id": "000483728",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kaushik",
   "pi_last_name": "Chowdhury",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Kaushik R Chowdhury",
   "pi_email_addr": "kaushik@utexas.edu",
   "nsf_id": "000541186",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7752",
   "pgm_ref_txt": "CDI NON SOLICITED RESEARCH"
  },
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 1250000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Human-in-the-Loop Cyber-Physical Systems (HiLCPS) offer assistive technology to augment human interaction with the physical world. HiLCPS applications are particularly challenging due to their complexity and requiring concerted efforts across multiple disciplines: signal processing, robotics, embedded systems and networking. In this project, we have developed a holistic framework that serves as a basis to align efforts across disciplines for rapid development of HiLCPS applications. We focused on assistive technologies and brain-controlled applications for demonstration purposes. Specifically, we focused on a setting where the human operator has a severe physical disability that prevents them from using their body to interact with the physical world. The framework allowed us to rapidly develop a brain-controlled wheelchair and brain controlled textual communication, allowing such individuals to regain some autonomy.</p>\n<p>For the interaction with the human, we have developed active human intent probing methodologies that dynamically analyze the available physiological signals. Multiple physiological signals were evaluated (non-invasive EEG from brain, EMG from muscles, gaze trajectory from eyes). Possible decisions are paired with a precise stimulus (e.g. visual, tactile) and the user expresses the choice by focusing on the stimulus associated with the desired decision. As the non-invasive EEG is a noisy and coarse grained physiological signal, advanced signal processing is needed to infer slightly more than one decision per second. To better utilize the long latency intent inference, we have developed methods to present close-to-optimal queries to the user in an attempt to reach the correct intended human command as quickly as possible while satisfying accuracy requirements. We have successfully demonstrated human intent estimation in dynamic contexts involving wheelchair and speller control applications.</p>\n<p>To foster a broader adoption and stimulate follow-on research, we have developed a suite of devices offering affordable solutions for brain-controlled HiLCPS applications. We have developed a portable embedded precision acquisition system: EEGu2 which capable of sensing brain signals (EEG - electroencephalogram) and processing them in real-time to infer the user&rsquo;s intent. It is flanked by a mobile visualization showing potential actions (given location and state), and a precision visual stimulus. Our hardware suite is fully integrated into the framework. In addition, our framework&rsquo;s synthesis module empowers algorithm designers to prototype portable, hardware-agnostic HiLCPS applications in MATLAB and then automatically deploying them to our devices, realizing a simple path to an embedded deployment without requiring embedded knowledge.</p>\n<p>To deal with the infrequent control inputs by the brain-controlled interfaces, the robotic wheel chair has to execute the human&rsquo;s decisions with some autonomy sensible to the dynamically changing environment. We have developed a new semi-autonomous robot navigation algorithm, CWave, which enables an individual to navigate in cluttered environments using low throughput inputs such as brain signals. We also developed modular and reconfigurable hardware and software designs to realize an autonomous wheelchair-arm system as a HiLCPS testbed. Our optimization-based motion planning algorithm for the wheelchair-arm system has been validated to perform common tasks such as opening doors or picking up objects from a table top.</p>\n<p>Efficient and reliable communication is essential to gather physiological signals from multiple points at the body. For communication along the human body, galvanic coupling (GC) is a very promising technology. It applies very weak electrical currents (well within safety guidelines) using the natural conduction of the body tissues for short range communication. By that it can save 100x energy compared to a classical wireless approach using over-the-air radiation. We have developed new analytical models for the galvanic coupled communication channel for the transmission bio-physiological signals gathered by multiple nodes along the body. We have rigorously validated these models with experimentation as well as simulation. We successfully prototyped GC communication on a synthetic tissue testbed. For a sample case of the human arm tissue, we identified the ideal signaling frequency and other transmission parameters. To also further over-the-air wireless communication, we studied the interference caused to wireless sensor communication within medical environments. We have developed interference mitigation techniques that allow coexistence with different users, differing in priority of channel access.</p>\n<p>Overall, research groups funded by this project graduated doctoral students, supported undergraduate research projects, and hosted high school students as summer interns. The project provided the context for their research and development projects that contributed to their education and career development. The outcomes are disseminated through publications in international peer-reviewed venues including journals and conferences; live demos were presented at workshops, scientific meetings, and nearby high schools.</p>\n<p>This research project tackled control problems in which the robot or computer application that is being operated by the human makes relatively slow maneuvers. Beyond the project performance period, using the framework developed, the team is pursuing a more challenging control problem that presents requirements for rapid and more precise responses - prosthetic hand control with brain and muscle electrical activity.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/16/2017<br>\n\t\t\t\t\tModified by: Gunar&nbsp;Schirner</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512436679_Fig1_HilCPS_Framework--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512436679_Fig1_HilCPS_Framework--rgov-800width.jpg\" title=\"HilCPS Framework\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512436679_Fig1_HilCPS_Framework--rgov-66x44.jpg\" alt=\"HilCPS Framework\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Framework</div>\n<div class=\"imageCredit\">ESL, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">HilCPS Framework</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512532024_Fig2_BrainControlledWheelChair--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512532024_Fig2_BrainControlledWheelChair--rgov-800width.jpg\" title=\"Brain-Controlled Wheelchair\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512532024_Fig2_BrainControlledWheelChair--rgov-66x44.jpg\" alt=\"Brain-Controlled Wheelchair\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example application of a brain-controlled wheelchair</div>\n<div class=\"imageCredit\">ESL, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">Brain-Controlled Wheelchair</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512698728_Fig3_EEGu2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512698728_Fig3_EEGu2--rgov-800width.jpg\" title=\"EEGu2\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512698728_Fig3_EEGu2--rgov-66x44.jpg\" alt=\"EEGu2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Portable EEG acquisition (16 channels, 24bit) and processing system</div>\n<div class=\"imageCredit\">ESL, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">EEGu2</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512828158_Fig4_VisualizationStimulus--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512828158_Fig4_VisualizationStimulus--rgov-800width.jpg\" title=\"Visualization / Stimulus\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484512828158_Fig4_VisualizationStimulus--rgov-66x44.jpg\" alt=\"Visualization / Stimulus\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Custom designed visualization and stimulus module. Offers precise control of up to 12 channels of visual stimulus.</div>\n<div class=\"imageCredit\">ESL, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">Visualization / Stimulus</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513231218_Fig6_GalvanicCoupling--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513231218_Fig6_GalvanicCoupling--rgov-800width.jpg\" title=\"Galvanic Coupling\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513231218_Fig6_GalvanicCoupling--rgov-66x44.jpg\" alt=\"Galvanic Coupling\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Galvanic Coupling Communication Principle</div>\n<div class=\"imageCredit\">GENESYS Lab, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">Galvanic Coupling</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513011384_Fig5_RoboticWheelChair--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513011384_Fig5_RoboticWheelChair--rgov-800width.jpg\" title=\"Robotic Wheelchair\"><img src=\"/por/images/Reports/POR/2017/1136027/1136027_10129006_1484513011384_Fig5_RoboticWheelChair--rgov-66x44.jpg\" alt=\"Robotic Wheelchair\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Semi-autonomous wheel chair</div>\n<div class=\"imageCredit\">RIVeR, Northeastern University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gunar&nbsp;Schirner</div>\n<div class=\"imageTitle\">Robotic Wheelchair</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHuman-in-the-Loop Cyber-Physical Systems (HiLCPS) offer assistive technology to augment human interaction with the physical world. HiLCPS applications are particularly challenging due to their complexity and requiring concerted efforts across multiple disciplines: signal processing, robotics, embedded systems and networking. In this project, we have developed a holistic framework that serves as a basis to align efforts across disciplines for rapid development of HiLCPS applications. We focused on assistive technologies and brain-controlled applications for demonstration purposes. Specifically, we focused on a setting where the human operator has a severe physical disability that prevents them from using their body to interact with the physical world. The framework allowed us to rapidly develop a brain-controlled wheelchair and brain controlled textual communication, allowing such individuals to regain some autonomy.\n\nFor the interaction with the human, we have developed active human intent probing methodologies that dynamically analyze the available physiological signals. Multiple physiological signals were evaluated (non-invasive EEG from brain, EMG from muscles, gaze trajectory from eyes). Possible decisions are paired with a precise stimulus (e.g. visual, tactile) and the user expresses the choice by focusing on the stimulus associated with the desired decision. As the non-invasive EEG is a noisy and coarse grained physiological signal, advanced signal processing is needed to infer slightly more than one decision per second. To better utilize the long latency intent inference, we have developed methods to present close-to-optimal queries to the user in an attempt to reach the correct intended human command as quickly as possible while satisfying accuracy requirements. We have successfully demonstrated human intent estimation in dynamic contexts involving wheelchair and speller control applications.\n\nTo foster a broader adoption and stimulate follow-on research, we have developed a suite of devices offering affordable solutions for brain-controlled HiLCPS applications. We have developed a portable embedded precision acquisition system: EEGu2 which capable of sensing brain signals (EEG - electroencephalogram) and processing them in real-time to infer the user?s intent. It is flanked by a mobile visualization showing potential actions (given location and state), and a precision visual stimulus. Our hardware suite is fully integrated into the framework. In addition, our framework?s synthesis module empowers algorithm designers to prototype portable, hardware-agnostic HiLCPS applications in MATLAB and then automatically deploying them to our devices, realizing a simple path to an embedded deployment without requiring embedded knowledge.\n\nTo deal with the infrequent control inputs by the brain-controlled interfaces, the robotic wheel chair has to execute the human?s decisions with some autonomy sensible to the dynamically changing environment. We have developed a new semi-autonomous robot navigation algorithm, CWave, which enables an individual to navigate in cluttered environments using low throughput inputs such as brain signals. We also developed modular and reconfigurable hardware and software designs to realize an autonomous wheelchair-arm system as a HiLCPS testbed. Our optimization-based motion planning algorithm for the wheelchair-arm system has been validated to perform common tasks such as opening doors or picking up objects from a table top.\n\nEfficient and reliable communication is essential to gather physiological signals from multiple points at the body. For communication along the human body, galvanic coupling (GC) is a very promising technology. It applies very weak electrical currents (well within safety guidelines) using the natural conduction of the body tissues for short range communication. By that it can save 100x energy compared to a classical wireless approach using over-the-air radiation. We have developed new analytical models for the galvanic coupled communication channel for the transmission bio-physiological signals gathered by multiple nodes along the body. We have rigorously validated these models with experimentation as well as simulation. We successfully prototyped GC communication on a synthetic tissue testbed. For a sample case of the human arm tissue, we identified the ideal signaling frequency and other transmission parameters. To also further over-the-air wireless communication, we studied the interference caused to wireless sensor communication within medical environments. We have developed interference mitigation techniques that allow coexistence with different users, differing in priority of channel access.\n\nOverall, research groups funded by this project graduated doctoral students, supported undergraduate research projects, and hosted high school students as summer interns. The project provided the context for their research and development projects that contributed to their education and career development. The outcomes are disseminated through publications in international peer-reviewed venues including journals and conferences; live demos were presented at workshops, scientific meetings, and nearby high schools.\n\nThis research project tackled control problems in which the robot or computer application that is being operated by the human makes relatively slow maneuvers. Beyond the project performance period, using the framework developed, the team is pursuing a more challenging control problem that presents requirements for rapid and more precise responses - prosthetic hand control with brain and muscle electrical activity.\n\n\t\t\t\t\tLast Modified: 01/16/2017\n\n\t\t\t\t\tSubmitted by: Gunar Schirner"
 }
}