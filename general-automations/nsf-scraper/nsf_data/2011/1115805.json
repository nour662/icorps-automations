{
 "awd_id": "1115805",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Stork Data Scheduler for Azure",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-04-15",
 "awd_exp_date": "2014-03-31",
 "tot_intn_awd_amt": 97122.0,
 "awd_amount": 97122.0,
 "awd_min_amd_letter_date": "2011-04-13",
 "awd_max_amd_letter_date": "2011-04-13",
 "awd_abstract_narration": "This project will further develop and enhance the Stork Data Scheduler to support Azure cloud computing environment, and to mitigate the end-to-end data handling bottleneck in data-intensive cloud computing applications. Stork data scheduler has been very actively used in many data-intensive application areas including coastal hazard prediction and storm surge modeling; oil flow and reservoir uncertainty analysis; numerical relativity and black hole collisions; educational video processing and behavioral assessment; digital sky imaging; and multiscale computational fluid dynamics. Making Stork available on the Azure environment will enable this already existing user base to easily migrate to the Azure Cloud Computing platform as well as other Azure application groups benefiting from the large-scale data handling capabilities of Stork.\r\n\r\nThe Stork Data Scheduler for Azure will make a distinctive contribution to cloud computing community because it focuses on planning, scheduling, monitoring and management of data placement tasks and application-level end-to-end optimization of networked I/O for petascale data-intensive applications. Unlike existing approaches, it will treat data resources and the tasks related to data access and movement as first class entities just like computational resources and compute tasks, and not simply the side effect of computation. Stork data scheduler for Azure will provide enhanced functionality for cloud computing such as data aggregation and connection caching; peer-to-peer and streamed data management; early error detection, classification, and recovery in data transfers; scheduled storage management; optimal protocol tuning; and end-to-end performance prediction services. The Stork data scheduler for Azure will dramatically change how domain scientists perform their research by rapidly facilitating sharing of large amounts of data in cloud computing environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tevfik",
   "pi_last_name": "Kosar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tevfik Kosar",
   "pi_email_addr": "tkosar@buffalo.edu",
   "nsf_id": "000581942",
   "pi_start_date": "2011-04-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Buffalo",
  "inst_street_address": "520 LEE ENTRANCE STE 211",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "7166452634",
  "inst_zip_code": "142282577",
  "inst_country_name": "United States",
  "cong_dist_code": "26",
  "st_cong_dist_code": "NY26",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "GMZUKXFDJMA9",
  "org_uei_num": "LMCJKRFW5R81"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Buffalo",
  "perf_str_addr": "520 LEE ENTRANCE STE 211",
  "perf_city_name": "AMHERST",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142282577",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "801000",
   "pgm_ele_name": "Computing in the Cloud"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8010",
   "pgm_ref_txt": "Computing in the Cloud"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 97122.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Stork data Scheduler is ported to&nbsp;work on the Windows-based systems and on the Azure Cloud Computing Environment. This will allow&nbsp;Azure users be able to immediately start using a broad range of Stork data management capabilities.&nbsp;</p>\n<p>We have implemented several inter-protocol translation modules as part of Stork Azure and started using them in real data transfers. Stork Azure can act as a negotiating system between different data storage systems/protocols and Azure. The modularity of Stork allows users to insert a plug-in to support their favorite storage system, protocol, or middleware easily. Stork can currently interact with data transfer protocols such as FTP, GridFTP, HTTP, SCP, SMTP, BITTORENT; and data storage systems such as RODS. Stork maintains a library of pluggable 'data placement' modules, which get executed by data placement job requests coming to Stork. &nbsp;</p>\n<p>Thin clients were implemented for the cloud hosted Stork Azure services (inclsuing a web interface, and a smartphone android app). These interfaces use the REST API to access Stork Azure services. The users are able to submit, manage, and monitor their data transfer tasks submitted to Stork Azure via these thin clients, which is very convenient.&nbsp;</p>\n<p>End-to-end data transfer throughput prediction models were implemented for Windows Azure. Using these prediction models, we are now able to provide a cloud-hosted 'data transfer completion time estimation service' as a SaaS. This estimation service will allow data movement operations to be scheduled in advance with a preferred &nbsp; time constraint given by the user, stating the earliest start time and desired latest completion time. This will allow users and higher level meta-schedulers to use data placement as a service where they can plan ahead and reserve the time period for their data movement operations between Azure and external storage systems. This service will &nbsp; eliminate possible long delays in completion of a transfer operation and increase utilization of Azure by giving an opportunity to provision the required network and storage resources in advance.</p>\n<p>We have analyzed various factors that affect the end-to-end data transfer throughput in wide-area distributed environments, such as number of parallel streams, CPU speed, and disk I/O speed. We have shown the effects of CPU-, disk-, and network-level parallelism in removing the bottlenecks one-by-one and increasing the end-to-end data transfer throughput.&nbsp;</p>\n<p>We have developed models and algorithms to set the best values for the application-level transfer tuning parameters such as pipelining, parallelism and concurrency. The tests conducted over high-speed networking and cloud testbeds show that our algorithms outperform the most popular data transfer tools like Globus-url-copy, Globus Online, and UDT in majority of the cases.</p>\n<div class=\"tinyMCEContent\">\n<p>The Stork Data Scheduler for Azure makes a distinctive contribution to cloud computing environments because it focuses on planning, scheduling, monitoring and management of data placement tasks and application-level end-to-end optimization of networked I/O for petascale data-intensive applications. Unlike existing approaches, it treats data resources and the tasks related to data access and movement as first class entities just like computational resources and compute tasks, and not simply the side effect of computation. Stork data scheduler for Azure provides enhanced functionality for cloud computing such as data aggregation and connection caching, peer-to-peer and streamed data management; early error detection, classification, and recovery in data transfers; scheduled storage management; optimal protocol tuning; and end-to-end performance prediction services.</p>\n</div>\n<p>Stork data scheduler has been very actively used in many application areas including coastal hazard ...",
  "por_txt_cntn": "\nStork data Scheduler is ported to work on the Windows-based systems and on the Azure Cloud Computing Environment. This will allow Azure users be able to immediately start using a broad range of Stork data management capabilities. \n\nWe have implemented several inter-protocol translation modules as part of Stork Azure and started using them in real data transfers. Stork Azure can act as a negotiating system between different data storage systems/protocols and Azure. The modularity of Stork allows users to insert a plug-in to support their favorite storage system, protocol, or middleware easily. Stork can currently interact with data transfer protocols such as FTP, GridFTP, HTTP, SCP, SMTP, BITTORENT; and data storage systems such as RODS. Stork maintains a library of pluggable 'data placement' modules, which get executed by data placement job requests coming to Stork.  \n\nThin clients were implemented for the cloud hosted Stork Azure services (inclsuing a web interface, and a smartphone android app). These interfaces use the REST API to access Stork Azure services. The users are able to submit, manage, and monitor their data transfer tasks submitted to Stork Azure via these thin clients, which is very convenient. \n\nEnd-to-end data transfer throughput prediction models were implemented for Windows Azure. Using these prediction models, we are now able to provide a cloud-hosted 'data transfer completion time estimation service' as a SaaS. This estimation service will allow data movement operations to be scheduled in advance with a preferred   time constraint given by the user, stating the earliest start time and desired latest completion time. This will allow users and higher level meta-schedulers to use data placement as a service where they can plan ahead and reserve the time period for their data movement operations between Azure and external storage systems. This service will   eliminate possible long delays in completion of a transfer operation and increase utilization of Azure by giving an opportunity to provision the required network and storage resources in advance.\n\nWe have analyzed various factors that affect the end-to-end data transfer throughput in wide-area distributed environments, such as number of parallel streams, CPU speed, and disk I/O speed. We have shown the effects of CPU-, disk-, and network-level parallelism in removing the bottlenecks one-by-one and increasing the end-to-end data transfer throughput. \n\nWe have developed models and algorithms to set the best values for the application-level transfer tuning parameters such as pipelining, parallelism and concurrency. The tests conducted over high-speed networking and cloud testbeds show that our algorithms outperform the most popular data transfer tools like Globus-url-copy, Globus Online, and UDT in majority of the cases.\n\n\nThe Stork Data Scheduler for Azure makes a distinctive contribution to cloud computing environments because it focuses on planning, scheduling, monitoring and management of data placement tasks and application-level end-to-end optimization of networked I/O for petascale data-intensive applications. Unlike existing approaches, it treats data resources and the tasks related to data access and movement as first class entities just like computational resources and compute tasks, and not simply the side effect of computation. Stork data scheduler for Azure provides enhanced functionality for cloud computing such as data aggregation and connection caching, peer-to-peer and streamed data management; early error detection, classification, and recovery in data transfers; scheduled storage management; optimal protocol tuning; and end-to-end performance prediction services.\n\n\nStork data scheduler has been very actively used in many application areas including coastal hazard prediction and storm surge modeling; oil flow and reservoir uncertainty analysis; numerical relativity and black hole collisions; educational video processing and behavioral asse..."
 }
}