{
 "awd_id": "1064976",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Medium: Compiler and Chip Multiprocessor Co-Design for Scalable Efficient Data Access and Communication",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2011-03-15",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 601671.0,
 "awd_amount": 809600.0,
 "awd_min_amd_letter_date": "2011-03-10",
 "awd_max_amd_letter_date": "2014-07-16",
 "awd_abstract_narration": "Multi-core computing, where several processor cores are combined together into a single chip, has become\r\nthe standard in computer processor design. In effect, each chip has become a small parallel computer\r\nand leveraging the processing power of parallel computing efficiently is a difficult challenge. Parallel\r\ncomputing attempts to accelerate computational tasks by separating the work into segments that can be\r\ncalculated independently using different processors. Unfortunately, these processors need to communicate\r\nwith each other to complete the computational tasks correctly. This communication and the resulting\r\naccess to data are major limiting factors to how much a computational task can be accelerated with\r\nmultiple processors.\r\nThis research proposes a cooperatively designed system that considers the method for storing and accessing\r\ndata (memory), the method for communication between processors (network), the software that\r\ncontrols how programs are executed (operating system), and the design of the program executables themselves\r\n(compilation) to maximize the program execution speed. The key observation is that while each\r\ncomponent of the system can be improved independently, each component contains information that can\r\nhelp the other components to realize even greater benefits. Just as a transportation infrastructure requires\r\ninformation about traffic patterns; for example, if traffic patterns were ignored and if highways connect\r\nrural areas and only side streets connect major cities, traffic would reach a standstill while highways are\r\ninefficiently used. Likewise, the communication network cannot be efficiently designed without information\r\nfrom programs on communication patterns.\r\nThe outcomes from this project will be the development of ?cross-layer? design concepts for multi-core\r\ncomputer architectures that will result in performance improvements and effective use of more processor\r\ncores within a single chip.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alex",
   "pi_last_name": "Jones",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Alex K Jones",
   "pi_email_addr": "akj@syr.edu",
   "nsf_id": "000239841",
   "pi_start_date": "2011-03-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rami",
   "pi_last_name": "Melhem",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rami Melhem",
   "pi_email_addr": "melhem@cs.pitt.edu",
   "nsf_id": "000214915",
   "pi_start_date": "2011-03-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sangyeun",
   "pi_last_name": "Cho",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sangyeun Cho",
   "pi_email_addr": "cho@cs.pitt.edu",
   "nsf_id": "000386645",
   "pi_start_date": "2011-03-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pittsburgh",
  "inst_street_address": "4200 FIFTH AVENUE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4126247400",
  "inst_zip_code": "152600001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "UNIVERSITY OF PITTSBURGH - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "MKAGLD59JRL1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pittsburgh",
  "perf_str_addr": "4200 FIFTH AVENUE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152600001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 393564.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 201545.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 214491.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Next generation computer processor architectures can no longer depend on technology scaling alone to provide enhancements in performance and energy consumption.&nbsp; As a result, modern processors have become increasingly parallel and heterogeneous to enable further performance and energy efficiency.&nbsp; Moreover, increasing amounts of memory and flexible interconnection are required to support this parallelism.&nbsp; This project made several advancements in the cooperative design of the computing cores, memory elements, and interconnection to fully leverage these resources efficiently.&nbsp; Moreover, it developed new ways to tailor these resources by learning about the application requirements from the compiler and runtime system for further system efficiency and performance improvements.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual Merit</strong></p>\n<p>The intellectual merit of this work can be seen in several outcomes that advance the community in the areas of cooperative design of modern computing systems.</p>\n<p><strong>Compiler</strong></p>\n<p>We developed a compiler that could determine the sharing property of data in the system.&nbsp; The compiler can determine if the data is private to a particular processing element or is shared amongst multiple processing elements.&nbsp; To improve on this categorization, we proposed a new category called &ldquo;practically private&rdquo; data, which is private for &ldquo;all intents and purposes.&rdquo; Based on these properties, we expanded the compiler to discover the intended data partitioning of an application.&nbsp; We used this information to enforce this partition in the system and guide the network to allow for fast communication between partners or small groups of processing elements that frequently share data.</p>\n<p>We also developed a compiled approach to utilizing emerging non-volatile memories in the system.&nbsp; The compiler uses a fast read-access mode when reads dominate and uses a slower but lower energy access mode when writes, which are typically most energy consuming in emerging memories, dominate.</p>\n<p><strong>Data Placement and Networks on Chip (NoCs)</strong></p>\n<p>We designed ?a Unique Private caching scheme targeting the class of interconnects which exploit communication locality to improve communication latency. The Unique Private cache stores the data that is mostly accessed by each processor core in the core's locally accessible ?cache bank, while leveraging dedicated high speed circuits in the interconnect to provide remote cores with fast access to shared data.&nbsp; We also proposed a partial sharing TLB (PS-TLB) for reducing off-chip translation misses without sacrificing the timing-critical requirement of on-chip ?translation. &nbsp;We further developed&nbsp;ContextPreRF: a method to enhance the performance and energy of register files constructed with hybrid conventional (e.g., SRAM/DRAM) and domain-wall memory in GPUs.</p>\n<p>For NoCs, we developed ?Deja Vu switching splits the NoC into two planes: a fast plane dedicated to the critical messages and a slower, more power-efficient plane dedicated only to the non-critical messages.&nbsp; Deja Vu enables reducing the voltage and frequency of one plane while reducing communication latency through circuit switching and support of advance, possibly conflicting, circuit reservations.</p>\n<p><strong>Encoding for Energy and Reliability</strong></p>\n<p>We proposed a Space Oblivious COmpression (SOCO), an in-place lightweight compression mechanism particularly designed for reducing non-volatile-based main-memory energy (such as phase change memory) rather than saving space. We further developed&nbsp;PRES, a Pseudo-Random Encoding Scheme and a Hybrid biased/random approach to increase the bit flip reduction in memories.</p>\n<p>We created a memory and network system co-design approach that stores data using in-place lightweight compressed pages in memory (e.g., SOCO), and utilizes this compressed data to send shortened blocks over a wireless point to point network. Additionally, we proposed a technique called source-aware layout reorganization (SALR) to improve the compressibility of certain types of data, using either software- or hardware-based approaches.&nbsp; We also created a low-cost Probabilistic Online Learning En/decoding (POLE) framework to improve energy efficiency of main memory buses by minimizing the number of 0s in the data being transmitted.</p>\n<p>We developed a counter-based tree structure to efficiently mitigate row hammering (wordline crosstalk) and a periodic flip encoding (PFE) to mitigate bitline crosstalk in DRAM main memory.</p>\n<p>&nbsp;</p>\n<p><strong>Broader Impact</strong></p>\n<p>As part of this work, we have developed several advancements that can be applied in core compiler research.&nbsp; Moreover, we have developed new simulation and validation tool methodologies to study the impact of proposed architectural and system advancements that have impacts to many other computer architecture as well as general computer science research problems.&nbsp; For example, we created In-N-Out, a fast approximate simulation method to reproduce the behavior of an out-of order superscalar processor with a reduced in-order trace. &nbsp;We developed a GPU accelerator for both cache and network simulations.&nbsp; We also developed a co-simulation methodology to integrate abstract and detailed simulators operating at different levels of precision.</p>\n<p>The PIs brought these research findings to outreach activities targeting female and underrepresented communities such as advisement of multiple female and African American undergraduate students through the EXCEL program and Computer Science Day, for students (including high school) in the Pittsburgh area.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/03/2017<br>\n\t\t\t\t\tModified by: Alex&nbsp;Jones</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNext generation computer processor architectures can no longer depend on technology scaling alone to provide enhancements in performance and energy consumption.  As a result, modern processors have become increasingly parallel and heterogeneous to enable further performance and energy efficiency.  Moreover, increasing amounts of memory and flexible interconnection are required to support this parallelism.  This project made several advancements in the cooperative design of the computing cores, memory elements, and interconnection to fully leverage these resources efficiently.  Moreover, it developed new ways to tailor these resources by learning about the application requirements from the compiler and runtime system for further system efficiency and performance improvements.\n\n \n\nIntellectual Merit\n\nThe intellectual merit of this work can be seen in several outcomes that advance the community in the areas of cooperative design of modern computing systems.\n\nCompiler\n\nWe developed a compiler that could determine the sharing property of data in the system.  The compiler can determine if the data is private to a particular processing element or is shared amongst multiple processing elements.  To improve on this categorization, we proposed a new category called \"practically private\" data, which is private for \"all intents and purposes.\" Based on these properties, we expanded the compiler to discover the intended data partitioning of an application.  We used this information to enforce this partition in the system and guide the network to allow for fast communication between partners or small groups of processing elements that frequently share data.\n\nWe also developed a compiled approach to utilizing emerging non-volatile memories in the system.  The compiler uses a fast read-access mode when reads dominate and uses a slower but lower energy access mode when writes, which are typically most energy consuming in emerging memories, dominate.\n\nData Placement and Networks on Chip (NoCs)\n\nWe designed ?a Unique Private caching scheme targeting the class of interconnects which exploit communication locality to improve communication latency. The Unique Private cache stores the data that is mostly accessed by each processor core in the core's locally accessible ?cache bank, while leveraging dedicated high speed circuits in the interconnect to provide remote cores with fast access to shared data.  We also proposed a partial sharing TLB (PS-TLB) for reducing off-chip translation misses without sacrificing the timing-critical requirement of on-chip ?translation.  We further developed ContextPreRF: a method to enhance the performance and energy of register files constructed with hybrid conventional (e.g., SRAM/DRAM) and domain-wall memory in GPUs.\n\nFor NoCs, we developed ?Deja Vu switching splits the NoC into two planes: a fast plane dedicated to the critical messages and a slower, more power-efficient plane dedicated only to the non-critical messages.  Deja Vu enables reducing the voltage and frequency of one plane while reducing communication latency through circuit switching and support of advance, possibly conflicting, circuit reservations.\n\nEncoding for Energy and Reliability\n\nWe proposed a Space Oblivious COmpression (SOCO), an in-place lightweight compression mechanism particularly designed for reducing non-volatile-based main-memory energy (such as phase change memory) rather than saving space. We further developed PRES, a Pseudo-Random Encoding Scheme and a Hybrid biased/random approach to increase the bit flip reduction in memories.\n\nWe created a memory and network system co-design approach that stores data using in-place lightweight compressed pages in memory (e.g., SOCO), and utilizes this compressed data to send shortened blocks over a wireless point to point network. Additionally, we proposed a technique called source-aware layout reorganization (SALR) to improve the compressibility of certain types of data, using either software- or hardware-based approaches.  We also created a low-cost Probabilistic Online Learning En/decoding (POLE) framework to improve energy efficiency of main memory buses by minimizing the number of 0s in the data being transmitted.\n\nWe developed a counter-based tree structure to efficiently mitigate row hammering (wordline crosstalk) and a periodic flip encoding (PFE) to mitigate bitline crosstalk in DRAM main memory.\n\n \n\nBroader Impact\n\nAs part of this work, we have developed several advancements that can be applied in core compiler research.  Moreover, we have developed new simulation and validation tool methodologies to study the impact of proposed architectural and system advancements that have impacts to many other computer architecture as well as general computer science research problems.  For example, we created In-N-Out, a fast approximate simulation method to reproduce the behavior of an out-of order superscalar processor with a reduced in-order trace.  We developed a GPU accelerator for both cache and network simulations.  We also developed a co-simulation methodology to integrate abstract and detailed simulators operating at different levels of precision.\n\nThe PIs brought these research findings to outreach activities targeting female and underrepresented communities such as advisement of multiple female and African American undergraduate students through the EXCEL program and Computer Science Day, for students (including high school) in the Pittsburgh area.\n\n\t\t\t\t\tLast Modified: 05/03/2017\n\n\t\t\t\t\tSubmitted by: Alex Jones"
 }
}