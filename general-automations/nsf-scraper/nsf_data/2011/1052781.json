{
 "awd_id": "1052781",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Communication, Perturbation, and Early Development",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Laura Namy",
 "awd_eff_date": "2011-06-15",
 "awd_exp_date": "2015-05-31",
 "tot_intn_awd_amt": 96029.0,
 "awd_amount": 104029.0,
 "awd_min_amd_letter_date": "2011-06-14",
 "awd_max_amd_letter_date": "2014-06-10",
 "awd_abstract_narration": "Young infants typically form lasting, emotional attachments to their caregivers. The strength and type of these attachments are related to emotional well-being and cognitive development. This project will explore how face-to-face interactions between infants and adults contribute to this important aspect of child development.\r\n\r\nDuring early interactions, infants and parents form expectations about one another. Will a smile be answered with a bigger smile, for example, or with no smile at all? If the parent is asked to stop interacting and just look at her infant, will the infant smile or vocalize in an attempt to repair the interaction?  Do these early patterns of interaction predict the infant's later security of attachment--their ability to be comforted after a brief separation from the parent? To answer these questions, seventy-five infants and their mothers will participate in a standard \"Face-To-Face/Still-Face\"\r\nprocedure at four months. Their security of attachment will then be assessed at\r\n12 months.\r\n\r\nIt is difficult to measure early interactive behavior-and human behavior more generally-objectively and efficiently. To address this challenge, the project's interdisciplinary team of psychological and computer scientists will implement automated, quantitative measurements of behavior in the Face-To-Face/Still-Face procedure. Automated facial image analysis and pattern recognition approaches will be used to produce objective, continuous measurements of infant and mother facial expression, head motion, gaze direction, and vocalizations. Precise measurement of this multimodal suite of infant and mother behaviors will be used to tackle a fundamental scientific problem: Modeling the structure of early interaction and its relation to later development.\r\n\r\nThis is a promising approach to understanding threats to typical development and learning associated with risk factors such as maternal depression and disorders such as autism. To maximize the project's impact, the team will make a database of audiovisual recordings, automated measurements, and pattern recognition and modeling software available to other scientists.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mohammad",
   "pi_last_name": "Mahoor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mohammad Mahoor",
   "pi_email_addr": "mmahoor@du.edu",
   "nsf_id": "000511471",
   "pi_start_date": "2011-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Denver",
  "inst_street_address": "2199 S UNIVERSITY BLVD RM 222",
  "inst_street_address_2": "",
  "inst_city_name": "DENVER",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3038712000",
  "inst_zip_code": "802104711",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "CO01",
  "org_lgl_bus_name": "UNIVERSITY OF DENVER",
  "org_prnt_uei_num": "WCUGNQQ8DZU1",
  "org_uei_num": "WCUGNQQ8DZU1"
 },
 "perf_inst": {
  "perf_inst_name": "University of Denver",
  "perf_str_addr": "2199 S UNIVERSITY BLVD RM 222",
  "perf_city_name": "DENVER",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "802104711",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "CO01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169800",
   "pgm_ele_name": "DS -Developmental Sciences"
  },
  {
   "pgm_ele_code": "775000",
   "pgm_ele_name": "CDI TYPE I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1698",
   "pgm_ref_txt": "DS-Developmental Sciences"
  },
  {
   "pgm_ref_code": "7750",
   "pgm_ref_txt": "CDI TYPE I"
  },
  {
   "pgm_ref_code": "7752",
   "pgm_ref_txt": "CDI NON SOLICITED RESEARCH"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 96029.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Automated recognition of spontaneous facial expressions and action units (AUs) defined by Facial Action Coding System (FACS) has remained a challenging problem in computer vision. Especially measuring facial action units of children is more challenging compared to adults due to sever head motion and lack of facial textures in children's face. Such measurements are used by our collaborators in psychology departments to study infant's emotion development and its effect during mother-infant face-to-face communication. In this collaborative project the DU team concentrated on developing novel and reliable methods for detecting and measuring facial action units in infants&rsquo; facial videos. We learned that simultaneous recognition of AUs are more reliable than measuring AUs individually. The target AUs are those essential to positive and negative infant's emotions such as AU-6&nbsp; (cheek raiser), AU-12 (lip corner puller), and AU-20 (lip stretcher). Methods such as Multi-task learning and structural learning based on Support Vector Machines were developed and applied in our research and we learned that these machine learning methods are more reliable than methods that only targets AUs individually. In our studies we also examined different feature descriptors such as HOG, LBPH, and Gabor for facial image representations and we learned that perhaps a combination of features would work better than single features for AU detection and measurement.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/21/2015<br>\n\t\t\t\t\tModified by: Mohammad&nbsp;Mahoor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAutomated recognition of spontaneous facial expressions and action units (AUs) defined by Facial Action Coding System (FACS) has remained a challenging problem in computer vision. Especially measuring facial action units of children is more challenging compared to adults due to sever head motion and lack of facial textures in children's face. Such measurements are used by our collaborators in psychology departments to study infant's emotion development and its effect during mother-infant face-to-face communication. In this collaborative project the DU team concentrated on developing novel and reliable methods for detecting and measuring facial action units in infants\u00c6 facial videos. We learned that simultaneous recognition of AUs are more reliable than measuring AUs individually. The target AUs are those essential to positive and negative infant's emotions such as AU-6  (cheek raiser), AU-12 (lip corner puller), and AU-20 (lip stretcher). Methods such as Multi-task learning and structural learning based on Support Vector Machines were developed and applied in our research and we learned that these machine learning methods are more reliable than methods that only targets AUs individually. In our studies we also examined different feature descriptors such as HOG, LBPH, and Gabor for facial image representations and we learned that perhaps a combination of features would work better than single features for AU detection and measurement.\n\n\t\t\t\t\tLast Modified: 09/21/2015\n\n\t\t\t\t\tSubmitted by: Mohammad Mahoor"
 }
}