{
 "awd_id": "1127316",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SDCI Net: UD* - A UDT-Based Application Suite for High Performance Data Transport",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 1499533.0,
 "awd_amount": 1499533.0,
 "awd_min_amd_letter_date": "2011-08-09",
 "awd_max_amd_letter_date": "2011-08-09",
 "awd_abstract_narration": "UDP-based Data Transfer (UDT) is a data transport protocol that is available as an open source software library.  UDT was designed to support transferring large datasets over wide area high performance networks.  TCP is often times ineffective in these situations. With UDT, users can send data from disk-to-disk at over 9Gb/s over a 10Gb/s wide area network. In addition, UDT has also been used for moving data across firewalls with UPD hole punching and for maintaining a very large number of connections.  The latter is useful for applications such as data intensive computing. TCP does not work well in either of these situations.  UDT is also configurable so that users can plug in customized control algorithms appropriate for specialized network topologies or applications.\r\nThe goal of the UD* Project is to make UDT a standard protocol for scientific data transfer and to facilitate the use of UDT by the scientific research community.  Although there have been many proposed solutions to address the TCP inefficiency problem, many users today still experience trouble when moving large datasets.  The UD* project has three components.\r\n\r\nThe first component is to make UDT more accessible by developing a web-based front end to UDT and by integrating UDT into standard utilities that are used for moving datasets, such as rsync. The second component is to provide network and software engineering support to the UDT Community, including providing technical assistance to interested users, improving documentation, responding to queries in mailing lists and blogs, creating tutorial materials, running workshops, and related activities. The UD* Project also provides direct technical support to three communities of NSF-supported scientists: i) the various scientists making use of the Open Cloud Consortium?s Open Science Data Cloud; ii) biologists using Bio-mirror?s various mirror sites; iii) and scientists moving large datasets over 40G and 100G networks that connect to the StarLight Facility in Chicago. The third component is to develop two new versions of UDT.  UDT5 will include features to support data intensive computing applications and data center scale computing applications.  UDX will be designed to scale to 40GE and 100GE wide area networks.\r\n\r\nIntellectual merit. The number and output capacity of scientific instruments, sensors and other devices are growing at the rate of Moore?s Law.  Large datasets and high performance networks are becoming increasingly common, yet there are still fundamental problems transporting large datasets over wide area high performance networks. This problem can be addressed in part by building and supporting a UDT Community and enhancing UDT to provide specific support for emerging applications, such as data intensive computing applications and applications over 40G and 100G wide area networks.\r\n\r\nBroader Impact.  Technology for transporting, storing, visualizing, and sharing multiple terabyte datasets is broadly important for a large number of scientific and defense applications, including climate modeling, simulation, and homeland defense applications.  UD* can have a direct transformative impact on any discipline that requires working with very large datasets.  The UD* Project develops tutorials, supports a UDT Users Group, and teaches one day workshops on UD* to broaden the number of users that can use UDT for transporting large datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Grossman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Robert L Grossman",
   "pi_email_addr": "rgrossman1@uchicago.edu",
   "nsf_id": "000278293",
   "pi_start_date": "2011-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606371428",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "768300",
   "pgm_ele_name": "SOFTWARE DEVELOPEMENT FOR CI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7683",
   "pgm_ref_txt": "SOFTWARE DEVELOPEMENT FOR CI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 1499533.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During the project, we developed, prototyped, tested with users several different applications to simplify the transfer of large datasets over wide area high performance networks using the UDT library.&nbsp; UDT is a high performance data transport protocol that is based upon the UDP Internet protocol instead of the more common TCP Internet protocol.&nbsp; In practice, applications using UDT can transport data over wide area networks with significantly higher performance than when using TCP.&nbsp;</p>\n<p>At the beginning of the project, UDT was available only as a library.&nbsp; For this reason, its use was limited since a programmer had to integrate the library with any application that required it.&nbsp; The goal of this project was to develop applications around UDT so that UDT could be more widely deployed.&nbsp; One of the more useful of the applications developed was an open source application called parcel that is available on&nbsp;github.com/LabAdvComp/parcel.</p>\n<p>With large datasets becoming more and more common, the problem of developing effective technologies that can be easily deployed for moving large datasets over wide area high performance networks is of growing importance.</p>\n<p>A common use case for using a high performance data transport utility like UDT is when a client on a local machine wants to download a large file on remote server and the local LAN containing the client and the remote LAN containing the server are connected by a wide area high performance network.</p>\n<p>The basic idea with parcel is to install a proxy on a local LAN and a proxy on the remote LAN and for the two proxies to communicate via UDT.&nbsp; Communication between the client on the local LAN is via TCP, and communication between the remote LAN and the server is via TCP.&nbsp;&nbsp; With this approach, common tools, such as scp, netcat, and wget can be used with parcel on the LAN.</p>\n<p>As an example, over a 10 Gbps wide area network connecting a server in Chicago and a client in Taiwan, a 344 GB file averaged 464 Mbps for a single flow using parcel with TCP and 1936 Mbps using Parcel with UDT.&nbsp; The effective bandwidth obtained in practice depends upon many factors, including: the read speed of the source disk, the write speed of the target disk, the speed of the network, the congestion on the network, the packet loss of the network, and whether encryption is enabled.</p>\n<p>As another example, an application developed in the project called udpipe transferred data at 42.08 Gpbs over a wide area 60 G network (3 x 20G) connecting Chicago and Oakland, CA.</p>\n<p>A common problem with using a UDP application like parcel is that UDP is blocked and only TCP connections are allowed, or that the non-standard ports required by parcel are blocked.&nbsp;&nbsp; For this reason, parcel also supports a mode that uses multiple TCP connections to connect the local and remote proxy servers.&nbsp; With this design, a user is ensured of being able to transfer a file, and if UDP traffic is permitted and the ports required by parcel are open, the higher performance possible with parcel can be achieved.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2015<br>\n\t\t\t\t\tModified by: Robert&nbsp;L&nbsp;Grossman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDuring the project, we developed, prototyped, tested with users several different applications to simplify the transfer of large datasets over wide area high performance networks using the UDT library.  UDT is a high performance data transport protocol that is based upon the UDP Internet protocol instead of the more common TCP Internet protocol.  In practice, applications using UDT can transport data over wide area networks with significantly higher performance than when using TCP. \n\nAt the beginning of the project, UDT was available only as a library.  For this reason, its use was limited since a programmer had to integrate the library with any application that required it.  The goal of this project was to develop applications around UDT so that UDT could be more widely deployed.  One of the more useful of the applications developed was an open source application called parcel that is available on github.com/LabAdvComp/parcel.\n\nWith large datasets becoming more and more common, the problem of developing effective technologies that can be easily deployed for moving large datasets over wide area high performance networks is of growing importance.\n\nA common use case for using a high performance data transport utility like UDT is when a client on a local machine wants to download a large file on remote server and the local LAN containing the client and the remote LAN containing the server are connected by a wide area high performance network.\n\nThe basic idea with parcel is to install a proxy on a local LAN and a proxy on the remote LAN and for the two proxies to communicate via UDT.  Communication between the client on the local LAN is via TCP, and communication between the remote LAN and the server is via TCP.   With this approach, common tools, such as scp, netcat, and wget can be used with parcel on the LAN.\n\nAs an example, over a 10 Gbps wide area network connecting a server in Chicago and a client in Taiwan, a 344 GB file averaged 464 Mbps for a single flow using parcel with TCP and 1936 Mbps using Parcel with UDT.  The effective bandwidth obtained in practice depends upon many factors, including: the read speed of the source disk, the write speed of the target disk, the speed of the network, the congestion on the network, the packet loss of the network, and whether encryption is enabled.\n\nAs another example, an application developed in the project called udpipe transferred data at 42.08 Gpbs over a wide area 60 G network (3 x 20G) connecting Chicago and Oakland, CA.\n\nA common problem with using a UDP application like parcel is that UDP is blocked and only TCP connections are allowed, or that the non-standard ports required by parcel are blocked.   For this reason, parcel also supports a mode that uses multiple TCP connections to connect the local and remote proxy servers.  With this design, a user is ensured of being able to transfer a file, and if UDP traffic is permitted and the ports required by parcel are open, the higher performance possible with parcel can be achieved.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 11/30/2015\n\n\t\t\t\t\tSubmitted by: Robert L Grossman"
 }
}