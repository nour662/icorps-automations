{
 "awd_id": "1118055",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Large-Scale Machine Learning for Connectomics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2011-08-30",
 "awd_max_amd_letter_date": "2011-08-30",
 "awd_abstract_narration": "Large-scale image data analysis has in recent years become a key bottleneck in natural science research, particularly in the field of neuroscience. Technological advances in automated data acquisition have enabled the collection of terabyte and petabyte-size datasets.  Extracting the rich information contained in these datasets manually would require an inordinate amount of human labor; reconstructing the neural connectivity in a complete fruitfly brain or cortical column of a mouse from electron microscopy data, key tasks of interest, would require ten thousand years of human labor using current state-of-the-art manual and semi-automated approaches. Improved automated image analysis tools are likely to be directly useful to the neuroscience community, enabling large-scale dense reconstruction of neural circuits from microscopy data, in which the morphology of every neuronal process is traced and all chemical synaptic connections between cells are identified, thereby mapping the complete \"wiring diagram\" of the circuit contained in the neural tissue. Such reconstructions have the potential to fundamentally impact the understanding of neural circuits by enabling competing models of brain architecture to finally be rigorously verified or falsified experimentally.\r\n\r\nThe large size of the datasets, the need for high accuracy to avoid incorrect scientific conclusions being drawn about the data, and the need for well-calibrated confidence measures in order to limit the time that must be spent manually verifying the output of algorithms, are all substantial challenges not well-addressed by existing segmentation methods.  The investigators propose to (i) Develop efficient algorithms for convolutional locality-sensitive hashing, a novel generalization of locality-sensitive hashing techniques to the highly applicable setting of dense overlapping patches from a larger data volume. (ii) Develop efficient algorithms for the overlapping patch and convolutional variants of sparse coding designed to scale to very large datasets, filter sizes and numbers of filters. The proposed convolutional locality-sensitive hashing approach will be employed to enable this. (iii) Develop algorithms that leverage (i) and (ii) to segment electron microscopy data, and compare empirically to existing segmentation methods. All of the proposed methods are highly scalable to executions on large compute clusters in order to handle large training and test datasets. Furthermore, since the proposed methods allow explicit representation of the data, they are expected to be better calibrated than parametric methods such as the existing neural network-based methods for segmentation of electron microscopy data that currently achieve the best accuracy.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pieter",
   "pi_last_name": "Abbeel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pieter Abbeel",
   "pi_email_addr": "pabbeel@cs.berkeley.edu",
   "nsf_id": "000511407",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "1608 4TH ST STE 201",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947101749",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Mapping neuroanatomy, in the pursuit of linking hypothesized computational models consistent with observed functions to the actual physical structures, has been a long-standing fundamental problem in neuroscience.&nbsp; One primary interest is in mapping the network structure of neural circuits by identifying the morphology of each neuron and the locations of synaptic connections between neurons, a field of study called connectomics.&nbsp; Currently, the most promising approach for obtaining such maps of neural circuit structure is volume electron microscopy of a stained and fixed block of tissue.</span><br /><br /><span>While recent advances in volume electron microscopy make feasible the imaging of very large circuits at sufficient resolution to discern even the smallest neuronal processes, image analysis remains a key challenge limiting the rate of discovery.&nbsp; Existing fully-automated algorithms offer inadequate accuracy to replace human annotators, and semi-automated methods offer only limited speedup.&nbsp; To address this image analysis problem, we designed, implemented, and evaluated novel methods based on machine learning and optimization related to three different sub-problems:</span><br /><br /><span>Detection of cell boundaries at the per-voxel level is a key analysis step, given that cell boundaries serve as the primary indication of cell morphology,&nbsp;&nbsp; We propose a highly-scalable, layered architecture for classification on 3-D volumes: unlike conventional dense deep learning approaches, this architecture relies on simple, parallelizable clustering algorithms and convex optimization to learn wide, sparse models.&nbsp; By exploiting rotational invariance of the data distribution and a highly-efficient distributed GPU implementation, we achieved performance comparable to or better than deep convolutional networks trained for weeks with only several hours of training, enabling much faster iteration on model design.</span><br /><br /><span>Certain promising high-throughput microscopy techniques result in significant discontinuities between section images even after alignment, due to variations in imaging conditions and section thickness, among other artifacts.&nbsp; These artifacts impede truly 3-D analysis of these volumes.&nbsp; We propose an iterative coarse-to-fine procedure that optimizes the parameters of spatially vary linear transformations of the intensity data in order to minimize discontinuities along the section axis, subject to detail-preserving regularization.&nbsp; Testing showed this technique to yield significant quantitative improvement in image quality, and qualitatively correcting essentially all visible discontinuities without any noticeable loss of detail; it also significantly improved 3-D segmentation accuracy.</span><br /><br /><span>To integrate higher-level prior information about shape, we introduce a new machine learning approach for image segmentation, based on a joint energy model over image features and novel local binary shape descriptors.&nbsp; These descriptors compactly represent rich shape information at multiple scales, including interactions between multiple objects.&nbsp; Our approach, which does not rely on any hand-designed features, reflects the inherent combinatorial nature of dense image segmentation problems.&nbsp; We propose efficient algorithms for learning deep neural networks to model the joint energy, and for local optimization of this energy in the space of supervoxel agglomerations.&nbsp; This architecture yields state-of-the-art performance on several challenging electron microscopy datasets, and scaled to teravoxel-size volumes.</span><br /><br /><span>These advances constitute critical progress towards fully-automated reconstruction of circuits of hundreds of thousands of neurons.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/17/2015<br>\n\t\t\t\t\tModified by: Pieter&nbsp;Abbeel</p>\n<...",
  "por_txt_cntn": "\nMapping neuroanatomy, in the pursuit of linking hypothesized computational models consistent with observed functions to the actual physical structures, has been a long-standing fundamental problem in neuroscience.  One primary interest is in mapping the network structure of neural circuits by identifying the morphology of each neuron and the locations of synaptic connections between neurons, a field of study called connectomics.  Currently, the most promising approach for obtaining such maps of neural circuit structure is volume electron microscopy of a stained and fixed block of tissue.\n\nWhile recent advances in volume electron microscopy make feasible the imaging of very large circuits at sufficient resolution to discern even the smallest neuronal processes, image analysis remains a key challenge limiting the rate of discovery.  Existing fully-automated algorithms offer inadequate accuracy to replace human annotators, and semi-automated methods offer only limited speedup.  To address this image analysis problem, we designed, implemented, and evaluated novel methods based on machine learning and optimization related to three different sub-problems:\n\nDetection of cell boundaries at the per-voxel level is a key analysis step, given that cell boundaries serve as the primary indication of cell morphology,   We propose a highly-scalable, layered architecture for classification on 3-D volumes: unlike conventional dense deep learning approaches, this architecture relies on simple, parallelizable clustering algorithms and convex optimization to learn wide, sparse models.  By exploiting rotational invariance of the data distribution and a highly-efficient distributed GPU implementation, we achieved performance comparable to or better than deep convolutional networks trained for weeks with only several hours of training, enabling much faster iteration on model design.\n\nCertain promising high-throughput microscopy techniques result in significant discontinuities between section images even after alignment, due to variations in imaging conditions and section thickness, among other artifacts.  These artifacts impede truly 3-D analysis of these volumes.  We propose an iterative coarse-to-fine procedure that optimizes the parameters of spatially vary linear transformations of the intensity data in order to minimize discontinuities along the section axis, subject to detail-preserving regularization.  Testing showed this technique to yield significant quantitative improvement in image quality, and qualitatively correcting essentially all visible discontinuities without any noticeable loss of detail; it also significantly improved 3-D segmentation accuracy.\n\nTo integrate higher-level prior information about shape, we introduce a new machine learning approach for image segmentation, based on a joint energy model over image features and novel local binary shape descriptors.  These descriptors compactly represent rich shape information at multiple scales, including interactions between multiple objects.  Our approach, which does not rely on any hand-designed features, reflects the inherent combinatorial nature of dense image segmentation problems.  We propose efficient algorithms for learning deep neural networks to model the joint energy, and for local optimization of this energy in the space of supervoxel agglomerations.  This architecture yields state-of-the-art performance on several challenging electron microscopy datasets, and scaled to teravoxel-size volumes.\n\nThese advances constitute critical progress towards fully-automated reconstruction of circuits of hundreds of thousands of neurons.\n\n\t\t\t\t\tLast Modified: 10/17/2015\n\n\t\t\t\t\tSubmitted by: Pieter Abbeel"
 }
}