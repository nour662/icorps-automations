{
 "awd_id": "1116414",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Scalable Integration and Analysis of the Provenance of Diverse Scientific Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Nan Zhang",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 485868.0,
 "awd_amount": 485868.0,
 "awd_min_amd_letter_date": "2011-08-08",
 "awd_max_amd_letter_date": "2011-08-08",
 "awd_abstract_narration": "As scientists begin to get access to data sets that are accompanied by automatically generated provenance records, they are faced with the challenge of integrating and analyzing this metadata. Independent sources are likely to have captured provenance at distinct levels of abstraction, have different levels of completeness, used separate sets of identifiers to refer to the same artifacts, processes, and agents, and introduced dissimilar semantics in the annotations.\r\n\r\nThis research studies the problem of semi-automatically integrating and analyzing the provenance of scientific data that originates from diverse sources, with independent annotation schema, semantics that may overlap only partially, representations at different granularity, and incomplete characterizations of the activity being recorded. In particular, (i) it develops a formal framework for combining provenance, (ii) provides an extensible software system for provenance ingestion, integration, and analysis, and (iii) creates canonical provenance data sets of various sizes, granularity, and domains, that can be utilized for comparison of provenance integration and analysis algorithms.\r\n\r\nMaintaining a record of all the transformations the data undergoes becomes increasingly critical as the length of the analysis grows and the age and diversity of sources of the data grow. Such provenance metadata can address a range of queries. For example, in situations where only derivative data is preserved, a provenance record can help validate claims about the procedures used to obtain the final results. Concerns about whether privacy-sensitive data (such as information from patient records) has been used in contravention to legal or security policies can be alleviated by checking for violations in the provenance records.\r\n\r\nMore information about the project can be found at: http://spade.csl.sri.com",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ashish",
   "pi_last_name": "Gehani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ashish Gehani",
   "pi_email_addr": "ashish.gehani@sri.com",
   "nsf_id": "000315262",
   "pi_start_date": "2011-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SRI International",
  "inst_street_address": "333 RAVENSWOOD AVE",
  "inst_street_address_2": "",
  "inst_city_name": "MENLO PARK",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6097342285",
  "inst_zip_code": "940253493",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "SRI INTERNATIONAL",
  "org_prnt_uei_num": "SRG2J1WS9X63",
  "org_uei_num": "SRG2J1WS9X63"
 },
 "perf_inst": {
  "perf_inst_name": "SRI International",
  "perf_str_addr": "333 RAVENSWOOD AVE",
  "perf_city_name": "MENLO PARK",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "940253493",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 485868.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project designed a framework for integrating provenance only. The need for this arises when multiple provenance traces (with different properties, such as temporal fidelity, monitored aspects, or abstraction levels) are collected for the same underlying phenomenon. It provides a provenance-only integration algorithm that merges provenance elements (vertices or edges) with sufficiently similar annotations (as defined by user-specified thresholds). It seeks to avoid integrating elements with different owners by imposing a cost for doing so. By finding the lowest thresholds that suffice for a given cost, provenance-only integration can be viewed as an optimization problem.</p>\n<p>The effort analyzed a set of micro-benchmark programs with three different provenance collection systems that monitor activity at system call, function call, and byte granularity. This revealed that the overhead varies greatly, depending on the computing patterns.&nbsp;More importantly, no single provenance monitoring system is suitable&nbsp;for all applications. Each has a distinct weak point. The analysis concluded that techniques for dynamically switching between&nbsp;different provenance instrumentation need to be explored.&nbsp;This will allow overhead to be kept low for most executions while still&nbsp;being able to produce detailed provenance when it is needed.</p>\n<p>The variability in provenance resulting from collecting it on different platforms was investigated. The same set of applications was run on multiple operating systems. Traces were collected and reported in an open format. The data was published, allowing other researchers to utilize it for their analyses.</p>\n<p>In addition to the above outcomes and datasets, the project resulted in a variety of investigations that were reported on in 14 academic peer-reviewed publications, as well as significant enhancements to the open source provenance middleware, SPADE.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/01/2016<br>\n\t\t\t\t\tModified by: Ashish&nbsp;Gehani</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project designed a framework for integrating provenance only. The need for this arises when multiple provenance traces (with different properties, such as temporal fidelity, monitored aspects, or abstraction levels) are collected for the same underlying phenomenon. It provides a provenance-only integration algorithm that merges provenance elements (vertices or edges) with sufficiently similar annotations (as defined by user-specified thresholds). It seeks to avoid integrating elements with different owners by imposing a cost for doing so. By finding the lowest thresholds that suffice for a given cost, provenance-only integration can be viewed as an optimization problem.\n\nThe effort analyzed a set of micro-benchmark programs with three different provenance collection systems that monitor activity at system call, function call, and byte granularity. This revealed that the overhead varies greatly, depending on the computing patterns. More importantly, no single provenance monitoring system is suitable for all applications. Each has a distinct weak point. The analysis concluded that techniques for dynamically switching between different provenance instrumentation need to be explored. This will allow overhead to be kept low for most executions while still being able to produce detailed provenance when it is needed.\n\nThe variability in provenance resulting from collecting it on different platforms was investigated. The same set of applications was run on multiple operating systems. Traces were collected and reported in an open format. The data was published, allowing other researchers to utilize it for their analyses.\n\nIn addition to the above outcomes and datasets, the project resulted in a variety of investigations that were reported on in 14 academic peer-reviewed publications, as well as significant enhancements to the open source provenance middleware, SPADE.\n\n \n\n\t\t\t\t\tLast Modified: 11/01/2016\n\n\t\t\t\t\tSubmitted by: Ashish Gehani"
 }
}