{
 "awd_id": "1116898",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Adapting Dataflow Analysis for Efficient and Precise Parallel Program Monitoring",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 478599.0,
 "awd_amount": 491399.0,
 "awd_min_amd_letter_date": "2011-07-29",
 "awd_max_amd_letter_date": "2014-04-11",
 "awd_abstract_narration": "Due to the industry-wide shift to multi-core processing, future\r\napplications will only run faster if they are written as parallel\r\nsoftware (i.e. where the work for a single program is accomplished by\r\nsimultaneously performing different parts of that work on different\r\nprocessors).  Unfortunately history has taught us that writing\r\nparallel software is a very error-prone task for programmers.  To\r\naddress this challenge, this research project is creating a powerful\r\nnew mechanism for identifying and hopefully fixing bugs in parallel\r\nsoftware on large-scale production systems.  Hopefully the resulting\r\nframework will not only support the parallel execution of existing\r\nmonitoring tools, but it will also spawn the creation of new classes\r\nof powerful tools that can recognize subtle bugs in parallel software.\r\nSuch tools can help programmers continue to reap the performance\r\nbenefits of future microprocessors, thereby continuing to enable all\r\nof the benefits that increasingly-faster computation has had on the\r\neconomy, science and technology, and our everyday lives in an\r\nInternet-connected world.\r\n\r\nMore specifically, the focus of this project is on sophisticated\r\nonline program monitoring tools that model various aspects of program\r\ncorrectness at an instruction-by-instruction granularity.  To strike a\r\npractical balance between performance, precision, and convenience for\r\nthe tool developer, this research has developed a novel framework that\r\nintroduces explicit \"windows of uncertainty\" combined with a new\r\napproach for avoiding a state space explosion in the analysis\r\n(inspired by Tarjan's interval analysis approach to dataflow analysis).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Mowry",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Todd Mowry",
   "pi_email_addr": "tcm@cs.cmu.edu",
   "nsf_id": "000216388",
   "pi_start_date": "2011-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 478599.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 12800.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Helvetica} -->\n<p class=\"p1\">In the old days, you could run your software faster by simply waiting until a new computer came out with a faster clock rate. &nbsp;Today, that is no longer possible: clock rates are not improving, but instead computers are supporting increasing amounts of parallelism (i.e. the computers contain multiple processors or \"cores\"). &nbsp;Unfortunately, writing software to take advantage of parallelism is a notoriously difficult task: history has taught us that as difficult as it is to avoid software bugs under normal circumstances, bugs are even more problematic in parallel software.</p>\n<p>In this project, we have developed a new approach for creating tools that look for bugs in parallel software as that software executes. &nbsp;A major challenge in creating such tools is understanding how a software thread running on one processor is interacting with the software threads running (at the same time) on other processors, since these interactions (through accesses to shared memory) are not directly visible to software.&nbsp; A key innovation in our approach is that we model an explicit &ldquo;window of uncertainty&rdquo; (combined with new analysis techniques) that enables our bug-finding tools run in parallel, which is critical in order for them to be able to keep up with the programs that they are monitoring.&nbsp; One side effect of modeling a window of uncertainty, however, is that bug-finding tools may sometimes produce false positives, where they report a bug that does not actually exist.&nbsp; Hence a major focus of our project has been on improving the precision of our analysis framework without sacrificing the performance of the bug-finding tools.</p>\n<p>Our first major outcome focused on extending our original framework to model the effects of explicit synchronization operations between software threads in the monitored parallel programs.&nbsp; Including the effects of these synchronization operations presented major challenges, both in terms of proving the correctness of our enhanced model and also maintaining its performance. Fortunately, we were able to prove the correctness of our enhanced model, and it reduced the number of false positives in a bug-finding tool (that looked for potential security vulnerabilities) by roughly a factor of 18.&nbsp; This improved precision did come at a performance cost, however, as it slowed down our tool by roughly a factor of two.&nbsp;</p>\n<p>Our second major outcome focused on achieving a balance between precision and run-time overhead by explicitly modeling &ldquo;uncertain&rdquo; states (i.e. cases where both safe and unsafe possibilities were observed within the window of uncertainty).&nbsp; These &ldquo;uncertain&rdquo; states enabled us to distinguish &ldquo;false positives&rdquo; from &ldquo;true positives&rdquo; in our analysis, thereby improving our precision.&nbsp; In addition, it enabled a dynamically adaptive mode of execution where our bug-finding tools can adjust the size of the window of uncertainty on-the-fly in order to trade off precision for performance in an intelligent way, based upon whether &ldquo;uncertain&rdquo; cases are actually observed dynamically.&nbsp; This dynamic approach enabled us to achieve a &ldquo;best of both worlds&rdquo; result with high precision and low run-time overhead.</p>\n<p class=\"p1\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/01/2016<br>\n\t\t\t\t\tModified by: Todd&nbsp;Mowry</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the old days, you could run your software faster by simply waiting until a new computer came out with a faster clock rate.  Today, that is no longer possible: clock rates are not improving, but instead computers are supporting increasing amounts of parallelism (i.e. the computers contain multiple processors or \"cores\").  Unfortunately, writing software to take advantage of parallelism is a notoriously difficult task: history has taught us that as difficult as it is to avoid software bugs under normal circumstances, bugs are even more problematic in parallel software.\n\nIn this project, we have developed a new approach for creating tools that look for bugs in parallel software as that software executes.  A major challenge in creating such tools is understanding how a software thread running on one processor is interacting with the software threads running (at the same time) on other processors, since these interactions (through accesses to shared memory) are not directly visible to software.  A key innovation in our approach is that we model an explicit \"window of uncertainty\" (combined with new analysis techniques) that enables our bug-finding tools run in parallel, which is critical in order for them to be able to keep up with the programs that they are monitoring.  One side effect of modeling a window of uncertainty, however, is that bug-finding tools may sometimes produce false positives, where they report a bug that does not actually exist.  Hence a major focus of our project has been on improving the precision of our analysis framework without sacrificing the performance of the bug-finding tools.\n\nOur first major outcome focused on extending our original framework to model the effects of explicit synchronization operations between software threads in the monitored parallel programs.  Including the effects of these synchronization operations presented major challenges, both in terms of proving the correctness of our enhanced model and also maintaining its performance. Fortunately, we were able to prove the correctness of our enhanced model, and it reduced the number of false positives in a bug-finding tool (that looked for potential security vulnerabilities) by roughly a factor of 18.  This improved precision did come at a performance cost, however, as it slowed down our tool by roughly a factor of two. \n\nOur second major outcome focused on achieving a balance between precision and run-time overhead by explicitly modeling \"uncertain\" states (i.e. cases where both safe and unsafe possibilities were observed within the window of uncertainty).  These \"uncertain\" states enabled us to distinguish \"false positives\" from \"true positives\" in our analysis, thereby improving our precision.  In addition, it enabled a dynamically adaptive mode of execution where our bug-finding tools can adjust the size of the window of uncertainty on-the-fly in order to trade off precision for performance in an intelligent way, based upon whether \"uncertain\" cases are actually observed dynamically.  This dynamic approach enabled us to achieve a \"best of both worlds\" result with high precision and low run-time overhead.\n \n\n\t\t\t\t\tLast Modified: 11/01/2016\n\n\t\t\t\t\tSubmitted by: Todd Mowry"
 }
}