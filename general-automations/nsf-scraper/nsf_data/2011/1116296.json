{
 "awd_id": "1116296",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CGV: Small: Collaborative Research: From Virtual to Real",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 257998.0,
 "awd_min_amd_letter_date": "2011-07-16",
 "awd_max_amd_letter_date": "2013-06-04",
 "awd_abstract_narration": "From Virtual to Real\r\nWojciech Matusik, MIT, and Hanspeter Pfister, Harvard University\r\n\r\nNovel and innovative digital output devices, such as stereoscopic TVs, passive (e-Ink) displays, and 3D printers, are entering the mass market. They are rapidly improving in quality and decreasing in price. This trend empowers users to consume and produce digital media like never before. However, while there has been tremendous progress in the hardware development of these output devices, the provided digital content creation software, algorithms, and tools are largely underdeveloped. For example, creating a 3D hardcopy of an animated computer graphics character is well beyond the reach of consumers, and to approximate the character's appearance and deformation behavior using multi-material 3D printers is difficult or perhaps even impossible for professionals. The main issues are a lack of accurate previews of how the output will look like, a lack of standardization between devices with similar capabilities, and a lack of accurate conversion tools and algorithms to go from the virtual (i.e., the computer model) to the real (i.e., the physical output).\r\n\r\nThis research involves the development of a complete process and software framework that allows moving from abstract computer models to their physical counterparts efficiently and accurately. Designing this process is posing the following fundamental computational challenges: (1) accurate and efficient simulation methods that can predict the properties and behavior of an output without physically generating it; (2) efficient methods to compute an output gamut that describe physically-realizable outputs for a given device; (3) general gamut mapping algorithms that convert abstract computer models to realizable points in the device gamut; and (4) accurate perceptual metrics that allow comparing different output elements during the gamut mapping algorithm. This research is focusing on two emerging classes of important output devices: multi-view auto-stereoscopic displays and multi-material 3D printers. The research is creating a complete and general software architecture that will support both existing and future output devices.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wojciech",
   "pi_last_name": "Matusik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wojciech Matusik",
   "pi_email_addr": "wojciech@csail.mit.edu",
   "nsf_id": "000579272",
   "pi_start_date": "2011-07-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 250000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 7998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Novel output devices, such as stereoscopic 3D TVs and 3D printers, are entering the mass market. They are rapidly improving in quality and decreasing in price. This trend empowers users to consume and produce digital media like never before. However, while there has been tremendous progress in the hardware development of these output devices, the provided digital content creation software, algorithms, and tools are largely underdeveloped. The main issues are a lack of accurate previews of how the output will look like, a lack of standardization between devices with similar capabilities, and a lack of accurate conversion tools and algorithms to go from the virtual (i.e., the computer model) to the real (i.e., the physical output). The overall situation is analogous to the digital printing and content creation revolution of the early 1980s before the advent of PostScript.</p>\n<p>This research has focused on two emerging classes of important output devices: multi-material 3D printers and multi-view auto-stereoscopic 3D displays. The research has produced complete and general software architectures that allow moving from abstract computer models to accurate device outputs.</p>\n<p>In the context of multi-material 3D printers, this research has produced OpenFab - a direct specification pipeline for multi-material fabrication - inspired by the programmable graphics pipelines used for film and real-time rendering. This architecture handles 3D printing of multi-material objects with arbitrary complexity. &nbsp;As an alternative to directly specifying material composition, it is often more natural to specify an object by defining its functional goal (e.g., specific color, deformation behavior). &nbsp;In order to solve this task, this research has also yielded Spec2Fab - a computationally efficient and general process for translating functional requirements to fabricable 3D prints. Spec2Fab provides an abstraction mechanism that simplifies the design, development, implementation, and reuse of fabrication algorithms.</p>\n<p>In the context of stereoscopic 3D, this research has addressed the problem of content generation for multi-view autostereoscopic displays &ndash; new types of displays that allow for 3D experience without wearing special glasses. This research has produced efficient computer processes that allow conversion of standard stereoscopic 3D content to the content required by multi-view 3D displays. Furthermore, this research has developed novel models for stereoscopic perception. These models are used to adapt the stereoscopic content to a given 3D display and improve the quality of the resulting 3D experience. &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/15/2015<br>\n\t\t\t\t\tModified by: Wojciech&nbsp;Matusik</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNovel output devices, such as stereoscopic 3D TVs and 3D printers, are entering the mass market. They are rapidly improving in quality and decreasing in price. This trend empowers users to consume and produce digital media like never before. However, while there has been tremendous progress in the hardware development of these output devices, the provided digital content creation software, algorithms, and tools are largely underdeveloped. The main issues are a lack of accurate previews of how the output will look like, a lack of standardization between devices with similar capabilities, and a lack of accurate conversion tools and algorithms to go from the virtual (i.e., the computer model) to the real (i.e., the physical output). The overall situation is analogous to the digital printing and content creation revolution of the early 1980s before the advent of PostScript.\n\nThis research has focused on two emerging classes of important output devices: multi-material 3D printers and multi-view auto-stereoscopic 3D displays. The research has produced complete and general software architectures that allow moving from abstract computer models to accurate device outputs.\n\nIn the context of multi-material 3D printers, this research has produced OpenFab - a direct specification pipeline for multi-material fabrication - inspired by the programmable graphics pipelines used for film and real-time rendering. This architecture handles 3D printing of multi-material objects with arbitrary complexity.  As an alternative to directly specifying material composition, it is often more natural to specify an object by defining its functional goal (e.g., specific color, deformation behavior).  In order to solve this task, this research has also yielded Spec2Fab - a computationally efficient and general process for translating functional requirements to fabricable 3D prints. Spec2Fab provides an abstraction mechanism that simplifies the design, development, implementation, and reuse of fabrication algorithms.\n\nIn the context of stereoscopic 3D, this research has addressed the problem of content generation for multi-view autostereoscopic displays &ndash; new types of displays that allow for 3D experience without wearing special glasses. This research has produced efficient computer processes that allow conversion of standard stereoscopic 3D content to the content required by multi-view 3D displays. Furthermore, this research has developed novel models for stereoscopic perception. These models are used to adapt the stereoscopic content to a given 3D display and improve the quality of the resulting 3D experience.  \n\n\t\t\t\t\tLast Modified: 01/15/2015\n\n\t\t\t\t\tSubmitted by: Wojciech Matusik"
 }
}