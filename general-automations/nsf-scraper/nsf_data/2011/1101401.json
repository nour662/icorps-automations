{
 "awd_id": "1101401",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AIS: Entanglement of Approximate Dynamic Programming and Modern Nonlinear Control for Complex Systems",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Radhakisan Baheti",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 281847.0,
 "awd_amount": 281847.0,
 "awd_min_amd_letter_date": "2011-07-21",
 "awd_max_amd_letter_date": "2011-07-21",
 "awd_abstract_narration": "The objective of this research is to develop a new framework for robust adaptive/approximate dynamic programming to address grand challenges arising from engineering and biology, such as smart grid, brain research, robotics, and flight control. The approach is to take explicit advantages of versatile techniques from two active areas of research in reinforcement learning systems and neural networks and in modern nonlinear control.\r\n\r\nIntellectual Merit\r\nThis interdisciplinary research initiative, driven by the need in building brain-like reinforcement learning systems and in understanding ultimately the brain function, is significant in different aspects. It will significantly advance the state of the art on approximate dynamic programming and address the truly model-free situation. In addition, instead of building exact mathematical models, which often is very hard, if not impossible, for contemporary complex problems arising from engineering and biology, this proposal adopts a novel interconnected system viewpoint on the basis of the PI?s work on nonlinear small-gain theory. \r\n\r\nBroader Impacts\r\nThe proposed work will lead to the development of new tools for robust adaptive critic designs in interconnected complex systems. Not only these tools are expected to find applications in emerging engineering applications such as smart grid, robotics and flight control, but also they will help gain a deeper insight toward the long-term goal in understanding brain functions and building brain-like reinforcement learning engineering systems. The proposed research will have a substantial direct impact upon education at the PI's institution by engaging students from several areas and departments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhong-Ping",
   "pi_last_name": "Jiang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhong-Ping Jiang",
   "pi_email_addr": "zjiang@nyu.edu",
   "nsf_id": "000665735",
   "pi_start_date": "2011-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 WASHINGTON SQ S",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760700",
   "pgm_ele_name": "EPCN-Energy-Power-Ctrl-Netwrks"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "109E",
   "pgm_ref_txt": "Sys theory in biology & medicine"
  },
  {
   "pgm_ref_code": "1653",
   "pgm_ref_txt": "Adaptive & intelligent systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 281847.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Adaptive/approximate dynamic programming (ADP) is a powerful technique for addressing optimal decision making problems for complex uncertain dynamic processes. Its constant development&nbsp; is driven by the need to solve challenging engineering and biology problems such as electric smart grid, transportation networks, and human movement and rehabilitation.</p>\n<p>Under the support of the NSF, the PI has successfully brought together two fields - nonlinear control and ADP - and proposed a new framework for data-driven, nonmodel-based, adaptive optimal control with guaranteed robustness to dynamic uncertainties. This new theory is termed&nbsp; &ldquo;robust adaptive dynamic programming&rdquo; (for short, RADP), and has been applied to solve challenging issues in power systems and biological motor control. Novel significant results based upon the proposed RADP theory are obtained for these two exciting topics. The related publication is selected as one of the very few annual publication spotlights by IEEE Transactions on Neural Networks and Learning Systems under the IEEE Computational Intelligence Society.</p>\n<p>With respect to the past literature of ADP, there has been very few research devoted to the consideration of dynamic uncertainty in physical and biological systems. Dynamic uncertainty arises from different contexts, such as model reduction, unmodeled dynamics and incomplete state information. This project has made significant contributions to the development of a robust variant of the existing ADP theory, by focusing mainly on continuous-time continuous state-space models. It is shown in a recent series of the work of PI that robust optimal control policies can be obtained via a recursive numerical algorithm using online information without solving the HJB equation (for nonlinear systems) and the algebraic Riccati equation (ARE) (for linear systems), even when the system dynamics are not precisely known. Robustness to dynamic uncertainty is guaranteed and analyzed rigorously using Lyapunov and small-gain methods. More recently, the PI and his students have filled up a gap in the past literature of ADP by studying continuous-time nonlinear systems subject to both parametric and dynamic uncertainties. Practical learning algorithms are developed, and have been applied to the controller design<br />problems for a jet engine and a one-machine power system. This can be seen as a step toward bringing together two separate fields: ADP and applied nonlinear control. While previous work of ADP focuses on affine systems, the PI has obtained a new result on ADP for nonaffine systems that contain nonlinearly appearing control inputs. More interestingly, we have initiated a study of global ADP for nonlinear systems without using neural network approximations, but instead using techniques from semidefinite programming. This line of research aims to achieve siginificant computational improvement with respect to previous ADP algorithms based on neural network approximations. Through extensive computer simulations and experimental data, it is shown that RADP explains well the learning mechanism behind&nbsp; the human movement.</p>\n<p>This project has also provided opportunities for students to engage in interdisciplinary studies and to interact with the international community through presentations of research findings at major international conferences. Upon invitation by IEEE-Wiley, a book summarizing the outcomes of this project will be completed soon. Some book chapters can be disseminated to students as class notes and reading materials or used toward term projects.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/06/2015<br>\n\t\t\t\t\tModified by: Zhong-Ping&nbsp;Jiang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAdaptive/approximate dynamic programming (ADP) is a powerful technique for addressing optimal decision making problems for complex uncertain dynamic processes. Its constant development  is driven by the need to solve challenging engineering and biology problems such as electric smart grid, transportation networks, and human movement and rehabilitation.\n\nUnder the support of the NSF, the PI has successfully brought together two fields - nonlinear control and ADP - and proposed a new framework for data-driven, nonmodel-based, adaptive optimal control with guaranteed robustness to dynamic uncertainties. This new theory is termed  \"robust adaptive dynamic programming\" (for short, RADP), and has been applied to solve challenging issues in power systems and biological motor control. Novel significant results based upon the proposed RADP theory are obtained for these two exciting topics. The related publication is selected as one of the very few annual publication spotlights by IEEE Transactions on Neural Networks and Learning Systems under the IEEE Computational Intelligence Society.\n\nWith respect to the past literature of ADP, there has been very few research devoted to the consideration of dynamic uncertainty in physical and biological systems. Dynamic uncertainty arises from different contexts, such as model reduction, unmodeled dynamics and incomplete state information. This project has made significant contributions to the development of a robust variant of the existing ADP theory, by focusing mainly on continuous-time continuous state-space models. It is shown in a recent series of the work of PI that robust optimal control policies can be obtained via a recursive numerical algorithm using online information without solving the HJB equation (for nonlinear systems) and the algebraic Riccati equation (ARE) (for linear systems), even when the system dynamics are not precisely known. Robustness to dynamic uncertainty is guaranteed and analyzed rigorously using Lyapunov and small-gain methods. More recently, the PI and his students have filled up a gap in the past literature of ADP by studying continuous-time nonlinear systems subject to both parametric and dynamic uncertainties. Practical learning algorithms are developed, and have been applied to the controller design\nproblems for a jet engine and a one-machine power system. This can be seen as a step toward bringing together two separate fields: ADP and applied nonlinear control. While previous work of ADP focuses on affine systems, the PI has obtained a new result on ADP for nonaffine systems that contain nonlinearly appearing control inputs. More interestingly, we have initiated a study of global ADP for nonlinear systems without using neural network approximations, but instead using techniques from semidefinite programming. This line of research aims to achieve siginificant computational improvement with respect to previous ADP algorithms based on neural network approximations. Through extensive computer simulations and experimental data, it is shown that RADP explains well the learning mechanism behind  the human movement.\n\nThis project has also provided opportunities for students to engage in interdisciplinary studies and to interact with the international community through presentations of research findings at major international conferences. Upon invitation by IEEE-Wiley, a book summarizing the outcomes of this project will be completed soon. Some book chapters can be disseminated to students as class notes and reading materials or used toward term projects.\n\n\t\t\t\t\tLast Modified: 10/06/2015\n\n\t\t\t\t\tSubmitted by: Zhong-Ping Jiang"
 }
}