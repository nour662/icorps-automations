{
 "awd_id": "1117042",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Developing and Applying Reuse Distance Analysis Techniques for Large-Scale Multicore Processors",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-07-15",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 499998.0,
 "awd_amount": 499998.0,
 "awd_min_amd_letter_date": "2011-07-11",
 "awd_max_amd_letter_date": "2011-07-11",
 "awd_abstract_narration": "Today, simulation is the de facto method for studying multicore cache hierarchies.  But simulation is costly due to the combinatorial design spaces involved, especially as multicore processors scale to 100s of cores and 100+ MB of on-chip cache.  Reuse distance (RD) analysis can help architects evaluate multicore memory performance more efficiently.  Unfortunately, locality in multicore processors depends on how per-thread memory reference streams interleave.  Reliance on memory interleaving makes multicore locality profiles architecture dependent, limiting their ability to analyze different configurations. For loop-based parallel programs, however, threads are typically symmetric and exhibit similar locality characteristics.  Such thread symmetry makes multicore RD analysis tractable: locality profiles remain stable with respect to cache capacity scaling, and change systematically with core count and problem size scaling.\r\n\r\nThis project is exploring several research directions related to multicore RD analysis for loop-based parallel programs.  First, it is characterizing how Concurrent RD and per-thread RD profiles for symmetric threads vary with processor and problem scaling.  Second, it is developing techniques to predict these profile variations.  Simple prediction techniques such as reference groups, as well as more sophisticated parametric and non-parametric learning approaches, are being studied.  Finally, it is applying the new RD analysis to explore large-scale multicore design spaces, identifying good cache hierarchy organizations.  It is also using the RD analyses to improve existing memory performance enhancement techniques such as multithreading and locality optimization.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Yeung",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Donald Yeung",
   "pi_email_addr": "yeung@umd.edu",
   "nsf_id": "000460886",
   "pi_start_date": "2011-07-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ankur",
   "pi_last_name": "Srivastava",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ankur Srivastava",
   "pi_email_addr": "ankurs@eng.umd.edu",
   "nsf_id": "000313791",
   "pi_start_date": "2011-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland, College Park",
  "perf_str_addr": "3112 LEE BUILDING",
  "perf_city_name": "COLLEGE PARK",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7329",
   "pgm_ref_txt": "COMPILERS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 499998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Hardware caches play a crucial role in optimizing the performance and<br />power consumption of microprocessors, so understanding their behavior<br />is extremely important.&nbsp; Traditionally, cache behavior has been<br />studied via simulation.&nbsp; Unfortunately, simulators are slow, so they<br />are often unable to fully explore large cache hierarchy design spaces.<br />Worse yet, speed limitations also prevent simulators from studying<br />realistic configurations--for example, a program running a<br />realistically large problem size on a large number of cores.<br /><br />A powerful alternative for studying cache behavior is reuse distance<br />(RD) analysis.&nbsp; RD analysis measures a program's memory reuse distance<br />histogram, or RD profile, using least recently used (LRU) stacks that<br />capture the application-level locality responsible for cache<br />performance.&nbsp; Once acquired, an RD profile can be used to predict the<br />cache performance of a large number of different cache configurations<br />(e.g., across all possible cache sizes).&nbsp; This not only accelerates<br />design space exploration, it also provides deep insights into how<br />programs utilize cache hierarchies.<br /><br />Historically, RD analysis has been relevant for analyzing<br />uniprocessors only.&nbsp; Techniques for multicore processors have been<br />elusive because parallel program locality is complex: it not only<br />depends on per-thread locality, but it also depends on how threads'<br />memory references interfere within the cache hierarchy.&nbsp; While no<br />solution exists yet for general threads, solutions do exist for<br />homogeneous threads such as those extant in programs exploiting<br />loop-level parallelism.&nbsp; Recently, researchers have provided RD<br />profiling techniques for homogeneous multithreaded programs.<br />Specifically, concurrent reuse distance (CRD) profiling yields<br />locality profiles for analyzing shared caches, while private-stack<br />reuse distance (PRD) profiling yields locality profiles for analyzing<br />private caches.&nbsp; (See Figure 1).<br /><br />Our research project builds on top of this recent work, advancing the<br />state-of-the-art for multicore RD analysis in two major ways.&nbsp; One<br />contribution is that we identified several fundamental parallel<br />locality behaviors that fall out of CRD/PRD analysis.&nbsp; First, both CRD<br />and PRD profiles are shifted versions of uniprocessor RD profiles,<br />where the shift reflects the locality degradation due to thread<br />interference.&nbsp; In fact, as core count scales up, the profiles simply<br />shift to larger cache capacities.&nbsp; Second, shifting in CRD profiles<br />only occurs up to a certain capacity, which we call \"Ccore.\"&nbsp; Because<br />thread interference can only happen within the scope of program<br />parallelization, locality degradation is limited.&nbsp; Ccore quantifies<br />the maximum scope of locality degradation--i.e., a program's \"parallel<br />working set size.\"&nbsp; Third, the shift in CRD and PRD profiles is<br />systematic, and hence, predictable.&nbsp; We developed several techniques<br />to predict this shift.&nbsp; Our techniques enable construction of locality<br />profiles for large-scale CPUs from profiles acquired on small-scale<br />CPUs.&nbsp; Finally, data sharing is capacity dependent.&nbsp; It tends to be<br />non-existent at small cache sizes.&nbsp; In the absence of sharing, shared<br />and private caches behave similarly, so CRD and PRD profiles are<br />coincident in this small-capacity region.&nbsp; However, as cache size<br />increases, data sharing starts to occur within the cache hierarchy<br />which causes CRD and PRD profiles to diverge.&nbsp; This CRD-PRD gap<br />quantifies the miss rate advantage of a shared cache over a private<br />cache.&nbsp; We call the capacity at which sharing starts to ma...",
  "por_txt_cntn": "\nHardware caches play a crucial role in optimizing the performance and\npower consumption of microprocessors, so understanding their behavior\nis extremely important.  Traditionally, cache behavior has been\nstudied via simulation.  Unfortunately, simulators are slow, so they\nare often unable to fully explore large cache hierarchy design spaces.\nWorse yet, speed limitations also prevent simulators from studying\nrealistic configurations--for example, a program running a\nrealistically large problem size on a large number of cores.\n\nA powerful alternative for studying cache behavior is reuse distance\n(RD) analysis.  RD analysis measures a program's memory reuse distance\nhistogram, or RD profile, using least recently used (LRU) stacks that\ncapture the application-level locality responsible for cache\nperformance.  Once acquired, an RD profile can be used to predict the\ncache performance of a large number of different cache configurations\n(e.g., across all possible cache sizes).  This not only accelerates\ndesign space exploration, it also provides deep insights into how\nprograms utilize cache hierarchies.\n\nHistorically, RD analysis has been relevant for analyzing\nuniprocessors only.  Techniques for multicore processors have been\nelusive because parallel program locality is complex: it not only\ndepends on per-thread locality, but it also depends on how threads'\nmemory references interfere within the cache hierarchy.  While no\nsolution exists yet for general threads, solutions do exist for\nhomogeneous threads such as those extant in programs exploiting\nloop-level parallelism.  Recently, researchers have provided RD\nprofiling techniques for homogeneous multithreaded programs.\nSpecifically, concurrent reuse distance (CRD) profiling yields\nlocality profiles for analyzing shared caches, while private-stack\nreuse distance (PRD) profiling yields locality profiles for analyzing\nprivate caches.  (See Figure 1).\n\nOur research project builds on top of this recent work, advancing the\nstate-of-the-art for multicore RD analysis in two major ways.  One\ncontribution is that we identified several fundamental parallel\nlocality behaviors that fall out of CRD/PRD analysis.  First, both CRD\nand PRD profiles are shifted versions of uniprocessor RD profiles,\nwhere the shift reflects the locality degradation due to thread\ninterference.  In fact, as core count scales up, the profiles simply\nshift to larger cache capacities.  Second, shifting in CRD profiles\nonly occurs up to a certain capacity, which we call \"Ccore.\"  Because\nthread interference can only happen within the scope of program\nparallelization, locality degradation is limited.  Ccore quantifies\nthe maximum scope of locality degradation--i.e., a program's \"parallel\nworking set size.\"  Third, the shift in CRD and PRD profiles is\nsystematic, and hence, predictable.  We developed several techniques\nto predict this shift.  Our techniques enable construction of locality\nprofiles for large-scale CPUs from profiles acquired on small-scale\nCPUs.  Finally, data sharing is capacity dependent.  It tends to be\nnon-existent at small cache sizes.  In the absence of sharing, shared\nand private caches behave similarly, so CRD and PRD profiles are\ncoincident in this small-capacity region.  However, as cache size\nincreases, data sharing starts to occur within the cache hierarchy\nwhich causes CRD and PRD profiles to diverge.  This CRD-PRD gap\nquantifies the miss rate advantage of a shared cache over a private\ncache.  We call the capacity at which sharing starts to manifest\nitself \"Cshare.\"  (See Figure 2 for an illustration of all of these\nparallel locality phenomena).  While the shape of the CRD and PRD\nprofiles and the values for Ccore and Cshare differ across parallel\nprograms, we find *all* homogeneous multithreaded programs exhibit\nthese phenomena.  (See Figure 3).  Thus, they are quite useful in\nhelping computer architects reason about parallel cache behavior.\n\nOur second contribution is that we applied multicore ..."
 }
}