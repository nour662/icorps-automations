{
 "awd_id": "1111124",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Programming with Crowds: Models and Tools for General Purpose Crowdsourcing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Frederick Kronz",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 373349.0,
 "awd_amount": 386149.0,
 "awd_min_amd_letter_date": "2011-09-19",
 "awd_max_amd_letter_date": "2013-08-02",
 "awd_abstract_narration": "Crowdsourcing is a powerful way to marshal small contributions from large numbers of people to solve real-world problems. Success stories range from classifying craters on Mars' surface (ClickWorker) to labeling images (the ESP Game, now Google Image Labeler) to task marketplaces (Amazon's Mechanical Turk). This project moves towards a vision of crowdsourcing that extends it to support complex, creative, and interdependent tasks, and embeds it into computing systems as part of our everyday lives. The project will focus on two application areas for complex crowdsourcing: science journalism and software development.\r\n\r\nThe intellectual merits of the project include the uncovering of new scientific knowledge about how to model online crowd behavior, and the development of new methods and tools for using crowds as part of computer system designs, particularly for complex, interdependent, real time work. The project will also show that these methods can be used for real-world problems. \r\n\r\nThe potential broader impacts include those specifically having to do with the two application areas, which could have significant impacts on society. Crowdsourcing science journalism will directly involve citizens in the process of science dissemination, making scientific information more accessible to the general public, and promoting greater awareness of science and the scientific process. Crowdsourcing software development can transform the way that software is created, lowering barriers and broadening participation in open source software development, and helping larger masses of people use and improve their programming skills. Other impacts will flow from the researchers' plans to publically share the infrastructure that they develop to facilitate complex crowdsourcing in many other areas. They also plan to integrate their research results into undergraduate courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aniket",
   "pi_last_name": "Kittur",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aniket Kittur",
   "pi_email_addr": "nkittur@cs.cmu.edu",
   "nsf_id": "000515842",
   "pi_start_date": "2011-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "795300",
   "pgm_ele_name": "SOCIAL-COMPUTATIONAL SYSTEMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7953",
   "pgm_ref_txt": "SOCIAL-COMPUTATIONAL SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 373349.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 12800.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Crowdsourcing can be a powerful way to marshall small contributions from millions of people to solve real-world problems, with success stories ranging from classifying craters on Mars&rsquo; surface (ClickWorkers) to designing t-shirts (Threadless) to labeling images (the ESP Game) to task marketplaces (Amazon&rsquo;s Mechanical Turk). However, the types of tasks accomplished through crowdsourcing have typically been limited to those that are low complexity, independent, and require little time and cognitive effort to complete. Our work funded by this award moves towards a vision of crowdsourcing in which it is both extended to support complex, creative, and interdependent tasks as well as embedded into computing systems as part of our everyday lives.</p>\n<p>To accomplish this we integrated insights from the organizational behavior literature for partitioning and coordinating work, and from the distributed computing literature for techniques to support these in distributed human computation. In doing so we tackled three core challenges that have prevented crowdsourcing from being applied to complex, creative, and subjective work.</p>\n<p><strong>Challenge 1: Complex and interdependent tasks</strong></p>\n<p>A core challenge with complex tasks such as producing articles, software, and even science is that many of the pieces involved cannot be done independently, and rely on other pieces. For example, to write an encyclopedic article about New York City one could not simply have 100 crowd workers write a sentence each and aggregate them together. We developed a system called CrowdForge that employs the crowd itself to determine how to decompose a complex task, and applies ideas from distributed computing to coordinate their work. The key insight is that many types of complex work can be broken up into sequences of having crowds partition the task, apply a complex function to each partition, and then combine those partitions (i.e., MapReduce). This system enabled inexpert crowds providing only a few minutes of time to reliably produce complex artifacts, including as encyclopedia articles rated as highly as Wikipedia articles. We further developed a visual workflow management system that allowed non-programmers to build even more complex workflows and to manage crowd factors such as uptake rates and quality control. As a grand challenge we worked with two professional journalists to crowdsource the process of scientific journalism. The resulting articles our systems produced were considered better than many traditional news outlets. We are now working to further develop our techniques to support the kinds of complex real world problems that companies are facing today.</p>\n<p><strong>Challenge 2: Quality control</strong></p>\n<p>One of the biggest challenges for crowdsourcing is achieving high quality work from a crowd of workers, many of whom may have limited expertise or motivation. Previous approaches to quality control have focused on worker output, such as having multiple workers answer the same question and choosing the most common answer, or creating a &ldquo;gold standard&rdquo; question for which the answer is known in order to weed out workers who answer it incorrectly. However, these approaches fail when the task is subjective or generative. For example, if each worker were asked to write a story, even if all the stories were high quality none of them would match another nor match a gold standard.</p>\n<p>Instead of the work <em>output</em>, we found that it can be valuable to focus on the work <em>process</em>. By analyzing how a worker scrolls, moves their mouse, and types, we developed machine learning algorithms that could accurately predict the quality of creative crowd work &ndash; even without looking at the output. We also introduced a new way to visualize and cluster complex user behaviors, which may help future analytics systems make sense of rich human...",
  "por_txt_cntn": "\nCrowdsourcing can be a powerful way to marshall small contributions from millions of people to solve real-world problems, with success stories ranging from classifying craters on Mars\u00c6 surface (ClickWorkers) to designing t-shirts (Threadless) to labeling images (the ESP Game) to task marketplaces (Amazon\u00c6s Mechanical Turk). However, the types of tasks accomplished through crowdsourcing have typically been limited to those that are low complexity, independent, and require little time and cognitive effort to complete. Our work funded by this award moves towards a vision of crowdsourcing in which it is both extended to support complex, creative, and interdependent tasks as well as embedded into computing systems as part of our everyday lives.\n\nTo accomplish this we integrated insights from the organizational behavior literature for partitioning and coordinating work, and from the distributed computing literature for techniques to support these in distributed human computation. In doing so we tackled three core challenges that have prevented crowdsourcing from being applied to complex, creative, and subjective work.\n\nChallenge 1: Complex and interdependent tasks\n\nA core challenge with complex tasks such as producing articles, software, and even science is that many of the pieces involved cannot be done independently, and rely on other pieces. For example, to write an encyclopedic article about New York City one could not simply have 100 crowd workers write a sentence each and aggregate them together. We developed a system called CrowdForge that employs the crowd itself to determine how to decompose a complex task, and applies ideas from distributed computing to coordinate their work. The key insight is that many types of complex work can be broken up into sequences of having crowds partition the task, apply a complex function to each partition, and then combine those partitions (i.e., MapReduce). This system enabled inexpert crowds providing only a few minutes of time to reliably produce complex artifacts, including as encyclopedia articles rated as highly as Wikipedia articles. We further developed a visual workflow management system that allowed non-programmers to build even more complex workflows and to manage crowd factors such as uptake rates and quality control. As a grand challenge we worked with two professional journalists to crowdsource the process of scientific journalism. The resulting articles our systems produced were considered better than many traditional news outlets. We are now working to further develop our techniques to support the kinds of complex real world problems that companies are facing today.\n\nChallenge 2: Quality control\n\nOne of the biggest challenges for crowdsourcing is achieving high quality work from a crowd of workers, many of whom may have limited expertise or motivation. Previous approaches to quality control have focused on worker output, such as having multiple workers answer the same question and choosing the most common answer, or creating a \"gold standard\" question for which the answer is known in order to weed out workers who answer it incorrectly. However, these approaches fail when the task is subjective or generative. For example, if each worker were asked to write a story, even if all the stories were high quality none of them would match another nor match a gold standard.\n\nInstead of the work output, we found that it can be valuable to focus on the work process. By analyzing how a worker scrolls, moves their mouse, and types, we developed machine learning algorithms that could accurately predict the quality of creative crowd work &ndash; even without looking at the output. We also introduced a new way to visualize and cluster complex user behaviors, which may help future analytics systems make sense of rich human behavior.\n\nChallenge 3: Towards a positive future of crowd work\n\nWe brought together researchers from diverse disciplines including computer science, psychology, economics, ..."
 }
}