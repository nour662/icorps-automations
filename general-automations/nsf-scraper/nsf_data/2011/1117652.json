{
 "awd_id": "1117652",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Small: Embodied Mediated Communication in Collaborative Work",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 487810.0,
 "awd_amount": 503810.0,
 "awd_min_amd_letter_date": "2011-07-28",
 "awd_max_amd_letter_date": "2016-06-16",
 "awd_abstract_narration": "The goal of this project is to gain a deeper understanding of mobile remote presence systems (MRPs) and to create guidelines for their effective design, development, and adaptation into organizational use. MRP systems enable embodied mediated communication in which individuals at a remote location connect to a local robot that is used to physically navigate in the local environment and to interact with local users via audio and video. MRP systems allow remote users to visit individuals in an organization and attend group meetings, seminars, and social gatherings in the local environment. MRPs enable new forms of interactions and offer remote users an improved sense of presence compared with stationary video-conferencing systems.\r\n \r\nThe project will study the use of MRPs in communication from an interdisciplinary approach drawing from and building on knowledge and methods from design, social and cognitive psychology, communication studies, and computer science. A series of field and laboratory studies will focus on four topics: (a) how remote users present themselves through MRPs; (b) how local users perceive remote users; (c) the role that social cues play in embodied mediated communication; and (d) the social and organizational outcomes of embodied mediated communication.\r\n \r\nIntellectual merit: The project will advance understanding of the role of embodiment in mediated communication in collaborative work and inform the design of future mobile remote presence systems. In addition, the results will contribute to basic science in human-computer and human-robot interaction.\r\n \r\nBroader impact: The results will enable more effective embodied mediated communication in organizations, thereby improving collaboration in distributed work groups.  The results will also inform the development of tools that help individuals with mobility-related disabilities interact with their social and professional communities. In addition, the project will enhance the undergraduate and graduate curriculum at the University of Wisconsin-Madison, and there will be an outreach program to disperse interdisciplinary knowledge in and methods for designing robotic technology into K-12 education through an annual summer camp and biannual daylong workshops.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bilge",
   "pi_last_name": "Mutlu",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Bilge D Mutlu",
   "pi_email_addr": "bilge@cs.wisc.edu",
   "nsf_id": "000546805",
   "pi_start_date": "2011-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Leila",
   "pi_last_name": "Takayama",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Leila A Takayama",
   "pi_email_addr": "takayama@willowgarage.com",
   "nsf_id": "000584351",
   "pi_start_date": "2011-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 N PARK ST STE 6301",
  "perf_city_name": "MADISON",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 158455.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 345355.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Telepresence robots&mdash;communication tools that enable remote users to navigate in an environment and interact with its inhabitants&mdash;have found widespread adoption in homes, businesses, schools, hospitals, museums, and temporary organizations such as conferences. These tools fulfill a number of unique communication needs, such as a sick child who wants to attend class from home, a rural hospital that wants access to specialists when a patient with a rare condition is admitted, or a conference that wishes to enable individuals with disabilities who cannot travel to attend sessions and social events. The ability of these tools to support autonomy in navigating in an environment and in engaging in communication with individuals in that environment without help from those individuals promises to more effectively fulfill these needs than conventional forms of communication, such as voice- and video-based communication. Realizing this promise, however, requires an understanding of how to best design these tools and how a range of factors, such as what type of task communicators are engaged in or the relationship between them, affect communication via telepresence robots. The goals of this project were to explore the design space for telepresence robots through a systematic evaluation of its design elements and to gain a deeper understanding of how individuals present themselves and perceive others when they communicate via a telepresence robot. For instance, the research team studied how the <em>height</em> of the telepresence robot affected team-based communications and found that remote users in leadership roles were perceived to be less persuasive when they used a robot that was shorter than the local user. Attached images illustrate the design space and provide additional examples of the project team's investigations.</p>\n<p>The novel features that the research team designed, such as a control interface for the remote operator that provided a 360-panoramic view of the environment to improve situation awareness, and findings from experimental studies, such as a comparison of robot-based communication against videoconferencing, serve as <em>scientific</em> knowledge that will form a foundation for further research and <em>practical</em> knowledge that industry can use to design future communication products. The scientific knowledge that has resulted from the project has been shared with the research community through the publication or submission of approximately a dozen peer-reviewed articles, including one doctoral dissertation in computer science. The practical knowledge that the project has generated have been transferred to industry through frequent communication with manufacturers of telepresence robots. The project also provided an interdisciplinary group of graduate and undergraduate students with backgrounds in computer science, electrical engineering, psychology, and communication studies with opportunities for advanced research training, professional development through mentoring, and hands-on research experience. Finally, the project team also organized several activities aimed at informing members of the public about telepresence robots and engaging them with the robot systems used by the research team. For example, an \"Open Lab\" event invited members of the public to visit the research laboratory to try out using telepresence robots. For broader dissemination, the project team presented the use of telepresence robots and discussed their promise for improving communication in a video series titled \"Science Narratives\" that has been published online.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/30/2017<br>\n\t\t\t\t\tModified by: Bilge&nbsp;D&nbsp;Mutlu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338400334_Figures-01--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338400334_Figures-01--rgov-800width.jpg\" title=\"Design Space for Telepresence Robots\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338400334_Figures-01--rgov-66x44.jpg\" alt=\"Design Space for Telepresence Robots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An illustration of the design space for telepresence robots</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Design Space for Telepresence Robots</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338469272_Figures-02--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338469272_Figures-02--rgov-800width.jpg\" title=\"Studying Robot Mobility\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338469272_Figures-02--rgov-66x44.jpg\" alt=\"Studying Robot Mobility\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of the effects of robot mobility on collaboration</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Studying Robot Mobility</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338562269_Figures-03--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338562269_Figures-03--rgov-800width.jpg\" title=\"Studying Framing Effects\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338562269_Figures-03--rgov-66x44.jpg\" alt=\"Studying Framing Effects\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of the effects of verbal/visual framing on communication</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Studying Framing Effects</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338610181_Figures-04--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338610181_Figures-04--rgov-800width.jpg\" title=\"Studying Robot Height\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338610181_Figures-04--rgov-66x44.jpg\" alt=\"Studying Robot Height\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of the effects of robot height on communication</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Studying Robot Height</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338676081_Figures-05--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338676081_Figures-05--rgov-800width.jpg\" title=\"Supporting User Situation Awareness\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338676081_Figures-05--rgov-66x44.jpg\" alt=\"Supporting User Situation Awareness\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The control interface featuring a panoramic view of the environment</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Supporting User Situation Awareness</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338754581_Figures-06--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338754581_Figures-06--rgov-800width.jpg\" title=\"Studying Robot Control\"><img src=\"/por/images/Reports/POR/2017/1117652/1117652_10114490_1509338754581_Figures-06--rgov-66x44.jpg\" alt=\"Studying Robot Control\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of the effects of who controls the navigation of the robot</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Studying Robot Control</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nTelepresence robots&mdash;communication tools that enable remote users to navigate in an environment and interact with its inhabitants&mdash;have found widespread adoption in homes, businesses, schools, hospitals, museums, and temporary organizations such as conferences. These tools fulfill a number of unique communication needs, such as a sick child who wants to attend class from home, a rural hospital that wants access to specialists when a patient with a rare condition is admitted, or a conference that wishes to enable individuals with disabilities who cannot travel to attend sessions and social events. The ability of these tools to support autonomy in navigating in an environment and in engaging in communication with individuals in that environment without help from those individuals promises to more effectively fulfill these needs than conventional forms of communication, such as voice- and video-based communication. Realizing this promise, however, requires an understanding of how to best design these tools and how a range of factors, such as what type of task communicators are engaged in or the relationship between them, affect communication via telepresence robots. The goals of this project were to explore the design space for telepresence robots through a systematic evaluation of its design elements and to gain a deeper understanding of how individuals present themselves and perceive others when they communicate via a telepresence robot. For instance, the research team studied how the height of the telepresence robot affected team-based communications and found that remote users in leadership roles were perceived to be less persuasive when they used a robot that was shorter than the local user. Attached images illustrate the design space and provide additional examples of the project team's investigations.\n\nThe novel features that the research team designed, such as a control interface for the remote operator that provided a 360-panoramic view of the environment to improve situation awareness, and findings from experimental studies, such as a comparison of robot-based communication against videoconferencing, serve as scientific knowledge that will form a foundation for further research and practical knowledge that industry can use to design future communication products. The scientific knowledge that has resulted from the project has been shared with the research community through the publication or submission of approximately a dozen peer-reviewed articles, including one doctoral dissertation in computer science. The practical knowledge that the project has generated have been transferred to industry through frequent communication with manufacturers of telepresence robots. The project also provided an interdisciplinary group of graduate and undergraduate students with backgrounds in computer science, electrical engineering, psychology, and communication studies with opportunities for advanced research training, professional development through mentoring, and hands-on research experience. Finally, the project team also organized several activities aimed at informing members of the public about telepresence robots and engaging them with the robot systems used by the research team. For example, an \"Open Lab\" event invited members of the public to visit the research laboratory to try out using telepresence robots. For broader dissemination, the project team presented the use of telepresence robots and discussed their promise for improving communication in a video series titled \"Science Narratives\" that has been published online.\n\n\t\t\t\t\tLast Modified: 10/30/2017\n\n\t\t\t\t\tSubmitted by: Bilge D Mutlu"
 }
}