{
 "awd_id": "1106084",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Objective Bayesian Model Selection and Estimation in High Dimensional Statistical Models",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2011-10-01",
 "awd_exp_date": "2015-09-30",
 "tot_intn_awd_amt": 100809.0,
 "awd_amount": 100809.0,
 "awd_min_amd_letter_date": "2011-09-20",
 "awd_max_amd_letter_date": "2011-09-20",
 "awd_abstract_narration": "It is widely accepted that in many high dimensional situations, model selection has to be performed either before parameter estimation or simultaneously, in order to reduce the number of parameters under consideration. Indeed, model selection is one of the major challenges facing statisticians working with high dimensional data. Tools such as regularization and sparsity are some of the common notions employed to obtain parsimonious models to explain observed data. In recent years, the field of statistics has witnessed an explosion of frequentist and Bayesian methods for high dimensional problems. Despite these and other advances, Bayesian model selection in an \"objective\" sense in high dimensional problems remains an important problem that has yet to be solved satisfactorily. The need for objectivity translates into a need for specifying noninformative improper priors, which in turn renders the traditional Bayes factors unusable. The project proposes to derive objective Bayesian estimation and model selection procedures in a large class of high dimensional graphical models. The methodology that is proposed in this project therefore aims to contribute to much needed theory in the area of objective Bayesian model selection for high dimensional graphical models. In the process the methodology studies the benefits and shortcomings of objective Bayesian methods in this context. The theory that is developed feeds into developing algorithms and computational techniques for model selection/estimation in high dimensional settings.\r\n\r\nThe availability of throughput or high dimensional data has touched almost every field of science. The need to formulate correct models that explain observed high dimensional data permeates through many scientific fields. Indeed, such data where the number of variables is often much higher than the number of samples, referred to as the \"large p small n\" problem, is now more pervasive than it has ever been. Discovering statistical signals in high dimensional data, proposing correct models that can explain such data, and parameter estimation in these high dimensional settings are some of the major challenges that modern day statisticians have to contend with. Moreover, such challenges also feature in high stakes debates such as climate change, effectiveness of certain drugs in clinical trials, and relevance of various biomarkers in cancer studies. This project proposes to develop statistical methodology which is specifically targeted towards identifying models which explain high dimensional data in an objective manner. In particular the project is designed to develop better objective Bayesian model selection and parameter estimation methods in high dimensional problems, and has widespread applications. The PI and co-PI collaborate with scientists in applied fields, especially with faculty/researchers in their Medical Schools, Schools of Engineering and Environmental Sciences. Training of graduate students and mentoring is an integral part of this collaborative research. Scientific output from the project is intended for publication in high impact peer-reviewed journals.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kshitij",
   "pi_last_name": "Khare",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kshitij Khare",
   "pi_email_addr": "kdkhare@stat.ufl.edu",
   "nsf_id": "000545160",
   "pi_start_date": "2011-09-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1523 UNION RD RM 207",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326111941",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 100809.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>High-dimensional data, or big data, where the number of variables is much larger than the sample size, is now available from a variety of scientific applications such as genetics, finance and climate sciences. Understanding the complex network of relationships in these datasets is an important goal, and estimation of the covariance matrix of the variables is a fundamental step towards that goal. The aim of this project was to develop methods for high-dimesional covariance estimation with strong methodological and computational properties. We have been successful in this goal.&nbsp;</p>\n<p>Our first contribution has been the development of a novel method for sparse estimation of the inverse covariance matrix, based on penalized pseudo-likelihood. This method builds on the previous work in this area, and provides a state of the art algorithm with strong methodological properties such as a provable convergence guarantee and consistency, and is computationally efficient.</p>\n<p>Our second contribution has been the development of a novel class of prior distributions for high-diemnsional Bayesian estimation of sparse inverse covariance matrices. Through these priors, efficient estimation is possible for a much larger class of sparsity patterns in the inverse covariance matrix than in the previous literature.</p>\n<p>We have also developed a novel Bayesian approach for statistical inference using envelope models, which provide a new and effective technique for dimension reduction in multivariate regression.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/15/2016<br>\n\t\t\t\t\tModified by: Kshitij&nbsp;Khare</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHigh-dimensional data, or big data, where the number of variables is much larger than the sample size, is now available from a variety of scientific applications such as genetics, finance and climate sciences. Understanding the complex network of relationships in these datasets is an important goal, and estimation of the covariance matrix of the variables is a fundamental step towards that goal. The aim of this project was to develop methods for high-dimesional covariance estimation with strong methodological and computational properties. We have been successful in this goal. \n\nOur first contribution has been the development of a novel method for sparse estimation of the inverse covariance matrix, based on penalized pseudo-likelihood. This method builds on the previous work in this area, and provides a state of the art algorithm with strong methodological properties such as a provable convergence guarantee and consistency, and is computationally efficient.\n\nOur second contribution has been the development of a novel class of prior distributions for high-diemnsional Bayesian estimation of sparse inverse covariance matrices. Through these priors, efficient estimation is possible for a much larger class of sparsity patterns in the inverse covariance matrix than in the previous literature.\n\nWe have also developed a novel Bayesian approach for statistical inference using envelope models, which provide a new and effective technique for dimension reduction in multivariate regression.\n\n \n\n\t\t\t\t\tLast Modified: 01/15/2016\n\n\t\t\t\t\tSubmitted by: Kshitij Khare"
 }
}