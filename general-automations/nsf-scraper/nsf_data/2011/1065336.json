{
 "awd_id": "1065336",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHB: Medium: Assistive Cloudlet-Based Mobile Computing for the Cognitively Impaired",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 1199272.0,
 "awd_amount": 1271272.0,
 "awd_min_amd_letter_date": "2011-08-30",
 "awd_max_amd_letter_date": "2014-06-11",
 "awd_abstract_narration": "This project advances computer science by producing scientific insights, algorithms, system designs, implementation techniques, and experimental validations at the intersection of three major subdisciplines. These subdisciplines are (1) computer systems (including mobile computing, operating systems, and wireless networking), (2) vision technologies (including computer vision and machine learning), and (3) human-computer interaction (including activity inferencing, distraction reduction, and context awareness). These will be integrated to create cognitive assistive systems that can function \"in the wild\" with sufficient functionality, performance and usability to be valuable at any time and place to provide help for the cognitively impaired.\r\n\r\nFrom a societal perspective, this research has the potential to improve the quality of lives of individuals whose cognitive capabilities have declined due to natural aging, illness or traumatic injuries (estimated at 20 million Americans). In addition, cognitive support can assure safe use and compliance with instructions in rehabilitation and management of chronic illness. From an educational viewpoint, this research offers many unique opportunities to train graduate and undergraduate students on how to approach problems from a broad multi-interdisciplinary perspective. In close partnership with industry, this research has the potential to impact mobile computing by empowering resource-poor mobile devices to run interactive, compute-intensive applications at any time and place. While this proposal focuses on applying this new capability to the problem of cognitive assistance, it can also address important needs of the general population. Further, the resulting cloudlet architecture has the potential to transform arenas as diverse as business, engineering, health care, and defense.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mahadev",
   "pi_last_name": "Satyanarayanan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mahadev Satyanarayanan",
   "pi_email_addr": "satya@cs.cmu.edu",
   "nsf_id": "000217675",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Siewiorek",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel P Siewiorek",
   "pi_email_addr": "dps@cs.cmu.edu",
   "nsf_id": "000278815",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Martial",
   "pi_last_name": "Hebert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Martial Hebert",
   "pi_email_addr": "martial.Hebert@cs.cmu.edu",
   "nsf_id": "000225106",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 FORBES AVE",
  "perf_city_name": "PITTSBURGH",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 1199272.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 24000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 24000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 24000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over 20 million Americans are affected by some form of cognitive decline that signi?cantly affects their ability to function as independent members of society.&nbsp;&nbsp; Our research was inspired by the goal of creating computer-based assistive technolgies for cognitive decline, just as crutches or prostheses can help a person with physical injuries.&nbsp; Our goal was to conduct the foundational research that could lead to the creation of such systems.&nbsp;&nbsp; <em>What hardware and software does one need to create so that helpful guidance to a cognitively challenged user is within the realm of feasibility?</em>&nbsp; That is the question that drove our research.<br /><br />We were especially interested in approaches that are minimally restrictive.&nbsp; In other words, we wanted to explore approaches that would not only work indoors, or in specially constructed environments such as a hospital or nursing home.&nbsp; Rather, we wanted to enable cognitive assistive systems that could function \"in the wild\" with suf?cient functionality, performance and usability to be valuable at any time and place.&nbsp; The emergence of wearable hardware, such as Google Glass and Microsoft Hololens, provides an opening for the creation of cognitive assistance systems. Imagine a cognitively challenged user wearing one of these devices, and having helping guidance (such as the name of the person in front of him) being whispered to him.&nbsp; That is the kind of system we wish to enable.<br /><br />Through this research over the past four years, we have created the software foundations for such assistive systems.&nbsp; Our efforts focused on three areas: (a) how to amplify the computational capabilities of a lightweight wearable computer by harnessing, through computational offload, the resources of a nearby mini-data center (called a \"cloudlet\"); (b) how to leverage these compute resources close by to peform real-time computer vision of sufficient accuracy for assistive scenarios; and (c) how to guide a user so that he or she is neither overwhelmed with detail, nor underinformed about his surroundings. Our research has addressed many of the core technical challenges in this space that need to be solved before assistive application software can succeed.&nbsp; As proof of concept, we have created a simple assistive application that uses Google Glass and performs computer vision on a cloudlet to guide a user in a simply assembly task using Lego blocks. A YouTube video of this assistive application can be found at <span style=\"text-decoration: underline;\">http://youtu.be/uy17Hz5xvmY</span>.<br /><br />Through the research that we have performed in this NSF grant, we have opened the door for companies to create assistive software on top of the open-source foundation that we have created.&nbsp; During the course of our research, we have been working in close partnership with companies such as Intel, Vodafone and Google.&nbsp; Our learnings and software are freely available to them, and to the startup companies that they invest in.&nbsp; Because of the results that we have been able to achieve, it is plausible that within the next five years commercial assistive applications of the kind that inspired this research will be become available.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/21/2015<br>\n\t\t\t\t\tModified by: Mahadev&nbsp;Satyanarayanan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2015/1065336/1065336_10128821_1448140843760_input--rgov-214x142.jpg\" origin...",
  "por_txt_cntn": "\nOver 20 million Americans are affected by some form of cognitive decline that signi?cantly affects their ability to function as independent members of society.   Our research was inspired by the goal of creating computer-based assistive technolgies for cognitive decline, just as crutches or prostheses can help a person with physical injuries.  Our goal was to conduct the foundational research that could lead to the creation of such systems.   What hardware and software does one need to create so that helpful guidance to a cognitively challenged user is within the realm of feasibility?  That is the question that drove our research.\n\nWe were especially interested in approaches that are minimally restrictive.  In other words, we wanted to explore approaches that would not only work indoors, or in specially constructed environments such as a hospital or nursing home.  Rather, we wanted to enable cognitive assistive systems that could function \"in the wild\" with suf?cient functionality, performance and usability to be valuable at any time and place.  The emergence of wearable hardware, such as Google Glass and Microsoft Hololens, provides an opening for the creation of cognitive assistance systems. Imagine a cognitively challenged user wearing one of these devices, and having helping guidance (such as the name of the person in front of him) being whispered to him.  That is the kind of system we wish to enable.\n\nThrough this research over the past four years, we have created the software foundations for such assistive systems.  Our efforts focused on three areas: (a) how to amplify the computational capabilities of a lightweight wearable computer by harnessing, through computational offload, the resources of a nearby mini-data center (called a \"cloudlet\"); (b) how to leverage these compute resources close by to peform real-time computer vision of sufficient accuracy for assistive scenarios; and (c) how to guide a user so that he or she is neither overwhelmed with detail, nor underinformed about his surroundings. Our research has addressed many of the core technical challenges in this space that need to be solved before assistive application software can succeed.  As proof of concept, we have created a simple assistive application that uses Google Glass and performs computer vision on a cloudlet to guide a user in a simply assembly task using Lego blocks. A YouTube video of this assistive application can be found at http://youtu.be/uy17Hz5xvmY.\n\nThrough the research that we have performed in this NSF grant, we have opened the door for companies to create assistive software on top of the open-source foundation that we have created.  During the course of our research, we have been working in close partnership with companies such as Intel, Vodafone and Google.  Our learnings and software are freely available to them, and to the startup companies that they invest in.  Because of the results that we have been able to achieve, it is plausible that within the next five years commercial assistive applications of the kind that inspired this research will be become available.\n\n\t\t\t\t\tLast Modified: 11/21/2015\n\n\t\t\t\t\tSubmitted by: Mahadev Satyanarayanan"
 }
}