{
 "awd_id": "1146249",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "What Works for Whom in What Context: A Practical Guide to Conducting Evaluations With Diverse Populations?.",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032925309",
 "po_email": "cdellapi@nsf.gov",
 "po_sign_block_name": "Connie Della-Piana",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 349792.0,
 "awd_amount": 349792.0,
 "awd_min_amd_letter_date": "2011-08-31",
 "awd_max_amd_letter_date": "2011-08-31",
 "awd_abstract_narration": "There is a need at NSF and in the field for a set of guidelines that would direct the evaluation process for projects whose purpose is to develop a more diverse STEM workforce. The purpose of this project is to create guidelines that would be used by PIs and proposal developers to write effective evaluation plans in their proposals; by evaluators to plan, implement and conduct rigorous project evaluations; and by Program Officers and reviewers to judge the merits of evaluation sections of proposals or to provide guidance for prospective or current projects. comprehensive guide, population-focused tip sheets, interactive internet materials and a wiki about conducting evaluations with diverse populations including considerations centering on gender, race/ethnicity, and disabilities.  Consideration is also given to the setting of the evaluation (e.g., institutional type, program type). The materials will include information about designing, implementing and assess the quality of projects and activities that focus on broaden participation in STEM education, especially those targeting post-high school participants.  The final products will be unique because they will specifically address evaluation issues related to diverse populations such as under represented minoritis, females, individuals with disabilities, and individuals in multiple categories. \r\n \r\nThis project builds on previous NSF-funded work by the PIs individually and together.  In addition, several specific NSF-funded or developed documents have led the way in formulating the idea and design for this project. Examples are the Framework for Evaluating Impacts of Broadening Participation Projects:  A Report from a National Science Foundation Workshop, co edited by Beatriz Chu Clewell and Norman Fortenberry under Contract Number GS-10F-0482P by the Division of Research on Learning, the Indigenous Evaluation Framework Report  by LaFrance and Nichols (Grant 0438720), and the Mixed Methods User-Friendly Handbook which was updated in 2010 (Contract REC 99-12175). The specific objectives of the project delineate the plan for the project, including a needs assessment with stakeholder groups, a literature review, the development and beta testing of materials, revision and field testing, and dissemination.  The project includes an Advisory Board that has the expertise to provide important input to the process. The project also includes an external, independent evaluator and an evaluation plan that considers the progress and outcomes of the project. \r\n\r\nThis project is a unique contribution to the fields of evaluation, broadening participation, and STEM education.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Jolly",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Jolly",
   "pi_email_addr": "ejolly@smm.org",
   "nsf_id": "000108914",
   "pi_start_date": "2011-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Patricia",
   "pi_last_name": "Campbell",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Patricia B Campbell",
   "pi_email_addr": "campbell@campbell-kibler.com",
   "nsf_id": "000188107",
   "pi_start_date": "2011-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Science Museum of Minnesota",
  "inst_street_address": "120 KELLOGG BLVD W",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT PAUL",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "7013174245",
  "inst_zip_code": "551021202",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MN04",
  "org_lgl_bus_name": "SCIENCE MUSEUM OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "FMBEN7W54M58"
 },
 "perf_inst": {
  "perf_inst_name": "Science Museum of Minnesota",
  "perf_str_addr": "120 West Kellogg Boulevard",
  "perf_city_name": "Saint Paul",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "551021202",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "726100",
   "pgm_ele_name": "Project & Program Evaluation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7261",
   "pgm_ref_txt": "PROGRAM EVALUATION"
  },
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0411",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001112DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 349792.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Outcomes</strong></p>\n<p>The primary project outcome is a user-friendly website, BeyondRigor.org, that provides evaluators and others with ways to better design and carry out evaluation with diverse populations.&nbsp; While the original goal was to provide this for evaluators of programs to increase STEM workforce diversity, the resulting research based tips and information have value for a much broader population.&nbsp; These tips help evaluators and others understand differential impacts of some evaluation strategies on participants from different demographic groups and how evaluations can be designed to minimize or even eliminate these effects.&nbsp;</p>\n<p>BeyondRigor.org also informs program officers about evaluation and what is needed to have better evaluations with diverse populations and better monitoring of their resource investments.&nbsp; A third section of BeyondRigor.org provides evaluators and others will easy to access information from seven existing resources on STEM Broadening Participation (BP) evaluations.</p>\n<p>Two of the guiding realities behind this project are that &ldquo;all populations are diverse&rdquo; and that &ldquo;each individual is diverse&rdquo;.&nbsp; That while populations may be homogeneous in one area but they are not homogeneous in all areas and that each individual encompasses a variety of demographic characteristics seems self-evident.&nbsp;&nbsp; Making these realities explicit and showing how they need to be considered in evaluation (and educational research) design, analysis and interpretation has the potential to change the approach to evaluation.&nbsp;</p>\n<p>For example, an evaluation of a STEM workforce development program that targets African Americans needs to look for diversity within that population and see if there are other factors, such as family income, that need to be considered in the analysis.&nbsp; A program that &ldquo;works for girls&rdquo; tells us little about whether it will work for specific subgroups of girls.&nbsp; The major outcome of this project, is a way for evaluators to tailor their evaluations to better determine &ldquo;what works for whom in what context.&rdquo;</p>\n<p><strong>&nbsp;Intellectual Merit</strong></p>\n<p>Key to being able to broaden participation in STEM, is to know what works for whom in what context.&nbsp; Without good evaluation this is not going to happen.&nbsp; It is not enough for evaluation to be methodologically rigorous.&nbsp; That is necessary but not sufficient to learn about what works for different groups of people.&nbsp; Evaluation methods need to be targeted toward the needs, issues and goals of different subgroups, if they are not then the results can be incomplete and even inaccurate.&nbsp; To help make this happen, the following resources were developed, reviewed and refined:</p>\n<ul>\n<li>with the assistance of over 30 principal investigators, evaluators and current and past NSF program officers, a series of tips and rationales for evaluators, principal investigators and others to use to improve evaluations with diverse populations tied to collecting more accurate data, using more appropriate analysis and collecting the right data.&nbsp; </li>\n<li>with the assistance of members of different groups and people with expertise working with specific populations, an overview of context and overviews of 11 of the contextual factors that those doing STEM evaluations over diverse populations need to consider.&nbsp;&nbsp; </li>\n<li>with the assistance of former NSF program officers, a series of tools for funders to use to improve evaluations at five different points in the grant process: the RFP/GA, Proposal Review, Grant Award, Project Implementation and Final Report.</li>\n<li>a resources section which provides readers with explicit, useful information on evaluation basics within the context of programs and projects to improve the quality, quantity and diversit...",
  "por_txt_cntn": "\nOutcomes\n\nThe primary project outcome is a user-friendly website, BeyondRigor.org, that provides evaluators and others with ways to better design and carry out evaluation with diverse populations.  While the original goal was to provide this for evaluators of programs to increase STEM workforce diversity, the resulting research based tips and information have value for a much broader population.  These tips help evaluators and others understand differential impacts of some evaluation strategies on participants from different demographic groups and how evaluations can be designed to minimize or even eliminate these effects. \n\nBeyondRigor.org also informs program officers about evaluation and what is needed to have better evaluations with diverse populations and better monitoring of their resource investments.  A third section of BeyondRigor.org provides evaluators and others will easy to access information from seven existing resources on STEM Broadening Participation (BP) evaluations.\n\nTwo of the guiding realities behind this project are that \"all populations are diverse\" and that \"each individual is diverse\".  That while populations may be homogeneous in one area but they are not homogeneous in all areas and that each individual encompasses a variety of demographic characteristics seems self-evident.   Making these realities explicit and showing how they need to be considered in evaluation (and educational research) design, analysis and interpretation has the potential to change the approach to evaluation. \n\nFor example, an evaluation of a STEM workforce development program that targets African Americans needs to look for diversity within that population and see if there are other factors, such as family income, that need to be considered in the analysis.  A program that \"works for girls\" tells us little about whether it will work for specific subgroups of girls.  The major outcome of this project, is a way for evaluators to tailor their evaluations to better determine \"what works for whom in what context.\"\n\n Intellectual Merit\n\nKey to being able to broaden participation in STEM, is to know what works for whom in what context.  Without good evaluation this is not going to happen.  It is not enough for evaluation to be methodologically rigorous.  That is necessary but not sufficient to learn about what works for different groups of people.  Evaluation methods need to be targeted toward the needs, issues and goals of different subgroups, if they are not then the results can be incomplete and even inaccurate.  To help make this happen, the following resources were developed, reviewed and refined:\n\nwith the assistance of over 30 principal investigators, evaluators and current and past NSF program officers, a series of tips and rationales for evaluators, principal investigators and others to use to improve evaluations with diverse populations tied to collecting more accurate data, using more appropriate analysis and collecting the right data.  \nwith the assistance of members of different groups and people with expertise working with specific populations, an overview of context and overviews of 11 of the contextual factors that those doing STEM evaluations over diverse populations need to consider.   \nwith the assistance of former NSF program officers, a series of tools for funders to use to improve evaluations at five different points in the grant process: the RFP/GA, Proposal Review, Grant Award, Project Implementation and Final Report.\na resources section which provides readers with explicit, useful information on evaluation basics within the context of programs and projects to improve the quality, quantity and diversity of the STEM workforce.\n\n\nThis project advanced the conceptual framework that evaluators bring to their work, including reminding them that the realties that all populations are diverse and that each individual is diverse needs to be considered in evaluation design, analysis and interpretation.\n\n Broader Impacts..."
 }
}