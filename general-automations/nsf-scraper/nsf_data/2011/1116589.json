{
 "awd_id": "1116589",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Approximate Message Passing for Systems with Linear Mixing and Randomization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 481472.0,
 "awd_amount": 481472.0,
 "awd_min_amd_letter_date": "2011-08-23",
 "awd_max_amd_letter_date": "2011-08-23",
 "awd_abstract_narration": "A fundamental challenge in many engineering and science problems today is to find tractable methods to handle large scale, complex nonlinear systems.  This research considers large systems with linear mixing, where the system components interact through aggregates of small, linearizable perturbations.  For such systems, the research investigates a promising new class of algorithms called generalized approximate message passing (GAMP) that exploits the nature of the linear mixing interactions to iteratively decompose large-scale problems into smaller, more tractable, problems.  The GAMP methodology provides a systematic procedure applicable to a large class of systems that is computationally scalable to very high dimensions and admits a tractable mathematical analysis in the case of certain high-dimensional random systems.  The potential for the GAMP algorithm is thus far reaching, and the research explores applications in diverse fields including scheduling in cellular wireless systems, image recovery, pattern recognition and detection of connectivity in neural networks.\r\n\r\nThe GAMP methodology is based on a Gaussian and quadratic approximations of loopy belief propagation on large, dense graphs.  The resulting algorithm is a general, but computationally simple, iterative procedure that alternates between scalar optimization and estimation operations based on the local behavior of the system, along with linear transforms that capture the interactions between system components.  The theoretical components of the research are to characterize the algorithm's asymptotic behavior, convergence and optimality along with developing extensions to the systems with mixes of linear and nonlinear interactions.  The research will leverage tools from and contribute to the broader fields of optimization, graphical models, numerical methods and random systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sundeep",
   "pi_last_name": "Rangan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sundeep Rangan",
   "pi_email_addr": "srangan@nyu.edu",
   "nsf_id": "000558888",
   "pi_start_date": "2011-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 WASHINGTON SQ S",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 481472.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many systems in science and engineering involve large numbers of components with complex interactions and dependencies. &nbsp;Estimation and optimization of these systems is often computationally and analytically challenging due to the potentially large scale of these systems and nonlinearities in the interactions. &nbsp;This project investigated a new class of algorithms called Generalized Approximate Message Passing (GAMP) that offer a computationally efficient and general methodology for approaching these problems. &nbsp;The framework is based on representing a large system as a network of simple nonlinear system with linear interactions. &nbsp;The GAMP algorithm then divides estimation or optimization into smaller, more tractable problems on these subsystems.<br />The project achieved several important outcomes for the development of the GAMP framework:<br />-- Extensions to complex systems: &nbsp;The initial GAMP framework, developed by the PI before the grant, considered only very simple systems: &nbsp;estimation of an iid random vector x through noisy measurements of z=Ax. &nbsp;Through the period of the grant extensions were developed for large numbers of problems including (i) matrix factorization, (ii) vectors with dependencies characterized via general graphical models, (iii) parametric uncertainty in the distributions and (iv) dynamics in the linear transforms. &nbsp;These extensions enable the framework to much larger number of problems as illustrated in the applications below.<br />-- Analysis on large random matrices: &nbsp;We were able to mathematically prove that the algorithm is optimal in a range of problems. &nbsp;For example, we obtained the first algorithm with provable consistency guarantees for linear-nonlinear cascade systems with parametric uncertainty. &nbsp;The method also obtained optimal rank one recovery. &nbsp;Optimality guarantees of this form are extremely rare for problems of this complexity.<br />-- Convergence and stability: &nbsp;A key obstacle for the algorithms was their convergence and stability. &nbsp;While the algorithm illustrated very good performance on certain large random problems, initial versions of the algorithm could diverge for many practical problems. &nbsp;We successfully developed several methods to improve the stability including damping, adaptive damping and ADMM-based optimization. &nbsp;We obtained several first convergence results as well.<br />-- Applications: &nbsp;The GAMP method was successfully illustrated in several novel areas includingimage processing, non-parametric MRI and wireless interference problems and neural connectivity. &nbsp;These problems involve systems that are all nonlinear, very large scale problems and the success of the GAMP method in these problems illustrates the method's success.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2015<br>\n\t\t\t\t\tModified by: Sundeep&nbsp;Rangan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany systems in science and engineering involve large numbers of components with complex interactions and dependencies.  Estimation and optimization of these systems is often computationally and analytically challenging due to the potentially large scale of these systems and nonlinearities in the interactions.  This project investigated a new class of algorithms called Generalized Approximate Message Passing (GAMP) that offer a computationally efficient and general methodology for approaching these problems.  The framework is based on representing a large system as a network of simple nonlinear system with linear interactions.  The GAMP algorithm then divides estimation or optimization into smaller, more tractable problems on these subsystems.\nThe project achieved several important outcomes for the development of the GAMP framework:\n-- Extensions to complex systems:  The initial GAMP framework, developed by the PI before the grant, considered only very simple systems:  estimation of an iid random vector x through noisy measurements of z=Ax.  Through the period of the grant extensions were developed for large numbers of problems including (i) matrix factorization, (ii) vectors with dependencies characterized via general graphical models, (iii) parametric uncertainty in the distributions and (iv) dynamics in the linear transforms.  These extensions enable the framework to much larger number of problems as illustrated in the applications below.\n-- Analysis on large random matrices:  We were able to mathematically prove that the algorithm is optimal in a range of problems.  For example, we obtained the first algorithm with provable consistency guarantees for linear-nonlinear cascade systems with parametric uncertainty.  The method also obtained optimal rank one recovery.  Optimality guarantees of this form are extremely rare for problems of this complexity.\n-- Convergence and stability:  A key obstacle for the algorithms was their convergence and stability.  While the algorithm illustrated very good performance on certain large random problems, initial versions of the algorithm could diverge for many practical problems.  We successfully developed several methods to improve the stability including damping, adaptive damping and ADMM-based optimization.  We obtained several first convergence results as well.\n-- Applications:  The GAMP method was successfully illustrated in several novel areas includingimage processing, non-parametric MRI and wireless interference problems and neural connectivity.  These problems involve systems that are all nonlinear, very large scale problems and the success of the GAMP method in these problems illustrates the method's success.\n\n\t\t\t\t\tLast Modified: 12/02/2015\n\n\t\t\t\t\tSubmitted by: Sundeep Rangan"
 }
}