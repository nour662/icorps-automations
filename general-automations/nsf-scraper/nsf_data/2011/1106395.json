{
 "awd_id": "1106395",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Problems in Bayesian Model Selection and Development and Analysis of Markov Chain Sampling Algorithms",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 239998.0,
 "awd_amount": 239998.0,
 "awd_min_amd_letter_date": "2011-08-13",
 "awd_max_amd_letter_date": "2011-08-13",
 "awd_abstract_narration": "Bayesian methods are now routinely used in very complex models, with posterior distributions estimated by Markov chain Monte Carlo (MCMC) methods.  There are two consequences to this.  First, complex Bayesian models are virtually always governed by some hyperparameters, which have a large impact on subsequent inference.  Therefore, there is now a strong need for methods that enable selection of these hyperparameters.  Second, the Markov chains used to estimate the posterior distributions now run in non-standard spaces, for example large function spaces, and there is a need for the development of MCMC methods that will work well in non-standard spaces.  The investigators develop methods for efficiently estimating marginal likelihoods for large number of hyperparameter values.  This will enable implementation of the empirical Bayes method, and also enables users to determine classes of hyperparameter values which constitute reasonable choices.  The exploration of intractable posterior distributions resulting from complex Bayesian models often requires MCMC.  Unfortunately, in contrast with classical Monte Carlo, establishing central limit theorems (CLTs) for MCMC estimators is not straightforward.  This is a serious practical problem because the ability to choose an appropriate MCMC sample size hinges upon the existence of a CLT.  The investigators use spectral methods to develop checkable sufficient conditions for CLTs as well as methods for comparing the asymptotic efficiency of MCMC algorithms with the same target distribution.  They apply the theoretical results to very concrete problems of model selection and assessment.\r\n\r\nModel selection in complex situations is an important and pervasive problem in scientific and medical research.  It includes in particular variable selection in regression, where a few important variables are to be selected from many candidates and used for understanding, prediction and decision making.  Different models can lead to different conclusions, with potential impact on public policy.  The investigators develop efficient computational methods for determining optimal models in complex settings.  The project has an educational component in that graduate students are involved in the research under the supervision of the investigators.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Hobert",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "James P Hobert",
   "pi_email_addr": "jhobert@stat.ufl.edu",
   "nsf_id": "000170306",
   "pi_start_date": "2011-08-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hani",
   "pi_last_name": "Doss",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Hani J Doss",
   "pi_email_addr": "doss@stat.ufl.edu",
   "nsf_id": "000183601",
   "pi_start_date": "2011-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "1523 UNION RD RM 207",
  "perf_city_name": "GAINESVILLE",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326111941",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 239998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Monte Carlo simulation is a methodology that uses random sampling to<br />arrive at numerical approximations to quantities that cannot be<br />computed exactly.&nbsp; The methodology allows researchers to use<br />extremely complex statistical models: if a potentially useful model<br />is so complicated that the solutions it provides cannot be computed,<br />the model can still be considered if one is willing to use<br />approximate solutions provided by Monte Carlo simulation.&nbsp; Generally<br />speaking, the longer the simulation, the more accurate are the<br />approximations.&nbsp; Recent advances in computing power have made Monte<br />Carlo simulation increasingly feasible, especially for problems<br />involving very large data sets.&nbsp; However, a key unsolved problem is<br />to determine the accuracy of the approximations that Monte Carlo<br />provides.<br /><br />Our research has produced two kinds of results.&nbsp; One of them is a<br />class of techniques for accurately quantifying the average<br />discrepancy between the approximation provided by Monte Carlo<br />simulation and the exact solution.&nbsp; The relevance of these results<br />is as follows.&nbsp; First, given a specific Monte Carlo procedure, the<br />ability to quantify the average error rate enables us to determine<br />how long we need to run the simulation to give acceptable results.<br />Second, given several competing Monte Carlo procedures, because we<br />can calculate the average error rate for each procedure, we can<br />select the optimal procedure, namely the one with the smallest<br />average error.&nbsp; Third, we can use our knowledge regarding error<br />rates to guide our development of new Monte Carlo procedures.<br /><br />The second class of results we have obtained pertain to variable<br />selection in regression.&nbsp; We consider the situation where we want to<br />relate a response variable to a set of p predictor variables.&nbsp; For<br />instance, in a medical situation the response might be a variable<br />indicating whether or not a patient benefited from a new treatment,<br />and the p predictor variables may be the activity levels for p genes<br />believed to be potentially related to the medical condition under<br />study.&nbsp; The goal is to select the predictor variables that are<br />actually do influence the response.&nbsp; Failing to include one or more<br />important predictors obviously gives rise to an inferior model,<br />while including irrelevant predictors gives rise to models that are<br />difficult to understand and are less useful.&nbsp; The standard<br />literature on variable selection has many procedures for choosing<br />the predictor variables.&nbsp; Each procedure gives rise to a single set<br />of variables to include.&nbsp; We have developed a method that does not<br />produce a single \"best\" model, but rather a list of possible best<br />models, together with uncertainty estimates: our methodology gives a<br />ranked list of models, where each model is presented together with<br />the probability that this is the best model.&nbsp; The benefits of this<br />is that someone analyzing the results of an experiment can interpret<br />the data from several different points of view, thus obtaining<br />insight that might be missed if one were to use only a single model.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/11/2015<br>\n\t\t\t\t\tModified by: Hani&nbsp;J&nbsp;Doss</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMonte Carlo simulation is a methodology that uses random sampling to\narrive at numerical approximations to quantities that cannot be\ncomputed exactly.  The methodology allows researchers to use\nextremely complex statistical models: if a potentially useful model\nis so complicated that the solutions it provides cannot be computed,\nthe model can still be considered if one is willing to use\napproximate solutions provided by Monte Carlo simulation.  Generally\nspeaking, the longer the simulation, the more accurate are the\napproximations.  Recent advances in computing power have made Monte\nCarlo simulation increasingly feasible, especially for problems\ninvolving very large data sets.  However, a key unsolved problem is\nto determine the accuracy of the approximations that Monte Carlo\nprovides.\n\nOur research has produced two kinds of results.  One of them is a\nclass of techniques for accurately quantifying the average\ndiscrepancy between the approximation provided by Monte Carlo\nsimulation and the exact solution.  The relevance of these results\nis as follows.  First, given a specific Monte Carlo procedure, the\nability to quantify the average error rate enables us to determine\nhow long we need to run the simulation to give acceptable results.\nSecond, given several competing Monte Carlo procedures, because we\ncan calculate the average error rate for each procedure, we can\nselect the optimal procedure, namely the one with the smallest\naverage error.  Third, we can use our knowledge regarding error\nrates to guide our development of new Monte Carlo procedures.\n\nThe second class of results we have obtained pertain to variable\nselection in regression.  We consider the situation where we want to\nrelate a response variable to a set of p predictor variables.  For\ninstance, in a medical situation the response might be a variable\nindicating whether or not a patient benefited from a new treatment,\nand the p predictor variables may be the activity levels for p genes\nbelieved to be potentially related to the medical condition under\nstudy.  The goal is to select the predictor variables that are\nactually do influence the response.  Failing to include one or more\nimportant predictors obviously gives rise to an inferior model,\nwhile including irrelevant predictors gives rise to models that are\ndifficult to understand and are less useful.  The standard\nliterature on variable selection has many procedures for choosing\nthe predictor variables.  Each procedure gives rise to a single set\nof variables to include.  We have developed a method that does not\nproduce a single \"best\" model, but rather a list of possible best\nmodels, together with uncertainty estimates: our methodology gives a\nranked list of models, where each model is presented together with\nthe probability that this is the best model.  The benefits of this\nis that someone analyzing the results of an experiment can interpret\nthe data from several different points of view, thus obtaining\ninsight that might be missed if one were to use only a single model.\n\n\t\t\t\t\tLast Modified: 11/11/2015\n\n\t\t\t\t\tSubmitted by: Hani J Doss"
 }
}