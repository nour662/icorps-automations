{
 "awd_id": "1111415",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CGV: Large: Collaborative Research: Analyzing Images Through Time",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 1028804.0,
 "awd_amount": 1028804.0,
 "awd_min_amd_letter_date": "2011-08-19",
 "awd_max_amd_letter_date": "2014-07-08",
 "awd_abstract_narration": "This collaborative research project leverages expertise of four research teams (IIS-1111415, Massachusetts Institute of Technology; IIS-1110955, Harvard University; IIS-1111398, Washington University; and IIS-1111534, Cornell University). Understanding time-varying processes and phenomena is fundamental to science and engineering. Due to tremendous progress in digital photography, images and videos (including images from webcams, time- lapse photography captured by scientists, surveillance videos, and Internet photo collections) are becoming an important source of information about our dynamic world. However, techniques for automated understanding and visualization of time-varying processes from images or videos are scarce and underdeveloped, requiring fundamental new models and algorithms for representing changes over time. This research involves creating systems that enable modeling, analysis, and visualization of time-varying processes based on image data. These models and algorithms will form the basis for a new set of tools that can help answer important questions about how our environment is changing, how our cities are evolving, and what significant events are happening around the world.\r\n\r\nAnalyzing images over time poses fundamental new technical challenges. This project focuses on developing and demonstrating end-to-end systems consisting of (1) novel representations necessary to model time-varying image datasets; (2) algorithms for estimating long-range temporal correspondence in image datasets; (3) algorithms for decomposing image datasets into intuitive primitives such as shading, illumination, reflectance, and motion; (4) analysis tools for deriving higher level information from the decomposed representations (e.g., trends, repeated patterns, and unusual events); and (5) tools for visualization of the high-level information and methods for re-synthesis of image data.\r\n\r\nThis work has the potential to have significant impact in a broad range of areas where images are generated over time, e.g., in ecology, astronomy, urban planning, health, and many others. The results of this research will be broadly disseminated by making source code and datasets publicly available via the project web site (https://groups.csail.mit.edu/vision/image_time/) and offering tutorials and organizing workshops at significant conferences. The project provides educational opportunities and offers hands-on collaborative research experience to students at both the undergraduate and graduate levels and the four institutions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Freeman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "William Freeman",
   "pi_email_addr": "wtf@ai.mit.edu",
   "nsf_id": "000418387",
   "pi_start_date": "2011-08-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Wojciech",
   "pi_last_name": "Matusik",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wojciech Matusik",
   "pi_email_addr": "wojciech@csail.mit.edu",
   "nsf_id": "000579272",
   "pi_start_date": "2011-08-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 901324.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 127480.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-7ecc99a5-67d6-b585-71ec-417aab990de3\">\n<p dir=\"ltr\"><span>Today, we can capture and share video on our cell phones with ease, we can set up webcams to record scenes for years at a time, and we can do a web search to find millions of photos of any city. Images and video are now a primary data type on the Web and in day-to-day human communication, and imagery is being captured all around the world at fantastic rates. What can we do with all of these images? Can we measure things in ways that were never before possible? Can we use all images ever captured as a new tool for science, for understanding and visualizing how things change?</span></p>\n<p dir=\"ltr\"><span>This award, &ldquo;Analyzing Images Through Time,&rdquo; brought together researchers from across several institutions to create new computational tools that can reveal changes in the world from images and video. This research explored many different aspects of change, at many different time scales. For instance, this award helped create:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>a &ldquo;motion microscope&rdquo; that can magnify tiny changes in a video that are normally impossible to see, such as a baby's stomach moving as it breathes, or the vibration of a pipe when struck by a hammer. These kinds of visualizations could help hospitals monitor patients, or engineers detect structural defects (see https://www.youtube.com/watch?v=e9ASH8IBJ2U). </span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>new methods for taking a webcam video of a scene, and automatic reconstructing a 3D model simply by observing how sunlight reflects off of objects. This capability provides new ways to measure and monitor buildings.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>new algorithms for building 3D models of dynamic places like Times Square from millions of photos downloaded from the Internet. These models enable a user to virtually fly through the reconstructed scene and view it from any vantage point, but also to adjust a time slider to see what it looked like at any moment in time (https://vimeo.com/105768016).</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>new apps for crowdsourced photography that can help researchers capture the same scene at many different times. These apps can be used, for example, to monitor all of the trees in a city.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>and new methods for measuring black holes from measurements taken at different times from a worldwide array of telescopes.</span></p>\n</li>\n</ul>\n<p dir=\"ltr\"><span>These are just a few examples of the work enabled by this grant. The resulting algorithms, software, and data also made major advances in computer vision and graphics, where analysis of time-varying imagery is becoming a key challenge. And the real-world applications of this work are numerous, from industrial inspection, to monitoring urban infrastructure, to ecological studies. For more information about all of these new results, please visit the project webpage at </span><a href=\"http://groups.csail.mit.edu/vision/image_time/\"><span>http://groups.csail.mit.edu/vision/image_time/</span></a><span>.</span></p>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/15/2016<br>\n\t\t\t\t\tModified by: William&nbsp;Freeman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nToday, we can capture and share video on our cell phones with ease, we can set up webcams to record scenes for years at a time, and we can do a web search to find millions of photos of any city. Images and video are now a primary data type on the Web and in day-to-day human communication, and imagery is being captured all around the world at fantastic rates. What can we do with all of these images? Can we measure things in ways that were never before possible? Can we use all images ever captured as a new tool for science, for understanding and visualizing how things change?\nThis award, \"Analyzing Images Through Time,\" brought together researchers from across several institutions to create new computational tools that can reveal changes in the world from images and video. This research explored many different aspects of change, at many different time scales. For instance, this award helped create:\n\n\na \"motion microscope\" that can magnify tiny changes in a video that are normally impossible to see, such as a baby's stomach moving as it breathes, or the vibration of a pipe when struck by a hammer. These kinds of visualizations could help hospitals monitor patients, or engineers detect structural defects (see https://www.youtube.com/watch?v=e9ASH8IBJ2U). \n\n\nnew methods for taking a webcam video of a scene, and automatic reconstructing a 3D model simply by observing how sunlight reflects off of objects. This capability provides new ways to measure and monitor buildings.\n\n\nnew algorithms for building 3D models of dynamic places like Times Square from millions of photos downloaded from the Internet. These models enable a user to virtually fly through the reconstructed scene and view it from any vantage point, but also to adjust a time slider to see what it looked like at any moment in time (https://vimeo.com/105768016).\n\n\nnew apps for crowdsourced photography that can help researchers capture the same scene at many different times. These apps can be used, for example, to monitor all of the trees in a city.\n\n\nand new methods for measuring black holes from measurements taken at different times from a worldwide array of telescopes.\n\n\nThese are just a few examples of the work enabled by this grant. The resulting algorithms, software, and data also made major advances in computer vision and graphics, where analysis of time-varying imagery is becoming a key challenge. And the real-world applications of this work are numerous, from industrial inspection, to monitoring urban infrastructure, to ecological studies. For more information about all of these new results, please visit the project webpage at http://groups.csail.mit.edu/vision/image_time/.\n\n\n \n\n\t\t\t\t\tLast Modified: 11/15/2016\n\n\t\t\t\t\tSubmitted by: William Freeman"
 }
}