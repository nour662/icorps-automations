{
 "awd_id": "1065632",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Medium: Collaborative Research: Information Theory and Statistical Inference from Large-Alphabet Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Richard Brown",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 369620.0,
 "awd_amount": 369620.0,
 "awd_min_amd_letter_date": "2011-08-08",
 "awd_max_amd_letter_date": "2011-08-08",
 "awd_abstract_narration": "Statistical analysis is key to many challenging applications such as text classification, speech recognition, and DNA analysis. However, often the amount of data available is comparable or even smaller than the set of symbols (alphabet) constituting the data. Unfortunately, not much is known about optimal inference in this so-called large-alphabet domain. Recently, several promising approaches have been developed by different scientific communities, including Bayesian nonparametrics in statistics and machine learning, universal compression in information theory, and the theory of graph limits in mathematics and computer science.\r\n\r\nThe investigators study the problem drawing from these multiple perspectives, but with a particular focus on developing the information theoretic approach. The research studies analytical properties of the \"pattern maximum likelihood'' estimator, which performs well in practice but is not understood theoretically, and also explores computational speedups. Moreover, it attempts to delineate which problem classes are better handled by Bayesian nonparametric techniques and which by the pattern approach, and explores links between these approaches. The investigators use the resulting theory for automatic document classification, allowing for more automation in storing, retrieving, and analyzing data. Furthermore, the investigators use the theory to study genetic variations, whose link with disease diagnosis is a crucial step in the systematic quantification of biology that is playing an increasingly important role in medical advancement. The research also brings new courses to the classroom, with a special outreach effort to involve women and under-represented minorities, including through the Native Hawaiian Science and Engineering Mentorship Program.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Narayana",
   "pi_last_name": "Santhanam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Narayana Santhanam",
   "pi_email_addr": "nsanthan@hawaii.edu",
   "nsf_id": "000524287",
   "pi_start_date": "2011-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Hawaii",
  "inst_street_address": "2425 CAMPUS RD SINCLAIR RM 1",
  "inst_street_address_2": "",
  "inst_city_name": "HONOLULU",
  "inst_state_code": "HI",
  "inst_state_name": "Hawaii",
  "inst_phone_num": "8089567800",
  "inst_zip_code": "968222247",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "HI01",
  "org_lgl_bus_name": "UNIVERSITY OF HAWAII",
  "org_prnt_uei_num": "",
  "org_uei_num": "NSCKLFSSABF2"
 },
 "perf_inst": {
  "perf_inst_name": "University of Hawaii",
  "perf_str_addr": "2425 CAMPUS RD SINCLAIR RM 1",
  "perf_city_name": "HONOLULU",
  "perf_st_code": "HI",
  "perf_st_name": "Hawaii",
  "perf_zip_code": "968222247",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "HI01",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 369620.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Statistical analysis in many applications today are challenging because they are undersampled. Conventional approaches perform estimation and inference with samples whose sizes are typically much larger than the number of parameters to be estimated. &nbsp;But today, there is also a requirement for inference and estimation using samples whose sizes are orders of magnitude smaller than is known to be feasible using conventional approaches.</p>\n<p>This project studied inference and estimation in this regime by drawing on multiple perspectives---an information theoretic approach using the notion of patterns of sequences and long standing statistical techniques based on exchangeability. One theme of work has been to obtain a deeper understanding of the connections between the two. To this end, the project quantified how estimators from one line of work measure up in the metrics used for the other. This highlighted the differences in emphasis between the two lines of work, also emphasizing when each technique performs better. We also leveraged the theory developed to build classification models that we adopted for biological data, to classify using clinical markers and protein expressions in cells whether leukemia patients would go into remission.</p>\n<p>A different kind of undersampling comes from mixing---best illustrated by trying to obtain news from social circles. In certain cases, news and opinions are polarized---in effect, people may sometimes be confined to \"echo chambers\" and may not be exposed to the totality of opinions and news that may be prevalent in a population. A good way to abstract out such models of disseminating information is via \"slow mixing\" random walks. &nbsp;We studied these in detail in the non-asymptotic regime, and our results published appear to be the first of their kind in emphasizing the non-asymptotic, data-derived regime.</p>\n<p>In all the problems above, the models used are much richer than can behandled in conventional means (technically speaking, they involve large alphabets or long memory or no mixing assumptions). Traditionally a lot of statistical guarantees for these problems involve \"eventually almost surely\" results---namely,estimators are good eventually. But we show that a catch in that kind of approach is that it may not always be possible to say, on any finite sample, whether or not the estimator is actually good---even when we know that its asymptotic limit is. Instead, we study in detail about when it is possible to be confident from the data that we have enough to estimate---namely, we either estimate correctly or wait for more samples, but never overreach and make claims that are not true. We believe this is an important foundation for future statistical work, and in future years, we will continue to develop on this even beyond the scope of the current project.</p>\n<p>The project emphasized several applications from biology. Apart from the classification of leukemia patients as mentioned before, we also adapted our models to estimate prevalences of epidemics by studying distribution modeling using samples corrupted with a sticky channel. The abstraction here captures different strains of a virusthat could be prevalent in different proportions (modeled by the distribution). We do not directly observe the virus strains of course,but we try to capture the same through observations of infections (the virulence now modeled by a sticky channel).</p>\n<p>Broader impacts<br />______________&nbsp;</p>\n<p>This project has supported numerous undergraduate projects (several of whom are both women and US persons) and led to 2 completed PhD theses, with one more being close to completion. Material from this project has been incorporated into machine learning, and communications courses at both the undergraduate and graduate level. In addition, broader principles uncovered by research done here are used to train incoming PhD students, and will be developed into self reading material for training in the data sciences to be used at UH Manoa. Finally, we have hosted several open houses to reach out to the general public, as well as worked with high school students on 6-week internships over summer to familiarize them with the notion of research, as well as helping them understand some of the basics of probability, statistics, programming and math.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/18/2017<br>\n\t\t\t\t\tModified by: Narayana&nbsp;Santhanam</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nStatistical analysis in many applications today are challenging because they are undersampled. Conventional approaches perform estimation and inference with samples whose sizes are typically much larger than the number of parameters to be estimated.  But today, there is also a requirement for inference and estimation using samples whose sizes are orders of magnitude smaller than is known to be feasible using conventional approaches.\n\nThis project studied inference and estimation in this regime by drawing on multiple perspectives---an information theoretic approach using the notion of patterns of sequences and long standing statistical techniques based on exchangeability. One theme of work has been to obtain a deeper understanding of the connections between the two. To this end, the project quantified how estimators from one line of work measure up in the metrics used for the other. This highlighted the differences in emphasis between the two lines of work, also emphasizing when each technique performs better. We also leveraged the theory developed to build classification models that we adopted for biological data, to classify using clinical markers and protein expressions in cells whether leukemia patients would go into remission.\n\nA different kind of undersampling comes from mixing---best illustrated by trying to obtain news from social circles. In certain cases, news and opinions are polarized---in effect, people may sometimes be confined to \"echo chambers\" and may not be exposed to the totality of opinions and news that may be prevalent in a population. A good way to abstract out such models of disseminating information is via \"slow mixing\" random walks.  We studied these in detail in the non-asymptotic regime, and our results published appear to be the first of their kind in emphasizing the non-asymptotic, data-derived regime.\n\nIn all the problems above, the models used are much richer than can behandled in conventional means (technically speaking, they involve large alphabets or long memory or no mixing assumptions). Traditionally a lot of statistical guarantees for these problems involve \"eventually almost surely\" results---namely,estimators are good eventually. But we show that a catch in that kind of approach is that it may not always be possible to say, on any finite sample, whether or not the estimator is actually good---even when we know that its asymptotic limit is. Instead, we study in detail about when it is possible to be confident from the data that we have enough to estimate---namely, we either estimate correctly or wait for more samples, but never overreach and make claims that are not true. We believe this is an important foundation for future statistical work, and in future years, we will continue to develop on this even beyond the scope of the current project.\n\nThe project emphasized several applications from biology. Apart from the classification of leukemia patients as mentioned before, we also adapted our models to estimate prevalences of epidemics by studying distribution modeling using samples corrupted with a sticky channel. The abstraction here captures different strains of a virusthat could be prevalent in different proportions (modeled by the distribution). We do not directly observe the virus strains of course,but we try to capture the same through observations of infections (the virulence now modeled by a sticky channel).\n\nBroader impacts\n______________ \n\nThis project has supported numerous undergraduate projects (several of whom are both women and US persons) and led to 2 completed PhD theses, with one more being close to completion. Material from this project has been incorporated into machine learning, and communications courses at both the undergraduate and graduate level. In addition, broader principles uncovered by research done here are used to train incoming PhD students, and will be developed into self reading material for training in the data sciences to be used at UH Manoa. Finally, we have hosted several open houses to reach out to the general public, as well as worked with high school students on 6-week internships over summer to familiarize them with the notion of research, as well as helping them understand some of the basics of probability, statistics, programming and math.\n\n\t\t\t\t\tLast Modified: 01/18/2017\n\n\t\t\t\t\tSubmitted by: Narayana Santhanam"
 }
}