{
 "awd_id": "1117939",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small:  Computational Tools for Visual Inference of Complex Materials",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 499851.0,
 "awd_amount": 531851.0,
 "awd_min_amd_letter_date": "2011-08-08",
 "awd_max_amd_letter_date": "2014-05-20",
 "awd_abstract_narration": "Central to the imaging process is the interaction of light with the objects in the scene. Remarkable progress has been made over the past several hundred years on solving inference problems (such as detection, classification, or estimation) for a large class of objects constructed from simple materials with Lambertian reflectance. Such objects scatter light such that the apparent brightness is invariant to the observer's view angle. Unfortunately, real world objects are made of considerably more complex materials that cannot be characterized in terms of such an isotropic reflectance. While humans are able to effortlessly reason about complex materials, today's image analysis and processing algorithms fail miserably. The reason is that complex, non-Lambertian materials can be characterized only by higher-dimensional functions that are relatively poorly understood and even more poorly modeled. \r\n\r\nThis research is developing new ways to model, capture, and process the rich reflectance patterns of complex materials.  The key tool is the object's plenoptic transport function, which describes the transformation of the incident to the irradiated light due to the properties of the material. In full generality, the plenoptic transport function is 14-dimensional; hence, a fundamental complication for sensing, analysis, and processing systems for complex materials is the dimensionality gap between the high dimensional plenoptic function and the ability of most conventional sensors (cameras) to acquire at best 2D or 3D image projections.  The tools and techniques under development include sparse and manifold models (to bridge the dimensionality gap), geometric features (to mitigate the presence of environmental illumination and other nuisance parameters), and new sensor designs (to most efficiently acquire plenoptic information from natural scenes).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ashok",
   "pi_last_name": "Veeraraghavan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ashok Veeraraghavan",
   "pi_email_addr": "Ashok.Veeraraghavan@gmail.com",
   "nsf_id": "000583333",
   "pi_start_date": "2011-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Baraniuk",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Richard G Baraniuk",
   "pi_email_addr": "richb@rice.edu",
   "nsf_id": "000334750",
   "pi_start_date": "2011-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Aswin",
   "pi_last_name": "Sankaranarayanan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aswin Sankaranarayanan",
   "pi_email_addr": "as48@rice.edu",
   "nsf_id": "000584357",
   "pi_start_date": "2011-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "6100 MAIN ST",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  },
  {
   "pgm_ele_code": "793600",
   "pgm_ele_name": "SIGNAL PROCESSING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 499851.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Central to the imaging process is the interaction of light with the objects in the scene. Remarkable progress has been made over the past several hundred years on solving inference problems (such as detection, classification, or estimation) for a large class of objects constructed from simple materials with Lambertian reflectance. Such objects feature isotropic reflectance and thus scatter light such that the apparent brightness is invariant to the observer&rsquo;s view angle. Unfortunately, real world objects are made of considerably more complex materials that cannot be characterized in terms of an isotropic reflectance. While humans are able to effortlessly reason about complex materials, today&rsquo;s image analysis and processing algorithms fail miserably. The reason is that complex, non-Lambertian materials can be characterized only by higher-dimensional functions that are relatively poorly understood and even more poorly modeled. The rich and complex reflectance patterns of complex materials are captured by the object&rsquo;s plenoptic transport function which describes the transformation of the incident to the irradiated light due to the properties of the material.</p>\n<p>&nbsp;</p>\n<p>In full generality, the plenoptic transport function is 14-dimensional; hence, a fundamental complication for sensing, analysis, and processing systems for complex materials is the dimensionality gap between the high dimensional plenoptic function and the ability of most conventional sensors (cameras) to acquire at best 2D or 3D image projections. If not dealt with correctly, the dimensionality gap leads to information loss and ultimately algorithm performance degradation.</p>\n<p>&nbsp;</p>\n<p>In this project, we developed new signal models, inference algorithms, and sensors for complex, non-Lambertian materials and scenes. Our inter-disciplinary research program exploited signal processing, computational imaging, and computer vision concepts and was organized into four inter-related research thrusts:</p>\n<p>(a) Sparse models: Complex material characteristics lead to higher-dimensional visual representations that can be approximated as sparse using an appropriate transformation. We extended the rich theoretical ideas in compressive sensing and sparse approximation towards</p>\n<p>understanding of complex materials.</p>\n<p>(b) Manifold models: Even materials with complex characteristics are constrained by laws of physics &ndash; the laws governing reflection, refraction, polarization, absorption such as Snell&rsquo;s law, conservation of energy, etc. These constraints imply that, in spite of a high dimensional characterization, these functions lie on low dimensional manifolds. We developed appropriate visual manifold models that are suited to complex materials and enable tractable analysis and inference of such materials.</p>\n<p>(c) Geometric features: Simple Lambertian materials have long been characterized using photometric features, but such features do not extend directly to complex materials due to the impact of environmental illumination and other nuisance parameters. We developed a new class of geometric features that are inherently insensitive to these nuisance parameters and hence enable tractable and robust inference on complex materials.</p>\n<p>(d) New sensor hardware designs: We designed new computational imaging systems that acquire measurements of the plenoptic transport function that are optimal for different inference tasks.</p>\n<p>&nbsp;</p>\n<p><strong>Broader impact:</strong> The results of this research program have the potential for far-reaching impact on a wide range of applications spanning consumer imaging, machine vision and automation, scientific/medical imaging, robotic vision and surveillance, satellite imaging, microscopy, and remote sensing. The PIs have ongoing collaborations in these areas and will work to increase the immediate impact of the research to these areas. The PIs have integrated their research into several signal processing, image processing and imaging courses offered at Rice University and beyond. This project has directly or indirectly led to the PIS filing several invention disclosures and preliminary patent filings. We have integrated the research outcomes of this project into various vision and imaging courses offered at Rice University and CMU. We have involved more than 6 undergraduate students as summer researchers in various efforts related to this project. We have also conducted several workshops, short courses and tutorials in premier conferences such as CVPR, ICCV and SIGGRAPH and disseminated the research results broadly through these workshops and tutorials. We have co-authored 3 articles in the IEEE Signal Processing Magazine to disseminate the results to a much wider technical audience than reached by traditional conferences and workshops. Our worl on lensless imaging was featured in an NPR broadcast and was also picked by popular science and news website including NBC, futurity, etc.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2016<br>\n\t\t\t\t\tModified by: Ashok&nbsp;Veeraraghavan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCentral to the imaging process is the interaction of light with the objects in the scene. Remarkable progress has been made over the past several hundred years on solving inference problems (such as detection, classification, or estimation) for a large class of objects constructed from simple materials with Lambertian reflectance. Such objects feature isotropic reflectance and thus scatter light such that the apparent brightness is invariant to the observer?s view angle. Unfortunately, real world objects are made of considerably more complex materials that cannot be characterized in terms of an isotropic reflectance. While humans are able to effortlessly reason about complex materials, today?s image analysis and processing algorithms fail miserably. The reason is that complex, non-Lambertian materials can be characterized only by higher-dimensional functions that are relatively poorly understood and even more poorly modeled. The rich and complex reflectance patterns of complex materials are captured by the object?s plenoptic transport function which describes the transformation of the incident to the irradiated light due to the properties of the material.\n\n \n\nIn full generality, the plenoptic transport function is 14-dimensional; hence, a fundamental complication for sensing, analysis, and processing systems for complex materials is the dimensionality gap between the high dimensional plenoptic function and the ability of most conventional sensors (cameras) to acquire at best 2D or 3D image projections. If not dealt with correctly, the dimensionality gap leads to information loss and ultimately algorithm performance degradation.\n\n \n\nIn this project, we developed new signal models, inference algorithms, and sensors for complex, non-Lambertian materials and scenes. Our inter-disciplinary research program exploited signal processing, computational imaging, and computer vision concepts and was organized into four inter-related research thrusts:\n\n(a) Sparse models: Complex material characteristics lead to higher-dimensional visual representations that can be approximated as sparse using an appropriate transformation. We extended the rich theoretical ideas in compressive sensing and sparse approximation towards\n\nunderstanding of complex materials.\n\n(b) Manifold models: Even materials with complex characteristics are constrained by laws of physics &ndash; the laws governing reflection, refraction, polarization, absorption such as Snell?s law, conservation of energy, etc. These constraints imply that, in spite of a high dimensional characterization, these functions lie on low dimensional manifolds. We developed appropriate visual manifold models that are suited to complex materials and enable tractable analysis and inference of such materials.\n\n(c) Geometric features: Simple Lambertian materials have long been characterized using photometric features, but such features do not extend directly to complex materials due to the impact of environmental illumination and other nuisance parameters. We developed a new class of geometric features that are inherently insensitive to these nuisance parameters and hence enable tractable and robust inference on complex materials.\n\n(d) New sensor hardware designs: We designed new computational imaging systems that acquire measurements of the plenoptic transport function that are optimal for different inference tasks.\n\n \n\nBroader impact: The results of this research program have the potential for far-reaching impact on a wide range of applications spanning consumer imaging, machine vision and automation, scientific/medical imaging, robotic vision and surveillance, satellite imaging, microscopy, and remote sensing. The PIs have ongoing collaborations in these areas and will work to increase the immediate impact of the research to these areas. The PIs have integrated their research into several signal processing, image processing and imaging courses offered at Rice University and beyond. This project has directly or indirectly led to the PIS filing several invention disclosures and preliminary patent filings. We have integrated the research outcomes of this project into various vision and imaging courses offered at Rice University and CMU. We have involved more than 6 undergraduate students as summer researchers in various efforts related to this project. We have also conducted several workshops, short courses and tutorials in premier conferences such as CVPR, ICCV and SIGGRAPH and disseminated the research results broadly through these workshops and tutorials. We have co-authored 3 articles in the IEEE Signal Processing Magazine to disseminate the results to a much wider technical audience than reached by traditional conferences and workshops. Our worl on lensless imaging was featured in an NPR broadcast and was also picked by popular science and news website including NBC, futurity, etc.\n\n \n\n\t\t\t\t\tLast Modified: 10/31/2016\n\n\t\t\t\t\tSubmitted by: Ashok Veeraraghavan"
 }
}