{
 "awd_id": "1106518",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Fourier Methods in the Analysis of nonstationary and nonlinear stochastic processes",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 127137.0,
 "awd_amount": 127137.0,
 "awd_min_amd_letter_date": "2011-06-23",
 "awd_max_amd_letter_date": "2011-06-23",
 "awd_abstract_narration": "The investigator develops new Fourier based methods for analyzing nonstationary and nonlinear time series. Fourier analysis is the well established de facto tool for analyzing linear, stationary time series. There are several reasons for this (i) the discrete Fourier transform asymptotically uncorrelates a stationary time series (ii) if the time series is stationary and linear, then estimates of the spectral density function can be used to identify the underlying linear model (iii) the spectral density function can be used as a means of checking goodness of fit of a linear model. However, it has long been observed that several time series models do not fit well within the stationary, linear model framework. Over long periods of time the assumption of stationarity is often quite unrealistic.  Even over short periods of time, the assumption of linearity can be too strong. Applying standard Fourier methods to such data can lead to uninformative and misleading conclusions. But in contrast to linear models, there does not exist universal methods for comparing non-nested, nonlinear models, checking adequacy of any given model, etc. As increasingly complex time series models are introduced, it has become increasingly important to develop such methods, and the investigator addresses these issues. The investigator focuses on three areas where, in applications, nonstationarity and nonlinearity can arise (i) nonstationary discrete time stochastic processes (ii) functional time series with random sampling (iii) nonlinear, stationary time series. These are detailed below. In the first project the investigator exploits the fact that the discrete Fourier transform only decorrelates second order stationary time series to characterize and model nonstationary behavior. In the second project the investigator considers continuous time series, which are only observed at discrete, randomly sampled time points. Here the focus is on functional time series, and the investigator defines a modified version of the discrete Fourier transform to test for stationarity and to develop goodness of fit tests. As mentioned above, often the assumption of linearity can be too strong, and in the third project the investigator considers stationary time series' which are not necessarily linear. The investigator defines a variant of the spectral density which captures the pair-wise dependence structure of a time series. This transformation allows one to understand the dependence structure of the time series on different parts of the domain of the time series. Using this transformation the investigator checks for model adequacy, tests for equality of pair-wise dependence between two time series and measures the dependence between two time series through an appropriate transformations of the data.  \r\n\r\nThe analysis of data which is observed over time (usually called a time series) is studied in several disciplines, including the atmospheric sciences, economics etc. As the observations are over time, usually there is dependence (a simple measure of dependence is correlation) between neighboring observations. Understanding and modeling this dependence allows one to forecast (for example, future global temperatures) and compare various different time series (for example, different financial markets). Under the assumption that the time series is stationary (the overall structure does not change over time), and linear (the transition in the times series is smooth), a rich literature on modeling the correlation structure exists. However, there are several real data examples where there are no realistic reasons that these assumptions should hold true, and indeed they could be an oversimplification of the system or simply wrong. In this project, the investigator develops statistical tools which allows one to check whether a time series satisfies the usual assumptions, and if not, how they may violate these assumptions, what impact this may have on standard statistical analysis and how it may effect the conclusions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Suhasini",
   "pi_last_name": "Subba Rao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Suhasini Subba Rao",
   "pi_email_addr": "suhasini@stat.tamu.edu",
   "nsf_id": "000492958",
   "pi_start_date": "2011-06-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Research Foundation",
  "inst_street_address": "400 HARVEY MITCHELL PKWY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M RESEARCH FOUNDATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "EQH8NQ4AXFT7"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University",
  "perf_str_addr": "400 HARVEY MITCHELL PKY S STE 300",
  "perf_city_name": "COLLEGE STATION",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778454375",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 127137.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br />In both time series and spatial data it is important to identify heterogeneities.&nbsp;Heterogeneity in the data usually suggest the influence of &nbsp;external factors, and these need to be taken into account when fitting models to the data. These models are of vital important as they often used&nbsp;in forecasting future events or making predictions at unobserved locations. Besides the statistical need to detect heterogeneities, heterogeneity in the data also convey important information about the dynamics that underline the data and influence the decision process. Examples include (i) heterogeneity in the financial markets (similar to the events of 2008) can fortell a crisis (ii) heterogeneity in climate data is an indicator of climate change (iii) heterogenity in ground ozone levels may suggest the influence of several external factors in the generation of the ground ozone and (iv) heterogeneity in the permeability of rock in a petroleum reservoir makes recovery of oil substantially more expensive and&nbsp;can mean the reservoir is not drilled.&nbsp;<br />The technical term for homogeneity and heterogeneity in statistics is stationary and nonstationary respectively. And the examples above provide my main motivation for detecting of nonstationarity.</p>\n<p>One of the primary objectives of this project was to develop practitioner friendly&nbsp;methods for detecting nonstationarity over space or time. Of course, &nbsp;in a few applications, it is clear that a data set is nonstationarity and there is no need to detect it.&nbsp;However, there are several applications where it is not possible `see the nonstationarity'. This requires one to develop delicate methods for detecting subtle deviations from stationarity - recalling that apriori we may not know where these deviations occur. &nbsp;</p>\n<p>Therefore the main contribution of this project was to</p>\n<p>1. Develop methods for detecting nonstationarity over time.</p>\n<p>2. Develop methods for detecting nonstationarity over space where the locations are &nbsp;irregular.&nbsp;</p>\n<p>3. The methods above above required us to develop rather sophisticated theory (even though the methods themselves were rather simple), in order to to obtain simple methods for distinguishing stationarity from nonstationarity.</p>\n<p>Now we illustrate how our methods can be applied. &nbsp;Tropospheric ozone (ground ozone) is a major constituent of photochemical smog. It is&nbsp;a powerful oxidant that damages human health and natural ecosystems. It is also an important greenhouse gas. Unlike many other pollutants ozone is not directly emitted - it is a secondary&nbsp;pollutant formed by sunlight-driven chemical reactions involving carbon monoxide, VOC and nitrogen oxide. The concentration of ozone in any given location and time depends on several factors, including the existence of heavy industry, density of vehicles and weatherfactors, in particular high temperatures (which drive the chemical reaction) but also wind (which can spread the ozone). Understand its dynamics is of primary importance. In the primary image we give the ground ozone levels in the Ohio Central Valley on the days 4th and 6th April 2014. Visually it is &nbsp;difficult to distinguish between the two. However, our test for April 4th gives a p-value which is greater than 30% whereas April 6th get a p-value of about 1%. This means there is a 1% chance of getting the April 6th data when the mechanism generated the ozone is stationary. This suggests that the possibility that the process underlying the April 6th data is nonstationary, whereas this does not appear to be the case for the April 4th data. However, a further analysis using the diagnostic plots (see the other image) points at some further interesting features. The `dark' colours in the plot suggest certain `statistically significant' nonstationary features. As we would expect the 6th April diagnostic plot ...",
  "por_txt_cntn": "\n\nIn both time series and spatial data it is important to identify heterogeneities. Heterogeneity in the data usually suggest the influence of  external factors, and these need to be taken into account when fitting models to the data. These models are of vital important as they often used in forecasting future events or making predictions at unobserved locations. Besides the statistical need to detect heterogeneities, heterogeneity in the data also convey important information about the dynamics that underline the data and influence the decision process. Examples include (i) heterogeneity in the financial markets (similar to the events of 2008) can fortell a crisis (ii) heterogeneity in climate data is an indicator of climate change (iii) heterogenity in ground ozone levels may suggest the influence of several external factors in the generation of the ground ozone and (iv) heterogeneity in the permeability of rock in a petroleum reservoir makes recovery of oil substantially more expensive and can mean the reservoir is not drilled. \nThe technical term for homogeneity and heterogeneity in statistics is stationary and nonstationary respectively. And the examples above provide my main motivation for detecting of nonstationarity.\n\nOne of the primary objectives of this project was to develop practitioner friendly methods for detecting nonstationarity over space or time. Of course,  in a few applications, it is clear that a data set is nonstationarity and there is no need to detect it. However, there are several applications where it is not possible `see the nonstationarity'. This requires one to develop delicate methods for detecting subtle deviations from stationarity - recalling that apriori we may not know where these deviations occur.  \n\nTherefore the main contribution of this project was to\n\n1. Develop methods for detecting nonstationarity over time.\n\n2. Develop methods for detecting nonstationarity over space where the locations are  irregular. \n\n3. The methods above above required us to develop rather sophisticated theory (even though the methods themselves were rather simple), in order to to obtain simple methods for distinguishing stationarity from nonstationarity.\n\nNow we illustrate how our methods can be applied.  Tropospheric ozone (ground ozone) is a major constituent of photochemical smog. It is a powerful oxidant that damages human health and natural ecosystems. It is also an important greenhouse gas. Unlike many other pollutants ozone is not directly emitted - it is a secondary pollutant formed by sunlight-driven chemical reactions involving carbon monoxide, VOC and nitrogen oxide. The concentration of ozone in any given location and time depends on several factors, including the existence of heavy industry, density of vehicles and weatherfactors, in particular high temperatures (which drive the chemical reaction) but also wind (which can spread the ozone). Understand its dynamics is of primary importance. In the primary image we give the ground ozone levels in the Ohio Central Valley on the days 4th and 6th April 2014. Visually it is  difficult to distinguish between the two. However, our test for April 4th gives a p-value which is greater than 30% whereas April 6th get a p-value of about 1%. This means there is a 1% chance of getting the April 6th data when the mechanism generated the ozone is stationary. This suggests that the possibility that the process underlying the April 6th data is nonstationary, whereas this does not appear to be the case for the April 4th data. However, a further analysis using the diagnostic plots (see the other image) points at some further interesting features. The `dark' colours in the plot suggest certain `statistically significant' nonstationary features. As we would expect the 6th April diagnostic plot contains a larger number of dark points than the 4th of April plot.  However, the 4th April plot does contain a few dark points. This suggests that may be there is still some undercur..."
 }
}