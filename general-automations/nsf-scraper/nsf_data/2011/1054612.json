{
 "awd_id": "1054612",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Content-Based Image and Video Coding Using Higher-Level Models of Human Vision",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2011-02-01",
 "awd_exp_date": "2015-06-30",
 "tot_intn_awd_amt": 400311.0,
 "awd_amount": 328244.0,
 "awd_min_amd_letter_date": "2011-02-02",
 "awd_max_amd_letter_date": "2015-07-07",
 "awd_abstract_narration": "Abstract #1054687\r\nCurrent methods of image and video coding are effective largely because they capitalize on low-level aspects of the human visual system (HVS). The single most predominant strategy is to place the errors into regions which can better hide the compression artifacts, an approach which can be guided by computational models of early/low-level HVS processing. The inherent assumption in this approach is that the consumer is looking for the distortion in the presence of the image. However, in actuality, the consumer is looking at the image in the presence of possible distortion, which is a fundamentally different perceptual task that requires a fundamentally different HVS model. Next-generation coding schemes which can take into account higher-level aspects such as content-adaptive masking; perceptual importance across space, frequency, and time; and elements of cognition; have the potential to dramatically reduce storage and bandwidth requirements while maximizing visual quality and the overall multimedia experience. In this project, the investigator researches how compression artifacts influence the HVS's ability to process and interpret images and video. Three main areas are investigated: (1) new models of visual masking which take into account image recognition; (2) appearance-preserving strategies of data quantization; and (3) analysis and quantization strategies which honor rules of visual cognition derived from quality-rating experiments coupled with eye-tracking. This research is integrated with an educational component that promotes student development in applying knowledge of human vision to engineering problems. Two new interdisciplinary graduate-level courses, an interdisciplinary summer workshop, and undergraduate research projects and curriculum reform are made available to students. Two multimedia-driven competitions that expose K-12 students and undergraduates to image-processing research are also made available.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Damon",
   "pi_last_name": "Chandler",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Damon M Chandler",
   "pi_email_addr": "damon.chandler@okstate.edu",
   "nsf_id": "000243712",
   "pi_start_date": "2011-02-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oklahoma State University",
  "inst_street_address": "401 WHITEHURST HALL",
  "inst_street_address_2": "",
  "inst_city_name": "STILLWATER",
  "inst_state_code": "OK",
  "inst_state_name": "Oklahoma",
  "inst_phone_num": "4057449995",
  "inst_zip_code": "740781031",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OK03",
  "org_lgl_bus_name": "OKLAHOMA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNYDFK5FTSX9"
 },
 "perf_inst": {
  "perf_inst_name": "Oklahoma State University",
  "perf_str_addr": "401 WHITEHURST HALL",
  "perf_city_name": "STILLWATER",
  "perf_st_code": "OK",
  "perf_st_name": "Oklahoma",
  "perf_zip_code": "740781031",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OK03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 156503.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 161310.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 10430.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Images and videos in digital format have revolutionized the way in which we access and share imagery. An important but lesser-known fact is that all images and videos must be digitally compressed in order to make their data sizes practical for storage and transmission. Digital compression operates by searching for and storing repetitions in the data using short, unique symbols. For images and videos, this compression is made even more aggressive by allowing the data to be approximated, which permits the use of even shorter symbols, but at the cost of approximation errors (so called &ldquo;compression artifacts&rdquo;) that lower the visual quality. A major goal in image and video compression research is to find new approximations that simultaneously minimize the total length of the symbols and maximize the visual quality.</p>\n<p>The research supported by this award was designed to study and model how our human visual system perceives compression artifacts and particularly how this visual perception is affected by characteristics of the image/video, and to apply the findings toward the development of content-adaptive perceptual compression technology. The results of our experiments yielded a number of new insights on the relations between measurable properties of images and videos and how the compression artifacts influence the visual quality. In particular, we found that the visibility of compression artifacts is not only influenced by the characteristics of the artifacts themselves, but is also highly influenced by properties such as the image&rsquo;s or video&rsquo;s brightness, contrast, pattern, motion, recognizability, category, depth, and combinations of these properties. We also found that the relationship between the visibility of the artifacts and the resulting visual quality of the image or video is highly content-dependent. These experiments yielded several important image/video databases to provide crucial ground-truth data for future studies. This research also yielded new visual perception models, and the applications of such models for improved compression and automated quality prediction. We also gained important insights on what it takes to make the models operate more quickly on typical home computers.</p>\n<p>The educational and outreach efforts supported by this award were designed to raise awareness of the importance of taking into account the human visual system when designing new engineering applications. Students from elementary school through high school (and their parents/grandparents) were exposed to perception-based technology via hands-on workshops. College students were exposed to perception-based signal-processing via new course modules and independent projects. Researchers and practitioners from the broader engineering community were exposed via a special conference session and invited talks.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/27/2015<br>\n\t\t\t\t\tModified by: Damon&nbsp;M&nbsp;Chandler</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nImages and videos in digital format have revolutionized the way in which we access and share imagery. An important but lesser-known fact is that all images and videos must be digitally compressed in order to make their data sizes practical for storage and transmission. Digital compression operates by searching for and storing repetitions in the data using short, unique symbols. For images and videos, this compression is made even more aggressive by allowing the data to be approximated, which permits the use of even shorter symbols, but at the cost of approximation errors (so called \"compression artifacts\") that lower the visual quality. A major goal in image and video compression research is to find new approximations that simultaneously minimize the total length of the symbols and maximize the visual quality.\n\nThe research supported by this award was designed to study and model how our human visual system perceives compression artifacts and particularly how this visual perception is affected by characteristics of the image/video, and to apply the findings toward the development of content-adaptive perceptual compression technology. The results of our experiments yielded a number of new insights on the relations between measurable properties of images and videos and how the compression artifacts influence the visual quality. In particular, we found that the visibility of compression artifacts is not only influenced by the characteristics of the artifacts themselves, but is also highly influenced by properties such as the image\u00c6s or video\u00c6s brightness, contrast, pattern, motion, recognizability, category, depth, and combinations of these properties. We also found that the relationship between the visibility of the artifacts and the resulting visual quality of the image or video is highly content-dependent. These experiments yielded several important image/video databases to provide crucial ground-truth data for future studies. This research also yielded new visual perception models, and the applications of such models for improved compression and automated quality prediction. We also gained important insights on what it takes to make the models operate more quickly on typical home computers.\n\nThe educational and outreach efforts supported by this award were designed to raise awareness of the importance of taking into account the human visual system when designing new engineering applications. Students from elementary school through high school (and their parents/grandparents) were exposed to perception-based technology via hands-on workshops. College students were exposed to perception-based signal-processing via new course modules and independent projects. Researchers and practitioners from the broader engineering community were exposed via a special conference session and invited talks.\n\n\t\t\t\t\tLast Modified: 09/27/2015\n\n\t\t\t\t\tSubmitted by: Damon M Chandler"
 }
}