{
 "awd_id": "1111943",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Large: Domain Specific Language Infrastructure for Biological Simulation Software",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2011-07-15",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 1770669.0,
 "awd_amount": 1770669.0,
 "awd_min_amd_letter_date": "2011-07-13",
 "awd_max_amd_letter_date": "2016-05-19",
 "awd_abstract_narration": "Biophysics simulation helps biomedical researchers understand the physical constraints on biological systems as they engineer novel drugs, synthetic tissues, medical devices, and surgical interventions. However, writing high-performance biophysics simulation software for modern parallel computer hardware is a challenging problem. This research project will solve this problem by developing a new generation of biophysics simulation software that is optimized for complex high-performance computer hardware. The project will develop this software using a family of domain specific languages (DSLs). A DSL is a concise programming language with a syntax that is designed to naturally express the semantics of a narrow problem domain. Biophysics simulation DSLs will be used to improve the productivity of simulation software developers and the efficiency and performance of the resulting software by enabling the DSL implementation to take advantage of high-level domain-specific optimizations that are inaccessible to general-purpose compilers and general-purpose languages. The simulation technology built from the family of biophysics simulation DSLs will be used to solve the important biological problems of developing new neuroprosthetics, combating viral infections, effective drug discovery, and understanding drug side effects. In addition, this research will expose students at the graduate and undergraduate level to the role that domain-specific languages play in computing in general and biophysics simulation in particular.\r\n\r\nThe biophysics simulation DSLs will be developed with a general DSL infrastructure. This infrastructure will make use of polymorphic embeddings, multi-stage compilation, and parallel execution patterns to implement the high-level, implicitly parallel DSLs in a common host language. The DSL infrastructure will simplify DSL development by providing a reusable framework for parallelism and domain-specific optimization. When completed, this infrastructure will allow scientists in other application domains to create and use their own high-performance DSLs, in the same manner that this research uses the infrastructure to develop DSLs for biophysics simulation. The result will be a new generation of DSLs in a number of domains that provide high-productivity application development and high-performance on modern heterogeneous parallel hardware such as multicore microprocessors, GPUs and distributed systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oyekunle",
   "pi_last_name": "Olukotun",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Oyekunle A Olukotun",
   "pi_email_addr": "kunle@stanford.edu",
   "nsf_id": "000320046",
   "pi_start_date": "2011-07-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Aiken",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Aiken",
   "pi_email_addr": "aiken@cs.stanford.edu",
   "nsf_id": "000281933",
   "pi_start_date": "2011-07-13",
   "pi_end_date": "2016-05-19"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Patrick",
   "pi_last_name": "Hanrahan",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Patrick M Hanrahan",
   "pi_email_addr": "hanrahan@cs.stanford.edu",
   "nsf_id": "000333801",
   "pi_start_date": "2011-07-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Russ",
   "pi_last_name": "Altman",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Russ B Altman",
   "pi_email_addr": "Russ.Altman@stanford.edu",
   "nsf_id": "000163179",
   "pi_start_date": "2011-07-13",
   "pi_end_date": "2016-05-19"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Vijay",
   "pi_last_name": "Pande",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Vijay S Pande",
   "pi_email_addr": "pande@stanford.edu",
   "nsf_id": "000155807",
   "pi_start_date": "2011-07-13",
   "pi_end_date": "2016-05-19"
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "450 JANE STANFORD WAY",
  "perf_city_name": "STANFORD",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 1770669.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p>Developing high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising way to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. We have developed the Delite compiler framework and the associated DSLs. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We have developed Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and have shown that they all achieve performance competitive to or exceeding manually generated C++ code.&nbsp;</p>\n<p>The Delite framework is the first system to provide a single system and programming model that is optimized both for modern hardware (high performance) and for modern programmers (high productivity). The Delite system is capable of running a variety of parallel applications, providing sequential baseline performance comparable to hand-optimized implementations, and continues to function well both as more resources are added to a single machine with multicore, NUMA and GPU (scale up) and as more machines are interconnected with clusters (scale out).</p>\n<p>We have identified several features useful for implementing real-world applications that are common in traditional programming models but various parallel systems have chosen to sacrifice. These features include rich data parallelism, the ability to use and compose a rich set of data-parallel operations beyond the classic map and reduce; and nested programming, the ability to logically nest parallel constructs. Many systems require a different (sequential) programming model within parallel computation. Even if parallel constructs can be logically nested, the system may or may not actually be capable of exploiting all levels of parallelism at runtime; we refer to this as nested parallelism. Systems that support multiple collections allow parallel computations to directly consume more than one parallel collection rather than having to first join the collections in some fashion. This is very useful in certain domains, e.g., linear algebra. Finally random reads allow arbitrary read access patterns of parallel collections rather than restricting reads to only the local element, which is very useful in, e.g., graph analytics. All previous systems have been forced to sacrifice many of these features in exchange for expanding to more complex hardware targets. We have shown that it is possible to retain all these features of a productive programming model and still attain high-performance on heterogeneous hardware (multicore, NUMA, GPU, clusters, and FPGAs).</p>\n<p>The broader impacts of high performance DSLs are that they enable other scientists to quickly analyze large data sets. Two examples of where Delite DSLs have had an impact are on protein folding analytics (Folding at home) and the knowledge base building work (DeepDive), which has been used to analyze gene-drug interactions.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n</div>\n</div>\n</div>\n</div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2016<br>\n\t\t\t\t\tModified by: Oyekunle&nbsp;A&nbsp;Olukotun</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490343618_Delite3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490343618_Delite3--rgov-800width.jpg\" title=\"MSM Builder\"><img src=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490343618_Delite3--rgov-66x44.jpg\" alt=\"MSM Builder\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">MSM Builder Using OptiML</div>\n<div class=\"imageCredit\">Kunle Olukotun</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Oyekunle&nbsp;A&nbsp;Olukotun</div>\n<div class=\"imageTitle\">MSM Builder</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490235425_Delite2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490235425_Delite2--rgov-800width.jpg\" title=\"Delite Overview\"><img src=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490235425_Delite2--rgov-66x44.jpg\" alt=\"Delite Overview\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Delite Overview</div>\n<div class=\"imageCredit\">Kunle Olukotun</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Oyekunle&nbsp;A&nbsp;Olukotun</div>\n<div class=\"imageTitle\">Delite Overview</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490075484_Delite1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490075484_Delite1--rgov-800width.jpg\" title=\"Delite DSLs\"><img src=\"/por/images/Reports/POR/2016/1111943/1111943_10107940_1480490075484_Delite1--rgov-66x44.jpg\" alt=\"Delite DSLs\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Delite DSLs</div>\n<div class=\"imageCredit\">Kunle Olukotun</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Oyekunle&nbsp;A&nbsp;Olukotun</div>\n<div class=\"imageTitle\">Delite DSLs</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n\n\n\n\n\n\nDeveloping high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising way to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. We have developed the Delite compiler framework and the associated DSLs. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We have developed Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and have shown that they all achieve performance competitive to or exceeding manually generated C++ code. \n\nThe Delite framework is the first system to provide a single system and programming model that is optimized both for modern hardware (high performance) and for modern programmers (high productivity). The Delite system is capable of running a variety of parallel applications, providing sequential baseline performance comparable to hand-optimized implementations, and continues to function well both as more resources are added to a single machine with multicore, NUMA and GPU (scale up) and as more machines are interconnected with clusters (scale out).\n\nWe have identified several features useful for implementing real-world applications that are common in traditional programming models but various parallel systems have chosen to sacrifice. These features include rich data parallelism, the ability to use and compose a rich set of data-parallel operations beyond the classic map and reduce; and nested programming, the ability to logically nest parallel constructs. Many systems require a different (sequential) programming model within parallel computation. Even if parallel constructs can be logically nested, the system may or may not actually be capable of exploiting all levels of parallelism at runtime; we refer to this as nested parallelism. Systems that support multiple collections allow parallel computations to directly consume more than one parallel collection rather than having to first join the collections in some fashion. This is very useful in certain domains, e.g., linear algebra. Finally random reads allow arbitrary read access patterns of parallel collections rather than restricting reads to only the local element, which is very useful in, e.g., graph analytics. All previous systems have been forced to sacrifice many of these features in exchange for expanding to more complex hardware targets. We have shown that it is possible to retain all these features of a productive programming model and still attain high-performance on heterogeneous hardware (multicore, NUMA, GPU, clusters, and FPGAs).\n\nThe broader impacts of high performance DSLs are that they enable other scientists to quickly analyze large data sets. Two examples of where Delite DSLs have had an impact are on protein folding analytics (Folding at home) and the knowledge base building work (DeepDive), which has been used to analyze gene-drug interactions.\n\n \n\n \n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/30/2016\n\n\t\t\t\t\tSubmitted by: Oyekunle A Olukotun"
 }
}