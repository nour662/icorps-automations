{
 "awd_id": "1116252",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Unified Framework for Adaptive Analog and Digital Performance Characterization using Learned Information from the Circuit Under Test",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2011-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2011-06-14",
 "awd_max_amd_letter_date": "2011-06-14",
 "awd_abstract_narration": "As semiconductor technology scales to make smaller circuits in order to reduce circuit fabrication costs, a by-product is that it is very hard to make circuit components that match specifications exactly.  Displacement of a single atom can make the circuit behave differently.  The diversity of devices being produced from the same process with the same design makes it un-economical to test them with a \"one size fits all\" test program.  Because each component is unique, we also need a test strategy that is fine-tuned to the circuit being tested.  The proposed work involves adjusting the test program to devices under test iteratively as we gather information about each device throughout the testing process.  \r\n\r\nKeeping a leading edge in information technology is essential for the economical and social well being of the nation.  Our most advanced technologies produce statistically diverse devices from the same design and manufacturing specification.  Future technologies will produce even more diverse devices.  Thorough testing of these increasingly complex devices is a key component in maintaining an edge in information technology.  This project will explore new testing methodologies by developing methods to enable a shift from static to dynamic test procedures.  In addition, this project will pilot a set of undergraduate design projects involving collaboration between Georgia Tech and Arizona State to mimic the prevalent need to collaborate over long distances in industry.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sule",
   "pi_last_name": "Ozev",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sule Ozev",
   "pi_email_addr": "sule.ozev@asu.edu",
   "nsf_id": "000488535",
   "pi_start_date": "2011-06-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "660 S MILL AVENUE STE 204",
  "perf_city_name": "TEMPE",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852813670",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Every electronic circuit that is manufactued needs to be extensively tested to ensure that it contains no defects and it conforms to the specifications for proper operation. This test process can be very time consuming and costly since expensive, industry-grade automated test equipment is necessary. Over the past decades, researchers have tried to find ways of reducing this test cost (which is typically specified in terms of test time) while attaining product qualtiy (which is typically specified in terms of defective parts per million - DPPM). The goal is to lower the test time, while also maintaning a low DPPM count. Unfortunately, there is a trade-off between these two parameters. While test flow can be optimized to reduce the time, &nbsp;this generally results in an uptick in DPPM, which is not desirable. This seemingly inescaple trade-off is compounded with the fact that natural variations in product performance increase with every new technology node, requiring even more testing to ensure quality. Moreover, advanced electronic manufacturing techniques not only make the testing at production time harder, but also result in devices being more susceptible to in-field wearout that degrades the product performance over time.</p>\n<p>This project has developed techniques that solve these dual problems of being able to assess product performance reliably and at a low cost, and being able to predict device performance over time and even mitigate the degradation in the field.</p>\n<p>The concept behind the developed techniques is an adaptive learning approach that relies on both collective (global) information learned from a population of devices and on real-time (local) information that is learned from the device that is being currently monitored. Collective information provides a guide with respect to the complex relationships between performance parameters and local information simplies this relationship so the results can be effectively predicted. In a way, this is a new machine learning method where the model is simply collected datapoints and the relation between them is retained in a joint probability densitiy function (JPDF). In this sense, learning from new data can be simply adding that data into the JPDF and adjusting the weights of each data sample. In order to make predictions for an incoming sample (device under test - DUT), a few measurements are taken, and the JPDF is collapsed around these few measurement. The resulting reduced JPDF simplifies the prediction and potential prediction error.</p>\n<p>This basic learning and prediction concept has been applied to many problems related to electronic device quality, test time, and performance prediction. Using large-scale industry data, it has been shown that the test time can be reduced by nearly 75% with fewer than 10-20 potentially defective devices being shipped out. This level of DPPM is common place in consumer electronics domain due to very low impact defects that escape detection. Comparatively, even recent techniques that do not adaptively change test flow result in much higher DPPM (sometimes in the thousands), with less reduction in test cost. The same pattern can be observed time and again with many different circuits, consistently enabling lower cost and high quality products.</p>\n<p>Product reliability can also be increased by applying these concepts in the field after the device is deployed. It has also been shown that product lifetime can be enhanced 2-3 fold by introducing very low-impact monitors into the circuit and using the results from these simple monitors, along with the prediction algorithms, to judge the device performance and tweak internal parameters if necessary.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/25/2016<br>\n\t\t\t\t\tModified by: Sule&nbsp;Ozev</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477421896336_TestQVsTime--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477421896336_TestQVsTime--rgov-800width.jpg\" title=\"Test Time Quality Trade-off\"><img src=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477421896336_TestQVsTime--rgov-66x44.jpg\" alt=\"Test Time Quality Trade-off\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Static compaction methods result in high test cost and low product quality. Adaptive test aims to bend this trade-off</div>\n<div class=\"imageCredit\">Self</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sule&nbsp;Ozev</div>\n<div class=\"imageTitle\">Test Time Quality Trade-off</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422010066_LearningMethod--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422010066_LearningMethod--rgov-800width.jpg\" title=\"Learning Method\"><img src=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422010066_LearningMethod--rgov-66x44.jpg\" alt=\"Learning Method\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Concept of adaptive learning. Each data sample represents a node with equal weight. Each node is assigned a kernel around it, signifying that it is a representative of its neighborhood. The kernels are added to obtain a smooth probability density function.</div>\n<div class=\"imageCredit\">Self</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sule&nbsp;Ozev</div>\n<div class=\"imageTitle\">Learning Method</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422136394_DPPMVsTime_Data--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422136394_DPPMVsTime_Data--rgov-800width.jpg\" title=\"Test Quality and Test Time Comparison\"><img src=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422136394_DPPMVsTime_Data--rgov-66x44.jpg\" alt=\"Test Quality and Test Time Comparison\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Achieved test cost reduction and quality compared with recent techniques. Blue line indicates the trade-off curve for static compaction. Large scale industry data is used to obtain the results.</div>\n<div class=\"imageCredit\">Se;f</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sule&nbsp;Ozev</div>\n<div class=\"imageTitle\">Test Quality and Test Time Comparison</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422266770_VCO_BIST--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422266770_VCO_BIST--rgov-800width.jpg\" title=\"In-field Recovery\"><img src=\"/por/images/Reports/POR/2016/1116252/1116252_10099645_1477422266770_VCO_BIST--rgov-66x44.jpg\" alt=\"In-field Recovery\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Monitor based in-field recovery for a voltage-controlled oscillator and the die photograph of the manufactured oscillator. The oscillator can fully recover its performance by changing the bias current in the field.</div>\n<div class=\"imageCredit\">Self</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Sule&nbsp;Ozev</div>\n<div class=\"imageTitle\">In-field Recovery</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nEvery electronic circuit that is manufactued needs to be extensively tested to ensure that it contains no defects and it conforms to the specifications for proper operation. This test process can be very time consuming and costly since expensive, industry-grade automated test equipment is necessary. Over the past decades, researchers have tried to find ways of reducing this test cost (which is typically specified in terms of test time) while attaining product qualtiy (which is typically specified in terms of defective parts per million - DPPM). The goal is to lower the test time, while also maintaning a low DPPM count. Unfortunately, there is a trade-off between these two parameters. While test flow can be optimized to reduce the time,  this generally results in an uptick in DPPM, which is not desirable. This seemingly inescaple trade-off is compounded with the fact that natural variations in product performance increase with every new technology node, requiring even more testing to ensure quality. Moreover, advanced electronic manufacturing techniques not only make the testing at production time harder, but also result in devices being more susceptible to in-field wearout that degrades the product performance over time.\n\nThis project has developed techniques that solve these dual problems of being able to assess product performance reliably and at a low cost, and being able to predict device performance over time and even mitigate the degradation in the field.\n\nThe concept behind the developed techniques is an adaptive learning approach that relies on both collective (global) information learned from a population of devices and on real-time (local) information that is learned from the device that is being currently monitored. Collective information provides a guide with respect to the complex relationships between performance parameters and local information simplies this relationship so the results can be effectively predicted. In a way, this is a new machine learning method where the model is simply collected datapoints and the relation between them is retained in a joint probability densitiy function (JPDF). In this sense, learning from new data can be simply adding that data into the JPDF and adjusting the weights of each data sample. In order to make predictions for an incoming sample (device under test - DUT), a few measurements are taken, and the JPDF is collapsed around these few measurement. The resulting reduced JPDF simplifies the prediction and potential prediction error.\n\nThis basic learning and prediction concept has been applied to many problems related to electronic device quality, test time, and performance prediction. Using large-scale industry data, it has been shown that the test time can be reduced by nearly 75% with fewer than 10-20 potentially defective devices being shipped out. This level of DPPM is common place in consumer electronics domain due to very low impact defects that escape detection. Comparatively, even recent techniques that do not adaptively change test flow result in much higher DPPM (sometimes in the thousands), with less reduction in test cost. The same pattern can be observed time and again with many different circuits, consistently enabling lower cost and high quality products.\n\nProduct reliability can also be increased by applying these concepts in the field after the device is deployed. It has also been shown that product lifetime can be enhanced 2-3 fold by introducing very low-impact monitors into the circuit and using the results from these simple monitors, along with the prediction algorithms, to judge the device performance and tweak internal parameters if necessary.\n\n\t\t\t\t\tLast Modified: 10/25/2016\n\n\t\t\t\t\tSubmitted by: Sule Ozev"
 }
}