{
 "awd_id": "1064606",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Database-As-A-Service for Long Tail Science",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 231977.0,
 "awd_amount": 231977.0,
 "awd_min_amd_letter_date": "2011-08-09",
 "awd_max_amd_letter_date": "2013-07-17",
 "awd_abstract_narration": "With tremendous amounts of data existing in scientific applications, database management becomes a critical issue, but database technology is not keeping pace.  This problem is especially acute in the long tail of science: the large number of relatively small labs and individual researchers who collectively produce the majority of scientific results.  These researchers lack the IT staff and specialized skills to deploy technology at scale, but have begun to routinely access hundreds of files and potentially terabytes of data to answer a scientific question.  This project develops the architecture for a database-as-a-service platform for science.  It explores techniques to automate the remaining barriers to use: ingesting data from native sources and automatically bootstrapping an initial set of queries and visualizations, in part by aggressively mining a shared corpus of data, queries, and user activity.  It investigates methods to extract global knowledge and patterns while offering scientists access control over their data, and some formal privacy guarantees.  The Intellectual Merit of this proposal consists of automating non-trivial cognitive tasks associated with data work: information extraction from unstructured data sources, data cleaning, logical schema design, privacy control, visualization, and application-building.  As Broader Impacts, the project helps scientists reduce the proportion of time spent \"handling data\" rather than \"doing science.\"  All software resulting from this project are open source, and all findings are disseminated broadly through publications and workshops. Sustainable support for science users of the software is coordinated through the University of Washington eScience Institute.  The research is incorporated in both undergraduate and graduate computer science courses, and the software is also incorporated into domain science courses as well. The project's outreach activities include advising students through special programs geared toward under-represented groups such as the CRA-W DREU. More information about this project is found at http://escience.washington.edu/dbaas.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Cafarella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Cafarella",
   "pi_email_addr": "michjc@umich.edu",
   "nsf_id": "000544946",
   "pi_start_date": "2011-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE STE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 166718.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 65259.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focused on data services for scientists in the \"long tail\" &mdash; the small labs and individual researchers who are pushing knowledge forward, but who lack the support and infrastructure of larger labs and organizations.&nbsp; In particular, one component of this work focused on data support for spreadsheets and web information extraction.</p>\n<p><br />Spreadsheets are an everyday tool of surprising importance to scientists.&nbsp; Many datasets are only available in spreadsheet form, and they are accessible even to scientists who lack much formal computer science training.&nbsp; Unfortunately, the very flexibility of spreadsheets means they are not compatible with most data analysis software, such as visualization and machine learning suites.&nbsp; We conducted research into a family of methods for automatically transforming spreadsheet data into the relational model that standard data analysis suites require.&nbsp; These methods work on most interesting spreadsheets, transform the data accurately, and are very little work for the practicing scientist.</p>\n<p>&nbsp;&nbsp;<br />As a result, scientists at smaller labs, who lack professional data staffers, can afford to manipulate and analyze more datasets than what was previously practical.</p>\n<p><br />A second major effort focused on extracting \"dictionaries\" from the Web, in order to support scientific tasks.&nbsp; Dictionaries -- say, a list of standard pharmaceuticals -- are useful across a range of data-handling tasks (such as configuring experiments, or ensuring the completeness of a scientific analysis).&nbsp; This effort showed how a scientist can extract dictionaries from Web pages with high accuracy and low user effort, even on long-tail items that appear online extremely infrequently. For example, a scientist who needs to quickly obtain a list of pharmaceuticals can almost certainly find a simple list that includes \"ibuprofen\".&nbsp; The core innovation of this work can turn a tiny number of user suggestions into a comprehensive list, by building page-specific extractors.</p>\n<p><br />A secondary but important innovation is that the system defers \"granularity\" issues until after execution. For example, consider a user who provides the seeds \"IBM\", \"Apple\", and \"Hewlett&shy; Packard\". Is the user specifying a set of Companies, American_Companies, or Computer_Companies? Any of these three interpretations is potentially correct; depending on the answer, the correct dictionaries could be very different. Moreover, the true answer cannot be known without asking the user for more data. Asking for very few seeds is a good way to increase user productivity, but often yields these ambiguous situations. Our system instead produces a range of possible output sets, and asks the user to finely&shy; tune the desired set after the extraction process. The result is that the user has something like a \"granularity dial\" with which to tune in the desired dictionary.</p>\n<p>All of the discovered methods were described and tested in papers published in top-level academic conferences.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/01/2018<br>\n\t\t\t\t\tModified by: Michael&nbsp;Cafarella</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focused on data services for scientists in the \"long tail\" &mdash; the small labs and individual researchers who are pushing knowledge forward, but who lack the support and infrastructure of larger labs and organizations.  In particular, one component of this work focused on data support for spreadsheets and web information extraction.\n\n\nSpreadsheets are an everyday tool of surprising importance to scientists.  Many datasets are only available in spreadsheet form, and they are accessible even to scientists who lack much formal computer science training.  Unfortunately, the very flexibility of spreadsheets means they are not compatible with most data analysis software, such as visualization and machine learning suites.  We conducted research into a family of methods for automatically transforming spreadsheet data into the relational model that standard data analysis suites require.  These methods work on most interesting spreadsheets, transform the data accurately, and are very little work for the practicing scientist.\n\n  \nAs a result, scientists at smaller labs, who lack professional data staffers, can afford to manipulate and analyze more datasets than what was previously practical.\n\n\nA second major effort focused on extracting \"dictionaries\" from the Web, in order to support scientific tasks.  Dictionaries -- say, a list of standard pharmaceuticals -- are useful across a range of data-handling tasks (such as configuring experiments, or ensuring the completeness of a scientific analysis).  This effort showed how a scientist can extract dictionaries from Web pages with high accuracy and low user effort, even on long-tail items that appear online extremely infrequently. For example, a scientist who needs to quickly obtain a list of pharmaceuticals can almost certainly find a simple list that includes \"ibuprofen\".  The core innovation of this work can turn a tiny number of user suggestions into a comprehensive list, by building page-specific extractors.\n\n\nA secondary but important innovation is that the system defers \"granularity\" issues until after execution. For example, consider a user who provides the seeds \"IBM\", \"Apple\", and \"Hewlett&shy; Packard\". Is the user specifying a set of Companies, American_Companies, or Computer_Companies? Any of these three interpretations is potentially correct; depending on the answer, the correct dictionaries could be very different. Moreover, the true answer cannot be known without asking the user for more data. Asking for very few seeds is a good way to increase user productivity, but often yields these ambiguous situations. Our system instead produces a range of possible output sets, and asks the user to finely&shy; tune the desired set after the extraction process. The result is that the user has something like a \"granularity dial\" with which to tune in the desired dictionary.\n\nAll of the discovered methods were described and tested in papers published in top-level academic conferences. \n\n \n\n\t\t\t\t\tLast Modified: 05/01/2018\n\n\t\t\t\t\tSubmitted by: Michael Cafarella"
 }
}