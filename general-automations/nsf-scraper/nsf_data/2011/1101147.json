{
 "awd_id": "1101147",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ICES: Small: Decision Making with Bounded Categorization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2011-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 328847.0,
 "awd_amount": 328847.0,
 "awd_min_amd_letter_date": "2011-04-18",
 "awd_max_amd_letter_date": "2011-04-18",
 "awd_abstract_narration": "Classical economic theory models humans as acting rationally through the optimization of their expected utilities.  The paradigm of bounded rationality takes a step toward greater realism by placing computational limitations on agents' abilities to determine optimal decisions. Behavioral and cognitive studies reveal that humans are also categorically bounded, meaning that they use a finite categorization of the set of decision problems that may be posed, with a small number of categories.  This project will focus on the use of quantization theory and information theory to establish foundations for the interplay between categorization and decision making.  The researchers aim to understand the impact of categorization on individual decision making, team decision making through majority voting, and sequential decision making.  The theory developed in the project will include both analysis of situations in which the categorization is fixed and optimal design of categorizations.  In addition to the behavioral justification for the study of categorization, informational limitations on learning suggest that categorization into classes of decision problems has ramifications for engineering design.\r\n\r\nThis project has the potential to influence economic theory and the understanding of certain social and organizational phenomena. Specifically, the project offers a way to understand the decision making performance of teams, with the incorporation of certain human limitations and the potential for differing preferences (e.g., between Type I and Type II errors) among teammates.  Differences in preferences lead to a quantifiable penalty of team discord, even when the team shares the common goal of making correct decisions.  There is also a quantifiable advantage from team diversity in the sense of obtaining better performance when teammates apply different categorizations. These new concepts could contribute to principles for team formation and for how data gathering policies can be optimized with the goal of fair decision making.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Vivek",
   "pi_last_name": "Goyal",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Vivek K Goyal",
   "pi_email_addr": "vgoyal@mit.edu",
   "nsf_id": "000392466",
   "pi_start_date": "2011-04-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "CAMBRIDGE",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "805200",
   "pgm_ele_name": "Inter Com Sci Econ Soc S (ICE)"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 328847.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Through the introduction of mathematical models, analysis of these models, and experiments with human subjects, this project advanced the understanding of decision making by groups of people. &nbsp;It had two main themes: &nbsp;understanding how humans are influenced by the decisions made by others who share their decision-making objective (their teammates), and the impact of the innate human tendency to form categories of situations. &nbsp;<br /><br />SOCIAL LEARNING IN TEAM DECISION MAKING</p>\n<p>Human agents are social beings that influence each other in myriad ways. &nbsp;Even limiting attention to decision making with two alternatives, the scenarios to study can range from the frivolous (say, picking between two restaurants) to the most serious (whether a physician should recommend a medical intervention). &nbsp;In these scenarios, an agent is influenced by the decisions of any other agents of which she is made aware. &nbsp;In the research literature, this is termed social learning, and in probabilistic modeling it is manifest as an agent changing the prior probability distribution for the correct decision based on the observed decisions of others (Bayesian belief update).</p>\n<p>This part of the project developed mathematical models for the effect of social learning in two sorts of team decision-making: &nbsp;voting and executive decision under advisement. &nbsp;Voting here is any aggregation where each agent's vote carries equal weight. &nbsp;For some fixed number K, at least K out of N total agents must agree on a positive decision for the team decision to be positive; otherwise the team decision is negative. &nbsp;This includes majority rule, but also rules requiring consensus. &nbsp;In the executive model, N-1 out of N agents act as advisers to a final agent who makes the final decision.&nbsp;</p>\n<p>For voting, the project introduced a new mathematical result in praise of secret ballots. &nbsp;When all the agents have equal quality of information, their decision as a team is not improved by voting publicly, in sequence, with each agent aware of the votes of the previous agents. &nbsp;Therefore, each agent should ignore any available information about the votes of others; any adjustment of the agent's decision rule would be for the worse. &nbsp;This may or should be surprising because for any one agent, knowing the votes of other agents will strictly improve decision-making performance. &nbsp;The subtle and essential fact is that trying to make a correct decision as an individual is not the same as trying to contribute to the best team decision. &nbsp;The project used a game show-like experiment to study the behavior of human subjects. &nbsp;This experiment revealed that humans perform worse when the decisions of other agents are made available; they apparently are influenced by information that they should ignore. &nbsp;People may be unable to understand the distinction between the two motivations (being correct themselves vs. the team being correct) despite monetary rewards, and they may lack faith in the rationality of their teammates.</p>\n<p>When the team has a final decider rather than voting, the sharing of individual decisions is essential. &nbsp;The new phenomenon introduced and explained by the project is that acting as a good decision maker is not the same as acting as the good adviser to the ultimate decision maker. &nbsp;The team performance is best when agents that act as advisers over-value the prior probability of the less likely alternative, a tendency termed \"being open-minded.\" &nbsp;For example, when in truth two possibilities have prior probabilities of 1% and 99%, the optimal (open-minded) adviser may behave as if these probabilities are 10% and 90%. &nbsp;The open-minded adviser is more informative to the decider, but her optimal behavior is different than maximizing information transfer in the sense of Shannon.</p>\n<p>The outcomes o...",
  "por_txt_cntn": "\nThrough the introduction of mathematical models, analysis of these models, and experiments with human subjects, this project advanced the understanding of decision making by groups of people.  It had two main themes:  understanding how humans are influenced by the decisions made by others who share their decision-making objective (their teammates), and the impact of the innate human tendency to form categories of situations.  \n\nSOCIAL LEARNING IN TEAM DECISION MAKING\n\nHuman agents are social beings that influence each other in myriad ways.  Even limiting attention to decision making with two alternatives, the scenarios to study can range from the frivolous (say, picking between two restaurants) to the most serious (whether a physician should recommend a medical intervention).  In these scenarios, an agent is influenced by the decisions of any other agents of which she is made aware.  In the research literature, this is termed social learning, and in probabilistic modeling it is manifest as an agent changing the prior probability distribution for the correct decision based on the observed decisions of others (Bayesian belief update).\n\nThis part of the project developed mathematical models for the effect of social learning in two sorts of team decision-making:  voting and executive decision under advisement.  Voting here is any aggregation where each agent's vote carries equal weight.  For some fixed number K, at least K out of N total agents must agree on a positive decision for the team decision to be positive; otherwise the team decision is negative.  This includes majority rule, but also rules requiring consensus.  In the executive model, N-1 out of N agents act as advisers to a final agent who makes the final decision. \n\nFor voting, the project introduced a new mathematical result in praise of secret ballots.  When all the agents have equal quality of information, their decision as a team is not improved by voting publicly, in sequence, with each agent aware of the votes of the previous agents.  Therefore, each agent should ignore any available information about the votes of others; any adjustment of the agent's decision rule would be for the worse.  This may or should be surprising because for any one agent, knowing the votes of other agents will strictly improve decision-making performance.  The subtle and essential fact is that trying to make a correct decision as an individual is not the same as trying to contribute to the best team decision.  The project used a game show-like experiment to study the behavior of human subjects.  This experiment revealed that humans perform worse when the decisions of other agents are made available; they apparently are influenced by information that they should ignore.  People may be unable to understand the distinction between the two motivations (being correct themselves vs. the team being correct) despite monetary rewards, and they may lack faith in the rationality of their teammates.\n\nWhen the team has a final decider rather than voting, the sharing of individual decisions is essential.  The new phenomenon introduced and explained by the project is that acting as a good decision maker is not the same as acting as the good adviser to the ultimate decision maker.  The team performance is best when agents that act as advisers over-value the prior probability of the less likely alternative, a tendency termed \"being open-minded.\"  For example, when in truth two possibilities have prior probabilities of 1% and 99%, the optimal (open-minded) adviser may behave as if these probabilities are 10% and 90%.  The open-minded adviser is more informative to the decider, but her optimal behavior is different than maximizing information transfer in the sense of Shannon.\n\nThe outcomes of this part may impact personalized recommendation systems and crowd-sourced ratings, which are rapidly displacing expert-based systems.\n\nCATEGORICAL THINKING\n\nClassical economic theory models humans as acting rationa..."
 }
}