{
 "awd_id": "1111888",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Large: Collaborative Research: PXGL: Cyberinfrastructure for Scalable Graph Execution",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 1100000.0,
 "awd_amount": 1100000.0,
 "awd_min_amd_letter_date": "2011-08-10",
 "awd_max_amd_letter_date": "2014-07-02",
 "awd_abstract_narration": "The most powerful computing systems in the world have historically been dedicated to solving scientific problems. Until recently, the computations performed by these systems have typically been simulations of various physical phenomena. However, a new paradigm for scientific discovery has been steadily rising in importance, namely, data-intensive science, which focuses sophisticated analysis techniques on the enormous (and ever increasing) amounts of data being produced in scientific, commercial, and social endeavors. Important research based on data-intensive science include areas as diverse as knowledge discovery, bioinformatics, proteomics and genomics, data mining and search, electronic design automation, computer vision, and Internet routing. Unfortunately, the computational approaches needed for data-intensive science differ markedly from those that have been so effective for simulation-based supercomputing. To enable and facilitate efficient execution of data-intensive scientific problems, this project will develop a comprehensive hardware and software supercomputing system for data-intensive science.\r\n\r\nGraph algorithms and data structures are fundamental to data-intensive computations and, consequently, this project is focused on providing fundamental, new understandings of the basics of large-scale graph processing and how to build scalable systems to efficiently solve large-scale graph problems. In particular, this work will characterize processing overheads and the limits of graph processing scalability, develop performance models that properly capture graph algorithms, define the (co-design) process for developing graph-specific hardware, and experimentally verify our approach with a prototype execution environment. Key capabilities of our system include: a novel fine-grained parallel programming model, a scalable library of graph algorithms and data structures, a graph-optimized core architecture, and a scalable graph execution platform. The project will also address the programming challenges involved in constructing scalable and reliable software for data-intensive problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Lumsdaine",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew Lumsdaine",
   "pi_email_addr": "al75@uw.edu",
   "nsf_id": "000420340",
   "pi_start_date": "2011-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "107 S INDIANA AVE",
  "perf_city_name": "BLOOMINGTON",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474057000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 811941.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 288059.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modeling and simulation, an important tool for discovery and computation, has long been recognized as the &ldquo;third pillar&rdquo; of scientific research. More recently, data analytic computing has emerged as a distinct form of computing and a distinct form of research likely to be as important as, if not more important than, modeling and simulation.</p>\n<p>The focus of traditional scientific computing has been in solving systems of PDEs (and the correspond- ing linear algebra problems that they induce). Hardware architectures, computer systems, and software platforms have evolved together to efficiently support solving these kinds of problems. Similar attention has not been devoted to efficiently solving data analytics problems. However, the executive order that created the National Strategic Computing Initiative (NSCI) specifically calls out data analytics as one of its five objectives:</p>\n<p><em>Increasing coherence between the technology base used for modeling and simulation and that used for data analytic computing.</em></p>\n<p>Within the broad domain of data analytics, the graph abstraction is a powerful conceptual tool that describes the relationships between discrete objects. Graphs are used in areas such as social network analysis, machine learning, compilers, electronic design automation, planning, and operations research. Other areas of scientific computing use graphs as well, in the guise of sparse matrices (often derived from structured or unstructured meshes).</p>\n<p>In this project, we have advanced the knowledge and understanding of graph computation in several ways. We developed implementations of graph algorithms in modern distributed runtimes AM++ and HPX-5, resulting in PBGL 2 and PXGL libraries. We investigated new asynchronous mode of graph computation called Distributed Control, where we avoid underutilization of resources by eliminating global barriers and data structures, minimizing the global interaction between threads of computation to &ldquo;termination detection.&rdquo; To achieve performance, such approach requires rethinking and redesign of existing algorithms, and it requires the right choice of order in which work is executed. Furthermore, asynchronous algorithms introduce the aspect of interaction with the underlying runtime. We have proposed that the run time is an integral part of a graph processing system, and that new research results should fully acknowledge this fact, increasing the reporting on the run time related aspects of performance. We have thoroughly analyzed interaction between AM++ and HPX run times and our algorithms in the context of this project.</p>\n<p>We have also considered theoretical developments for graph computation. We proposed Abstract Graph Machines (AGMs) as a high level framework for describing data-driven graph algorithms. AGMs capture graph computation as independent tasks that can be ordered in some way that impacts the semantics and the performance of the algorithms they describe. An Extended AGM (EAGM) expands the notion of ordering onto an abstraction of the underlying architecture, allowing description and analysis of performance improvements possible by placing non-semantic ordering at different levels of hardware.</p>\n<p>We also considered new abstractions for graph libraries. As a part of this project, we have participated in the development and specification of GraphBLAS, a set of functions that extend the ideas form linear algebra to graphs. In the GraphBLAS approach, a graph is viewed as a matrix, most often the adjacency matrix, and it is processed through a series of BLAS-like operations. GraphBLAS selects a small set of useful BLAS operations and extends them with parametrization by the underlying semiring. This extension allows customization of the traditional BLAS methods to the tasks of a particular graph algorithm. We have developed a prototype library called GraphBLAS Template Library, and we have investigated seamless mapping of the GraphBLAS interface to different backends such as CPU and GPU.</p>\n<p>Several software artifacts were developed in this project. These artifacts are released as open source and are available to the public under non-restrictive license. Examples of projects developed are the PXGL library, the PBGL 2 library, the GBTL library, and the AM++ and HPX-5 runtimes. This project also contributed to standardization efforts (GraphBLAS). We have produced several publications on different aspects of graph computation, and we have participated in standardization and development of new ideas and software interfaces. Last but not least, this project directly supported four PhD students over its course who completed some, if not the bulk of their graduate work under this project.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/02/2016<br>\n\t\t\t\t\tModified by: Andrew&nbsp;Lumsdaine</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nModeling and simulation, an important tool for discovery and computation, has long been recognized as the \"third pillar\" of scientific research. More recently, data analytic computing has emerged as a distinct form of computing and a distinct form of research likely to be as important as, if not more important than, modeling and simulation.\n\nThe focus of traditional scientific computing has been in solving systems of PDEs (and the correspond- ing linear algebra problems that they induce). Hardware architectures, computer systems, and software platforms have evolved together to efficiently support solving these kinds of problems. Similar attention has not been devoted to efficiently solving data analytics problems. However, the executive order that created the National Strategic Computing Initiative (NSCI) specifically calls out data analytics as one of its five objectives:\n\nIncreasing coherence between the technology base used for modeling and simulation and that used for data analytic computing.\n\nWithin the broad domain of data analytics, the graph abstraction is a powerful conceptual tool that describes the relationships between discrete objects. Graphs are used in areas such as social network analysis, machine learning, compilers, electronic design automation, planning, and operations research. Other areas of scientific computing use graphs as well, in the guise of sparse matrices (often derived from structured or unstructured meshes).\n\nIn this project, we have advanced the knowledge and understanding of graph computation in several ways. We developed implementations of graph algorithms in modern distributed runtimes AM++ and HPX-5, resulting in PBGL 2 and PXGL libraries. We investigated new asynchronous mode of graph computation called Distributed Control, where we avoid underutilization of resources by eliminating global barriers and data structures, minimizing the global interaction between threads of computation to \"termination detection.\" To achieve performance, such approach requires rethinking and redesign of existing algorithms, and it requires the right choice of order in which work is executed. Furthermore, asynchronous algorithms introduce the aspect of interaction with the underlying runtime. We have proposed that the run time is an integral part of a graph processing system, and that new research results should fully acknowledge this fact, increasing the reporting on the run time related aspects of performance. We have thoroughly analyzed interaction between AM++ and HPX run times and our algorithms in the context of this project.\n\nWe have also considered theoretical developments for graph computation. We proposed Abstract Graph Machines (AGMs) as a high level framework for describing data-driven graph algorithms. AGMs capture graph computation as independent tasks that can be ordered in some way that impacts the semantics and the performance of the algorithms they describe. An Extended AGM (EAGM) expands the notion of ordering onto an abstraction of the underlying architecture, allowing description and analysis of performance improvements possible by placing non-semantic ordering at different levels of hardware.\n\nWe also considered new abstractions for graph libraries. As a part of this project, we have participated in the development and specification of GraphBLAS, a set of functions that extend the ideas form linear algebra to graphs. In the GraphBLAS approach, a graph is viewed as a matrix, most often the adjacency matrix, and it is processed through a series of BLAS-like operations. GraphBLAS selects a small set of useful BLAS operations and extends them with parametrization by the underlying semiring. This extension allows customization of the traditional BLAS methods to the tasks of a particular graph algorithm. We have developed a prototype library called GraphBLAS Template Library, and we have investigated seamless mapping of the GraphBLAS interface to different backends such as CPU and GPU.\n\nSeveral software artifacts were developed in this project. These artifacts are released as open source and are available to the public under non-restrictive license. Examples of projects developed are the PXGL library, the PBGL 2 library, the GBTL library, and the AM++ and HPX-5 runtimes. This project also contributed to standardization efforts (GraphBLAS). We have produced several publications on different aspects of graph computation, and we have participated in standardization and development of new ideas and software interfaces. Last but not least, this project directly supported four PhD students over its course who completed some, if not the bulk of their graduate work under this project. \n\n \n\n\t\t\t\t\tLast Modified: 11/02/2016\n\n\t\t\t\t\tSubmitted by: Andrew Lumsdaine"
 }
}