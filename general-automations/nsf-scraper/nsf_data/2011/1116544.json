{
 "awd_id": "1116544",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TC: Small: Collaborative Research: Influencing Mental Models of Security",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 258193.0,
 "awd_amount": 314193.0,
 "awd_min_amd_letter_date": "2011-07-15",
 "awd_max_amd_letter_date": "2016-05-27",
 "awd_abstract_narration": "Over 80 million households in the United States have a home computer and an Internet connection. The vast majority of these are overseen by people who have little computer security knowledge or training, and many users try to avoid making security decisions because they feel they don't have the knowledge and skills to maintain proper security. Nevertheless, home computer users still make security-related decisions on a regular basis --- for example, whether or not to click on a link in an email message --- without being aware that is what they are doing. Their decisions are guided by how they think about computer security,their mental models.  Interestingly, these models do not have to be technically correct to lead to desirable security behaviors. In other words, sometimes even \"wrong\" mental models produce good security decisions. This project will explore the implications of that insight. By eliminating the constraint that non-technical users must become more like computer security experts to properly protect themselves, this project will identify and create more effective ways of helping home computer users make good security decisions.\r\n\r\nThis project will help advance our understanding of how mental models of security are formed and how ideas are incorporated into mental models and transmitted from person to person. What kinds of information are incorporated into home computer users' mental models? Work will initially be focused on experimentally testing two hypotheses: a) stories about experiences have a larger influence on behavior than behavioral advice, and b) information from friends and colleagues has a stronger influence on mental models, and therefore behavior, than information from security experts.  Additionally, the prevalence of particular mental models will be measured and correlated with actual user security behaviors. Through these investigations, this project will characterize the reasons that many home computer users choose not to act securely --- a question which is one of the biggest challenges of home computer security. Finally, this project will explore ways of encouraging behaviors that support secure system use by developing a prototype socio-technical system that is capable of influencing their mental models and moving people toward models that lead to greater security.\r\n\r\nHome computer security and personal information security are large problems today. Current education campaigns have failed to effect widespread changes in the security behaviors of non-technical users. New technologies are being developed, but will do nothing if users intentionally choose to ignore the technology or to work around it. This project will find better ways of informing people about security issues, altering their understanding of security threats and thereby their security behaviors, which will ultimately create more secure home computers. It will produce research tools, including survey instruments and security behavior measurement software that can be used by other security researchers. It will train a number of students, both graduate and undergraduate, in working on multi-disciplinary, distributed teams. The results from this study will be disseminated broadly to multiple academic communities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Wash",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Wash",
   "pi_email_addr": "wash@msu.edu",
   "nsf_id": "000575042",
   "pi_start_date": "2011-07-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Michigan State University",
  "inst_street_address": "426 AUDITORIUM RD RM 2",
  "inst_street_address_2": "",
  "inst_city_name": "EAST LANSING",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "5173555040",
  "inst_zip_code": "488242600",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MI07",
  "org_lgl_bus_name": "MICHIGAN STATE UNIVERSITY",
  "org_prnt_uei_num": "VJKZC4D1JN36",
  "org_uei_num": "R28EKN92ZTZ9"
 },
 "perf_inst": {
  "perf_inst_name": "Michigan State University",
  "perf_str_addr": "426 AUDITORIUM RD RM 2",
  "perf_city_name": "EAST LANSING",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "488242600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MI07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7795",
   "pgm_ref_txt": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 258193.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over 80 million households in the United States have a home computer and an Internet connection. The vast majority of these are administered by people who have little computer security knowledge or training, and many users try to avoid making security decisions because they feel they don't have the knowledge and skills to maintain proper security. Nevertheless, home computer users still make security-related decisions on a regular basis---for example, whether or not to click on a shady link in an email message---without even knowing that's what they are doing. Their decisions are guided by how they think about computer security, or their \"mental models,\" which do not have to be technically correct to lead to desirable security behaviors. In other words, sometimes even \"wrong\" mental models produce good security decisions. This project explored the implications of that insight.&nbsp;</p>\n<p><br />We discovered that stories are important for computer security. Most people can relay a story that they have heard from their peers about computer security. These stories are usually heard in informal settings from family and friends, and often contain some form of lesson about what should or shouldn't be done. About 50% of these stories caused people to change the way they use computers, and almost all of these stories caused people to change the way they think about computer security. We compared stories to two other sources that non-expert computer users learn about cybersecurity from: news articles, and educational web pages from third parties. We found that stories between end users focus more on who conducts attacks, communications representing expert advice focus on how attacks are conducted, and communications from the news focus on the consequences of attacks. No single source is sufficient for an end user to learn from. We also found that stories were an effective method for training people about phishing, but only when they appeared to be told by peers rather than experts.&nbsp; &nbsp;More traditional facts-and-advice, on the other hand, were effective but only when coming from experts rather than peers. Therefore, storytelling about security is an important way that non-experts learn about computer security.&nbsp;</p>\n<p><br />Many social science theories include a chain of logic that says that people develop an attitude toward something, then form an intention to do something, and then actually do it.&nbsp; Most work in this area is focused on the first link in that chain -- how attitudes shape into intentions.&nbsp; Using a survey, we asked a large representative sample of United States Internet users about different causal beliefs related to computer security, and about the actions they regularly undertake to protect their computers. We found demographic differences in both beliefs about security and security behaviors that pose challenges for helping users become more informed about security.&nbsp; Many participants reported weakly held beliefs, but having a strong belief about cause and effect---any cause and effect---may encourage people to take protective actions.</p>\n<p><br />However, we found that this second link -- intention to behavior -- often doesn't happen.&nbsp; We found that people find it very difficult to execute on their intentions about software software updates (which often makes people more secure, because they cannot successfully turn off updates or prevent them from being installed). We found that self-reported behaviors about passwords strength and password re-use are positively related to actual password behaviors.&nbsp; Additionally, across many security behaviors, we found that actions that are discrete choices and are relatively visible to end users are self-reported more accurately than actions that are less visible, or actions that require continuous attention. This inability to execute on intentions can be a problem; even if you educate people successfully (so they form secure intentions), if they can't execute on those intentions then they aren't secure.&nbsp;&nbsp;</p>\n<p><br />We identified what types of passwords people tend to re-use across multiple websites.&nbsp; &nbsp;By far, the strongest predictor of password re-use was how frequently a user has to enter a password in.&nbsp; Moving from entering a password once a week to entering it three times a week over doubles the probability that the password will be re-used on other websites. This suggests that frequent entry is being used as a strategy to memorize passwords, and organizations that require frequent password entry (e.g. via short login timeouts) may be encouraging their users to re-use those passwords on other websites.</p>\n<p><br />We trained 1 post-doc, 1 PhD student, and 21 undergraduate students, including both computer scientist students and social science students, most of whom are from under-represented groups. Our training includes helping the students learn how to communicate across disciplines and work together on a interdisciplinary team. We also provided computer security training to over 2000 MSU employees. We have made code and research instruments available for other researchers to use.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/05/2017<br>\n\t\t\t\t\tModified by: Richard&nbsp;Wash</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver 80 million households in the United States have a home computer and an Internet connection. The vast majority of these are administered by people who have little computer security knowledge or training, and many users try to avoid making security decisions because they feel they don't have the knowledge and skills to maintain proper security. Nevertheless, home computer users still make security-related decisions on a regular basis---for example, whether or not to click on a shady link in an email message---without even knowing that's what they are doing. Their decisions are guided by how they think about computer security, or their \"mental models,\" which do not have to be technically correct to lead to desirable security behaviors. In other words, sometimes even \"wrong\" mental models produce good security decisions. This project explored the implications of that insight. \n\n\nWe discovered that stories are important for computer security. Most people can relay a story that they have heard from their peers about computer security. These stories are usually heard in informal settings from family and friends, and often contain some form of lesson about what should or shouldn't be done. About 50% of these stories caused people to change the way they use computers, and almost all of these stories caused people to change the way they think about computer security. We compared stories to two other sources that non-expert computer users learn about cybersecurity from: news articles, and educational web pages from third parties. We found that stories between end users focus more on who conducts attacks, communications representing expert advice focus on how attacks are conducted, and communications from the news focus on the consequences of attacks. No single source is sufficient for an end user to learn from. We also found that stories were an effective method for training people about phishing, but only when they appeared to be told by peers rather than experts.   More traditional facts-and-advice, on the other hand, were effective but only when coming from experts rather than peers. Therefore, storytelling about security is an important way that non-experts learn about computer security. \n\n\nMany social science theories include a chain of logic that says that people develop an attitude toward something, then form an intention to do something, and then actually do it.  Most work in this area is focused on the first link in that chain -- how attitudes shape into intentions.  Using a survey, we asked a large representative sample of United States Internet users about different causal beliefs related to computer security, and about the actions they regularly undertake to protect their computers. We found demographic differences in both beliefs about security and security behaviors that pose challenges for helping users become more informed about security.  Many participants reported weakly held beliefs, but having a strong belief about cause and effect---any cause and effect---may encourage people to take protective actions.\n\n\nHowever, we found that this second link -- intention to behavior -- often doesn't happen.  We found that people find it very difficult to execute on their intentions about software software updates (which often makes people more secure, because they cannot successfully turn off updates or prevent them from being installed). We found that self-reported behaviors about passwords strength and password re-use are positively related to actual password behaviors.  Additionally, across many security behaviors, we found that actions that are discrete choices and are relatively visible to end users are self-reported more accurately than actions that are less visible, or actions that require continuous attention. This inability to execute on intentions can be a problem; even if you educate people successfully (so they form secure intentions), if they can't execute on those intentions then they aren't secure.  \n\n\nWe identified what types of passwords people tend to re-use across multiple websites.   By far, the strongest predictor of password re-use was how frequently a user has to enter a password in.  Moving from entering a password once a week to entering it three times a week over doubles the probability that the password will be re-used on other websites. This suggests that frequent entry is being used as a strategy to memorize passwords, and organizations that require frequent password entry (e.g. via short login timeouts) may be encouraging their users to re-use those passwords on other websites.\n\n\nWe trained 1 post-doc, 1 PhD student, and 21 undergraduate students, including both computer scientist students and social science students, most of whom are from under-represented groups. Our training includes helping the students learn how to communicate across disciplines and work together on a interdisciplinary team. We also provided computer security training to over 2000 MSU employees. We have made code and research instruments available for other researchers to use.\n\n \n\n\t\t\t\t\tLast Modified: 10/05/2017\n\n\t\t\t\t\tSubmitted by: Richard Wash"
 }
}