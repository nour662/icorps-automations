{
 "awd_id": "1116213",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Methods for Diagnosis of Non-Classical Faults in Digital Circuits",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2011-06-15",
 "awd_max_amd_letter_date": "2011-06-15",
 "awd_abstract_narration": "The research in this project focuses on diagnostic test generation methods for non-classical faults, such as transition delay and bridging faults, which represent the fault behaviors of modern VLSI devices. Although, the existing tools for VLSI circuit testing incorporate years of research they only deal with classical stuck-at faults. A stuck-at fault is detectable by a single input pattern. Detection of a transition fault is more complex because it requires a sequence of two patterns. Also, the existing tools find tests that detect faults and may not diagnose them, i.e., identify the exact cause of a failure. The traditional metric used in testing is fault coverage. This research investigates the use of a new metric termed diagnostic coverage for the effectiveness of tests in their role of fault diagnosis. For example, to distinguish between two faults one must use a test that detects one fault but not the other; such a test is called an exclusive test. This research provides new algorithms to generate tests for diagnosis of non-classical faults while allowing the use of the available testing tools.\r\n\r\nMoore's law prediction of the number of devices on a VLSI chip doubling every eighteen months simply follows the trend of minimum cost per transistor. The enabling technology driver is the shrinking geometry of features allowing higher transistor density and speed. Nanometer geometries have, however, led to greater process variations. Two characteristics separate the testing of modern VLSI technologies. First, the complex fault mechanisms are no longer represented by the classical stuck-at faults. Second, the impact of increased process variation on yield requires testing to be diagnostic-oriented; faults must be identified so that their causes can be eliminated. The research in this project addresses both needs of the advancing VLSI technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Vishwani",
   "pi_last_name": "Agrawal",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Vishwani D Agrawal",
   "pi_email_addr": "vagrawal@eng.auburn.edu",
   "nsf_id": "000297287",
   "pi_start_date": "2011-06-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Auburn University",
  "inst_street_address": "321-A INGRAM HALL",
  "inst_street_address_2": "",
  "inst_city_name": "AUBURN",
  "inst_state_code": "AL",
  "inst_state_name": "Alabama",
  "inst_phone_num": "3348444438",
  "inst_zip_code": "368490001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "AL03",
  "org_lgl_bus_name": "AUBURN UNIVERSITY",
  "org_prnt_uei_num": "DMQNDJDHTDG4",
  "org_uei_num": "DMQNDJDHTDG4"
 },
 "perf_inst": {
  "perf_inst_name": "Auburn University",
  "perf_str_addr": "321-A INGRAM HALL",
  "perf_city_name": "AUBURN",
  "perf_st_code": "AL",
  "perf_st_name": "Alabama",
  "perf_zip_code": "368490001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "AL03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Moore&rsquo;s law prediction of the number of devices on a VLSI chip doubling every eighteen months follows the trend of minimum cost per transistor. The enabling technology driver is the shrinking transistor geometry allowing higher density and speed. Nanometer geometries, however, lead to greater process variations. Several characteristics separate the testing of modern VLSI technologies from those of the past. First, the complex fault mechanisms are no longer represented by classical stuck-at faults. Second, increased process variation impacts yield requiring test to be diagnostic-oriented; faults must be identified and their causes eliminated. Third, increasing transistor density aggravates test power, time and cost issues. This project addresses fault modeling, diagnosis, and test time versus power issues. It produced five doctoral and three master&rsquo;s dissertations. Six participating students are presently contributing to test related activities in the industry. Principal outcomes and respective intellectual merits and broader impacts are listed below under three subareas. In addition, a large number of journal and refereed conference papers were produced. The project helped five PhD and three master's students complete their dissertations. Six of them have joined the industry and are contributing to VLSI testing.</p>\n<p><strong>Diagnostic Testing</strong></p>\n<p>In traditional pass/fail testing if a manufactured very large scale integration (VLSI) circuits is found to be bad, then we may not test further to determine what exactly is wrong. Thus, existing test algorithms and tools focus on detection (finding whether any fault occurred) rather than identification or diagnosis (finding which fault occurred). &nbsp;In the present-day nanometer technologies, device geometries are not much larger than the manufacturing tolerances. Hence, it is important to diagnose the exact faults so that their causes can be eliminated to enhance the production yield of devices. This research advances the test methodology from detection to diagnosis. Prevailing tools in the industry support test generation for detecting a given fault, and fault simulation to determine the coverage in a fault set by given tests. This research provided new algorithms to generate tests to distinguish between any pair of faults, and for diagnostic fault simulation to determine how well the faults in a given set can be uniquely identified by given tests. Similar to fault coverage that has been used as a test quality metric, we define a new diagnostic coverage metric that is measured by diagnostic fault simulation.</p>\n<p><strong>Non-Classical Faults</strong></p>\n<p>A stuck-at fault in a digital circuit means that a faulty signal is permanently fixed at a logic (0 or 1) state. This is the industry-standard classical fault model. Many actual defects in nanometer devices, characterized by high density and speed, do not conform to this fault model and the semiconductor industry recognizes the need for a change. A transition fault, in which a faulty signal is either too slow to rise from 0 to 1 or too slow to fall from 1 to 0, is a non-classical fault model that can represent the faulty timing behavior. Although the transition fault model has gained popularity, algorithms and tools for diagnosis are lacking. The present research attempts to satisfy this need.</p>\n<p>The 3D-stacked VLSI devices belong to an upcoming technology. Chips, containing processors and memories, are bonded on top of each other, allowing significant benefits of compactness, high speed, and low cost. Signals pass between chips by through silicon via (TSV) conductors. A typical 3D-stack may contain ten thousand or more TSVs. Testing of their defects that are resistive in nature is a critical problem. Our research provides algorithms for optimized TSV testing. Specifically, tests are selected and sequenced through mathematical optim...",
  "por_txt_cntn": "\nMoore\u00c6s law prediction of the number of devices on a VLSI chip doubling every eighteen months follows the trend of minimum cost per transistor. The enabling technology driver is the shrinking transistor geometry allowing higher density and speed. Nanometer geometries, however, lead to greater process variations. Several characteristics separate the testing of modern VLSI technologies from those of the past. First, the complex fault mechanisms are no longer represented by classical stuck-at faults. Second, increased process variation impacts yield requiring test to be diagnostic-oriented; faults must be identified and their causes eliminated. Third, increasing transistor density aggravates test power, time and cost issues. This project addresses fault modeling, diagnosis, and test time versus power issues. It produced five doctoral and three master\u00c6s dissertations. Six participating students are presently contributing to test related activities in the industry. Principal outcomes and respective intellectual merits and broader impacts are listed below under three subareas. In addition, a large number of journal and refereed conference papers were produced. The project helped five PhD and three master's students complete their dissertations. Six of them have joined the industry and are contributing to VLSI testing.\n\nDiagnostic Testing\n\nIn traditional pass/fail testing if a manufactured very large scale integration (VLSI) circuits is found to be bad, then we may not test further to determine what exactly is wrong. Thus, existing test algorithms and tools focus on detection (finding whether any fault occurred) rather than identification or diagnosis (finding which fault occurred).  In the present-day nanometer technologies, device geometries are not much larger than the manufacturing tolerances. Hence, it is important to diagnose the exact faults so that their causes can be eliminated to enhance the production yield of devices. This research advances the test methodology from detection to diagnosis. Prevailing tools in the industry support test generation for detecting a given fault, and fault simulation to determine the coverage in a fault set by given tests. This research provided new algorithms to generate tests to distinguish between any pair of faults, and for diagnostic fault simulation to determine how well the faults in a given set can be uniquely identified by given tests. Similar to fault coverage that has been used as a test quality metric, we define a new diagnostic coverage metric that is measured by diagnostic fault simulation.\n\nNon-Classical Faults\n\nA stuck-at fault in a digital circuit means that a faulty signal is permanently fixed at a logic (0 or 1) state. This is the industry-standard classical fault model. Many actual defects in nanometer devices, characterized by high density and speed, do not conform to this fault model and the semiconductor industry recognizes the need for a change. A transition fault, in which a faulty signal is either too slow to rise from 0 to 1 or too slow to fall from 1 to 0, is a non-classical fault model that can represent the faulty timing behavior. Although the transition fault model has gained popularity, algorithms and tools for diagnosis are lacking. The present research attempts to satisfy this need.\n\nThe 3D-stacked VLSI devices belong to an upcoming technology. Chips, containing processors and memories, are bonded on top of each other, allowing significant benefits of compactness, high speed, and low cost. Signals pass between chips by through silicon via (TSV) conductors. A typical 3D-stack may contain ten thousand or more TSVs. Testing of their defects that are resistive in nature is a critical problem. Our research provides algorithms for optimized TSV testing. Specifically, tests are selected and sequenced through mathematical optimization using integer liner programming (ILP).\n\nTest Power and Time \n\n\nCircuits are designed to consume certain maximum power. A test that exce..."
 }
}