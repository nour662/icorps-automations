{
 "awd_id": "1115385",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Matrix Functions, Rational Approximation, and Quadrature with Applications",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": "7032924488",
 "po_email": "jwang@nsf.gov",
 "po_sign_block_name": "Junping Wang",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 180000.0,
 "awd_amount": 180000.0,
 "awd_min_amd_letter_date": "2011-08-16",
 "awd_max_amd_letter_date": "2013-06-27",
 "awd_abstract_narration": "This research project is concerned with the development and analysis of novel methods for the approximation of matrix functions and integrals defined by matrix functions. The research blends linear algebra and approximation theory. New rational Lanczos methods for Hermitian matrices with short recursion formulas are being developed. The existence of short recursion relations is of significant theoretical and practical interest. It speeds up the computations because each new rational Lanczos vector only has to be orthogonalized against a few of the most recently computed Lanczos vectors.  The number of required explicit orthogonalizations is bounded independently of the number of rational Lanczos steps. The recursion relations define the orthogonal projection of a given matrix onto a rational Krylov subspace. The projection is represented by a pentadiagonal matrix, which also has a block structure. This matrix is analogous to the symmetric tridiagonal matrix associated with a (standard) Gauss quadrature rule, and is the basis for new algorithms for the evaluation of rational Gauss, Gauss-Radau rules, and Gauss-Lobatto quadrature rules. The research is an extension of the very important work by Gene Golub, and his collaborators, on matrices, moments, orthogonal polynomials, and quadrature. There may be connections to the structured matrices, such as the CMV-matrices, which arise in the context of orthogonal polynomials and orthogonal rational functions on the unit circle, as well as to to semi- and quasi-separable matrices. When the given matrix is non-Hermitian, rational Arnoldi and rational non-Hermitian Lanczos processes can be applied. The projections onto the rational Krylov subspace again have a structure, the exploitation of which is an important topic in linear algebra. The need to estimate matrix functionals arises in many applications, including the investigation of social networks and in Tikhonov regularization of ill-posed inverse  problems.  \r\n\r\nThe principal investigator is studying developments of faster numerical methods for the evaluation, bounding or estimation of complicated nonlinear expressions that involve large symmetric or nonsymmetric matrices. The gain in speed is achieved by exploiting structure that until now has been ignored. The development of fast methods is important when solving large-scale problems of interest to scientists and engineers. These methods are applicable in the investigation of social networks, whose properties recently have received considerable attention, not only by scientists, but also by the New York Times. A major hurdle in the investigation of social networks is their large size. The research provides improved tools for investigating these kinds of networks. The methods can also be applied in solution methods for Maxwell's equation in three space-dimensions. Essentially, one has to compute the exponential of very large matrices. These matrices are much too large to allow the use of standard software. The methods to be developed within the framework of this proposal speed up the computations by exploiting inherent structure of these problems. Work on the problems of this proposal requires background in linear algebra, orthogonal polynomials and rational functions, approximation theory, and Gauss-type quadrature. Hence the research is well suited for doctoral students working on this project.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lothar",
   "pi_last_name": "Reichel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lothar Reichel",
   "pi_email_addr": "reichel@math.kent.edu",
   "nsf_id": "000341820",
   "pi_start_date": "2011-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Kent State University",
  "inst_street_address": "1500 HORNING RD",
  "inst_street_address_2": "",
  "inst_city_name": "KENT",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "3306722070",
  "inst_zip_code": "442420001",
  "inst_country_name": "United States",
  "cong_dist_code": "14",
  "st_cong_dist_code": "OH14",
  "org_lgl_bus_name": "KENT STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "KXNVA7JCC5K6"
 },
 "perf_inst": {
  "perf_inst_name": "Kent State University",
  "perf_str_addr": "1500 HORNING RD",
  "perf_city_name": "KENT",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "442420001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "14",
  "perf_st_cong_dist": "OH14",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 82375.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 59063.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 38562.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the foci of &nbsp;the research was the approximation of functions of a large matrix, such as exp(A), where A is a large square matrix. The need to evaluate functions of matrices arises in a variety of applications, including network analysis. Let A be the adjacency matrix for an undirected graph. Then A is symmetric with the entry A_{i,j}=1 if there is an edge between the vertices i and j; otherwise A_{i,j}=0. Each vertex corresponds to a row and a column of A. Therefore, A is large if the network has many vertices. Estrada and his collaborators suggested that important vertices in a network are associated with large diagonal entries of exp(A). We are interested in determining the diagonal entries of exp(A) in order to tell which nodes are the most important ones. The matrix A may be very large in applications. It is impossible to evaluate exp(A) when A is very large, but it is possible to compute approximations of desired elements of exp(A). This can be achieved by application of a few steps of the Lanczos or block Lanczos processes to A with a suitable initial vector or block vector. The computed approximations can be interpreted as Gauss quadrature rules. Each step of the&nbsp;Lanczos or block Lanczos processes gives an additional node and weight of the Gauss or block Gauss rule. We have developed new techniques to estimate the error in the computed approximations. The ability to estimate the error is importnat, because each step with the Lanczos or block Lanczos processes is expensive when A is large. We would like to carry out enough steps to compute the desired quantities (say diagonal entries of exp(A)) with sufficient accuray, but we wish to avoid carrying out more steps than required for achieve the needed accuracy. Software for the methods developed is made publicly available. A user easily can apply the methods to the analysis of networks.</p>\n<p>Another area of interest is the development of rational Lanczos methods. These methods are analogous to (standard) Lanczos methods, but determine rational approximants instead of polynomial approximants. Rational Lanczos methods are associated with rational Gauss quadrature rules, while the standard Lanczos method is connected to standard Gauss quadrature. The former iimplicitly approximate the integrand by a rational functions with preselected poles and then integrate this rational function exactly, while standard Gauss quadrature implicitly approximate the integrand by a polynomial and then integrates this polynomial exactly. Rational Gauss quadrature rules can give significantly higher accuracy than standard Gauss rules with the same number of nodes in certain applications. The rational Lanczos method is associated with rational Gauss quadrature, while the standard Lanczos method is connected to standard Gauss quadrature. The structure of rational Lanczos methods uncovered in our research suggests new efficient methods for the computation of rational Gauss quadrature rules. &nbsp;The methods obtained are analogous to those commonly used to compute standard Gauss quadrature rules. Our research also suggests new ways of implementing rational Lanczos methods.</p>\n<p>A third focus for our work is the solution of ill-posed problems. Ill-posed problems arise when one would like to determine the cause of an observed effect. They appear, for instance, in remote sensing, computerized tomorgraphy, and image restoration The solutions of ill-posed problems are. very sensitive to errors in the data. The data for ill-posed problems that arise in the sciences and engineering typically is contaminated by measurement inaccuracies. Starightforward solution of these problems generally does not produce a meaningful result. This difficulty can be reduced by replacing the given ill-posed problem by a nearby one that is less sensitive to the error in the data. One of the most popular regularization methods is due to Tikhonon...",
  "por_txt_cntn": "\nOne of the foci of  the research was the approximation of functions of a large matrix, such as exp(A), where A is a large square matrix. The need to evaluate functions of matrices arises in a variety of applications, including network analysis. Let A be the adjacency matrix for an undirected graph. Then A is symmetric with the entry A_{i,j}=1 if there is an edge between the vertices i and j; otherwise A_{i,j}=0. Each vertex corresponds to a row and a column of A. Therefore, A is large if the network has many vertices. Estrada and his collaborators suggested that important vertices in a network are associated with large diagonal entries of exp(A). We are interested in determining the diagonal entries of exp(A) in order to tell which nodes are the most important ones. The matrix A may be very large in applications. It is impossible to evaluate exp(A) when A is very large, but it is possible to compute approximations of desired elements of exp(A). This can be achieved by application of a few steps of the Lanczos or block Lanczos processes to A with a suitable initial vector or block vector. The computed approximations can be interpreted as Gauss quadrature rules. Each step of the Lanczos or block Lanczos processes gives an additional node and weight of the Gauss or block Gauss rule. We have developed new techniques to estimate the error in the computed approximations. The ability to estimate the error is importnat, because each step with the Lanczos or block Lanczos processes is expensive when A is large. We would like to carry out enough steps to compute the desired quantities (say diagonal entries of exp(A)) with sufficient accuray, but we wish to avoid carrying out more steps than required for achieve the needed accuracy. Software for the methods developed is made publicly available. A user easily can apply the methods to the analysis of networks.\n\nAnother area of interest is the development of rational Lanczos methods. These methods are analogous to (standard) Lanczos methods, but determine rational approximants instead of polynomial approximants. Rational Lanczos methods are associated with rational Gauss quadrature rules, while the standard Lanczos method is connected to standard Gauss quadrature. The former iimplicitly approximate the integrand by a rational functions with preselected poles and then integrate this rational function exactly, while standard Gauss quadrature implicitly approximate the integrand by a polynomial and then integrates this polynomial exactly. Rational Gauss quadrature rules can give significantly higher accuracy than standard Gauss rules with the same number of nodes in certain applications. The rational Lanczos method is associated with rational Gauss quadrature, while the standard Lanczos method is connected to standard Gauss quadrature. The structure of rational Lanczos methods uncovered in our research suggests new efficient methods for the computation of rational Gauss quadrature rules.  The methods obtained are analogous to those commonly used to compute standard Gauss quadrature rules. Our research also suggests new ways of implementing rational Lanczos methods.\n\nA third focus for our work is the solution of ill-posed problems. Ill-posed problems arise when one would like to determine the cause of an observed effect. They appear, for instance, in remote sensing, computerized tomorgraphy, and image restoration The solutions of ill-posed problems are. very sensitive to errors in the data. The data for ill-posed problems that arise in the sciences and engineering typically is contaminated by measurement inaccuracies. Starightforward solution of these problems generally does not produce a meaningful result. This difficulty can be reduced by replacing the given ill-posed problem by a nearby one that is less sensitive to the error in the data. One of the most popular regularization methods is due to Tikhononov. This method depends on a parameter that determines how much the regularized problem d..."
 }
}