{
 "awd_id": "1054830",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: CPU and GPU Based Heterogeneous Architecture Design and Managements",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-03-01",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 460000.0,
 "awd_amount": 508000.0,
 "awd_min_amd_letter_date": "2010-12-21",
 "awd_max_amd_letter_date": "2015-04-27",
 "awd_abstract_narration": "Heterogeneous computer architectures, especially those that combine CPUs and GPUs, have become widespread in both desktop and mobile platforms. These architectures increase the complexity of architecture  designs and the severity of resource management problems. To increase energy efficiency and performance in these architectures, this CAREER project investigates new resource management system that combines static and dynamic analysis. It uses analytical and  statistical models to predict application performance and energy consumption behaviors. These models will be also used for exploiting heterogeneous architecture design choices. The proposed research brings together cross-disciplinary techniques from architecture, compiler, and power measurement systems, and researchers from academia and industry. The results of this research can be directly used for designing the next generations of heterogeneous architectures and software systems. The PI plans to collaborate with industrial partners to ensure a direct path for technology transfer.\r\n\r\nIn this project, the investigator plans to develop a new undergraduate course and a new simple GPU simulator framework for undergraduate students and graduate students. The proposed simulator will be available to a wide community of researchers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hyesoon",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hyesoon Kim",
   "pi_email_addr": "hyesoon@cc.gatech.edu",
   "nsf_id": "000084212",
   "pi_start_date": "2010-12-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Research Corporation",
  "perf_str_addr": "926 DALNEY ST NW",
  "perf_city_name": "ATLANTA",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303186395",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "794200",
   "pgm_ele_name": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7329",
   "pgm_ref_txt": "COMPILERS"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 99215.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 87366.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 107751.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 112385.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 101283.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\">The increases in the amount of data and high compute<span class=\"s1\">-</span>intensive applications such as machine learning applications have taken advantage of the recent advances in massively parallel architectures<span class=\"s1\">,</span> especially GPUs. To support both traditional applications and emerging applications such as big data/graph/machine learning, combining CPUs and GPUs on the same chip has become a popular architecture trend. <span class=\"s1\">However, these heterogeneous architectures put more pressure on shared resource management. </span>This research advances software and hardware solutions to the problems of managing shared resources.<span>&nbsp;</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p1\">The major intellectual outcomes of this program are several and focus on CPU+GPU/GPU modeling and resource management techniques that rely on CPU and GPU characteristic differences. First, we developed CPU+GPU timing simulators and distributed them as an open source.<span>&nbsp; </span>Second, we developed CPU+GPU power modeling. Third, we developed GPU analytical models to aid compilers&rsquo; optimizations or to speed up the architecture simulation so that big data applications can be also simulated. Fourth, we advanced the cache partitioning algorithm on CPU+GPU architectures. The solution introduced the concept of utilizing thread<span class=\"s1\">-</span> level parallelism to decide the cache management schemes. Fifth, we analyzed recent applications such as graph applications and machine learning applications on both CPUs and GPUs and identified new performance bottlenecks on GPUs such as memory divergence problems or memory bandwidth issues. Finally, we developed an FPGA-based new GPU architecture course project for undergraduate students. These outcomes have enhanced the understanding of the CPU+GPU architectures and also improved the performance and power efficiency.<span>&nbsp;</span></p>\n<p class=\"p2\">&nbsp;</p>\n<p class=\"p3\">The engineering contributions of this program translated the preceding intellectual contributions into open source software artifacts to benefit the larger research and development community and enable further developments. These include i) CPU+GPU architecture simulators and ii) CPU and GPU versions of graph benchmarks. Collectively, the preceding intellectual and engineering contributions advance the state of the art CPU+GPU architecture designs and modeling.&nbsp;</p>\n<p class=\"p4\">&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/23/2018<br>\n\t\t\t\t\tModified by: Hyesoon&nbsp;Kim</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The increases in the amount of data and high compute-intensive applications such as machine learning applications have taken advantage of the recent advances in massively parallel architectures, especially GPUs. To support both traditional applications and emerging applications such as big data/graph/machine learning, combining CPUs and GPUs on the same chip has become a popular architecture trend. However, these heterogeneous architectures put more pressure on shared resource management. This research advances software and hardware solutions to the problems of managing shared resources. \n \nThe major intellectual outcomes of this program are several and focus on CPU+GPU/GPU modeling and resource management techniques that rely on CPU and GPU characteristic differences. First, we developed CPU+GPU timing simulators and distributed them as an open source.  Second, we developed CPU+GPU power modeling. Third, we developed GPU analytical models to aid compilers? optimizations or to speed up the architecture simulation so that big data applications can be also simulated. Fourth, we advanced the cache partitioning algorithm on CPU+GPU architectures. The solution introduced the concept of utilizing thread- level parallelism to decide the cache management schemes. Fifth, we analyzed recent applications such as graph applications and machine learning applications on both CPUs and GPUs and identified new performance bottlenecks on GPUs such as memory divergence problems or memory bandwidth issues. Finally, we developed an FPGA-based new GPU architecture course project for undergraduate students. These outcomes have enhanced the understanding of the CPU+GPU architectures and also improved the performance and power efficiency. \n \nThe engineering contributions of this program translated the preceding intellectual contributions into open source software artifacts to benefit the larger research and development community and enable further developments. These include i) CPU+GPU architecture simulators and ii) CPU and GPU versions of graph benchmarks. Collectively, the preceding intellectual and engineering contributions advance the state of the art CPU+GPU architecture designs and modeling. \n \n\n\t\t\t\t\tLast Modified: 05/23/2018\n\n\t\t\t\t\tSubmitted by: Hyesoon Kim"
 }
}