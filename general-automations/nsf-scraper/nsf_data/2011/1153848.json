{
 "awd_id": "1153848",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Evaluation of Teacher Education Programs: Toward a Framework for Innovation",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2011-10-01",
 "awd_exp_date": "2014-09-30",
 "tot_intn_awd_amt": 299996.0,
 "awd_amount": 299996.0,
 "awd_min_amd_letter_date": "2011-09-25",
 "awd_max_amd_letter_date": "2011-09-25",
 "awd_abstract_narration": "This EAGER project proposes an initiative to review existing methods and to create a design framework for the development of new and innovative approaches for evaluation of teacher education programs.\r\n\r\nThe George Washington University School of Education and Human Development and the National Academy of Education will lead the effort and the project will result in the following products: (1) a synthesis of existing research and experiential approaches in evaluating teacher education program quality and effectiveness; (2) an exploration of new and innovative approaches to evaluation in teacher education; and (3) a roadmap of issues and recommendations for new approaches.  Issues in teacher education are politically at the forefront of the education policy agenda at the present time and an EAGER is an appropriate vehicle for exploring alternatives to current evaluation practices.  Specific products will include commissioned papers, a synthesis report, policy briefs and other materials for dissemination.\r\n\r\nTeacher education is at a crossroads with calls for increasing accountability and efforts to guage teachers' performance to student outcomes and to the institutions/programs where they were prepared.  The synthesis and roadmap provided by this project will link traditional preparation programs with alternatives of various kinds and shed light on new ways to evaluate all different kinds of programs.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Feuer",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Michael J Feuer",
   "pi_email_addr": "mjfeuer@gwu.edu",
   "nsf_id": "000597204",
   "pi_start_date": "2011-09-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "White",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory White",
   "pi_email_addr": "gwhite@naeducation.org",
   "nsf_id": "000568686",
   "pi_start_date": "2011-09-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Washington University",
  "inst_street_address": "1918 F ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2029940728",
  "inst_zip_code": "200520042",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "GEORGE WASHINGTON UNIVERSITY (THE)",
  "org_prnt_uei_num": "",
  "org_uei_num": "ECR5E2LU5BL6"
 },
 "perf_inst": {
  "perf_inst_name": "The Graduate School of Education",
  "perf_str_addr": "2134 G Street, NW",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200520086",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "726100",
   "pgm_ele_name": "Project & Program Evaluation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0411",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001112DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 299996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>National Science Foundation</strong></p>\n<p><strong>Project Outcomes Report</strong></p>\n<p><strong>&nbsp;</strong></p>\n<div>\n<p><strong>Graduate School of Education and Human Development of the George Washington University, in partnership with the National Academy of Education</strong></p>\n<p><strong>&nbsp;</strong></p>\n<p><strong>Project Title:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Evaluation of Teacher Education Programs: Toward a Framework for Innovation</strong></p>\n<p><strong>NSF Award No.:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1153848 <br /> <br /> </strong></p>\n</div>\n<p>&nbsp;</p>\n<p>In recent years the improvement of teaching and teacher preparation has become a high political priority. Numerous approaches are currently used or are being proposed to evaluate teacher preparation programs (TPP) &ndash; particularly during a time when traditional programs are being called upon to prove their utility and when new teacher pathways are emerging with greater frequency. However, these evaluation mechanisms (e.g., national accreditation systems, state program approval, media and independent rating systems, and program self-studies) are works in progress, and the design of new and better methods necessitates a willingness to invest in exploration. Simply put, there has at present been no obvious blueprint to guide the development of new methods, but rather the beginnings of an evidentiary base to support disciplined (and multi-disciplinary) exploration coupled with a commitment to assessment, revision, and continued experimentation in the design of evaluation systems for improving teacher preparation.</p>\n<p>&nbsp;</p>\n<p>With generous support from the National Science Foundation, the George Washington University (prime sponsor) and the National Academy of Education (NAEd) conducted a study to examine existing methods of evaluating the quality of teacher preparation programs, and to develop a framework for designing and implementing innovative evaluation systems. A steering committee comprised of the following members was assembled: Michael Feuer (chair), Deborah Ball, Jeanne Burns, Robert Floden, Susan Fuhrman (ex-officio), Lionel Howard, and Brian Rowan. The steering committee organized two workshops (the first in 2012, and a second workshop in 2013) that brought together leaders with diverse expertise to deliberate and identify emerging issues in the current landscape of evaluating preparation programs. To inform the study process, the committee commissioned four papers that address various aspects of evaluation systems:</p>\n<p>&nbsp;</p>\n<p><em>Recent Developments in STEM Education Relevant to the Qualities of Teacher Preparation Programs</em><strong>&nbsp;</strong></p>\n<p><strong>Suzanne Wilson</strong>, University of Connecticut <strong>&nbsp;</strong></p>\n<p><em>&nbsp;</em></p>\n<p><em>Protecting the Public: Ensuring Nursing Education Quality</em><strong>&nbsp;</strong></p>\n<p><strong>Jean Johnson &amp; Christine Pintz</strong>, School of Nursing, George Washington University<strong>&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p><em>Inspecting Initial Teacher Education in England &ndash; the Work of Ofsted</em><strong>&nbsp;</strong></p>\n<p><strong>John Furlong</strong>, University of Oxford<strong>&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p><em>Variations in Teacher Preparation Evaluation Systems: International Perspectives<strong>&nbsp;</strong></em></p>\n<p><strong>Maria Teresa Tatto, Joseph Krajcik, &amp; James Pippin</strong>, Michigan State University<strong><em>&nbsp;</em></strong></p>\n<p>&nbsp;</p>\n<p>A final report, <strong><em>Evaluation of Teacher Preparation Programs: Purposes, Methods, and Policy Options</em></strong>, provides (1) a clear overview of the current landscape of teacher preparation program evaluation and (2) an analysis of key issues in designing and implementing evaluation mechanisms. The report synthesi...",
  "por_txt_cntn": "\nNational Science Foundation\n\nProject Outcomes Report\n\n \n\n\nGraduate School of Education and Human Development of the George Washington University, in partnership with the National Academy of Education\n\n \n\nProject Title:             Evaluation of Teacher Education Programs: Toward a Framework for Innovation\n\nNSF Award No.:        1153848 \n \n \n\n\n \n\nIn recent years the improvement of teaching and teacher preparation has become a high political priority. Numerous approaches are currently used or are being proposed to evaluate teacher preparation programs (TPP) &ndash; particularly during a time when traditional programs are being called upon to prove their utility and when new teacher pathways are emerging with greater frequency. However, these evaluation mechanisms (e.g., national accreditation systems, state program approval, media and independent rating systems, and program self-studies) are works in progress, and the design of new and better methods necessitates a willingness to invest in exploration. Simply put, there has at present been no obvious blueprint to guide the development of new methods, but rather the beginnings of an evidentiary base to support disciplined (and multi-disciplinary) exploration coupled with a commitment to assessment, revision, and continued experimentation in the design of evaluation systems for improving teacher preparation.\n\n \n\nWith generous support from the National Science Foundation, the George Washington University (prime sponsor) and the National Academy of Education (NAEd) conducted a study to examine existing methods of evaluating the quality of teacher preparation programs, and to develop a framework for designing and implementing innovative evaluation systems. A steering committee comprised of the following members was assembled: Michael Feuer (chair), Deborah Ball, Jeanne Burns, Robert Floden, Susan Fuhrman (ex-officio), Lionel Howard, and Brian Rowan. The steering committee organized two workshops (the first in 2012, and a second workshop in 2013) that brought together leaders with diverse expertise to deliberate and identify emerging issues in the current landscape of evaluating preparation programs. To inform the study process, the committee commissioned four papers that address various aspects of evaluation systems:\n\n \n\nRecent Developments in STEM Education Relevant to the Qualities of Teacher Preparation Programs \n\nSuzanne Wilson, University of Connecticut  \n\n \n\nProtecting the Public: Ensuring Nursing Education Quality \n\nJean Johnson &amp; Christine Pintz, School of Nursing, George Washington University \n\n \n\nInspecting Initial Teacher Education in England &ndash; the Work of Ofsted \n\nJohn Furlong, University of Oxford \n\n \n\nVariations in Teacher Preparation Evaluation Systems: International Perspectives \n\nMaria Teresa Tatto, Joseph Krajcik, &amp; James Pippin, Michigan State University \n\n \n\nA final report, Evaluation of Teacher Preparation Programs: Purposes, Methods, and Policy Options, provides (1) a clear overview of the current landscape of teacher preparation program evaluation and (2) an analysis of key issues in designing and implementing evaluation mechanisms. The report synthesizes existing knowledge about the purposes, contexts, and principles of evaluation systems, and presents the concept of mapping, i.e., linking characteristics of evaluation systems with various purposes and intended uses. Comparative information about how selected professions (e.g., nursing education) and other countries evaluate their pre-service education and training programs, as well as issues in evaluating science and mathematics teacher preparation, are interspersed throughout the report. It concludes with a decision framework that can be used by policymakers, evaluation practitioners, researchers, and administrators for designing, using, and interpreting evaluation mechanisms.\n\n \n\nDecision Framework. The environment for research leading to policy reforms and practical alternatives can be risky..."
 }
}