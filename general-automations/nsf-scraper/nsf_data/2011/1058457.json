{
 "awd_id": "1058457",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Ethics for Developing Technologies: An Analysis of Artficial Agent Technology",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Linda Layne",
 "awd_eff_date": "2011-04-15",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 213049.0,
 "awd_amount": 213049.0,
 "awd_min_amd_letter_date": "2011-04-06",
 "awd_max_amd_letter_date": "2012-04-02",
 "awd_abstract_narration": "Moral notions and practices shape and are shaped by new technologies. Ethics for developing technologies involves identification and analysis of the ethical issues associated with a new technology in ways that can influence its design and use. Bringing ethical perspectives into the early stages of technological development is the best opportunity for those perspectives to have an influence.\r\n\r\nThis project examines the discourse around artificial agent technology--computer systems that are described as autonomous decision-making entities--in order to understand how moral concepts and practices shape and are shaped by new technologies. Concepts of agency and autonomy are central to morality; they underpin the very possibility of morality and are strongly linked to concepts of responsibility and accountability. This project will examine how computer scientists and engineers conceptualize issues of responsibility with regard to artificial agents.\r\n\r\nThe project will focus on two case studies: 1) the discussion centered around artificial moral agents, and 2) the discourse about autonomous military robots. The overarching descriptive research question for each case is: How are notions of responsibility, agency, and autonomy being negotiated? The overarching normative question is: How should artificial agents be conceptualized and designed? The methodology combines discourse analysis, philosophical analysis, and in-depth interviews with computer scientists and engineers. The project will have broader impact by training a postdoctoral fellow in ethics in science research and qualitative social science research methods. The results will be disseminated broadly to scholars as well as those who are engaged in the development of artificial agent technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Deborah",
   "pi_last_name": "Johnson",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Deborah G Johnson",
   "pi_email_addr": "dgj7p@virginia.edu",
   "nsf_id": "000329838",
   "pi_start_date": "2011-04-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Virginia Main Campus",
  "inst_street_address": "1001 EMMET ST N",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTESVILLE",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "4349244270",
  "inst_zip_code": "229034833",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "VA05",
  "org_lgl_bus_name": "RECTOR & VISITORS OF THE UNIVERSITY OF VIRGINIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJG6HU8PA4S5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Virginia Main Campus",
  "perf_str_addr": "1001 EMMET ST N",
  "perf_city_name": "CHARLOTTESVILLE",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "229034833",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "VA05",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "760300",
   "pgm_ele_name": "STS-Sci, Tech & Society"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7915",
   "pgm_ref_txt": "Ethics & Values of SET"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 119316.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 93733.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to examine the discourse around artificial agent technology and responsibility.&nbsp; Artificial agents are software programs and software-hardware combinations (such as robots and drones) that make decisions and perform tasks independently in space and time from those who design and deploy them. Artificial agents are said to operate autonomously and to make decisions that may be incomprehensible to the humans who design and deploy them.&nbsp; Some have suggested that because of the autonomy and opacity of artificial agents, no human beings can or will in the future be responsible for the behavior of some artificial agents.&nbsp; Our intention was to examine this discourse to better understand how discussion and decision in the early stages of this technology&rsquo;s development are shaping ideas and practices related to responsibility. &nbsp;</p>\n<p>&nbsp;</p>\n<p>We examined two threads of the discourse, one centered on artificial <em>moral</em> agents (i.e., agents that are programmed to behave according to moral rules), and the other centered on autonomous military robots. Our analyses are both descriptive and normative.&nbsp; Several of our publications identify the diverse ways in which 'agency' and &lsquo;autonomy&rsquo; are being used, and the ways in which design decisions may set the conditions for distribution of responsibility.&nbsp; Several of the publications engage in the discourse in a critical way.&nbsp; Our final publication is a set of recommendations for the future development of artificial agents.</p>\n<p>&nbsp;</p>\n<p>As part of the project, we held a workshop on January 24-25 for 18 participants.&nbsp; The participants consisted of experts from computer science and engineering, philosophy/ethics, law, STS, artificial intelligence and military ethics.&nbsp; Participants were given drafts of papers and our recommendations before the workshop and their comments and feedback were discussed during the workshop and later used to make revisions.&nbsp;</p>\n<p>&nbsp;</p>\n<p>The results of our research were published in five journal articles and one book chapter, and were presented at nine conferences.&nbsp; The papers were targeted for publications that would reach diverse audiences.&nbsp; One paper appears in the <em>Military Review</em>, a publication for military personnel and policy makers.&nbsp; The Recommendations paper will appear in <em>Technology &amp; Society Magazine</em>, an IEEE journal read by engineers and computer scientists as well as STS scholars.&nbsp; Another paper is published in the<em> Journal of Business Ethics</em> which has an audience of academic business school scholars and academic ethicists. &nbsp;The other two papers appear in <em>Ethics and Information Technology</em> and <em>Science and Engineering Ethics</em>; these journals are read by interdisciplinary scholars and practitioners.</p>\n<p>&nbsp;</p>\n<p>Significant results of the project include delineation of the different uses of the term autonomy in the two discourses on artificial agents and demonstration of how design decisions influence the distribution of responsibility.&nbsp; In achieving these results we developed a new way of thinking about responsibility - as a set of normative social practices rather than something with a metaphysical character that is found in a person or in the nature of an action.</p>\n<p>&nbsp;</p>\n<p>Our set of recommendations for the future development of artificial agents is also a significant result.&nbsp; The recommendations include the following principles: 1) Artificial agents should be understood to be sociotechnical systems or networks consisting of artifacts and social practices organized to accomplish specified tasks through their interactions; 2) Responsibility issues should be addressed when artificial agent technologies are in the early stages of development; 3) Claims about the autonomy of artifi...",
  "por_txt_cntn": "\nThe goal of this project was to examine the discourse around artificial agent technology and responsibility.  Artificial agents are software programs and software-hardware combinations (such as robots and drones) that make decisions and perform tasks independently in space and time from those who design and deploy them. Artificial agents are said to operate autonomously and to make decisions that may be incomprehensible to the humans who design and deploy them.  Some have suggested that because of the autonomy and opacity of artificial agents, no human beings can or will in the future be responsible for the behavior of some artificial agents.  Our intention was to examine this discourse to better understand how discussion and decision in the early stages of this technology\u00c6s development are shaping ideas and practices related to responsibility.  \n\n \n\nWe examined two threads of the discourse, one centered on artificial moral agents (i.e., agents that are programmed to behave according to moral rules), and the other centered on autonomous military robots. Our analyses are both descriptive and normative.  Several of our publications identify the diverse ways in which 'agency' and \u00e6autonomy\u00c6 are being used, and the ways in which design decisions may set the conditions for distribution of responsibility.  Several of the publications engage in the discourse in a critical way.  Our final publication is a set of recommendations for the future development of artificial agents.\n\n \n\nAs part of the project, we held a workshop on January 24-25 for 18 participants.  The participants consisted of experts from computer science and engineering, philosophy/ethics, law, STS, artificial intelligence and military ethics.  Participants were given drafts of papers and our recommendations before the workshop and their comments and feedback were discussed during the workshop and later used to make revisions. \n\n \n\nThe results of our research were published in five journal articles and one book chapter, and were presented at nine conferences.  The papers were targeted for publications that would reach diverse audiences.  One paper appears in the Military Review, a publication for military personnel and policy makers.  The Recommendations paper will appear in Technology &amp; Society Magazine, an IEEE journal read by engineers and computer scientists as well as STS scholars.  Another paper is published in the Journal of Business Ethics which has an audience of academic business school scholars and academic ethicists.  The other two papers appear in Ethics and Information Technology and Science and Engineering Ethics; these journals are read by interdisciplinary scholars and practitioners.\n\n \n\nSignificant results of the project include delineation of the different uses of the term autonomy in the two discourses on artificial agents and demonstration of how design decisions influence the distribution of responsibility.  In achieving these results we developed a new way of thinking about responsibility - as a set of normative social practices rather than something with a metaphysical character that is found in a person or in the nature of an action.\n\n \n\nOur set of recommendations for the future development of artificial agents is also a significant result.  The recommendations include the following principles: 1) Artificial agents should be understood to be sociotechnical systems or networks consisting of artifacts and social practices organized to accomplish specified tasks through their interactions; 2) Responsibility issues should be addressed when artificial agent technologies are in the early stages of development; 3) Claims about the autonomy of artificial agents should be judiciously and explicitly specified; and 4) Responsibility issues involving artificial agents can best be addressed by thinking in terms of responsibility practices.\n\nThe project involved collaboration between an early career scholar who has an interdisciplinary background in arti..."
 }
}