{
 "awd_id": "1048311",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CiC (RDDC) Parallelizing Large Scale Graph Problems on the Cloud",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-04-01",
 "awd_exp_date": "2014-03-31",
 "tot_intn_awd_amt": 369889.0,
 "awd_amount": 369889.0,
 "awd_min_amd_letter_date": "2011-03-28",
 "awd_max_amd_letter_date": "2011-03-28",
 "awd_abstract_narration": "This research explores application development and optimizations for cloud platforms by developing: 1) cloud based parallelization for data intensive graph algorithms, 2) a framework for efficient scheduling and execution of applications in a heterogeneous cloud environment, and 3) hierarchical programming abstraction to specify parallelism.  The work investigates and adapts wealth of techniques in traditional parallel computing for graph problems based on a performance model of the cloud and explore strategies for scheduling and load balancing applications on the cloud.  These include centralized and distributed approaches for scheduling and work stealing and work sharing.  Methodologies to evaluate the framework in executing applications that involve data intensive graph computations are being developed.  The broader impact of this project includes addressing key challenges in the areas of application mapping and performance optimization. The research makes developing data intensive graph applications across public and private clouds easier. The developed software will be released as free and open source software to the community, making it possible for researchers and engineers in academia and industry to leverage this work and develop applications for the cloud. Graph problems and streaming applications arising in the area of energy informatics are considered to illustrate the techniques.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Viktor",
   "pi_last_name": "Prasanna",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Viktor K Prasanna",
   "pi_email_addr": "prasanna@usc.edu",
   "nsf_id": "000209825",
   "pi_start_date": "2011-03-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Karthik",
   "pi_last_name": "Rajagopal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karthik Rajagopal",
   "pi_email_addr": "gomadam@usc.edu",
   "nsf_id": "000566484",
   "pi_start_date": "2011-03-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S FLOWER ST FL 3",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "90033",
  "perf_ctry_code": "US",
  "perf_cong_dist": "34",
  "perf_st_cong_dist": "CA34",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "8010",
   "pgm_ref_txt": "Computing in the Cloud"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 369889.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the age of cyber-social-physical network, there is tremendous value in data integration and association. The emergence of social computing, mobile computing, and the rapid adoption of near ubiquitous sensors that monitor and transmit data about physical objects, has led to applications handling data at a scale never seen before. This has made the task of meaningful data integration or &ldquo;connecting the dots&rdquo;, a challenge. It is in this context that cloud computing, with the promise of on demand scalability and virtually unlimited resources, has emerged as a powerful platform for developing and deploying applications that scale to meet the data challenge. Despite its significant advantages, the adoption of cloud computing as computing paradigm has been impeded by numerous concerns: (1) development of cloud based parallelization <del datetime=\"2014-04-25T22:14\" cite=\"mailto:Viktor%20Prasanna\"></del>techniques for data intensive applications, (2) simple programming abstraction<strong> </strong>for specifying parallelism, (3) framework for efficient scheduling and execution of applications in a heterogeneous private-public cloud environment, and (4) data privacy and security.</p>\n<p>The project addressed the above challenges by developing and implementing architectures that demonstrated the feasibility and performance improvements as well as cost benefits of using cloud infrastructures. These scalable platforms were used to handle large scale problems such as graph algorithms which form the basis of social network analysis and large scale machine learning models.</p>\n<p>We evaluated our the general-purpose graph processing framework on public cloud platforms; and developed resource allocation strategies for use in hybrid cloud computing environments; modeled application dynamism to enable elasticity in continuous workflows and benchmarked the system on a practical real-world application, that of enabling d<del datetime=\"2014-04-25T22:23\" cite=\"mailto:Viktor%20Prasanna\"></del>ynamic d<del datetime=\"2014-04-25T22:23\" cite=\"mailto:Viktor%20Prasanna\"></del>emand r<del datetime=\"2014-04-25T22:23\" cite=\"mailto:Viktor%20Prasanna\"></del>esponse in a Smart Power Grid Cyber-Physical System using c<del datetime=\"2014-04-25T22:16\" cite=\"mailto:Viktor%20Prasanna\"></del>loud technologies.</p>\n<p>Our findings extend beyond the field of computer science and engineering. The architectures and algorithms we proposed can be used in many disciplines. For example<ins datetime=\"2014-04-25T22:23\" cite=\"mailto:Viktor%20Prasanna\">,</ins> they can be used by social sciences researchers to analyze social graphs and study <del datetime=\"2014-04-25T10:07\" cite=\"mailto:Marc%20Frincu\"></del>human behavior through the analysis. In particular, we built a Cloud-based software platform for data-driven analytics for a smart grid that will be part of the Los Angeles Smart Grid Project. The graph algorithms that we use to evaluate the performance of our proposed systems form the basis for social network analysis. Our software products are open source and can be publicly used and extended by the research community for specific needs. We have implemented three open source systems namely, &ldquo;Pillcrow&rdquo; for scalable graph analysis, &ldquo;OpenPlanet&rdquo; for large scale machine learning and &ldquo;Cryptonite&rdquo; for secure data repository. Of these, Pillcrow and Cryptonite were implemented on the Microsoft Azure platform and OpenPlanet is implemented using the open source Hadoop, an implementation of Map-Reduce programming model.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/25/2014<br>\n\t\t\t\t\tModified by: Viktor&nbsp;K&nbsp;Prasanna</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the age of cyber-social-physical network, there is tremendous value in data integration and association. The emergence of social computing, mobile computing, and the rapid adoption of near ubiquitous sensors that monitor and transmit data about physical objects, has led to applications handling data at a scale never seen before. This has made the task of meaningful data integration or \"connecting the dots\", a challenge. It is in this context that cloud computing, with the promise of on demand scalability and virtually unlimited resources, has emerged as a powerful platform for developing and deploying applications that scale to meet the data challenge. Despite its significant advantages, the adoption of cloud computing as computing paradigm has been impeded by numerous concerns: (1) development of cloud based parallelization techniques for data intensive applications, (2) simple programming abstraction for specifying parallelism, (3) framework for efficient scheduling and execution of applications in a heterogeneous private-public cloud environment, and (4) data privacy and security.\n\nThe project addressed the above challenges by developing and implementing architectures that demonstrated the feasibility and performance improvements as well as cost benefits of using cloud infrastructures. These scalable platforms were used to handle large scale problems such as graph algorithms which form the basis of social network analysis and large scale machine learning models.\n\nWe evaluated our the general-purpose graph processing framework on public cloud platforms; and developed resource allocation strategies for use in hybrid cloud computing environments; modeled application dynamism to enable elasticity in continuous workflows and benchmarked the system on a practical real-world application, that of enabling dynamic demand response in a Smart Power Grid Cyber-Physical System using cloud technologies.\n\nOur findings extend beyond the field of computer science and engineering. The architectures and algorithms we proposed can be used in many disciplines. For example, they can be used by social sciences researchers to analyze social graphs and study human behavior through the analysis. In particular, we built a Cloud-based software platform for data-driven analytics for a smart grid that will be part of the Los Angeles Smart Grid Project. The graph algorithms that we use to evaluate the performance of our proposed systems form the basis for social network analysis. Our software products are open source and can be publicly used and extended by the research community for specific needs. We have implemented three open source systems namely, \"Pillcrow\" for scalable graph analysis, \"OpenPlanet\" for large scale machine learning and \"Cryptonite\" for secure data repository. Of these, Pillcrow and Cryptonite were implemented on the Microsoft Azure platform and OpenPlanet is implemented using the open source Hadoop, an implementation of Map-Reduce programming model.\n\n \n\n\t\t\t\t\tLast Modified: 04/25/2014\n\n\t\t\t\t\tSubmitted by: Viktor K Prasanna"
 }
}