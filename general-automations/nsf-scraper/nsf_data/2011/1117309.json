{
 "awd_id": "1117309",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Expansion, Unique Games, and Efficient Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 458000.0,
 "awd_min_amd_letter_date": "2011-07-07",
 "awd_max_amd_letter_date": "2012-06-01",
 "awd_abstract_narration": "Graph expansion refers to the problem of partitioning a graph into two (or more) large pieces while minimizing the size of the \"interface\" between them. Graph partitions or separators are central objects of study in the theory of Markov chains, geometric embeddings, etc., and are a natural algorithmic primitive in numerous settings. Exact computation is NP-hard, so we are interested in approximate solutions. Despite much work, the status of most expansion-type problems is still open, in contrast to better-understood problems such as MAX-3SAT. In recent years it has become clearer that expansion-like problems hold the key to many of the remaining mysteries of approximation, such as the unique games conjecture or UGC (formulated by Khot when he was the PI's graduate student) and the Small-set expansion conjecture (formulated recently by Raghavendra and Steuerer, and part of Steurer's 2010 dissertation supervised by the PI). \r\n\r\nA principal goal of this award is to apply new spectral (as in eigenvalues/eigenvectors) ideas to study graph expansion. These ideas were introduced in the PI's recent coauthored work with Barak and Steurer on subexponential algorithms for Unique Games problem.\r\n\r\nThis award may result in transformative outcomes such as resolution of the unique games conjecture, or new algorithms for graph partitioning based upon the full spectrum (as opposed to algorithms using just the second eigenvector whose limitations are well-known).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sanjeev",
   "pi_last_name": "Arora",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjeev Arora",
   "pi_email_addr": "arora@cs.princeton.edu",
   "nsf_id": "000101873",
   "pi_start_date": "2011-07-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "1 NASSAU HALL",
  "perf_city_name": "PRINCETON",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 450000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of this project was to design provable algorithms for a host of computational problems, including problems arising in machine learning and &ldquo;big data&rdquo; settings.</p>\n<p>One object of study were Lasserre relaxations, a hierarchy of algorithms based upon &nbsp;convex programming. In FOCS'12 they were used to design a new approach to Sparsest Cut, which also gave (1+c)-approximation for interesting families of graphs, for every c &gt;0.&nbsp; Grad student Sachdeva in some coauthored work gave unexpectedly more efficient spectral algorithms for graph partitioning. More recently, grad student Ma has explored the power and limitations of Lasserre relaxations for machine learning problems, including tensor decomposition and sparse PCA.&nbsp;</p>\n<p>The biggest breakthroughs came in designing new provable algorithms for well-known machine learning problems. This proceeds by making reasonable assumptions about the structure of the inputs. The first success was in topic modeling, a popular approach to automatically infer the thematic structure of a corpus of documents. A new theoretical algorithm was published in IEEE FOCS&rsquo;12; and a more practical version that vastly improved upon earlier algorithms was published in ICML&rsquo;13. &nbsp;Grad student Rong Ge was involved in developing a nice new framework for machine learning problems using tensor decomposition.</p>\n<p>Progress was also made in understanding sparse coding. Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non&shy;convex optimization problem which is solved in practice by heuristics based on alternating minimization. Over two papers in COLT&rsquo;14 and COLT&rsquo;15 it was shown how to analyse such procedures and design algorithms with provable runtime guarantees.</p>\n<p>The project has also been training a new generation of researchers who are equally fluent in theoretical computer science and machine learning, as well as comfortable in experimental big data work. Postdoc Moitra is now a faculty member at MIT, and grad student Ge is a faculty member at Duke. Several undergrads worked with the PI and are now in top graduate schools around the US.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/04/2016<br>\n\t\t\t\t\tModified by: Sanjeev&nbsp;Arora</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of this project was to design provable algorithms for a host of computational problems, including problems arising in machine learning and \"big data\" settings.\n\nOne object of study were Lasserre relaxations, a hierarchy of algorithms based upon  convex programming. In FOCS'12 they were used to design a new approach to Sparsest Cut, which also gave (1+c)-approximation for interesting families of graphs, for every c &gt;0.  Grad student Sachdeva in some coauthored work gave unexpectedly more efficient spectral algorithms for graph partitioning. More recently, grad student Ma has explored the power and limitations of Lasserre relaxations for machine learning problems, including tensor decomposition and sparse PCA. \n\nThe biggest breakthroughs came in designing new provable algorithms for well-known machine learning problems. This proceeds by making reasonable assumptions about the structure of the inputs. The first success was in topic modeling, a popular approach to automatically infer the thematic structure of a corpus of documents. A new theoretical algorithm was published in IEEE FOCS\u00c612; and a more practical version that vastly improved upon earlier algorithms was published in ICML\u00c613.  Grad student Rong Ge was involved in developing a nice new framework for machine learning problems using tensor decomposition.\n\nProgress was also made in understanding sparse coding. Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non&shy;convex optimization problem which is solved in practice by heuristics based on alternating minimization. Over two papers in COLT\u00c614 and COLT\u00c615 it was shown how to analyse such procedures and design algorithms with provable runtime guarantees.\n\nThe project has also been training a new generation of researchers who are equally fluent in theoretical computer science and machine learning, as well as comfortable in experimental big data work. Postdoc Moitra is now a faculty member at MIT, and grad student Ge is a faculty member at Duke. Several undergrads worked with the PI and are now in top graduate schools around the US. \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/04/2016\n\n\t\t\t\t\tSubmitted by: Sanjeev Arora"
 }
}