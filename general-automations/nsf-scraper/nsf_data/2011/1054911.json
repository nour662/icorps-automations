{
 "awd_id": "1054911",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Learning- and Incentives-Based Techniques for Aggregating Community-Generated Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2011-06-01",
 "awd_exp_date": "2015-03-31",
 "tot_intn_awd_amt": 496671.0,
 "awd_amount": 238627.0,
 "awd_min_amd_letter_date": "2011-01-19",
 "awd_max_amd_letter_date": "2015-04-08",
 "awd_abstract_narration": "The Internet has led to the availability of novel sources of data on the preferences, behaviors, and beliefs of massive communities of users. \r\nBoth researchers and engineers are eager to aggregate and interpret this data. However, websites sometimes fail to incentivize high-quality contributions, leading to variable quality data. Furthermore, assumptions made by traditional theories of learning break down in these settings.\r\n\r\nThis project seeks to create foundational machine learning models and algorithms to address and explain the issues that arise when aggregating local beliefs across large communities, and to advance the state-of-the-art understanding of how to motivate high quality contributions. The research can be split into three directions:\r\n\r\n1. Developing mathematical foundations and algorithms for learning from community-labeled data.  This direction involves developing learning models for data from disparate (potentially self-interested or\r\nmalicious) sources and using insight from these models to design efficient learning algorithms.\r\n\r\n2. Understanding and designing better incentives for crowdsourcing. This direction involves modeling crowdsourcing contributions to determine which features to include in systems to encourage the highest quality contributions.\r\n\r\n3. Introducing novel economically-motivated mechanisms for opinion aggregation. This involves formalizing the properties a prediction market should satisfy and making use of ideas from machine learning and optimization to derive tractable market mechanisms satisfying these properties.\r\n\r\nThis research will have clear impact on industry, especially for web-based crowdsourcing. The PI will pursue her long-term goal of attracting and retaining women in computer science via her involvement in workshops and mentoring programs.  Results will be disseminated at http://www.cs.ucla.edu/~jenn/projects/CAREER.html.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Vaughan",
   "pi_mid_init": "W",
   "pi_sufx_name": "Dr.",
   "pi_full_name": "Jennifer W Vaughan",
   "pi_email_addr": "jenn@cs.ucla.edu",
   "nsf_id": "000560979",
   "pi_start_date": "2011-01-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "10889 WILSHIRE BLVD STE 700",
  "perf_city_name": "LOS ANGELES",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900244200",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "1187",
   "pgm_ref_txt": "PECASE- eligible"
  },
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 80830.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 144266.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 13530.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The primary goal of this project was to advance the state-of-the-art understanding of how to elicit and aggregate high quality information and beliefs from (online) crowds.<br /><br />The results can be broken down into three primary directions.<br /><br />First, this research produced novel online learning algorithms to assign crowdworkers to tasks. Crowdsourcing markets provide a way for requesters to inexpensively obtain distributed labor and information, and have recently become popular among researchers who use them to conduct user studies, run behavioral experiments, and collect data that is easy for humans to generate but difficult for computers. Unlike in traditional labor markets, requesters interact with many workers rapidly and can potentially adjust their behavior as they learn more about salient features of the environment, such as workers&rsquo; skill levels, the difficulty of their tasks, and workers&rsquo; willingness to accept their tasks at given prices. We addressed the challenge that a requester faces when assigning heterogeneous tasks to workers with unknown, heterogeneous skills. We formalized this &ldquo;online task assignment problem,&rdquo; provided a task assignment algorithm that is provably near-optimal given that workers return repeatedly, and evaluated this algorithm on data collected from the popular crowdsourcing platform Amazon Mechanical Turk. We then extended this line of work to cover classification or labeling tasks in which the quality of work cannot be judged immediately.<br /><br />Second, this research contributed to a more thorough understanding of performance-based incentives in crowdsourcing systems. We designed and ran randomized behavioral experiments on Amazon Mechanical Turk with the goal of understanding when, where, and why performance-based payments improve work quality, identifying properties of the payment, payment structure, and the task itself that make them most effective. Based on our findings, we proposed a new model of worker behavior that extends the standard principal-agent model from economics to include a worker&rsquo;s subjective beliefs about his likelihood of being paid. We also designed an algorithm using multi-armed bandit techniques for optimally setting the amounts of performance-based payments for tasks assuming workers strategically choose their level of effort.<br /><br />Finally, this research contributed a thorough study of several key research questions surrounding the design of prediction market mechanisms that elicit and aggregate beliefs from crowds of traders. A prediction market is a market in which traders buy and sell securities with values that are contingent on the outcome of a future event. For example, a security may pay off $1 if a Democrat wins the 2016 US Presidential election and $0 otherwise. The market price of such a security is thought to reflect the traders&rsquo; collective belief about the likelihood that a Democrat will win. To facilitate trade, a prediction market can be operated by an automated market maker, an algorithmic agent that offers to buy or sell securities at some current market price determined by a pricing mechanism that makes use of the trade history. The market maker provides liquidity in the market, effectively subsidizing the market and rewarding traders for their private information. This is especially useful in &ldquo;combinatorial markets&rdquo; which offer securities defined on a large or infinite outcome space and propagate information (in the form of prices) appropriately across logically-related securities.<br /><br />We proposed a general framework for the design of efficient pricing mechanisms over very large or infinite outcome spaces. We took an axiomatic approach, specifying a set of formal mathematical properties that any reasonable market should satisfy and fully characterized the set of pricing mechanisms that satisfy these properties....",
  "por_txt_cntn": "\nThe primary goal of this project was to advance the state-of-the-art understanding of how to elicit and aggregate high quality information and beliefs from (online) crowds.\n\nThe results can be broken down into three primary directions.\n\nFirst, this research produced novel online learning algorithms to assign crowdworkers to tasks. Crowdsourcing markets provide a way for requesters to inexpensively obtain distributed labor and information, and have recently become popular among researchers who use them to conduct user studies, run behavioral experiments, and collect data that is easy for humans to generate but difficult for computers. Unlike in traditional labor markets, requesters interact with many workers rapidly and can potentially adjust their behavior as they learn more about salient features of the environment, such as workers\u00c6 skill levels, the difficulty of their tasks, and workers\u00c6 willingness to accept their tasks at given prices. We addressed the challenge that a requester faces when assigning heterogeneous tasks to workers with unknown, heterogeneous skills. We formalized this \"online task assignment problem,\" provided a task assignment algorithm that is provably near-optimal given that workers return repeatedly, and evaluated this algorithm on data collected from the popular crowdsourcing platform Amazon Mechanical Turk. We then extended this line of work to cover classification or labeling tasks in which the quality of work cannot be judged immediately.\n\nSecond, this research contributed to a more thorough understanding of performance-based incentives in crowdsourcing systems. We designed and ran randomized behavioral experiments on Amazon Mechanical Turk with the goal of understanding when, where, and why performance-based payments improve work quality, identifying properties of the payment, payment structure, and the task itself that make them most effective. Based on our findings, we proposed a new model of worker behavior that extends the standard principal-agent model from economics to include a worker\u00c6s subjective beliefs about his likelihood of being paid. We also designed an algorithm using multi-armed bandit techniques for optimally setting the amounts of performance-based payments for tasks assuming workers strategically choose their level of effort.\n\nFinally, this research contributed a thorough study of several key research questions surrounding the design of prediction market mechanisms that elicit and aggregate beliefs from crowds of traders. A prediction market is a market in which traders buy and sell securities with values that are contingent on the outcome of a future event. For example, a security may pay off $1 if a Democrat wins the 2016 US Presidential election and $0 otherwise. The market price of such a security is thought to reflect the traders\u00c6 collective belief about the likelihood that a Democrat will win. To facilitate trade, a prediction market can be operated by an automated market maker, an algorithmic agent that offers to buy or sell securities at some current market price determined by a pricing mechanism that makes use of the trade history. The market maker provides liquidity in the market, effectively subsidizing the market and rewarding traders for their private information. This is especially useful in \"combinatorial markets\" which offer securities defined on a large or infinite outcome space and propagate information (in the form of prices) appropriately across logically-related securities.\n\nWe proposed a general framework for the design of efficient pricing mechanisms over very large or infinite outcome spaces. We took an axiomatic approach, specifying a set of formal mathematical properties that any reasonable market should satisfy and fully characterized the set of pricing mechanisms that satisfy these properties. Then, using techniques from convex analysis, we provided a method for designing specific pricing mechanisms that satisfy these properties, and described how to..."
 }
}