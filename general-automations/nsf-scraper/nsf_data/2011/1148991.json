{
 "awd_id": "1148991",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Theory and Applications of Random Forests",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2011-07-01",
 "awd_exp_date": "2014-06-30",
 "tot_intn_awd_amt": 159999.0,
 "awd_amount": 159999.0,
 "awd_min_amd_letter_date": "2011-09-01",
 "awd_max_amd_letter_date": "2013-04-22",
 "awd_abstract_narration": "This research develops theory for random forests specifically for the purpose of better facilitating its use in practical settings. Theoretical considerations include balancedness, subtrees, node distributions, node splitting, depth of variables, and other novel tree concepts.  These concepts are used to improve prediction and variable selection for random forests in both high and low-dimensional problems.  \r\n\r\nOne of the simplest techniques for improving the performance of a statistical method such as a tree is to take its average over multiple instances of the data. This averaging process is often referred to as ensemble learning and has attracted considerable attention as it has been widely observed that combining elementary learners can yield a predictor with superior prediction performance. One of the most successful tree ensemble learners is random forests.  Random forests has met with considerable empirical success, yet much is still unknown about it.  This research seeks to improve our understanding of random forests and utilize this knowledge to enhance its application in practical settings.  This research focuses on cardiovascular disease, the number one cause of death in the developed world, cancer staging and prognostication for cancer patients, and identifying and developing genotype signatures for myelodsyplastic syndromes, a heterogeneous diseases of blood stem cells having no current curative medical therapy.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hemant",
   "pi_last_name": "Ishwaran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hemant Ishwaran",
   "pi_email_addr": "HIshwaran@med.miami.edu",
   "nsf_id": "000113468",
   "pi_start_date": "2011-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Miami School of Medicine",
  "inst_street_address": "1320 S DIXIE HWY STE 1200",
  "inst_street_address_2": "",
  "inst_city_name": "CORAL GABLES",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3052843924",
  "inst_zip_code": "331462926",
  "inst_country_name": "United States",
  "cong_dist_code": "27",
  "st_cong_dist_code": "FL27",
  "org_lgl_bus_name": "UNIVERSITY OF MIAMI",
  "org_prnt_uei_num": "",
  "org_uei_num": "F8THLJQSAF93"
 },
 "perf_inst": {
  "perf_inst_name": "University of Miami School of Medicine",
  "perf_str_addr": "1120 NW 14th Street. Clinical Research Building",
  "perf_city_name": "Miami",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "331362107",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "FL26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 63874.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 55694.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 40431.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Ensemble learning involves the simple task of taking elementary procedures (base-learners) and combining them to form an ensemble. This simple process often yields a predictor with superior performance; one of the most successful examples is random&nbsp; forests (RF), an ensemble formed using random tree base-learners. &nbsp;In this project a unified theory for splitting properties of RF was developed which yields not only a deeper understanding of the method, but always points to means for improving it in applications. &nbsp;It was shown that a class of weighted splitting rules possess a unique adaptive property to signal and noise, and in particular under noise weighted splitting favors end-cut splits. While end-cut splits have traditionally been viewed as undesirable for single trees, it is beneficial to RF for several reasons. &nbsp;This points to means for developing more general splitting rules: including unsupervised rules and multivariate rules which could be used for missing data analysis and multivariate regression problems. &nbsp;The project has also contributed to the extension of RF to more general problems. &nbsp;RF has traditionally been used for regression and classification. &nbsp;This project has extended its applications to other data analysis settings, such as competing risks, a data problem often seen in medical studies. A unified, user friendly parallel enabled open source RF software package was developed and is available to the general public and will be useful to scientists worldwide as a general, powerful data analysis tool.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/11/2014<br>\n\t\t\t\t\tModified by: Hemant&nbsp;Ishwaran</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405091273484_minimal_depth--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405091273484_minimal_depth--rgov-800width.jpg\" title=\"Minimal Depth\"><img src=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405091273484_minimal_depth--rgov-66x44.jpg\" alt=\"Minimal Depth\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Minimal depth is a measure of the distance of a variable relative to the root of the tree for directly assessing thepredictiveness of a variable.</div>\n<div class=\"imageCredit\">Chen X. and Ishwaran H. (2012). Random forests for genomic data analysis. Genomics, 99, 323-329</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Hemant&nbsp;Ishwaran</div>\n<div class=\"imageTitle\">Minimal Depth</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405092148755_splitting--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405092148755_splitting--rgov-800width.jpg\" title=\"Splitting behavior\"><img src=\"/por/images/Reports/POR/2014/1148991/1148991_10093515_1405092148755_splitting--rgov-66x44.jpg\" alt=\"Splitting behavior\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">End-cut preference (ECP) behavior for different splitting rules.  Black, blue and red indicate low, medium and high ECP values.  ECP splits have generally been viewed as undesirable for trees, but we have shown they are very important for random forests.</div>\n<div class=\"imageCredit\">Ishwaran H. The effect of splitting on random forests. (2014). Machine Learning. doi 10.1007/s10994-014-5451-2</div>\n<div class=\"imagePermisssions\">C...",
  "por_txt_cntn": "\nEnsemble learning involves the simple task of taking elementary procedures (base-learners) and combining them to form an ensemble. This simple process often yields a predictor with superior performance; one of the most successful examples is random  forests (RF), an ensemble formed using random tree base-learners.  In this project a unified theory for splitting properties of RF was developed which yields not only a deeper understanding of the method, but always points to means for improving it in applications.  It was shown that a class of weighted splitting rules possess a unique adaptive property to signal and noise, and in particular under noise weighted splitting favors end-cut splits. While end-cut splits have traditionally been viewed as undesirable for single trees, it is beneficial to RF for several reasons.  This points to means for developing more general splitting rules: including unsupervised rules and multivariate rules which could be used for missing data analysis and multivariate regression problems.  The project has also contributed to the extension of RF to more general problems.  RF has traditionally been used for regression and classification.  This project has extended its applications to other data analysis settings, such as competing risks, a data problem often seen in medical studies. A unified, user friendly parallel enabled open source RF software package was developed and is available to the general public and will be useful to scientists worldwide as a general, powerful data analysis tool.\n\n\t\t\t\t\tLast Modified: 07/11/2014\n\n\t\t\t\t\tSubmitted by: Hemant Ishwaran"
 }
}