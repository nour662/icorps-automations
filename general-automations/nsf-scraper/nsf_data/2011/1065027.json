{
 "awd_id": "1065027",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2011-06-01",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 389952.0,
 "awd_amount": 436467.0,
 "awd_min_amd_letter_date": "2011-06-02",
 "awd_max_amd_letter_date": "2015-05-06",
 "awd_abstract_narration": "This research involves collaboration among investigators at four institutions.  Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning.  While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms.  For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control.  The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions.  These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof).  The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags.  The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date.  In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics.  To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR).  An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis.  Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder.  To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined.\r\n\r\nBroader Impacts:  This research will revolutionize the control and interface of upper limb prosthetics.  The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease.  The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research.  The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Gillespie",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Richard B Gillespie",
   "pi_email_addr": "brentg@engin.umich.edu",
   "nsf_id": "000463310",
   "pi_start_date": "2011-06-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "Regents of the University of Michigan - Ann Arbor",
  "perf_str_addr": "1109 GEDDES AVE STE 3300",
  "perf_city_name": "ANN ARBOR",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091015",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 100112.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 112550.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 201295.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16010.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 6500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When using an upper limb prosthesis to manipulate objects or discover their mechanical properties, an amputee only has visual feedback to rely on, supplemented weakly by forces transmitted through the prosthesis fitting or, in the case of a body-powered prosthesis, transmitted through a control cable. These feedback signals make poor substitutes for the cues normally available from tactile and kinesthetic sensors in an intact hand. And while advanced powered prostheses are moving closer to the natural limb in terms of the number and form of joints, the means of control and the sensory feedback available to support dexterous control lag far behind.&nbsp;In this project we have developed a suite of haptic display technologies that relay proprioceptive, force, and contact cues from a prosthetic terminal device back to the residual limb and thereby reduce reliance on visual feedback. We have also contributed basic science results that will continue to guide future efforts to improve manual dexterity and reduce visual load for upper limb amputees.</p>\n<p class=\"Default\">Our contributions to basic science are three-fold.&nbsp; First, they include a quantification of the benefits of force feedback available in body-powered prostheses.&nbsp; We outfitted a body-powered prosthesis with a segment of &ldquo;virtual cable&rdquo; (a single-axis teleoperator) that allowed us to optionally remove force feedback without changing control operation and found that force feedback contributes to an ability to sort foam blocks by stiffness even better than visual feedback. Second, we quantified a compromise inherent in the use of haptic display with myoelectric control&mdash;that force feedback cannot be delivered to the same muscle used for generating a myoelectric control signal.&nbsp; Using a novel haptic device that could optionally be configured for one or two limbs, we showed that when action/reaction cues are decoupled, perception of stiffness degrades, even when sensory substitution is avoided. Third, we evaluated decrements in dexterity associated with the use of motorized joints that are highly geared and therefore non-backdrivable (as typically required in prosthetic joints to meet power and weight requirements).&nbsp; In experiments involving both amputees and non-amputees using proportional myoelectric control and a backdrivable terminal device, we showed that referred haptic feedback improves coordination and mitigates slips in a grasp and lift task. Taken together, these experimental results expose and characterize important tradeoffs in the use of control and sensory feedback technologies currently available and those that might be made available in the future, including direct brain and peripheral nerve interface technologies.&nbsp; We continue to use these quantified tradeoffs to guide our research in non-invasive direct brain interface and peripheral nerve interface as well as continued improvements to body-powered and myoelectric interface technologies for prosthetics, with special emphasis on the value of sensory feedback.&nbsp;&nbsp;</p>\n<p class=\"Default\">With collaborators at Rice University, the University of Houston, and Drexel University, we have designed and validated decoding algorithms that derive real-time grip force control signals from electroencephalographic signals collected noninvasively using electrodes worn on the scalp.&nbsp; We have employed these signals together with sensory feedback to provide grip function in a motorized prosthesis. This project has enjoyed synergies created by a highly functional interdisciplinary team focused on innovation in education, training, co-advising, course development, involvement of undergraduates in research, and exchange of students.&nbsp;This project also provided training in human-machine interface, prosthetics, and haptics for all researchers involved, including cross-training between residents in the Prosthetics and Orthotics program, students in Mechanical Engineering, and students from each of the collaborating labs.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/17/2017<br>\n\t\t\t\t\tModified by: Richard&nbsp;B&nbsp;Gillespie</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhen using an upper limb prosthesis to manipulate objects or discover their mechanical properties, an amputee only has visual feedback to rely on, supplemented weakly by forces transmitted through the prosthesis fitting or, in the case of a body-powered prosthesis, transmitted through a control cable. These feedback signals make poor substitutes for the cues normally available from tactile and kinesthetic sensors in an intact hand. And while advanced powered prostheses are moving closer to the natural limb in terms of the number and form of joints, the means of control and the sensory feedback available to support dexterous control lag far behind. In this project we have developed a suite of haptic display technologies that relay proprioceptive, force, and contact cues from a prosthetic terminal device back to the residual limb and thereby reduce reliance on visual feedback. We have also contributed basic science results that will continue to guide future efforts to improve manual dexterity and reduce visual load for upper limb amputees.\nOur contributions to basic science are three-fold.  First, they include a quantification of the benefits of force feedback available in body-powered prostheses.  We outfitted a body-powered prosthesis with a segment of \"virtual cable\" (a single-axis teleoperator) that allowed us to optionally remove force feedback without changing control operation and found that force feedback contributes to an ability to sort foam blocks by stiffness even better than visual feedback. Second, we quantified a compromise inherent in the use of haptic display with myoelectric control&mdash;that force feedback cannot be delivered to the same muscle used for generating a myoelectric control signal.  Using a novel haptic device that could optionally be configured for one or two limbs, we showed that when action/reaction cues are decoupled, perception of stiffness degrades, even when sensory substitution is avoided. Third, we evaluated decrements in dexterity associated with the use of motorized joints that are highly geared and therefore non-backdrivable (as typically required in prosthetic joints to meet power and weight requirements).  In experiments involving both amputees and non-amputees using proportional myoelectric control and a backdrivable terminal device, we showed that referred haptic feedback improves coordination and mitigates slips in a grasp and lift task. Taken together, these experimental results expose and characterize important tradeoffs in the use of control and sensory feedback technologies currently available and those that might be made available in the future, including direct brain and peripheral nerve interface technologies.  We continue to use these quantified tradeoffs to guide our research in non-invasive direct brain interface and peripheral nerve interface as well as continued improvements to body-powered and myoelectric interface technologies for prosthetics, with special emphasis on the value of sensory feedback.  \nWith collaborators at Rice University, the University of Houston, and Drexel University, we have designed and validated decoding algorithms that derive real-time grip force control signals from electroencephalographic signals collected noninvasively using electrodes worn on the scalp.  We have employed these signals together with sensory feedback to provide grip function in a motorized prosthesis. This project has enjoyed synergies created by a highly functional interdisciplinary team focused on innovation in education, training, co-advising, course development, involvement of undergraduates in research, and exchange of students. This project also provided training in human-machine interface, prosthetics, and haptics for all researchers involved, including cross-training between residents in the Prosthetics and Orthotics program, students in Mechanical Engineering, and students from each of the collaborating labs. \n\n \n\n\t\t\t\t\tLast Modified: 10/17/2017\n\n\t\t\t\t\tSubmitted by: Richard B Gillespie"
 }
}