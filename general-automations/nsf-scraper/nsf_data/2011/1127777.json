{
 "awd_id": "1127777",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AIR:  Next-generation Graphics in the Cloud",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Barbara H. Kenny",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2013-07-31",
 "tot_intn_awd_amt": 149651.0,
 "awd_amount": 149651.0,
 "awd_min_amd_letter_date": "2011-07-20",
 "awd_max_amd_letter_date": "2011-11-18",
 "awd_abstract_narration": "The proposal seeks to establish a means to do high performance 3-D multiviepoint gaming in the cloud as a foundation for a fundamental change in the gaming industry now dominated by specialized hardware local to each gamer. The approach uses PLASM (Parallel Lighting and Animation Subscription Model), an architecture for multi-viewpoint computer graphics designed for large-scale computer systems, to exploit graphics computations across multiple users drawing on cloud data center and computational resources. The proposed method has the potential to achieve orders-of-magnitude increases in graphics computation at constant hardware cost for multiple concurrent users. \r\n\r\nThe PI intends to create a startup company around this technology which has the potential to be disruptive to the current gaming solutions. The license by usage time suggested seeks to obtain a market share of the current 3B playing hours per week of gamers. PLASM has the potential to be enabling to the migration of other important graphics applications to the cloud computing environment including real time interactive maps, e-design, visualization and medicine involving multiple users and collaborators. The effort is linked with Project Olympus at CMU school of computer science aimed at bridging research and commercialization.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Adrien",
   "pi_last_name": "Treuille",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Adrien Treuille",
   "pi_email_addr": "treuille@cs.cmu.edu",
   "nsf_id": "000527103",
   "pi_start_date": "2011-07-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Barbara",
   "pi_last_name": "Carryer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Barbara Carryer",
   "pi_email_addr": "bcarryer@andrew.cmu.edu",
   "nsf_id": "000579809",
   "pi_start_date": "2011-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Ave.",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801900",
   "pgm_ele_name": "Accelerating Innovation Rsrch"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8019",
   "pgm_ref_txt": "Accelerating Innovation Rsrch"
  },
  {
   "pgm_ref_code": "8028",
   "pgm_ref_txt": "Sensor Technology"
  },
  {
   "pgm_ref_code": "8035",
   "pgm_ref_txt": "Hardware Devices"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 149651.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The video game industry is a major economic driver with worldwide revenues of $57B. The industry is driven by demand for new and better graphics technology. However, despite major advances, computer graphics remains far from modeling the complexity of the world. Complex lighting, physics, and geometric phenomena all elude real-time modeling. Nor will current hardware trends soon solve this problem: the gap between real and virtual reality requires orders-of magnitude greater computation.The gaming industry is moving into cloud computing. This shift is part of a trend in an array of applications towards exploiting the economies of scale inherent in cloud computing. For games specifically, shifting to the cloud opens a new and currently unexploited potential to fundamentally increase graphics performance.</p>\n<p><br />This project explored a new architecture for computer graphics which realizes the potential of cloud-based simulation and rendering for the first time. By exploiting graphics amortization in large-data centers, this technology will transcend current hardware limitations and enable major improvements in graphics computation.</p>\n<p><br />The project has lead to the development of a new cloud-based cloth simulator which uses several thousand CPU-hours of cloud precompuation to perform a massive exploration of the space of cloth motion. Significantly, we find that it is possible to sample the dynamical space to a low visual error tolerance and that secondary motion graphs containing tens of gigabytes of raw mesh data can be compressed down to only tens of megabytes. These results allow us to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efficiently as part of an interactive application.</p>\n<p><br />More generally, these results illuminate a path for cloud computing to significantly improve the realism of next-generation graphics. We are now working to generalize these results to a broader range of physical phenomena which are even more complex, notably fluid dynamics. We view this work as an important precursor to demonstrating the commercial viability of cloud-based graphics.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2013<br>\n\t\t\t\t\tModified by: Adrien&nbsp;Treuille</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe video game industry is a major economic driver with worldwide revenues of $57B. The industry is driven by demand for new and better graphics technology. However, despite major advances, computer graphics remains far from modeling the complexity of the world. Complex lighting, physics, and geometric phenomena all elude real-time modeling. Nor will current hardware trends soon solve this problem: the gap between real and virtual reality requires orders-of magnitude greater computation.The gaming industry is moving into cloud computing. This shift is part of a trend in an array of applications towards exploiting the economies of scale inherent in cloud computing. For games specifically, shifting to the cloud opens a new and currently unexploited potential to fundamentally increase graphics performance.\n\n\nThis project explored a new architecture for computer graphics which realizes the potential of cloud-based simulation and rendering for the first time. By exploiting graphics amortization in large-data centers, this technology will transcend current hardware limitations and enable major improvements in graphics computation.\n\n\nThe project has lead to the development of a new cloud-based cloth simulator which uses several thousand CPU-hours of cloud precompuation to perform a massive exploration of the space of cloth motion. Significantly, we find that it is possible to sample the dynamical space to a low visual error tolerance and that secondary motion graphs containing tens of gigabytes of raw mesh data can be compressed down to only tens of megabytes. These results allow us to capture the effect of high-resolution, off-line cloth simulation for a rich space of character motion and deliver it efficiently as part of an interactive application.\n\n\nMore generally, these results illuminate a path for cloud computing to significantly improve the realism of next-generation graphics. We are now working to generalize these results to a broader range of physical phenomena which are even more complex, notably fluid dynamics. We view this work as an important precursor to demonstrating the commercial viability of cloud-based graphics.\n\n\t\t\t\t\tLast Modified: 12/01/2013\n\n\t\t\t\t\tSubmitted by: Adrien Treuille"
 }
}