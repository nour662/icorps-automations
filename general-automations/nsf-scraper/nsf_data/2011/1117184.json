{
 "awd_id": "1117184",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Generation of High-Quality Tests by Treating Tests as Proof Encoding",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 495258.0,
 "awd_amount": 495258.0,
 "awd_min_amd_letter_date": "2011-06-30",
 "awd_max_amd_letter_date": "2011-06-30",
 "awd_abstract_narration": "Verification is a bottleneck of crisis proportions in the design\r\nof the hardware and software systems society depends on.  The two\r\nmain approaches to verification are formal verification and\r\ntesting. Formal verification has the advantage that it rules out\r\nthe existence of any logical bugs that violate the properties\r\nunder consideration. Unfortunately, current formal methods are\r\nnot scalable and cannot be directly applied to entire designs. In\r\ncontrast, testing is very scalable and is therefore the method of\r\nchoice in practice. The disadvantage of testing is that it does\r\nnot rule out the existence of bugs, and bugs that escape the\r\ntesting process can lead to recalls, software crashes, and even\r\nthe loss of life. The research proposed will make testing more\r\neffective by developing methods of test generation that reduce\r\nthe probability of missing bugs while simultaneously keeping the\r\nnumber of tests generated relatively small.\r\n\r\nThe proposed research is based on the new idea that tests can be\r\nthought of as encodings of proofs. This is a fundamentally\r\ndifferent way of viewing testing, which is traditionally thought\r\nof as a method for sampling the space of all possible system\r\nbehaviors. The research will explore several potentially\r\ntranformative directions. The first is that one can effectively\r\ngenerate small and complete test sets, i.e., tests sets that rule\r\nout the existence of bugs. Another direction is that testing\r\nregimes can be compared by checking to see which lead to test\r\nsets that are closest to encoding relevant proofs.  A third\r\ndirection is to establish strong connections that bridge the gap\r\nbetween formal verification and testing. Finally, the proposed\r\nresearch will lead to the development of efficient algorithms for\r\ntest generation that will be applied to a range of important\r\nproblems arising in hardware and software verification.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Panagiotis",
   "pi_last_name": "Manolios",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Panagiotis Manolios",
   "pi_email_addr": "pete@ccs.neu.edu",
   "nsf_id": "000186555",
   "pi_start_date": "2011-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Evgueni",
   "pi_last_name": "Goldberg",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Evgueni Goldberg",
   "pi_email_addr": "eigold@ccs.neu.edu",
   "nsf_id": "000555208",
   "pi_start_date": "2011-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 HUNTINGTON AVE",
  "perf_city_name": "BOSTON",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 495258.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The processing, storage, analysis and distribution of data using computational methods corresponds to a significant portion of the US economy.&nbsp; A basic, fundamental research question is how to effectively model and analyze such computational systems with the goal of engineering robust, reliable, safe and secure systems. During the course of this project we have explored how to synergystically combine the two basic paradigms used for this purpose: proofs and testing. We developed fundamental methods that can be used to generate high-quality tests, by treating a set of tests as an encoding of a proof that a property under consideration holds. A test is \"high-quality\" if it meaningfully contributes in a fundamental way to a proof of the property. We have used this insight to develop equivalence checking algorithms. Such algorithms are widely used to ensure that local changes to systems, say to satisfy some non-functional design constraints, do not change their global functional behavior of the system under consideration in unexpected ways. We developed new algorithms for performing quantifier elimination, a basic operation used to manipulate logical formulas arising in the analysis of systems. Improvements in quantifier elimination algorithms can enable numerous new applications.&nbsp; We developed refinement frameworks for reasoning about optimized reactive systems, systems that maintain an ongoing interaction with their environment. We developed methods that allow us to significantly extend the kinds of systems that can be automatically analyzed using theorem proving and model-checking technology. Finally, we developed user-friendly methods for modeling, specifying and analyzing systems using computer-aided reasoning tools. We have used these tools to teach over 1,000 undergraduate students how to model and reason about computation. Teaching the next generation of engineers how to build reliable systems by using the advances we developed will allow society to benefit from more secure, reliable and safe systems in the future.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/20/2017<br>\n\t\t\t\t\tModified by: Panagiotis&nbsp;Manolios</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe processing, storage, analysis and distribution of data using computational methods corresponds to a significant portion of the US economy.  A basic, fundamental research question is how to effectively model and analyze such computational systems with the goal of engineering robust, reliable, safe and secure systems. During the course of this project we have explored how to synergystically combine the two basic paradigms used for this purpose: proofs and testing. We developed fundamental methods that can be used to generate high-quality tests, by treating a set of tests as an encoding of a proof that a property under consideration holds. A test is \"high-quality\" if it meaningfully contributes in a fundamental way to a proof of the property. We have used this insight to develop equivalence checking algorithms. Such algorithms are widely used to ensure that local changes to systems, say to satisfy some non-functional design constraints, do not change their global functional behavior of the system under consideration in unexpected ways. We developed new algorithms for performing quantifier elimination, a basic operation used to manipulate logical formulas arising in the analysis of systems. Improvements in quantifier elimination algorithms can enable numerous new applications.  We developed refinement frameworks for reasoning about optimized reactive systems, systems that maintain an ongoing interaction with their environment. We developed methods that allow us to significantly extend the kinds of systems that can be automatically analyzed using theorem proving and model-checking technology. Finally, we developed user-friendly methods for modeling, specifying and analyzing systems using computer-aided reasoning tools. We have used these tools to teach over 1,000 undergraduate students how to model and reason about computation. Teaching the next generation of engineers how to build reliable systems by using the advances we developed will allow society to benefit from more secure, reliable and safe systems in the future.\n\n \n\n\t\t\t\t\tLast Modified: 09/20/2017\n\n\t\t\t\t\tSubmitted by: Panagiotis Manolios"
 }
}