{
 "awd_id": "1101226",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ICES: Small: Manipulation of Learning Heuristics in Strategic Interaction",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2011-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 188532.0,
 "awd_amount": 188532.0,
 "awd_min_amd_letter_date": "2011-06-16",
 "awd_max_amd_letter_date": "2011-06-16",
 "awd_abstract_narration": "This project analyzes strategic manipulation of learning players in repeated games. People are not born with optimal strategies, but instead learn to interact in markets and other social situations. Increasingly, humans interact with computerized agents who may be programmed to use some adaptive learning heuristic. Especially when economic success is at stake, resources may be invested to manipulate learning players. First, the Principle Investigator (PI) seeks to find simple adaptive heuristics that are essentially unbeatable by any opponent in generic and economically relevant classes of games. Second, the PI seeks to discover simple adaptive heuristics whose long run outcome can not be manipulated by sophisticated opponents. Such heuristics are of interest to robustly implement outcomes in mechanisms with learning players. Third, the PI will investigate the existence of simple adaptive heuristics whose long run outcome is not only close to Nash equilibrium but which can also not be manipulated by sophisticated opponents in generic and economically relevant classes of games. Prior work on learning in games focuses on simple heuristics that lead in all games to Nash equilibrium. The objective is to settle the important open question whether such learning heuristics themselves can be robust to strategic manipulation. Finally, the PI aims to find dynamically optimal strategies against well-known adaptive heuristics such as myopic best reply, fictitious play, reinforcement learning, imitation, trail & error learning, and regret matching in generic and economically relevant classes of games.\r\n\r\nThe findings developed in this project are not only relevant for the theory of learning in games in economics but they are foremost relevant for the understanding of real-life strategic interaction and the design of interacting learning machines. In reality, players almost always have to learn how to interact and are almost always heterogeneous with respect to knowledge, strategic sophistication and learning abilities. This becomes obvious for instance in the increasing interaction of humans with machines such as calling robots and automated trading. Especially for automated trading in financial markets, one expects simple learning players to be manipulated by other more sophisticated players if the latter can achieve a strategic advantage. The results of this project are expected to influence the design of interacting learning machines robust to manipulation in many environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Burkhard",
   "pi_last_name": "Schipper",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Burkhard C Schipper",
   "pi_email_addr": "bcschipper@ucdavis.edu",
   "nsf_id": "000487882",
   "pi_start_date": "2011-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Davis",
  "perf_str_addr": "1850 RESEARCH PARK DR STE 300",
  "perf_city_name": "DAVIS",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956186153",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "805200",
   "pgm_ele_name": "Inter Com Sci Econ Soc S (ICE)"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 188532.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Summary</strong></p>\n<p>Game theory is the most prevalent approach to rigorously analyze strategic interaction in economics, computer science, political science, biology, and national defense. Nash equilibrium is the most frequently used solution concept to games. It is often justified by arguing that learning of players would eventually lead to equilibrium. In the research project we showed that</p>\n<ol>\n<li>Players using uncoupled learning heuristics leading to Nash equilibrium can be manipulated. </li>\n<li>There are learning heuristics that cannot be manipulated but those learning heuristics do not generally lead to Nash equilibrium and/or are coupled.</li>\n</ol>\n<p>During the course of the research, we also characterized the class of games in which tit-for-tat is unbeatable by any other strategy no matter how sophisticated. We also characterized the class of symmetric two-player zero-sum games that possess pure equilibria. Moreover, our results also imply that rational learning selects among equilibria in repeated games.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual merit</strong></p>\n<p>There are several far-reaching implications of our results: First, they suggest that uncoupled learning of Nash equilibrium lacks a strategic foundation. The moment players do not forget that they play a game while learning equilibrium, they may try to manipulate each others&rsquo; learning input and thus may not reach stage-game equilibrium. Second, the results suggest that uncoupled learning cannot have an evolutionary foundation. That is, players that are &ldquo;programmed\" by evolution to uncoupled learning heuristics may not be evolutionary stable as there are other strategic teaching heuristics that would do strictly better against such learning population. Third, there cannot exist uncoupled learning heuristics that \"learn themselves\". The last observation is in contrast to the existence of fully self-referential universal learning algorithms in non-strategic contexts from artificial intelligence. Finally, there is a class of boundedly rational learning heuristics, in particular various forms of imitation rules, that are extremely hard to manipulate in many relevant strategic contexts. Yet those heuristics may not lead to equilibrium.</p>\n<p>&nbsp;</p>\n<p><strong>Broader Impact </strong></p>\n<p>This project contributes to the core ideas of game theory and thus it affects any area in which game theory used. In particular, it may lead to the design of mechanisms and institutions in economics that allow for efficient resource allocations or effective conflict resolution among boundedly rational learning players in a way that the outcomes cannot be manipulated. Thus, our results may have impact on welfare and prosperity. Finally, the better understanding of manipulation of learning decision makers in strategic contexts may in future support national defense.</p>\n<p>This award contributed to graduate education. It resulted in peer-reviewed publications in leading international journals in game theory.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/16/2016<br>\n\t\t\t\t\tModified by: Burkhard&nbsp;C&nbsp;Schipper</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSummary\n\nGame theory is the most prevalent approach to rigorously analyze strategic interaction in economics, computer science, political science, biology, and national defense. Nash equilibrium is the most frequently used solution concept to games. It is often justified by arguing that learning of players would eventually lead to equilibrium. In the research project we showed that\n\nPlayers using uncoupled learning heuristics leading to Nash equilibrium can be manipulated. \nThere are learning heuristics that cannot be manipulated but those learning heuristics do not generally lead to Nash equilibrium and/or are coupled.\n\n\nDuring the course of the research, we also characterized the class of games in which tit-for-tat is unbeatable by any other strategy no matter how sophisticated. We also characterized the class of symmetric two-player zero-sum games that possess pure equilibria. Moreover, our results also imply that rational learning selects among equilibria in repeated games.\n\n \n\nIntellectual merit\n\nThere are several far-reaching implications of our results: First, they suggest that uncoupled learning of Nash equilibrium lacks a strategic foundation. The moment players do not forget that they play a game while learning equilibrium, they may try to manipulate each others? learning input and thus may not reach stage-game equilibrium. Second, the results suggest that uncoupled learning cannot have an evolutionary foundation. That is, players that are \"programmed\" by evolution to uncoupled learning heuristics may not be evolutionary stable as there are other strategic teaching heuristics that would do strictly better against such learning population. Third, there cannot exist uncoupled learning heuristics that \"learn themselves\". The last observation is in contrast to the existence of fully self-referential universal learning algorithms in non-strategic contexts from artificial intelligence. Finally, there is a class of boundedly rational learning heuristics, in particular various forms of imitation rules, that are extremely hard to manipulate in many relevant strategic contexts. Yet those heuristics may not lead to equilibrium.\n\n \n\nBroader Impact \n\nThis project contributes to the core ideas of game theory and thus it affects any area in which game theory used. In particular, it may lead to the design of mechanisms and institutions in economics that allow for efficient resource allocations or effective conflict resolution among boundedly rational learning players in a way that the outcomes cannot be manipulated. Thus, our results may have impact on welfare and prosperity. Finally, the better understanding of manipulation of learning decision makers in strategic contexts may in future support national defense.\n\nThis award contributed to graduate education. It resulted in peer-reviewed publications in leading international journals in game theory.\n\n \n\n\t\t\t\t\tLast Modified: 08/16/2016\n\n\t\t\t\t\tSubmitted by: Burkhard C Schipper"
 }
}