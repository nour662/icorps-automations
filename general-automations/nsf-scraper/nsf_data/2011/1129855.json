{
 "awd_id": "1129855",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "U.S.-German Collaboration: Building common high-dimensional models of neural representational spaces",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2011-09-15",
 "awd_exp_date": "2014-08-31",
 "tot_intn_awd_amt": 348685.0,
 "awd_amount": 348685.0,
 "awd_min_amd_letter_date": "2011-09-26",
 "awd_max_amd_letter_date": "2011-09-26",
 "awd_abstract_narration": "Methods known as 'multivariate pattern' (MVP) analysis can be used to decode the information patterns in brain activity obtained using functional magnetic resonance imaging (fMRI).  However, a new decoding model has to be built for each brain, because two brains (and the representational spaces they employ) are difficult to align at a fine spatial scale. As a consequence, we do not yet know if different brains use the same codes or idiosyncratic codes to represent the same things. With funding from the National Science Foundation, Drs. James V. Haxby of Dartmouth College, and Peter J. Ramadge of Princeton University, in collaboration with Michael Hanke of the University of Magdeburg (Germany), are developing new methods to discover a coding scheme that works accurately across different brains. The methods being developed align brain activity across brains by projecting individual brain data into a common, high-dimensional space. This approach allows the researchers to build models of brain representational spaces for different cortical areas that are valid both across brains and across a wide range of stimuli and cognitive states. The researchers are developing two algorithms. One is referred to as 'hyperalignment' and the other as 'functional connectivity hyperalignment.'  Hyperalignment rotates the voxel spaces (i.e., the smallest units in a brain image) of individual brains into a single high-dimensional space, in which each dimension is a profile of differential responses to stimuli, that is common across brains.  Functional connectivity hyperalignment aligns voxel spaces based on the functional connectivity profile (i.e., relationships among activated brain areas) for each cortical location. Functional connectivity profiles allow for models of areas that do not respond to external stimuli in a consistent manner, for example, those areas in the so-called 'default-intrinsic system' that plays a central role in social cognition. The investigators are an interdisciplinary partnership - cognitive neuroscientists and signal-processing engineers - who have been working together successfully for several years.  \r\n\r\nDeveloping the computational methods to build common models of representational spaces will augment the power of brain activity decoding techniques, making it possible to investigate how finer, more detailed information is embedded in brain activity patterns, and to read out that information from functional brain imaging data.  The proposed methods also will allow extension of brain decoding to the neural codes that underlie social cognition, that is, the representation of knowledge about the personal traits and mental states of others. These models also will allow investigation of how neural coding is altered within brain regions that are affected by experience, by development, and by psychopathology.\r\n\r\nThis project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering.  A companion project is being funded by the German Ministry of Education and Research (BMBF).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Ramadge",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Peter J Ramadge",
   "pi_email_addr": "ramadge@princeton.edu",
   "nsf_id": "000199906",
   "pi_start_date": "2011-09-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "Olden Street",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169900",
   "pgm_ele_name": "Cognitive Neuroscience"
  },
  {
   "pgm_ele_code": "729800",
   "pgm_ele_name": "International Research Collab"
  },
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1699",
   "pgm_ref_txt": "COGNEURO"
  },
  {
   "pgm_ref_code": "5936",
   "pgm_ref_txt": "GERMANY (F.R.G.)"
  },
  {
   "pgm_ref_code": "5979",
   "pgm_ref_txt": "Europe and Eurasia"
  },
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "7752",
   "pgm_ref_txt": "CDI NON SOLICITED RESEARCH"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 348685.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This grant supported research on the development of new representations of multi-subject fMRI data aimed at identifying and representing the shared cognitive response elicited under a common rich visual and auditory stimulus. Since every healthy subject&rsquo;s brain is both anatomically and functionally slightly different, in order to make best use of multi-subject fMRI data, we need techniques that go beyond simply aligning anatomy, and spatial smoothing. The research supported under this grant took up this challenge. The objective is to identify a common representational space for the all subject&rsquo;s data, and within this space to identify a component that is shared across subjects. The shared component can be regarded as the shared response elicited by the stimulus.</p>\n<p>&nbsp;Our approach collects the data from subject j into a matrix X(j).&nbsp; For example, this might be data from an anatomically selected region of interest (e.g., temporal cortex), or from a searchlight of voxels. We then seek a subject specific transformation R(j) of each subject&rsquo;s data into a common (or shared) space: T = X(j)R(j) + E(j). Here E(j) is the error in the alignment of the data across subjects. In the common representational space T, we can compare each subject&rsquo;s data, denoise the data, and make predictions of one subject&rsquo;s response based on the aggregate response of the other subjects.</p>\n<p>One important problem is to identify the dimension of this common representational space. For example, data may be collected over time from tens of thousands of voxels (volumetric units of space), but the number of underlying degrees of freedom in the data may be far less than the number of voxels. So, roughly, one seeks a common representation space of the smallest dimension that captures the shared response across subjects in some meaningful way.</p>\n<p>&nbsp;The primary thrust of this research is directed to achieve inter-subject alignment of functional brain imaging data with a mathematical method that we call hyperalignment. We have completed the developed of a functional response version of the hyperalignment algorithm. This is based on subject specific orthogonal transformations of the fMRI data into a common aligned space. The basic approach, and an initial evaluation of its merits, appeared in a 2011 journal article in Neuron.</p>\n<p>&nbsp;We subsequently developed a regularized version of the functional response hyperalignment algorithm. This makes interesting connections with canonical correlation analysis. Regularization of hyperalignment can have significant benefits for small datasets. We believe this is important since most fMRI datasets fall into this category. This work was published as archival article in the Proceedings of the 2012 IEEE Statistical Signal Processing Workshop. We also investigated a kernelized version of functional response hyperalignment. This allows for a more general nonlinear alignment process. It is also more efficient. A paper reporting the method and results of this development was presented at the Neural Information Processing Systems Conference (NIPS) in December, 2012. The paper was selected for a spotlight presentation at the conference.</p>\n<p>We then used our method of aligning data in a common space to investigate to accomplish &ldquo;collaborative denoising&rdquo; of multi-subject fMRI data using the common features of the hyperaligned multi-subject data. The idea is that in the aligned space the data can be filtered across subjects to reduce noise, then the de-noised data can be projected back into the original voxel spaces. This work was presented as a spotlight talk and poster at New York Academy of Sciences 7th Annual Symposium of Machine Learning, October, 2012. The presentation received one of the best presentation prizes. The work subsequently appeared as an archival paper in the IEEE flagship conference on s...",
  "por_txt_cntn": "\nThis grant supported research on the development of new representations of multi-subject fMRI data aimed at identifying and representing the shared cognitive response elicited under a common rich visual and auditory stimulus. Since every healthy subject\u00c6s brain is both anatomically and functionally slightly different, in order to make best use of multi-subject fMRI data, we need techniques that go beyond simply aligning anatomy, and spatial smoothing. The research supported under this grant took up this challenge. The objective is to identify a common representational space for the all subject\u00c6s data, and within this space to identify a component that is shared across subjects. The shared component can be regarded as the shared response elicited by the stimulus.\n\n Our approach collects the data from subject j into a matrix X(j).  For example, this might be data from an anatomically selected region of interest (e.g., temporal cortex), or from a searchlight of voxels. We then seek a subject specific transformation R(j) of each subject\u00c6s data into a common (or shared) space: T = X(j)R(j) + E(j). Here E(j) is the error in the alignment of the data across subjects. In the common representational space T, we can compare each subject\u00c6s data, denoise the data, and make predictions of one subject\u00c6s response based on the aggregate response of the other subjects.\n\nOne important problem is to identify the dimension of this common representational space. For example, data may be collected over time from tens of thousands of voxels (volumetric units of space), but the number of underlying degrees of freedom in the data may be far less than the number of voxels. So, roughly, one seeks a common representation space of the smallest dimension that captures the shared response across subjects in some meaningful way.\n\n The primary thrust of this research is directed to achieve inter-subject alignment of functional brain imaging data with a mathematical method that we call hyperalignment. We have completed the developed of a functional response version of the hyperalignment algorithm. This is based on subject specific orthogonal transformations of the fMRI data into a common aligned space. The basic approach, and an initial evaluation of its merits, appeared in a 2011 journal article in Neuron.\n\n We subsequently developed a regularized version of the functional response hyperalignment algorithm. This makes interesting connections with canonical correlation analysis. Regularization of hyperalignment can have significant benefits for small datasets. We believe this is important since most fMRI datasets fall into this category. This work was published as archival article in the Proceedings of the 2012 IEEE Statistical Signal Processing Workshop. We also investigated a kernelized version of functional response hyperalignment. This allows for a more general nonlinear alignment process. It is also more efficient. A paper reporting the method and results of this development was presented at the Neural Information Processing Systems Conference (NIPS) in December, 2012. The paper was selected for a spotlight presentation at the conference.\n\nWe then used our method of aligning data in a common space to investigate to accomplish \"collaborative denoising\" of multi-subject fMRI data using the common features of the hyperaligned multi-subject data. The idea is that in the aligned space the data can be filtered across subjects to reduce noise, then the de-noised data can be projected back into the original voxel spaces. This work was presented as a spotlight talk and poster at New York Academy of Sciences 7th Annual Symposium of Machine Learning, October, 2012. The presentation received one of the best presentation prizes. The work subsequently appeared as an archival paper in the IEEE flagship conference on signal processing (ICASSP) in 2013.\n\nA second research thrust proposes to achieve inter-subject hyperalignment by hyperaligning intra-subject patterns of c..."
 }
}