{
 "awd_id": "1065228",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research: Teaching Computers to Follow Verbal Instructions",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Weng-keen Wong",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 296003.0,
 "awd_amount": 311743.0,
 "awd_min_amd_letter_date": "2011-08-30",
 "awd_max_amd_letter_date": "2013-04-08",
 "awd_abstract_narration": "The goal of this research is to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language on behalf of a user.  It will study each of these components in isolation, but a significant focus will be on integrating them into a coherent system.  The project will also leverage this technology to provide an entry point to educate non- or pre-computer science students about the capabilities and utility of computers as tools.\r\n\r\nOur approach uses three main subcomponents, each of which requires innovative research to solve its portion of the overall problem.  In addition, the integrated architecture is a novel contribution of this work.  The three components are (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning, (2) translating instructions to task specifications using novel techniques in the area of natural language processing, and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing abstractions.\r\n\r\nThe goal of the work is develop technology for an improved ability for human users to interact with intelligent agents, the incorporation of novel AI research insights and activities into education and outreach activities, and the development of resources for the AI educator community.  In addition to permitting intelligent agents to be developed and trained in the future for a broad range of complex application domains, the interactive agents that we will develop will be used for outreach and student learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marie",
   "pi_last_name": "desJardins",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Marie E desJardins",
   "pi_email_addr": "mariedj@cs.umbc.edu",
   "nsf_id": "000231667",
   "pi_start_date": "2011-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland Baltimore County",
  "inst_street_address": "1000 HILLTOP CIR",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4104553140",
  "inst_zip_code": "212500001",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND BALTIMORE COUNTY",
  "org_prnt_uei_num": "",
  "org_uei_num": "RNKYWXURFRL5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland Baltimore County",
  "perf_str_addr": "1000 HILLTOP CIR",
  "perf_city_name": "BALTIMORE",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212500001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 296003.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 15740.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Helvetica} -->\n<p class=\"p1\">The goal of this project was to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language (English) on behalf of a user. Our approach used three main subcomponents: (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning (IRL), (2) translating instructions to task specifications using novel techniques in the area of natural language processing (NLP), and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing task abstractions (TA). &nbsp;These subcomponents are closely integrated, using a probabilistic model that permits evidence from training examples to be combined with evidence from linguistic annotations, across multiple tasks, to form appropriate task abstractions, linguistic models, and goal representations. The learning system uses a shared representation that is based on object-oriented Markov decision processes (MDPs), and has been tested on several simulated and physical robot domains.</p>\n<p class=\"p1\">Our novel IRL algorithm allows arbitrary mappings from state features to rewards to be learned. It uses a modular design so that any new regression algorithm can be integrated into the system. The probabilistic model permits the use of different linguistic models. &nbsp;We also developed new option discovery methods for object-oriented MDP domains, based on previous techniques that were developed for discrete state domains. These new methods enable abstraction and knowledge transfer in more complex domains. The framework also supports transfer of task learning across different domains with different action spaces, including transfer from simulated environments to a physical mobile robot.</p>\n<p class=\"p1\">Our work has been presented in several workshop and conference papers, as well as a AAAI student abstract and an IJCAI doctoral consortium presentation. Two UMBC Ph.D. students, two UMBC M.S. students, and seven undergraduates worked on the project. &nbsp;Three of the graduate students and six of the undergraduates coauthored published paeprs on the work. &nbsp;Three of the undergraduates continued into graduate programs, and a fourth undergarduate intends to continue for his Ph.D. after he graduates.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2016<br>\n\t\t\t\t\tModified by: Marie&nbsp;E&nbsp;Desjardins</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to develop techniques that will permit a computer or robot to learn from examples to carry out multipart tasks specified in natural language (English) on behalf of a user. Our approach used three main subcomponents: (1) recognizing intention from observed behavior using extensions of inverse reinforcement learning (IRL), (2) translating instructions to task specifications using novel techniques in the area of natural language processing (NLP), and (3) creating generalized task specifications to match user intentions using probabilistic methods for creating and managing task abstractions (TA).  These subcomponents are closely integrated, using a probabilistic model that permits evidence from training examples to be combined with evidence from linguistic annotations, across multiple tasks, to form appropriate task abstractions, linguistic models, and goal representations. The learning system uses a shared representation that is based on object-oriented Markov decision processes (MDPs), and has been tested on several simulated and physical robot domains.\nOur novel IRL algorithm allows arbitrary mappings from state features to rewards to be learned. It uses a modular design so that any new regression algorithm can be integrated into the system. The probabilistic model permits the use of different linguistic models.  We also developed new option discovery methods for object-oriented MDP domains, based on previous techniques that were developed for discrete state domains. These new methods enable abstraction and knowledge transfer in more complex domains. The framework also supports transfer of task learning across different domains with different action spaces, including transfer from simulated environments to a physical mobile robot.\nOur work has been presented in several workshop and conference papers, as well as a AAAI student abstract and an IJCAI doctoral consortium presentation. Two UMBC Ph.D. students, two UMBC M.S. students, and seven undergraduates worked on the project.  Three of the graduate students and six of the undergraduates coauthored published paeprs on the work.  Three of the undergraduates continued into graduate programs, and a fourth undergarduate intends to continue for his Ph.D. after he graduates.\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2016\n\n\t\t\t\t\tSubmitted by: Marie E Desjardins"
 }
}