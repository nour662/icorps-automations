{
 "awd_id": "1065603",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CIF: Medium: Assessment and Modeling of Temporal Variation in Perceived Audio and Video Quality Using Direct Brainwave Measurement",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 892055.0,
 "awd_amount": 892055.0,
 "awd_min_amd_letter_date": "2011-04-07",
 "awd_max_amd_letter_date": "2014-06-30",
 "awd_abstract_narration": "The goal of this project is to better model the human perception of quality variations in audio, video, and audiovisual signals.   A fundamental challenge in accomplishing this goal, however, is to develop a human subjective testing methodology that can assess such the perceived quality variations with sufficient accuracy in time.  Rather than conducting human trials that simply ask subjects to rate the signal quality at given moments in time, in this research the electrical patterns of each subject's brain responses to multimedia signals of varying quality are captured using a high resolution electroencephalograph (EEG).  By analyzing these EEG signals, it becomes possible to detect a change in the perceived quality of the signal before the human observer/listener even becomes consciously aware that the quality has changed.\r\n\r\nA major difficulty, however, is that the EEG waveforms captured during these trials contain large amounts of noise, and it is therefore necessary to sift through a large set of data to identify the components of the collected EEG waveforms that correspond to changes in perceived quality.  To accomplish this task, both deterministic time-space-frequency analysis techniques will be applied as well as stochastic techniques based on information spectra.  To create computer-based models of perceived quality, AR/ARMA (autoregressive/autoregressive moving average) modeling techniques will be considered and support vector machines along with related kernel-based classifiers will be designed to output class indexes corresponding to perceived quality.  Beyond its potential for improving audiovisual transmission systems, the broader impacts of this research include the possibility that it will open up new and more efficient avenues for transferring information from computers to human beings.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Creusere",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Charles D Creusere",
   "pi_email_addr": "ccreuser@nmsu.edu",
   "nsf_id": "000452745",
   "pi_start_date": "2011-04-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Kroger",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "James K Kroger",
   "pi_email_addr": "jkroger@nmsu.edu",
   "nsf_id": "000480952",
   "pi_start_date": "2011-04-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Joerg",
   "pi_last_name": "Kliewer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joerg Kliewer",
   "pi_email_addr": "jkliewer@njit.edu",
   "nsf_id": "000501242",
   "pi_start_date": "2011-04-07",
   "pi_end_date": "2014-06-26"
  }
 ],
 "inst": {
  "inst_name": "New Mexico State University",
  "inst_street_address": "1050 STEWART ST.",
  "inst_street_address_2": "",
  "inst_city_name": "LAS CRUCES",
  "inst_state_code": "NM",
  "inst_state_name": "New Mexico",
  "inst_phone_num": "5756461590",
  "inst_zip_code": "88003",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NM02",
  "org_lgl_bus_name": "NEW MEXICO STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "J3M5GZAT8N85"
 },
 "perf_inst": {
  "perf_inst_name": "New Mexico State University",
  "perf_str_addr": "1050 STEWART ST.",
  "perf_city_name": "LAS CRUCES",
  "perf_st_code": "NM",
  "perf_st_name": "New Mexico",
  "perf_zip_code": "88003",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NM02",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 216245.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 219804.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 224969.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 231037.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>As stated in the title, the goal of this research was to determine how one might infer the human perception of audiovisual quality directly from brain responses as measured by an electroencephalogram (EEG). &nbsp;Underlying this specific goal, however, is the broader problem of understanding how the brain processes audiovisual stimuli. &nbsp;Most of our efforts in this project have been directed towards gaining such understanding since very little previous research existed.</p>\n<p>We have learned a lot about how the human brain processes audio and video: both the brain responses that individuals appear to have in common and those that appear to be differentiated. &nbsp;For example, in Fig. 1 we study the modeling of spectral power features as log-normal and plot the estimated mean (given by E(X) and variance (given by V(X)) at each spatial location on the scalp for different qualities of video ('base' = full quality). &nbsp;These results are averaged over 38 subjects with hundreds of different presentations per quality level. &nbsp;We see that, depending on the position of the electrode on the scalp, there are variations as the quality changes. &nbsp;</p>\n<p>Choosing a single electrode in a spot where these variations versus video quality are particularly prominant (specifically, electrode #22 which is above the occipital lobe), we see in Fig. 2 that there is clearly a correlation in the mean estimate of the log-normal distribution (labeled as Greek letter 'mu' in the figure) and the ratings for the same video sequences provided by the test subjects. &nbsp;It turns out that this correlation justifies the use of cepstral feature vectors for quality classification purposes.</p>\n<p>Interestingly, we have also found that human brain response to video can be very effectively used as a biometric for security or privacy applications. &nbsp;Fig. 3 illustrates the clustering of higher dimensional feature vectors (projected onto 2-dimensional plane) for a subset of test subjects (including three subjects who participated in the complete set of trials twice on different days, circled in red). &nbsp;We see that the feature clusters are largely separated, indicating that human identication and verification results are likely to be very good when machine learning is applied. &nbsp;In fact, from single video presentations, we achieve identification accuracy of around 70% (using the above-mentioned cepstral power features). &nbsp;If multiple video are presented to a subject, identification rates in excess of 90% are achieved.</p>\n<p>During the course of this project, we also studied the information theoretic modeling of human perception with a &nbsp;particular focus on the audio stimuli. &nbsp;After introducing a novel framework for evaluating audio quality perception based on recorded EEG brain data for subjects listening to time-varying distorted audio, we used an information theoretic analysis to quantitatively measure how accurately the quality of the audio stimulus was transmitted over the brain response channel as shown in Fig. 4. The results revealed a large correlation between the actual audio quality and the recorded EEG, irrespective of the music sequence or distortion type used in the testing. The results also demonstrated the practical applicability of this approach and provided a performance measure for evaluating the subject's perception with respect to the change in audio quality: i.e., the larger the amount of information transmitted over the brain response channel, the stronger the subjects perception of the quality change.</p>\n<p>&nbsp;Additionally, we also used directional and causal information measures to infer the functional connectivity between EEG sensors appropriately grouped into specific regions of interest over the cortex. The information transfer results indicated a signicant variation in the connectivity pattern with a notable difference between the information transfer rates for the two audio different qualities as shown in Figs. 5 and 6. In particular, there appeared to be a higher amount of information flow between the cortical regions when the subjects were listening to distorted quality audio. This strongly suggests an increase in brain activity in the regions of interest when the the subjects were listening to distorted audio, most likely because the subjects were forced concentrate harder on the reduced-quality audio to understand or interpret it.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/10/2016<br>\n\t\t\t\t\tModified by: Charles&nbsp;D&nbsp;Creusere</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476136019308_Biosemi_nm_good--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476136019308_Biosemi_nm_good--rgov-800width.jpg\" title=\"Good audio Connectivity\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476136019308_Biosemi_nm_good--rgov-66x44.jpg\" alt=\"Good audio Connectivity\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 6: Functional connectivity graphs over the cortex inferred by calculating the pair-wise instantaneous information transfer rates between regions of interest for the case where the subjects listen to high quality audio. Red, orange, and yellow arrows indicate successively decreasing connectivity</div>\n<div class=\"imageCredit\">Ketan Mehta</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">Good audio Connectivity</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475614989992_ChangeInLognormalParameters_singChan_fv2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1a--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475614989992_ChangeInLognormalParameters_singChan_fv2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1a--rgov-800width.jpg\" title=\"ch22_mean_var\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475614989992_ChangeInLognormalParameters_singChan_fv2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1a--rgov-66x44.jpg\" alt=\"ch22_mean_var\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 2:  Estimated mean (mu) and Variance (sigma) for 4-8Hz spectral power assuming log-normal distribution for electrode 22.  Comparisons are made to subjective ratings given by slider bar.</div>\n<div class=\"imageCredit\">P Davis</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">ch22_mean_var</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475679055163_CepFV_ConstQual_repeatSub_tsne_nolabel_chGrp10_UBM_GMM_ADAPT_COV_NumSub58_ssub2005_v1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475679055163_CepFV_ConstQual_repeatSub_tsne_nolabel_chGrp10_UBM_GMM_ADAPT_COV_NumSub58_ssub2005_v1--rgov-800width.jpg\" title=\"cluster_plot\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475679055163_CepFV_ConstQual_repeatSub_tsne_nolabel_chGrp10_UBM_GMM_ADAPT_COV_NumSub58_ssub2005_v1--rgov-66x44.jpg\" alt=\"cluster_plot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 3: Clustering of features for different human subjects.  Red circled clusters indicate data from the same subjects collected in different days.</div>\n<div class=\"imageCredit\">P. Davis</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">cluster_plot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475613823358_LognormalHeadPlot_fv2_results_degBaseQual_FV2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1_ZSCORE1_RM4th0_Ver0_v1a--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475613823358_LognormalHeadPlot_fv2_results_degBaseQual_FV2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1_ZSCORE1_RM4th0_Ver0_v1a--rgov-800width.jpg\" title=\"log_normal_brain_plots\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1475613823358_LognormalHeadPlot_fv2_results_degBaseQual_FV2__NumSub38_sub2007vid1to24_numVid16_series2000_rmBadD1_PSD1_ZSCORE1_RM4th0_Ver0_v1a--rgov-66x44.jpg\" alt=\"log_normal_brain_plots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 1: Scalp plots of log-normal mean and variance of spectral power features in 1-4Hz band for varying quality video</div>\n<div class=\"imageCredit\">P. Davis</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">log_normal_brain_plots</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135879232_Biosemi_nm_bad--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135879232_Biosemi_nm_bad--rgov-800width.jpg\" title=\"Response to bad audio\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135879232_Biosemi_nm_bad--rgov-66x44.jpg\" alt=\"Response to bad audio\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 5: Functional connectivity graphs over the cortex inferred by calculating the pair-wise instantaneous information transfer rates between regions of interest for the case where the subjects listen to distorted audio. Red, orange, and yellow arrows indicate successively decreasing connectivity.</div>\n<div class=\"imageCredit\">Ketan Mehta</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">Response to bad audio</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135567651_ERP_Channel--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135567651_ERP_Channel--rgov-800width.jpg\" title=\"ERP Channel\"><img src=\"/por/images/Reports/POR/2016/1065603/1065603_10084012_1476135567651_ERP_Channel--rgov-66x44.jpg\" alt=\"ERP Channel\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Fig. 4: The entire \"transmission chain\" comprising stimulus generation, brain processing by the human subject, and the electroencephalograph (EEG) response measurements as a nonlinear, time-varying communication channelwith memory.</div>\n<div class=\"imageCredit\">Ketan Mehta</div>\n<div class=\"imagePermisssions\">Royalty-free (unrestricted use)</div>\n<div class=\"imageSubmitted\">Charles&nbsp;D&nbsp;Creusere</div>\n<div class=\"imageTitle\">ERP Channel</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAs stated in the title, the goal of this research was to determine how one might infer the human perception of audiovisual quality directly from brain responses as measured by an electroencephalogram (EEG).  Underlying this specific goal, however, is the broader problem of understanding how the brain processes audiovisual stimuli.  Most of our efforts in this project have been directed towards gaining such understanding since very little previous research existed.\n\nWe have learned a lot about how the human brain processes audio and video: both the brain responses that individuals appear to have in common and those that appear to be differentiated.  For example, in Fig. 1 we study the modeling of spectral power features as log-normal and plot the estimated mean (given by E(X) and variance (given by V(X)) at each spatial location on the scalp for different qualities of video ('base' = full quality).  These results are averaged over 38 subjects with hundreds of different presentations per quality level.  We see that, depending on the position of the electrode on the scalp, there are variations as the quality changes.  \n\nChoosing a single electrode in a spot where these variations versus video quality are particularly prominant (specifically, electrode #22 which is above the occipital lobe), we see in Fig. 2 that there is clearly a correlation in the mean estimate of the log-normal distribution (labeled as Greek letter 'mu' in the figure) and the ratings for the same video sequences provided by the test subjects.  It turns out that this correlation justifies the use of cepstral feature vectors for quality classification purposes.\n\nInterestingly, we have also found that human brain response to video can be very effectively used as a biometric for security or privacy applications.  Fig. 3 illustrates the clustering of higher dimensional feature vectors (projected onto 2-dimensional plane) for a subset of test subjects (including three subjects who participated in the complete set of trials twice on different days, circled in red).  We see that the feature clusters are largely separated, indicating that human identication and verification results are likely to be very good when machine learning is applied.  In fact, from single video presentations, we achieve identification accuracy of around 70% (using the above-mentioned cepstral power features).  If multiple video are presented to a subject, identification rates in excess of 90% are achieved.\n\nDuring the course of this project, we also studied the information theoretic modeling of human perception with a  particular focus on the audio stimuli.  After introducing a novel framework for evaluating audio quality perception based on recorded EEG brain data for subjects listening to time-varying distorted audio, we used an information theoretic analysis to quantitatively measure how accurately the quality of the audio stimulus was transmitted over the brain response channel as shown in Fig. 4. The results revealed a large correlation between the actual audio quality and the recorded EEG, irrespective of the music sequence or distortion type used in the testing. The results also demonstrated the practical applicability of this approach and provided a performance measure for evaluating the subject's perception with respect to the change in audio quality: i.e., the larger the amount of information transmitted over the brain response channel, the stronger the subjects perception of the quality change.\n\n Additionally, we also used directional and causal information measures to infer the functional connectivity between EEG sensors appropriately grouped into specific regions of interest over the cortex. The information transfer results indicated a signicant variation in the connectivity pattern with a notable difference between the information transfer rates for the two audio different qualities as shown in Figs. 5 and 6. In particular, there appeared to be a higher amount of information flow between the cortical regions when the subjects were listening to distorted quality audio. This strongly suggests an increase in brain activity in the regions of interest when the the subjects were listening to distorted audio, most likely because the subjects were forced concentrate harder on the reduced-quality audio to understand or interpret it.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/10/2016\n\n\t\t\t\t\tSubmitted by: Charles D Creusere"
 }
}