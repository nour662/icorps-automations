{
 "awd_id": "1065390",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Medium: Collaborative Research: Semantically Discriminative : Guiding Mid-Level Representations for Visual Object Recognition with External Knowledge",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2011-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 498994.0,
 "awd_amount": 498994.0,
 "awd_min_amd_letter_date": "2011-03-25",
 "awd_max_amd_letter_date": "2013-09-26",
 "awd_abstract_narration": "This project explores (semi-)automatic ways to create \"semantically discriminative\" mid-level cues for visual object categorization, by introducing external knowledge of object properties into the statistical learning procedures that learn to distinguish them.  In particular, the PIs investigate four key ideas: (1) exploiting taxonomies over object categories to inform feature selection algorithms such that they home in on the most abstract description for a given granularity of label predictions; (2) leveraging inter-object relationships conveyed by the same taxonomies to guide context learning, so that it captures more than simple data-driven co-occurrences; (3) exploring the utility of visual attributes drawn from natural language, both as auxiliary learning problems to bias models for object categorization, as well as ordinal properties that must be teased out using non-traditional human supervision strategies; (4) mining attributes that are both distinctive and human-nameable, moving beyond manually constructed semantics.\r\n\r\nThe project entails original contributions in both computer vision and machine learning, and is an integral step towards semantically-grounded object categorization.  Whereas mainstream approaches reduce human knowledge to mere category labels on exemplars, this work leverages semantically rich knowledge more deeply and earlier in the learning pipeline. The approach results in vision systems that are less prone to overfit incidental visual patterns, and representations that are readily extendible to novel visual learning tasks.  Beyond the research community, the work has broader impact through inter-disciplinary training of graduate and undergraduate students, and outreach to pre-college educators and students through workshops and summer camps encouraging young students to pursue science and engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kristen",
   "pi_last_name": "Grauman",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Kristen L Grauman",
   "pi_email_addr": "grauman@cs.utexas.edu",
   "nsf_id": "000282504",
   "pi_start_date": "2011-03-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "110 INNER CAMPUS DR",
  "perf_city_name": "AUSTIN",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121139",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 121783.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 125590.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 251621.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this collaborative research project was to explore semantically discriminative mid-level cues for visual recognition.&nbsp; The idea was to introduce external knowledge about real-world properties of objects into the statistical learning procedures that learn to distinguish the visual categories. &nbsp;&nbsp;In particular, we investigated how human-nameable semantics---whether known or interactively discovered---can restrict the hypothesis space of the ultimate visual classifiers. Whereas mainstream object recognition approaches often reduce the role of human knowledge to mere category labels on image exemplars, we aimed to leverage known inter-category relationships and visual properties early in the learning pipeline, so that machine learning models could essentially be regularized by the rich outside knowledge.&nbsp; As a result, we demonstrated models that are less prone to overfit incidental visual patterns and representations that are readily extendible to novel visual learning tasks.</p>\n<p>In terms of intellectual merit, there are four key areas of technical contributions from the project.&nbsp; The first is visual attributes.&nbsp; We developed new models to represent and predict human-describable visual properties in images.&nbsp; This entailed novel contributions for inferring fine-grained, subtle comparative attributes with local learning and image synthesis; for decorrelating attribute models via multi-task learning; for inferring analogous attributes when training instances are few; and for applying attributes as mid-level cues in fashion image analysis to understand and forecast cultural trends.&nbsp; The second area of technical contribution is zero shot learning.&nbsp; Here we developed new algorithms for training object category models with as few as zero training examples, showing how semantic linguistic descriptions---together with transfer from previously trained categories---can enable learning objects even without labeled exemplars.&nbsp; The third main area of technical contributions is metric learning algorithms imbued with semantics.&nbsp; Here we developed semantic kernel forests to blend external knowledge from multiple taxonomies; hierarchical metric learning methods with orthogonal feature regularization; and multi-task feature learning with objects and their attributes.&nbsp; Finally, the fourth main area of contribution was visual question answering, where we made contributions in modeling ambiguity in visual questions and eradicating bias in the associated datasets.</p>\n<p>The work yielded 20 peer reviewed papers in top-tier computer vision and machine learning conferences, one journal article, two book chapters, and three workshop papers.&nbsp; At the time of the project closing, these papers had been cited more than 1,500 times in total.&nbsp; The project also yielded a slate of new datasets and codebases for the algorithms that are publicly available from the project websites, linked from&nbsp;http://www.cs.utexas.edu/~grauman/research/pubs.html and&nbsp;http://www-bcf.usc.edu/~feisha/projects.html.&nbsp; Aside from publications, the research results were also regularly disseminated via invited talks by the PIs at international meetings and university seminars.&nbsp;</p>\n<p>In terms of broader impact, the key outcomes of the project entail graduate and undergraduate student training and mentorship, outreach efforts for promoting wider participation in computer science education, and scientific impact of the newly developed algorithms.&nbsp;&nbsp; The project helped train Ph.D. students in the areas of this research, as well as general skills needed to perform and present research. &nbsp;&nbsp;In particular, over the project period, five PhD students involved in the research completed their PhDs and two postdoctoral researchers involved in the research completed their stay and accepted tenure track faculty positions.&nbsp; The project also supported the PIs&rsquo; work with individual undergraduate students on independent research projects, helping them learn research skills and prepare for graduate school or employment in STEM areas.&nbsp; In particular, several undergraduate researchers participated in the research with the PIs, and two completed honors bachelors theses directly supporting the project goals and proceeded to graduate programs in Computer Science.&nbsp; The project's outreach component contributed to efforts that widen participation in computer science, with particular emphasis on reaching female students and K-12 students.&nbsp; Finally, the generality of the machine learning approaches developed in this project makes them transferrable to problems outside of computer vision.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2017<br>\n\t\t\t\t\tModified by: Kristen&nbsp;L&nbsp;Grauman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this collaborative research project was to explore semantically discriminative mid-level cues for visual recognition.  The idea was to introduce external knowledge about real-world properties of objects into the statistical learning procedures that learn to distinguish the visual categories.   In particular, we investigated how human-nameable semantics---whether known or interactively discovered---can restrict the hypothesis space of the ultimate visual classifiers. Whereas mainstream object recognition approaches often reduce the role of human knowledge to mere category labels on image exemplars, we aimed to leverage known inter-category relationships and visual properties early in the learning pipeline, so that machine learning models could essentially be regularized by the rich outside knowledge.  As a result, we demonstrated models that are less prone to overfit incidental visual patterns and representations that are readily extendible to novel visual learning tasks.\n\nIn terms of intellectual merit, there are four key areas of technical contributions from the project.  The first is visual attributes.  We developed new models to represent and predict human-describable visual properties in images.  This entailed novel contributions for inferring fine-grained, subtle comparative attributes with local learning and image synthesis; for decorrelating attribute models via multi-task learning; for inferring analogous attributes when training instances are few; and for applying attributes as mid-level cues in fashion image analysis to understand and forecast cultural trends.  The second area of technical contribution is zero shot learning.  Here we developed new algorithms for training object category models with as few as zero training examples, showing how semantic linguistic descriptions---together with transfer from previously trained categories---can enable learning objects even without labeled exemplars.  The third main area of technical contributions is metric learning algorithms imbued with semantics.  Here we developed semantic kernel forests to blend external knowledge from multiple taxonomies; hierarchical metric learning methods with orthogonal feature regularization; and multi-task feature learning with objects and their attributes.  Finally, the fourth main area of contribution was visual question answering, where we made contributions in modeling ambiguity in visual questions and eradicating bias in the associated datasets.\n\nThe work yielded 20 peer reviewed papers in top-tier computer vision and machine learning conferences, one journal article, two book chapters, and three workshop papers.  At the time of the project closing, these papers had been cited more than 1,500 times in total.  The project also yielded a slate of new datasets and codebases for the algorithms that are publicly available from the project websites, linked from http://www.cs.utexas.edu/~grauman/research/pubs.html and http://www-bcf.usc.edu/~feisha/projects.html.  Aside from publications, the research results were also regularly disseminated via invited talks by the PIs at international meetings and university seminars. \n\nIn terms of broader impact, the key outcomes of the project entail graduate and undergraduate student training and mentorship, outreach efforts for promoting wider participation in computer science education, and scientific impact of the newly developed algorithms.   The project helped train Ph.D. students in the areas of this research, as well as general skills needed to perform and present research.   In particular, over the project period, five PhD students involved in the research completed their PhDs and two postdoctoral researchers involved in the research completed their stay and accepted tenure track faculty positions.  The project also supported the PIs? work with individual undergraduate students on independent research projects, helping them learn research skills and prepare for graduate school or employment in STEM areas.  In particular, several undergraduate researchers participated in the research with the PIs, and two completed honors bachelors theses directly supporting the project goals and proceeded to graduate programs in Computer Science.  The project's outreach component contributed to efforts that widen participation in computer science, with particular emphasis on reaching female students and K-12 students.  Finally, the generality of the machine learning approaches developed in this project makes them transferrable to problems outside of computer vision.\n\n \n\n\t\t\t\t\tLast Modified: 12/29/2017\n\n\t\t\t\t\tSubmitted by: Kristen L Grauman"
 }
}