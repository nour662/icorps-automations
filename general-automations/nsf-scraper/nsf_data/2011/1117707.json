{
 "awd_id": "1117707",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Algebraic and Spectral Structure of Data in High Dimension",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924481",
 "po_email": "hmunoz@nsf.gov",
 "po_sign_block_name": "Hector Munoz-Avila",
 "awd_eff_date": "2011-07-01",
 "awd_exp_date": "2015-12-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2011-06-29",
 "awd_max_amd_letter_date": "2015-04-07",
 "awd_abstract_narration": "Obtaining information from data is one of the most fundamental problems of modern science and technology. The aim of machine learning is to develop algorithms to automatically extract useful information from complex, high-dimensional data.   Making progress toward this aim requires developing an understanding of the aspects of data, which are amenable to analysis and can be learned using computationally efficient methods. In particular, modeling non-linear structures in high-dimensional data has become one of the very challenging and active lines of research, which has seen significant progress over the last ten years.\r\n\r\nThe goal of this project is to develop and analyze new mathematical representations for data, based on spectral and algebraic methods. We will explore how different structures in the data, such as cluster, manifold or parametric model structures, are reflected in their spectral and algebraic properties and how they can be extracted algorithmically from data, paying particular attention to the issues of high dimensionality and non-linearity. These insights will be used to build better and more adaptive algorithms for inference and data analysis tasks. \r\n\r\nWe will also analyze experimentally and theoretically properties of these algorithms, when data deviates from the posited model structure.  This is a key issue in practical applications, which nearly always involve uncertainty and noise.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mikhail",
   "pi_last_name": "Belkin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mikhail Belkin",
   "pi_email_addr": "mbelkin@ucsd.edu",
   "nsf_id": "000107334",
   "pi_start_date": "2011-06-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "1960 KENNY RD",
  "perf_city_name": "COLUMBUS",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Modern data often consist of complex and high-dimensional objects, with a large number of different attributes. For example, documents may be represented by frequencies of various words and word combinations, while images are often represented by the intensity and color of individual pixel or sets of more sophisticated characteristics, such as edge locations.&nbsp;&nbsp; To extract useful information from these high-dimensional data we need to develop new classes of methods and theoretical analyses.</p>\n<p>&nbsp;</p>\n<p>In the course of this project we concentrated on several different types of structure and approaches to learn from data. In particular, we developed methods for understanding the structure in unlabeled data.&nbsp; We also considered the problem of semi-supervised learning, i.e. of combining labeled and unlabeled data as well as that of scaling these methods to larger datasets.</p>\n<p>&nbsp;</p>\n<p>1. We designed methods to understand data by analyzing spectral properties of certain matrices associated to unlabeled points. We provided connections to Fredholm integral equations, a type of inverse problem studied in mathematical analysis. We also showed how these ideas connect to some of these ideas can lead to more powerful and scalable algorithms for data analysis.</p>\n<p>&nbsp;</p>\n<p>2. We have developed a class of methods generalizing classical matrix methods, such as&nbsp; power iteration to a non-linear, non-tensorial setting. &nbsp;We developed an understanding of the structure of these optimization problems, connecting them to convex maximization and applied these ideas to tasks such as spectral clustering and image segmentation.</p>\n<p>&nbsp;</p>\n<p>3. We developed methods based on hierarchical structures in data. We designed software to visualize such data and developed theoretical foundations to better understand how such structures can be imposed an a theoretically justified way.</p>\n<p>&nbsp;</p>\n<p>These finding have been presented and published in the leading venues in the fields of Machine Learning, Learning Theory and&nbsp; Computer Science.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/25/2016<br>\n\t\t\t\t\tModified by: Mikhail&nbsp;Belkin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nModern data often consist of complex and high-dimensional objects, with a large number of different attributes. For example, documents may be represented by frequencies of various words and word combinations, while images are often represented by the intensity and color of individual pixel or sets of more sophisticated characteristics, such as edge locations.   To extract useful information from these high-dimensional data we need to develop new classes of methods and theoretical analyses.\n\n \n\nIn the course of this project we concentrated on several different types of structure and approaches to learn from data. In particular, we developed methods for understanding the structure in unlabeled data.  We also considered the problem of semi-supervised learning, i.e. of combining labeled and unlabeled data as well as that of scaling these methods to larger datasets.\n\n \n\n1. We designed methods to understand data by analyzing spectral properties of certain matrices associated to unlabeled points. We provided connections to Fredholm integral equations, a type of inverse problem studied in mathematical analysis. We also showed how these ideas connect to some of these ideas can lead to more powerful and scalable algorithms for data analysis.\n\n \n\n2. We have developed a class of methods generalizing classical matrix methods, such as  power iteration to a non-linear, non-tensorial setting.  We developed an understanding of the structure of these optimization problems, connecting them to convex maximization and applied these ideas to tasks such as spectral clustering and image segmentation.\n\n \n\n3. We developed methods based on hierarchical structures in data. We designed software to visualize such data and developed theoretical foundations to better understand how such structures can be imposed an a theoretically justified way.\n\n \n\nThese finding have been presented and published in the leading venues in the fields of Machine Learning, Learning Theory and  Computer Science.\n\n\t\t\t\t\tLast Modified: 04/25/2016\n\n\t\t\t\t\tSubmitted by: Mikhail Belkin"
 }
}