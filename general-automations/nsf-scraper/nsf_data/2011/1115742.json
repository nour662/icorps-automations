{
 "awd_id": "1115742",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "HCC: Small: Collaborative Research: Gestural and Linguistic Expressivity and Entrainment in Dialogue",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 249999.0,
 "awd_amount": 297999.0,
 "awd_min_amd_letter_date": "2011-08-24",
 "awd_max_amd_letter_date": "2014-04-15",
 "awd_abstract_narration": "This research will advance the state of the art in conversational character systems (Intelligent Virtual Agents) in two ways. First, it seeks to better understand the interplay of gesture and language in both generating the perception of personality and allowing participants to adapt to the ongoing conversational context. Second, it will use this understanding to build novel computational models for gesture and language generation that provide fine grained control over the perception of personality and support agent adaptation in response to the conversational context.  The theoretical basis for the personality-based modeling in this project is the well-established \"Big Five\" model of personality, which consists of five orthogonal dimensions of individual variation.\r\n\r\nThe work on adaptation will be couched in the collaborative theory of language use and communication accommodation theory, which predict that communicative behavior varies based on partner specificity. Initial work will form a motion capture, video and audio corpus of three kinds of exchanges. This will be used to both study gestural entrainment during human interactions, determining if audio-based findings extend to the gestural domain, and to enhance scientific understanding of the relationship between gesture and personality. This will inform the modeling work which will build a joint model for personality-based language and gesture production. The model will extend a pilot study on gesture generation for extraversion to three Big Five traits and integrate it with personality-based language generation. An experimental stage will validate these models and study the interactions of movement and language. The research will also study the role of adaptation. Questions to be answered include: (1) whether people gesturally entrain with computers, or indeed produce any gestures while communicating with a computer, (2) whether computers? gestural entrainment promotes similar levels of affiliation as observed with vocal entrainment, and (3) whether changing gestural entrainment over the course of an interaction is more powerful than aligning gestures from the outset of an interaction. \r\n\r\nCharacter systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior like entrainment, has a direct impact on the effectiveness of the applications in which they are used. For example, it will have a direct impact on student learning. As these applications become more ubiquitous in society, particularly among children, it is important to be able to harness their full benefit, and indeed, avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent interactions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jean",
   "pi_last_name": "Fox Tree",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Jean E Fox Tree",
   "pi_email_addr": "foxtree@ucsc.edu",
   "nsf_id": "000106307",
   "pi_start_date": "2011-08-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marilyn",
   "pi_last_name": "Walker",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Marilyn A Walker",
   "pi_email_addr": "mawalker@ucsc.edu",
   "nsf_id": "000515313",
   "pi_start_date": "2011-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Cruz",
  "inst_street_address": "1156 HIGH ST",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA CRUZ",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8314595278",
  "inst_zip_code": "950641077",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "CA19",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA SANTA CRUZ",
  "org_prnt_uei_num": "",
  "org_uei_num": "VXUFPE4MCZH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Cruz",
  "perf_str_addr": "1156 HIGH ST",
  "perf_city_name": "SANTA CRUZ",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "950641077",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "CA19",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 249999.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>To create the next generation of Intelligent Virtual Agents, we advanced two fields of research, psychology and computer science. We tested gestural adaptation between pairs of human interlocutors (Tolins et al., 2013) and between humans and agents. We also tested how humans perceive the gestural behavior of individual agents and of two agents interacting with and adapting to each other. For the individual agents, we assessed how humans perceived the personalities of agents that were designed to portray different personalities. We found that the personalities reported differed depending on whether the assessment measure employed an open-ended question or closed questions (Liu et al., 2013, 2015).&nbsp;</p>\n<p>In order to directly test the effect of agent gestural behavior on human gestural behavior when humans interact with agents, we developed a novel experimental paradigm of an agent telling a human a story in installments, and then observing the human's behavior when retelling the same installments back to the agent. We wished to test whether humans would behave naturally and gesture in this collaborative storytelling environment when their partner was an artificial agent. We observed that most people will gesture to agents while repeating back a story the agent told, but that the gesture rate varied widely.&nbsp;</p>\n<p>Hand pose and finger motion have been relatively understudied aspects of nonverbal communication.&nbsp; We conducted a sequence of perceptual experiments that showed that people make consistent personality judgments based on agent hand pose and finger motion.&nbsp; We also showed that people will continue to make these judgments even in the presence of arm and body motion.&nbsp; This suggests that these relatively small scale aspects of motion are actually highly communicative and must be carefully modeled in virtual agents.&nbsp; We presented guidelines on specific pose and finger motion variations that can be made to alter perception of each of the Big Five personality traits (Wang et al., in press).&nbsp;</p>\n<p>In order to test human perceptions of adaptation behavior in dialogue, without the confound of requiring agents to interact naturally with humans, we set up an experimental paradigm of two agents co-telling a story, adapted to be dialogic by re-using personal narratives posted in weblogs. In this story co-telling setup we were able, for the first time, to test whether it was possible to design intelligent virtual agents to express personality over an extended dialogic interaction. We found that we could control user perceptions of introversion and extraversion through manipulation of gestural parameters. We also tested whether humans perceived the differences and preferred adapting or non-adapting agents. Adapting agents were preferred (Hu et al., 2015). &nbsp;</p>\n<p>Technology has also been developed that supported this work and will support future research.&nbsp; This includes new methods for obtaining accurate hand shapes from data gloves (Wang and Neff, 2013), facilitating Tolins et al. (2013), and highly efficient motion retrieval techniques based on deep learning (Wang &amp; Neff, 2015).&nbsp;We have also prepared for public release a number of corpora produced during this research so that others can build on the work.&nbsp;</p>\n<p>Character systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior such as adaptively changing over time, has a direct impact on the effectiveness of the applications in which they are used. As these applications become more ubiquitous, it is important to harness their full benefit and avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a ...",
  "por_txt_cntn": "\nTo create the next generation of Intelligent Virtual Agents, we advanced two fields of research, psychology and computer science. We tested gestural adaptation between pairs of human interlocutors (Tolins et al., 2013) and between humans and agents. We also tested how humans perceive the gestural behavior of individual agents and of two agents interacting with and adapting to each other. For the individual agents, we assessed how humans perceived the personalities of agents that were designed to portray different personalities. We found that the personalities reported differed depending on whether the assessment measure employed an open-ended question or closed questions (Liu et al., 2013, 2015). \n\nIn order to directly test the effect of agent gestural behavior on human gestural behavior when humans interact with agents, we developed a novel experimental paradigm of an agent telling a human a story in installments, and then observing the human's behavior when retelling the same installments back to the agent. We wished to test whether humans would behave naturally and gesture in this collaborative storytelling environment when their partner was an artificial agent. We observed that most people will gesture to agents while repeating back a story the agent told, but that the gesture rate varied widely. \n\nHand pose and finger motion have been relatively understudied aspects of nonverbal communication.  We conducted a sequence of perceptual experiments that showed that people make consistent personality judgments based on agent hand pose and finger motion.  We also showed that people will continue to make these judgments even in the presence of arm and body motion.  This suggests that these relatively small scale aspects of motion are actually highly communicative and must be carefully modeled in virtual agents.  We presented guidelines on specific pose and finger motion variations that can be made to alter perception of each of the Big Five personality traits (Wang et al., in press). \n\nIn order to test human perceptions of adaptation behavior in dialogue, without the confound of requiring agents to interact naturally with humans, we set up an experimental paradigm of two agents co-telling a story, adapted to be dialogic by re-using personal narratives posted in weblogs. In this story co-telling setup we were able, for the first time, to test whether it was possible to design intelligent virtual agents to express personality over an extended dialogic interaction. We found that we could control user perceptions of introversion and extraversion through manipulation of gestural parameters. We also tested whether humans perceived the differences and preferred adapting or non-adapting agents. Adapting agents were preferred (Hu et al., 2015).  \n\nTechnology has also been developed that supported this work and will support future research.  This includes new methods for obtaining accurate hand shapes from data gloves (Wang and Neff, 2013), facilitating Tolins et al. (2013), and highly efficient motion retrieval techniques based on deep learning (Wang &amp; Neff, 2015). We have also prepared for public release a number of corpora produced during this research so that others can build on the work. \n\nCharacter systems are becoming increasingly important for a range of applications, from virtual worlds to tutoring systems. There is growing evidence that the way personality is presented through these characters, and how well they mimic expected human behavior such as adaptively changing over time, has a direct impact on the effectiveness of the applications in which they are used. As these applications become more ubiquitous, it is important to harness their full benefit and avoid unintended negative consequences. This involves both advances in computational models that allow an agent to reflect a given personality and adapt to a human user, and also a deeper understanding of the role of personality and adaptation in effective human-agent int..."
 }
}