{
 "awd_id": "1124240",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DIP: Exploiting Longitudinal Electroencephalogram (EEG) Input in a Reading Tutor",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Christopher Hoadley",
 "awd_eff_date": "2011-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 1350000.0,
 "awd_amount": 1382000.0,
 "awd_min_amd_letter_date": "2011-09-06",
 "awd_max_amd_letter_date": "2012-11-29",
 "awd_abstract_narration": "Automated (and human) tutors are limited in their ability to infer what is going on in students' heads based on their observable behavior. The proposed work addresses this limitation by investigating how EEG input from a commercially-available device can be used as evidence about students' mental states. In particular, the project focuses on adding EEG-enhanced feedback to Project LISTEN's Reading Tutor, an intelligent tutoring system that helps children learn to read. The project seeks to answer two questions: (1) How can we use EEG to detect mental states that predict, indicate, or reflect student learning? (2) How can we use such detection to improve student learning? Analysis to answer these questions and to enhance the capabilities of the Reading Tutor draws on existing tools to explore annotate, and mine EEG data logged by the Reading Tutor. The research aims to tell us more about how to use EEG to identify mental states that predict learning and to use machine learning to make an intelligent tutoring system better, and it may also add to what is known about sources of reading difficulties. Expected technological contributions of this work include advances in relating EEG data to children's behavior, cognition, engagement, and learning and advances in elucidating how intelligent tutors can robustly exploit noisy EEG input to better assist learning. \r\n\r\nThe technological innovation in this project is particularly important for those children who need extra help with sounding out, word recognition, and/or making simple inferences needed for understanding.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Mostow",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "David J Mostow",
   "pi_email_addr": "mostow@cs.cmu.edu",
   "nsf_id": "000112424",
   "pi_start_date": "2011-09-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kai-Min",
   "pi_last_name": "Chang",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Kai-Min K Chang",
   "pi_email_addr": "kkchang@cs.cmu.edu",
   "nsf_id": "000603914",
   "pi_start_date": "2011-10-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "8842",
   "pgm_ref_txt": "Design and Implementation Projects"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 1350000.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The ultimate automated tutor could peer directly into students&rsquo; minds to identify their mental states (knowledge, thoughts, feelings, and so forth) and decide accordingly what and how to teach at each moment. We proposed to investigate a novel source of input from as close to the brain as non-surgically practicable: EEG. The major goal of this project was to apply EEG technology in meaningful learning tasks (reading), using a uniquetestbed (Project LISTEN's Reading Tutor) to pursue useful targets (e.g., user intention, comprehension, if student is having difficulty, etc.).</p>\n<p>As part of this grant, we collected ~3 years of tutor usage data collected in vivo at a primary school. The tutor is Project LISTEN's Reading Tutor and EEG was recorded with NeuroSky BrainBands. The Reading Tutor helps students learn how to read by listening (using Automated Speech Recognition) to them read story aloud. We annotated the time-course of a reading session with the sentence that the student was reading. The dataset consists of roughly 169 hours of EEG recording and 200,000 sentences. To assist researchers who are new to this topic, we also implemented a machine learning toolkit to help process the EEG data. We made both the (anonymized) dataset and toolkit publically available.</p>\n<p>We published papers, gave talks, and presented posters and demos in the conferences, workshops and journals. Our notable results included using EEG to detect cheating (CSCW 2015), improve Knowledge Tracing (ITS 2014), detect comprehension (LAK 2014), detect engagement (AIED 2013), improve spoken dialog interface (ICMI 2012), improve automatic speech recognition (ACL 2012), improve intelligent tutoring system (IJAIED 2013). Results from this project were also part of a CMU Masters thesis. Undergraduate research were presented at the 2013 Meeting of the Minds Undergraduate Research Symposium and 2011-2014 PSLC Summer Intern Poster Session at CMU. To further disseminate our results internationally, we co-organized a wrkshop on Utilizing EEG Input in Intelligent Tutoring Systems in Hololulu, Hawaii (ITS 2014) and a tutorial on Student Modeling Applications, Recent Developments &amp; Toolkits (SMART) in Madrid, Spain (EDM 2015).</p>\n<p>Finally, we received an iCorps NSF award to commercialize this research in the form of \"SynMetric.&rdquo;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/16/2015<br>\n\t\t\t\t\tModified by: David&nbsp;J&nbsp;Mostow</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe ultimate automated tutor could peer directly into students\u00c6 minds to identify their mental states (knowledge, thoughts, feelings, and so forth) and decide accordingly what and how to teach at each moment. We proposed to investigate a novel source of input from as close to the brain as non-surgically practicable: EEG. The major goal of this project was to apply EEG technology in meaningful learning tasks (reading), using a uniquetestbed (Project LISTEN's Reading Tutor) to pursue useful targets (e.g., user intention, comprehension, if student is having difficulty, etc.).\n\nAs part of this grant, we collected ~3 years of tutor usage data collected in vivo at a primary school. The tutor is Project LISTEN's Reading Tutor and EEG was recorded with NeuroSky BrainBands. The Reading Tutor helps students learn how to read by listening (using Automated Speech Recognition) to them read story aloud. We annotated the time-course of a reading session with the sentence that the student was reading. The dataset consists of roughly 169 hours of EEG recording and 200,000 sentences. To assist researchers who are new to this topic, we also implemented a machine learning toolkit to help process the EEG data. We made both the (anonymized) dataset and toolkit publically available.\n\nWe published papers, gave talks, and presented posters and demos in the conferences, workshops and journals. Our notable results included using EEG to detect cheating (CSCW 2015), improve Knowledge Tracing (ITS 2014), detect comprehension (LAK 2014), detect engagement (AIED 2013), improve spoken dialog interface (ICMI 2012), improve automatic speech recognition (ACL 2012), improve intelligent tutoring system (IJAIED 2013). Results from this project were also part of a CMU Masters thesis. Undergraduate research were presented at the 2013 Meeting of the Minds Undergraduate Research Symposium and 2011-2014 PSLC Summer Intern Poster Session at CMU. To further disseminate our results internationally, we co-organized a wrkshop on Utilizing EEG Input in Intelligent Tutoring Systems in Hololulu, Hawaii (ITS 2014) and a tutorial on Student Modeling Applications, Recent Developments &amp; Toolkits (SMART) in Madrid, Spain (EDM 2015).\n\nFinally, we received an iCorps NSF award to commercialize this research in the form of \"SynMetric.\"\n\n\t\t\t\t\tLast Modified: 11/16/2015\n\n\t\t\t\t\tSubmitted by: David J Mostow"
 }
}