{
 "awd_id": "1117829",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Efficient Query Processing in Large Search Engines",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2011-08-15",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 499852.0,
 "awd_amount": 499852.0,
 "awd_min_amd_letter_date": "2011-08-16",
 "awd_max_amd_letter_date": "2011-08-16",
 "awd_abstract_narration": "The largest web search engines now receive hundreds of millions of queries per day that need to be answered in fractions of a second on collections of tens of billions of web documents. In order to process all these queries, search engines consume increasing amounts of hardware and energy resources. This project focuses on developing new algorithms, index structures, and other software techniques for scaling query processing in search engines, that is, techniques that allow queries to be executed faster and on larger data sets using fewer hardware and energy resources. \r\n\r\n Research activities in this project focus on three main approaches. First, the project studies how index size and access time can be reduced through improved index compression techniques. Second, work on new early termination techniques considers how the top results for a query can be computed without exhaustive traversal of the index structures for the query terms, for simple ranking functions such as BM25 or Cosine, and for the more complex functions with many features used by current web search engines. Finally, the project explores general techniques for query optimization in information retrieval (IR) systems, inspired by the significant body of work on query optimizers in database systems.  \r\n\r\n Web search engines are a multi-billion dollar industry and a crucial component of the internet. Techniques resulting from this project are expected to benefit this industry by reducing the hardware cost and energy consumption of large-scale search services. Results will be disseminated through publications in major conferences and journals, tutorials at conferences, distribution of software libraries, contributions to existing software tools such as Lucene. This project provides research and educational opportunities for graduate and undergraduate students and prepare them for later work at companies, research labs, or universities. Web site (http://cis.poly.edu/westlab/queryproc/) provides more information about this project.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Torsten",
   "pi_last_name": "Suel",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Torsten Suel",
   "pi_email_addr": "torsten.suel@nyu.edu",
   "nsf_id": "000493079",
   "pi_start_date": "2011-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "70 WASHINGTON SQ S",
  "perf_city_name": "NEW YORK",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 499852.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>This project developed new techniques that allow web search engines to more efficiently execute keyword queries posed by users. Large search engines receive billions of queries per day that have to be processed over hundreds of billions of web pages and other types of documents. To do this, companies have to build many large data centers with thousands of machines each, resulting in large hardware, maintenance, and energy costs. Reducing these costs by even a moderate amount thus can have great benefits for the economy and environment.</span></p>\n<p>Our work proposed new algorithmic techniques (i.e., smart algorithms and data structures) for this problem that can improve efficiency in many scenarios. Our two main contributions are as follows:</p>\n<p><strong>1. A new approach for fast candidate generation for cascading rankers</strong>. State-of-the-art search engines order query results based on highly complex ranking functions that use hundreds of features (signals). This increases the cost of query processing, but is necessary to return relevant results to the user. For efficiency, search engines implement this by using a cascading approach to query processing that first applies a very simple ranking function to the entire index to narrow down the field and identify a small set of candidate documents; these candidates are then further ranked and winnowed using increasingly complex ranking functions. We proposed a new approach that identifies such candidates much faster than previous oublished work, thus significantly reducing the cost of the first phase of the cascading approach.</p>\n<p><strong>2. Faster algorithms for disjunctive top-k queries under simple ranking functions.</strong> Disjunctive top-k queries return the k results with highest scores among all documents containing at least one of the query keywords. Such queries are an important building block in search engines, e.g., for first-cascade ranking, and a classical problem in Information Retrieval that has been studied by many researchers. Our work further improved an approach based on so-called block-max index structures, which are index structures that enable skipping of less relevant parts of the index during query processing. Our algorithms achieve speed-ups of 2-5 over the fastest previous solutions on standard data sets.</p>\n<p>Other research conducted in this project proposed improved algorithms for index pruning (which is the process of identifying and removing index entries that are unlikely to be useful for any queries that are likely to happen), for updating and reorganizing large text index structures on single machines and in distributed systems, and for quickly estimating distances in very large graphs, such as those arising from social networks or the hyperlink structure of the web.</p>\n<p>The research conducted in this project has the potential to improve the efficiency of existing commercial search engines, an industry with tens of billions of dollars of economic impact per year in the US, and to help new companies entering this and related fields. The project also supported the training of 5 PhD and 3 MS students in Computer Science, including a female PhD graduate, a Hispanic PhD student, and an MS student with disabilities. Results of this research were published in peer-reviewed publication venues and are expected to lead to significant follow-up work by other researchers.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/04/2016<br>\n\t\t\t\t\tModified by: Torsten&nbsp;Suel</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed new techniques that allow web search engines to more efficiently execute keyword queries posed by users. Large search engines receive billions of queries per day that have to be processed over hundreds of billions of web pages and other types of documents. To do this, companies have to build many large data centers with thousands of machines each, resulting in large hardware, maintenance, and energy costs. Reducing these costs by even a moderate amount thus can have great benefits for the economy and environment.\n\nOur work proposed new algorithmic techniques (i.e., smart algorithms and data structures) for this problem that can improve efficiency in many scenarios. Our two main contributions are as follows:\n\n1. A new approach for fast candidate generation for cascading rankers. State-of-the-art search engines order query results based on highly complex ranking functions that use hundreds of features (signals). This increases the cost of query processing, but is necessary to return relevant results to the user. For efficiency, search engines implement this by using a cascading approach to query processing that first applies a very simple ranking function to the entire index to narrow down the field and identify a small set of candidate documents; these candidates are then further ranked and winnowed using increasingly complex ranking functions. We proposed a new approach that identifies such candidates much faster than previous oublished work, thus significantly reducing the cost of the first phase of the cascading approach.\n\n2. Faster algorithms for disjunctive top-k queries under simple ranking functions. Disjunctive top-k queries return the k results with highest scores among all documents containing at least one of the query keywords. Such queries are an important building block in search engines, e.g., for first-cascade ranking, and a classical problem in Information Retrieval that has been studied by many researchers. Our work further improved an approach based on so-called block-max index structures, which are index structures that enable skipping of less relevant parts of the index during query processing. Our algorithms achieve speed-ups of 2-5 over the fastest previous solutions on standard data sets.\n\nOther research conducted in this project proposed improved algorithms for index pruning (which is the process of identifying and removing index entries that are unlikely to be useful for any queries that are likely to happen), for updating and reorganizing large text index structures on single machines and in distributed systems, and for quickly estimating distances in very large graphs, such as those arising from social networks or the hyperlink structure of the web.\n\nThe research conducted in this project has the potential to improve the efficiency of existing commercial search engines, an industry with tens of billions of dollars of economic impact per year in the US, and to help new companies entering this and related fields. The project also supported the training of 5 PhD and 3 MS students in Computer Science, including a female PhD graduate, a Hispanic PhD student, and an MS student with disabilities. Results of this research were published in peer-reviewed publication venues and are expected to lead to significant follow-up work by other researchers.\n\n \n\n\t\t\t\t\tLast Modified: 08/04/2016\n\n\t\t\t\t\tSubmitted by: Torsten Suel"
 }
}