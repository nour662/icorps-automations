{
 "awd_id": "1048296",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CiC (RDDC):  Continuous Bulk Processing in the Cloud",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2011-04-01",
 "awd_exp_date": "2015-03-31",
 "tot_intn_awd_amt": 360000.0,
 "awd_amount": 360000.0,
 "awd_min_amd_letter_date": "2011-03-28",
 "awd_max_amd_letter_date": "2011-03-28",
 "awd_abstract_narration": "This research explores an alternative data processing architecture that\r\nfundamentally improves computing efficiency to reduce costs and provide\r\nenhanced data mining capabilities for cloud computing.  The next major\r\nadvancements in IT, medical, and science informatics will largely be\r\ndictated by our ability to store, manage, and analyze large amounts of\r\ninformation.  For many important problems, advances in data acquisition\r\ntools are rapidly increasing data generation rates, exceeding our ability\r\nto manage and process the data they produce.\r\n\r\nThis proposal investigates novel architectures for continuous bulk data\r\nprocessing, which support data-intensive applications that perform complex\r\nmulti-step computations over successive batches of input data (e.g., from\r\nscientific or medical instruments), allowing analytics to simply be\r\nupdated, not recomputed, when new data arrives.  The research seeks to\r\nraise incremental processing as a first-class abstraction, significantly\r\nlowering the barrier of data-intensive projects to take advantage of cloud\r\ncomputing.  Towards that end, the work will develop data analysis portal\r\narchitectures to increase the reach of on-demand data analytics across\r\nvarious application domains.  As a case study, it will develop a portal for\r\nfatty-liver disease, allowing care givers on-demand access to medical\r\nanalytics to improve care, reduce cost, and improve clinical outcomes for\r\nthis important disease.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kenneth",
   "pi_last_name": "Yocum",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Kenneth G Yocum",
   "pi_email_addr": "kyocum@cs.ucsd.edu",
   "nsf_id": "000367876",
   "pi_start_date": "2011-03-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rohit",
   "pi_last_name": "Loomba",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rohit Loomba",
   "pi_email_addr": "roloomba@ucsd.edu",
   "nsf_id": "000565910",
   "pi_start_date": "2011-03-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 GILMAN DR",
  "perf_city_name": "LA JOLLA",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "8010",
   "pgm_ref_txt": "Computing in the Cloud"
  },
  {
   "pgm_ref_code": "9218",
   "pgm_ref_txt": "BASIC RESEARCH & HUMAN RESORCS"
  },
  {
   "pgm_ref_code": "HPCC",
   "pgm_ref_txt": "HIGH PERFORMANCE COMPUTING & COMM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 360000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The next major advancements in IT, medical, and science informatics will largely be dictated by our ability to store, manage, and analyze large amounts of information. &nbsp;For many important problems, advances in data acquisition tools are rapidly increasing data generation rates, exceeding our ability tomanage and process the data they produce. This rapid data ``deluge'' gives rise to many exciting data mining opportunities. Here, large, daily data arrivals (e.g., from scientific or medical instruments) must be combined with data derived from previous batches or iterated upon to produce results. Cloud computing promises to radically reduce the cost and complexity of performing these large-scale analytics by providing storage, network, and processing resources commensurate with the size of the data.&nbsp;</p>\n<p>In this environment, a primary bottleneck to leveraging big data is developing algorithms(analytics) to process and understand data. &nbsp;&nbsp;Many processing error cases arise when running at scale on large input data sets; errors may occur after tens to thousands of machine hours. &nbsp;This proposal addresses this problem by investigating how to understand, debug, and tune analytics.&nbsp;</p>\n<p><strong>Intellectual Merit:</strong></p>\n<p>The goals of this work were to develop semantics and systems for continuously processing bulk data, identify methods for debugging and tuning large scale analytics, and evaluate the ideas with prototype software.</p>\n<ul>\n<li>The work explored how to add continuous data processing semantics to an existing relational scripting language (Pig) originally designed for batch processing systems like Hadoop MapReduce. &nbsp;This reduced the latency of operations, such as aggregations, that incrementally ingest new data.&nbsp;</li>\n<li>The research resulted in data provenance models for MapReduce and graph processing systems. &nbsp;Data provenance can be used to determine the set of inputs used to produce each new data item -- the PI's explored how to use such provenance to debug and tune analytics. &nbsp;The work produced provenance collection systems that could efficiently extract this fine-grain (per output record) data flow information from a variety of data-intensive computing systems including Hadoop, Hyracks, Spark, and GraphLab.</li>\n<li>The project developed new methods for employing provenance to improve analytics through debugging and data cleaning. &nbsp; &nbsp;This approach allows a data scientist to record and then inspect provenance to discover potential errors in the analytic. This research illustrated that one could capture fine-grain provenance in systems like Hadoop with sizea nd space overheads less than 50%. &nbsp;Having the entire provenance \"at hand\" allows a data scientist to debug and tune large-scale analytics in an interactive manner. In addition, this work has shown that provenance may be used for data cleaning sophisticated multi-step non-relationaltransforms (i.e., de novo genome assembly). &nbsp; This technique leveraged an ability to remove data from a pipeline and we used it to improve de novo genetic assembly when input data sets are polluted with DNA from multiple organisms.</li>\n<li>Finally, the work investigated how to use fine-grain provenance to understand and improve graph processing analytics. Exploiting provenance information in this setting raised significant technical challenges, stemming from the fact that provenance data attains big data scales even when it pertains to analytics over modest input graphs. &nbsp;In response to this challenge, the research gave rise to a number of novel technical solutions, including: (i) a formal semantic model of provenance in parallel graph processing frameworks and (ii) a low-overhead provenance capture and storage system. &nbsp;The work also began an investigation into a declarative provenance query language and a set of provenance queries th...",
  "por_txt_cntn": "\nThe next major advancements in IT, medical, and science informatics will largely be dictated by our ability to store, manage, and analyze large amounts of information.  For many important problems, advances in data acquisition tools are rapidly increasing data generation rates, exceeding our ability tomanage and process the data they produce. This rapid data ``deluge'' gives rise to many exciting data mining opportunities. Here, large, daily data arrivals (e.g., from scientific or medical instruments) must be combined with data derived from previous batches or iterated upon to produce results. Cloud computing promises to radically reduce the cost and complexity of performing these large-scale analytics by providing storage, network, and processing resources commensurate with the size of the data. \n\nIn this environment, a primary bottleneck to leveraging big data is developing algorithms(analytics) to process and understand data.   Many processing error cases arise when running at scale on large input data sets; errors may occur after tens to thousands of machine hours.  This proposal addresses this problem by investigating how to understand, debug, and tune analytics. \n\nIntellectual Merit:\n\nThe goals of this work were to develop semantics and systems for continuously processing bulk data, identify methods for debugging and tuning large scale analytics, and evaluate the ideas with prototype software.\n\nThe work explored how to add continuous data processing semantics to an existing relational scripting language (Pig) originally designed for batch processing systems like Hadoop MapReduce.  This reduced the latency of operations, such as aggregations, that incrementally ingest new data. \nThe research resulted in data provenance models for MapReduce and graph processing systems.  Data provenance can be used to determine the set of inputs used to produce each new data item -- the PI's explored how to use such provenance to debug and tune analytics.  The work produced provenance collection systems that could efficiently extract this fine-grain (per output record) data flow information from a variety of data-intensive computing systems including Hadoop, Hyracks, Spark, and GraphLab.\nThe project developed new methods for employing provenance to improve analytics through debugging and data cleaning.    This approach allows a data scientist to record and then inspect provenance to discover potential errors in the analytic. This research illustrated that one could capture fine-grain provenance in systems like Hadoop with sizea nd space overheads less than 50%.  Having the entire provenance \"at hand\" allows a data scientist to debug and tune large-scale analytics in an interactive manner. In addition, this work has shown that provenance may be used for data cleaning sophisticated multi-step non-relationaltransforms (i.e., de novo genome assembly).   This technique leveraged an ability to remove data from a pipeline and we used it to improve de novo genetic assembly when input data sets are polluted with DNA from multiple organisms.\nFinally, the work investigated how to use fine-grain provenance to understand and improve graph processing analytics. Exploiting provenance information in this setting raised significant technical challenges, stemming from the fact that provenance data attains big data scales even when it pertains to analytics over modest input graphs.  In response to this challenge, the research gave rise to a number of novel technical solutions, including: (i) a formal semantic model of provenance in parallel graph processing frameworks and (ii) a low-overhead provenance capture and storage system.  The work also began an investigation into a declarative provenance query language and a set of provenance queries that can help identify opportunities for optimizing graph analytics.  \n\n\nBroader Impacts:\n\nA key producer of big data is the medical community, though dealing with medical data is often complex.  One goal of this work ..."
 }
}