{
 "awd_id": "1054229",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Evidence in Federated Distributed Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Susanne Wetzel",
 "awd_eff_date": "2011-02-01",
 "awd_exp_date": "2018-01-31",
 "tot_intn_awd_amt": 508636.0,
 "awd_amount": 508636.0,
 "awd_min_amd_letter_date": "2011-01-12",
 "awd_max_amd_letter_date": "2017-01-17",
 "awd_abstract_narration": "There is an increasing trend towards federated distributed systems, i.e., systems that are operated jointly by multiple different organizations or individuals. The interests of the participants in such a system are often highly diverse and/or in conflict with one another; for example, participants may be business competitors or based in hostile nations. Thus, federated systems are inherently vulnerable to insider attacks: the participants can try to subvert the system, exploit it for their own benefit, or attack other participants.\r\n\r\nHowever, the participants in a federated system are typically connected in the 'offline world' as well, e.g., through social networks or business relationships. This context can be leveraged to handle misbehavior through well-known, time-tested techniques like accountability and transparency. For example, if one participant can detect and prove that another participant has misbehaved, she can sue that participant for breach of contract.\r\n\r\nThe goal of this research is to develop a key technology for enabling this approach, namely a reliable and general way to generate and verify evidence of misbehavior in federated systems. The project (i) studies the fundamental tradeoffs, requirements, and inherent costs of creating evidence; (ii) develops new algorithms for efficiently supporting different kinds of evidence; and (iii) evaluates these algorithms in the context of practical systems.\r\n\r\nThe project is integrated with Penn's new undergraduate program in Market and Social Systems Engineering. It will produce and freely distribute software that can be used to defend federated systems against attacks and malicious insiders.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Haeberlen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas Haeberlen",
   "pi_email_addr": "ahae@cis.upenn.edu",
   "nsf_id": "000562850",
   "pi_start_date": "2011-01-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "3451 WALNUT ST STE 440A",
  "perf_city_name": "PHILADELPHIA",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779500",
   "pgm_ele_name": "TRUSTWORTHY COMPUTING"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7795",
   "pgm_ref_txt": "TRUSTWORTHY COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 96133.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 98928.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 101803.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 103960.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 107812.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many modern computer systems are federated - that is, they are operated jointly by multiple different individuals or organizations. The participants in such systems can have very different goals and interests, and their goals can be in conflict; for instance, they can be business competitors or based in hostile nations. Hence, there is a risk that these systems will be subverted \"from within\": the participants can easily change the software on their own machines, and thus cause them to \"misbehave\", if it helps them achieve their goals; they can even collude with other participants. Many instances of such misbehavior have been observed in widely deployed federated systems.<br /><br />This project has explored a new approach to this problem, which leverages the fact that the participants in a federated system are also connected in the \"offline\" world - e.g., through a social network or through business relationships. Because of this, it is not necessary to prevent all misbehavior: in many cases, the participants can be held accountable (e.g., in court), as long as there is a way to reliably detect that misbehavior has occurred, and to provably attribute it to a specific participant. This is difficult because, in general, there are many different ways in which participants can misbehave in a given system, and not all of them are necessarily known up front, when the system is designed. <br /><br />To enable this approach, the project has developed a range of new techniques for detecting misbehavior in federated systems and for generating evidence, including:<br /><br />* Algorithms that can (provably) detect a large class of misbehaviors and are applicable to a wide range of systems;<br />* Techniques for generating, verifying, and storing evidence efficiently;<br />* Ways to accommodate privacy concerns, e.g., when the system is handling sensitive data or the data is distributed across multiple participants;<br />* Techniques for detecting and proving timing-related misbehavior, such as slow processing speeds;<br />* Solutions for especially challenging forms of misbehavior, such as information leakage or covert timing channels;<br />* Generalizations to misbehavior that involves the omission of a required action; and<br />* Highly efficient algorithms that can generate evidence at very high speeds (e.g., for fast Internet connections) and can be implemented in hardware.<br /><br />We have shown how to apply our techniques to a wide range of systems and scenarios, including data analytics systems, peer-to-peer systems, cyber-physical systems, and the Internet's interdomain routing system. Implementations of our techniques are freely available under an open-source license. We have also worked on technology transfer with collaborators at Intel, BAE Systems, Akamai, and Microsoft. <br /><br />The project has contributed to several different areas. In distributed systems, it has established accountability as a new approach to handling faults and misbehavior; in security, it has introduced new types of evidence, and it has shown new ways to address challenging problems, such as information flow or covert channels; and in networking, it has provided new diagnostic and forensic techniques. Our work has also had impact beyond computer science: for instance, it has provided a way to add accountability for scientific studies that rely on private data, it has inspired a new approach to handling difficult product liability questions, and it has contributed to a new approach to measuring systemic risk in financial networks.<br /><br />The project has helped to train eight PhD students and one Master's student, and several of them have won awards, including a Yahoo KSC award and a MSR fellowship. Of the six students that have already graduated, one has become a tenure-track faculty member (at Rice University), and the five others have accepted positions in the tech industry (e.g., at Facebook, Intel, and Oracle). Results from the project have been integrated with two courses at Penn, and more than 1,000 undergraduate and graduate students have already learned about accountability using the materials we developed.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/19/2018<br>\n\t\t\t\t\tModified by: Andreas&nbsp;Haeberlen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany modern computer systems are federated - that is, they are operated jointly by multiple different individuals or organizations. The participants in such systems can have very different goals and interests, and their goals can be in conflict; for instance, they can be business competitors or based in hostile nations. Hence, there is a risk that these systems will be subverted \"from within\": the participants can easily change the software on their own machines, and thus cause them to \"misbehave\", if it helps them achieve their goals; they can even collude with other participants. Many instances of such misbehavior have been observed in widely deployed federated systems.\n\nThis project has explored a new approach to this problem, which leverages the fact that the participants in a federated system are also connected in the \"offline\" world - e.g., through a social network or through business relationships. Because of this, it is not necessary to prevent all misbehavior: in many cases, the participants can be held accountable (e.g., in court), as long as there is a way to reliably detect that misbehavior has occurred, and to provably attribute it to a specific participant. This is difficult because, in general, there are many different ways in which participants can misbehave in a given system, and not all of them are necessarily known up front, when the system is designed. \n\nTo enable this approach, the project has developed a range of new techniques for detecting misbehavior in federated systems and for generating evidence, including:\n\n* Algorithms that can (provably) detect a large class of misbehaviors and are applicable to a wide range of systems;\n* Techniques for generating, verifying, and storing evidence efficiently;\n* Ways to accommodate privacy concerns, e.g., when the system is handling sensitive data or the data is distributed across multiple participants;\n* Techniques for detecting and proving timing-related misbehavior, such as slow processing speeds;\n* Solutions for especially challenging forms of misbehavior, such as information leakage or covert timing channels;\n* Generalizations to misbehavior that involves the omission of a required action; and\n* Highly efficient algorithms that can generate evidence at very high speeds (e.g., for fast Internet connections) and can be implemented in hardware.\n\nWe have shown how to apply our techniques to a wide range of systems and scenarios, including data analytics systems, peer-to-peer systems, cyber-physical systems, and the Internet's interdomain routing system. Implementations of our techniques are freely available under an open-source license. We have also worked on technology transfer with collaborators at Intel, BAE Systems, Akamai, and Microsoft. \n\nThe project has contributed to several different areas. In distributed systems, it has established accountability as a new approach to handling faults and misbehavior; in security, it has introduced new types of evidence, and it has shown new ways to address challenging problems, such as information flow or covert channels; and in networking, it has provided new diagnostic and forensic techniques. Our work has also had impact beyond computer science: for instance, it has provided a way to add accountability for scientific studies that rely on private data, it has inspired a new approach to handling difficult product liability questions, and it has contributed to a new approach to measuring systemic risk in financial networks.\n\nThe project has helped to train eight PhD students and one Master's student, and several of them have won awards, including a Yahoo KSC award and a MSR fellowship. Of the six students that have already graduated, one has become a tenure-track faculty member (at Rice University), and the five others have accepted positions in the tech industry (e.g., at Facebook, Intel, and Oracle). Results from the project have been integrated with two courses at Penn, and more than 1,000 undergraduate and graduate students have already learned about accountability using the materials we developed.\n\n\t\t\t\t\tLast Modified: 04/19/2018\n\n\t\t\t\t\tSubmitted by: Andreas Haeberlen"
 }
}