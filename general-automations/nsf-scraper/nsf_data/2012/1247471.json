{
 "awd_id": "1247471",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop: Data Curation: Ensuring Quality and Access to Enable New Science",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 49954.0,
 "awd_amount": 49954.0,
 "awd_min_amd_letter_date": "2012-08-27",
 "awd_max_amd_letter_date": "2012-08-27",
 "awd_abstract_narration": "This award supports the NSF Workshop: Data Curation: Ensuring Quality and Access to Enable New Science, to be held in September 2012 in Arlington, VA. The value of data to the global economy has been well-documented and spawned calls for training professionals who practice data curation and stewardship, data analytics, and \"big data\" management. It is evident that poor data is worse than no data because it wastes time, leads to poor science and decisions, and diminishes trust in the entire data enterprise. Data curation demands tools and techniques at each phase of the data life cycle that lead to effective and efficient data services that people trust. This workshop brings together leading researchers in data curation to establish a research agenda to guide development of these tools and techniques. \r\n\r\nThis workshop will have impact on the emerging data curation research and development community by defining directions for tools and techniques that support selection, metadata annotation, storage, access, use and reuse, and preservation of scientific and scholarly data. Such tools and techniques will make science and scholarship more effective and may be adapted to personal data management applications such as personal health or educational records. The workshop web site (http://datacuration.web.unc.edu/) provides will be used to disseminate further information, including the resulting workshop report that will provide a roadmap for the future data curation research and follow-up activities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gary",
   "pi_last_name": "Marchionini",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Gary J Marchionini",
   "pi_email_addr": "march@ils.unc.edu",
   "nsf_id": "000323065",
   "pi_start_date": "2012-08-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Lee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Lee",
   "pi_email_addr": "callee@ils.unc.edu",
   "nsf_id": "000592776",
   "pi_start_date": "2012-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993360",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 49954.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Science is built on observations.&nbsp; If our observational data is bad, we cannot trust the results that come from these observations.&nbsp; Data quality is an assertion about data properties, typically assumed within a context defined by a collection that holds the data.&nbsp; The assertion is made by the creator of the data.&nbsp; The collection context includes both metadata that describe provenance and representation information, and procedures that are able to parse and manipulate the data.&nbsp; However data quality from the perspective of users is defined based on the data properties that are required for use within their scientific research.&nbsp; The user believes data is of high quality when assertions about compliance can be shown to their research requirements.&nbsp; Digital data can accumulate rich contextual and derivative data as it is collected, analyzed, used, and reused, and planning for the management of this history requires new kinds of tools, techniques, standards, workflows, and attitudes.&nbsp; As science and industry recognize the need for digital curation, scientists and information professionals recognize that access and use of data depend on trust in the accuracy and veracity of data.&nbsp; In all data sets trust and reuse depend on accessible context and metadata that make explicit provenance, precision, and other traces of the datum and data life cycle.&nbsp;&nbsp; Poor data quality can be worse than missing data because it can waste resources and lead to faulty ideas and solutions, or at minimum challenges trust in the results and implications drawn from the data.&nbsp; Improvement in data quality can thus have significant benefits.&nbsp;&nbsp;</p>\n<p>&nbsp;The National Science Foundation sponsored a workshop on September 10 and 11, 2012, in Arlington, Virginia on &ldquo;Curating for Quality: Ensuring Data Quality to Enable New Science.&rdquo;&nbsp; Individuals from government, academic and industry settings gathered to discuss issues, strategies and priorities for ensuring quality in collections of data.&nbsp; This workshop aimed to define data quality research issues and potential solutions. The workshop objectives were organized into four clusters:&nbsp; (1) data quality criteria and contexts, (2) human and institutional factors, (3) tools for effective and painless curation, and (4) metrics for data quality.</p>\n<p>&nbsp;In addition to the contributed papers and breakout discussions, the workshop also yielded insights on several high-level themes.&nbsp; These include:</p>\n<ul>\n<li>There are many perspectives on quality: quality assessment will depend on whether the agent making the assessment is a data curator, curation professional, or end user (including algorithms); </li>\n<li>quality can be assessed based on&nbsp; technical, logical, semantic, or cultural criteria and issues; and </li>\n<li>quality be assessed at different granularities that include&nbsp; data item, data set, data collection, or disciplinary repository.&nbsp; </li>\n</ul>\n<p>&nbsp;This implies that assessments of quality must carefully specify underlying assumptions and conditions under which the assessment was made. There is movement toward more nuanced models of data control and curation such as maturity levels (matrix models) that consider levels of stability and quality across different criteria and perspectives.</p>\n<p>&nbsp;The workshop identified several key challenges that include:</p>\n<ul>\n<li>selection strategies&mdash;how to determine what is most valuable to preserve </li>\n<li>how much and which context to include&mdash;how to insure that data is interpretable and usable in the future, what metadata to include</li>\n<li>tools and techniques to support painless curation&mdash;creating and sharing tools and techniques that apply across disciplines </li>\n<li>cost and accountability models&mdash;how to balance selection, context decisions with cost const...",
  "por_txt_cntn": "\nScience is built on observations.  If our observational data is bad, we cannot trust the results that come from these observations.  Data quality is an assertion about data properties, typically assumed within a context defined by a collection that holds the data.  The assertion is made by the creator of the data.  The collection context includes both metadata that describe provenance and representation information, and procedures that are able to parse and manipulate the data.  However data quality from the perspective of users is defined based on the data properties that are required for use within their scientific research.  The user believes data is of high quality when assertions about compliance can be shown to their research requirements.  Digital data can accumulate rich contextual and derivative data as it is collected, analyzed, used, and reused, and planning for the management of this history requires new kinds of tools, techniques, standards, workflows, and attitudes.  As science and industry recognize the need for digital curation, scientists and information professionals recognize that access and use of data depend on trust in the accuracy and veracity of data.  In all data sets trust and reuse depend on accessible context and metadata that make explicit provenance, precision, and other traces of the datum and data life cycle.   Poor data quality can be worse than missing data because it can waste resources and lead to faulty ideas and solutions, or at minimum challenges trust in the results and implications drawn from the data.  Improvement in data quality can thus have significant benefits.  \n\n The National Science Foundation sponsored a workshop on September 10 and 11, 2012, in Arlington, Virginia on \"Curating for Quality: Ensuring Data Quality to Enable New Science.\"  Individuals from government, academic and industry settings gathered to discuss issues, strategies and priorities for ensuring quality in collections of data.  This workshop aimed to define data quality research issues and potential solutions. The workshop objectives were organized into four clusters:  (1) data quality criteria and contexts, (2) human and institutional factors, (3) tools for effective and painless curation, and (4) metrics for data quality.\n\n In addition to the contributed papers and breakout discussions, the workshop also yielded insights on several high-level themes.  These include:\n\nThere are many perspectives on quality: quality assessment will depend on whether the agent making the assessment is a data curator, curation professional, or end user (including algorithms); \nquality can be assessed based on  technical, logical, semantic, or cultural criteria and issues; and \nquality be assessed at different granularities that include  data item, data set, data collection, or disciplinary repository.  \n\n\n This implies that assessments of quality must carefully specify underlying assumptions and conditions under which the assessment was made. There is movement toward more nuanced models of data control and curation such as maturity levels (matrix models) that consider levels of stability and quality across different criteria and perspectives.\n\n The workshop identified several key challenges that include:\n\nselection strategies&mdash;how to determine what is most valuable to preserve \nhow much and which context to include&mdash;how to insure that data is interpretable and usable in the future, what metadata to include\ntools and techniques to support painless curation&mdash;creating and sharing tools and techniques that apply across disciplines \ncost and accountability models&mdash;how to balance selection, context decisions with cost constraints.\n\n\n \n\n\t\t\t\t\tLast Modified: 09/30/2013\n\n\t\t\t\t\tSubmitted by: Gary J Marchionini"
 }
}