{
 "awd_id": "1244695",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:  Automatically Annotated Repository of Digital Video and Audio Resources Community  (AARDVARC)",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2012-09-15",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 86253.0,
 "awd_amount": 86253.0,
 "awd_min_amd_letter_date": "2012-09-23",
 "awd_max_amd_letter_date": "2012-09-23",
 "awd_abstract_narration": "Audio and video data from understudied languages is useful to linguists, anthropologists, educators, and computer scientists interested in visual action extraction, speech technology or software localization. Terabytes of such data exist, having been collected in large amounts by documentary linguists since the advent of easy digital recording via handheld devices.  As records of vanishing languages and cultures, video and audio records are far richer and more captivating than paper records, but they need to be indexed and transcribed so that they reach their full potential as research tools.  The current project, AARDVARC (Automatically Annotated Repository of Digital Audio and Video Resources Community) will address the problem of untranscribed, and therefore unavailable, documentation of understudied languages by building an interdisciplinary community of linguists, anthropologists, and computer scientists to share knowledge and collaborate on the specification of a repository and suite of tools to facilitate transcription.  It will provide for two workshops and a symposium to design a \"take one leave one\" repository and to explore recent advances in speech and video processing that will allow anthropologists and linguists to break the 'transcription bottleneck' for language data. Even partial automation will greatly facilitate the work of the analyst and dramatically increase the amount of transcribed audio and video available to researchers in multiple disciplines.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Douglas",
   "pi_last_name": "Whalen",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Douglas H Whalen",
   "pi_email_addr": "whalen@haskins.yale.edu",
   "nsf_id": "000542916",
   "pi_start_date": "2012-09-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "CUNY Graduate School University Center",
  "inst_street_address": "365 5TH AVE STE 8113",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128177526",
  "inst_zip_code": "100164309",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "QVW9TFAZJFE7"
 },
 "perf_inst": {
  "perf_inst_name": "CUNY Graduate School University Center",
  "perf_str_addr": "365 Fifth Avenue",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100164309",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806800",
   "pgm_ele_name": "Data Infrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 86253.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Language is our most human characteristic, and the wide variety of languages spoken in the world today (approximately 7000 of them) shows how flexible we are at adapting our language to our surroundings.&nbsp; Many of these languages are falling silent as speakers switch to larger, world-wide languages, but their structure holds great insight into how we use and think in language.&nbsp; Linguists are documenting these languages, and those records are valuable, but they are not as accessible as we would like them to be.&nbsp; The three workshops and two symposia held under this grant brought together researchers from various disciplines (linguistics, anthropology, speech technology and archiving) to find better ways of using modern speech technology to unlock the potential of these archives.&nbsp; Speech technology has improved greatly in recent years, and it is now being used to automatically analyze large collections of speech.&nbsp; The extensions to smaller, less well described languages still presents a challenge, but progress is being made there as well.&nbsp; Experts in these fields presented the latest tools and techniques at these meetings, and linguists and anthropologists reported on their use of those tools.&nbsp; Some of those efforts resulted in success, with automatic speech methods greatly reducing the time it takes for some linguistic transcription work.&nbsp; Other efforts met further challenges, as with the video analysis of interactive conversations, where the speaker of interest was often not as well framed as necessary for a good outcome.&nbsp; The workshops succeeded in their main goal, which was to create teams to apply for new grants (one of which has already been funded).&nbsp; The symposia succeeded in informing audiences at two national conferences of the possibilities for labor-saving use of technology.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/19/2015<br>\n\t\t\t\t\tModified by: Douglas&nbsp;H&nbsp;Whalen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLanguage is our most human characteristic, and the wide variety of languages spoken in the world today (approximately 7000 of them) shows how flexible we are at adapting our language to our surroundings.  Many of these languages are falling silent as speakers switch to larger, world-wide languages, but their structure holds great insight into how we use and think in language.  Linguists are documenting these languages, and those records are valuable, but they are not as accessible as we would like them to be.  The three workshops and two symposia held under this grant brought together researchers from various disciplines (linguistics, anthropology, speech technology and archiving) to find better ways of using modern speech technology to unlock the potential of these archives.  Speech technology has improved greatly in recent years, and it is now being used to automatically analyze large collections of speech.  The extensions to smaller, less well described languages still presents a challenge, but progress is being made there as well.  Experts in these fields presented the latest tools and techniques at these meetings, and linguists and anthropologists reported on their use of those tools.  Some of those efforts resulted in success, with automatic speech methods greatly reducing the time it takes for some linguistic transcription work.  Other efforts met further challenges, as with the video analysis of interactive conversations, where the speaker of interest was often not as well framed as necessary for a good outcome.  The workshops succeeded in their main goal, which was to create teams to apply for new grants (one of which has already been funded).  The symposia succeeded in informing audiences at two national conferences of the possibilities for labor-saving use of technology.\n\n \n\n\t\t\t\t\tLast Modified: 05/19/2015\n\n\t\t\t\t\tSubmitted by: Douglas H Whalen"
 }
}