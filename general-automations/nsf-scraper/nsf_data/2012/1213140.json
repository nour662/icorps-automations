{
 "awd_id": "1213140",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Large: Collaborative Research: Enabling Privacy-Utility Trade-Offs in Pervasive Computing Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2015-09-30",
 "tot_intn_awd_amt": 162999.0,
 "awd_amount": 162999.0,
 "awd_min_amd_letter_date": "2012-08-07",
 "awd_max_amd_letter_date": "2012-08-07",
 "awd_abstract_narration": "Pervasive computing, such as sensors in smartphones, buildings, automobiles and cities, result in increased sharing of sensor data, whether initiated by users or by other authorities such as service providers, government entities, interest groups, and individuals. Embedded in this data is information which others, even using sophisticated data mining algorithms, can fuse to construct a virtual biography of our activities, revealing private behaviors and lifestyle patterns. Researchers in this project are devising computational methods to let users exercise privacy control over their personal sensory data that is shared.\r\n\r\nIntellectual Merit: The project is developing a user-configurable cryptographically-secure ?privacy shield? to run on smartphones and act upon sensor information flowing to other users, apps, and services. To make privacy understandable, the user is presented with a higher level abstraction for expressing privacy and sharing in terms of rich inferences and contexts drawn from sensor measurements. The user can designate some inferences and contexts as private.  To provide privacy while ensuring the quality of service provided by the recipients of the sensory information, the system also incorporates algorithms which, over time, learn a personalized model of the privacy risk from sharing an inference. The theoretical concepts and the system realization are being validated via user studies in mobile health and personal sensing. \r\n\r\nBroader Impacts: By providing better understanding of the behavioral privacy problem and risks inherent in sharing seemingly innocuous data, results from this project will lead to a more educated and informed citizenry, regulators, and policy makers, and provide effective tools for privacy management to those who share sensory information.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mani",
   "pi_last_name": "Srivastava",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Mani B Srivastava",
   "pi_email_addr": "mbs@ucla.edu",
   "nsf_id": "000468770",
   "pi_start_date": "2012-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Pottie",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory J Pottie",
   "pi_email_addr": "pottie@ee.ucla.edu",
   "nsf_id": "000168026",
   "pi_start_date": "2012-08-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Millstein",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Todd D Millstein",
   "pi_email_addr": "todd@cs.ucla.edu",
   "nsf_id": "000229495",
   "pi_start_date": "2012-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951594",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 162999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-5dd1b50d-027a-6c43-5a00-86c71ab0cbb1\"> </span></p>\n<p dir=\"ltr\"><span>Sensors have become ubiquitous and our society now depends on information provided by sensors for decision-making at multiple scales. &nbsp;This seed project sought to explore the difficult and unique privacy challenges that are presented by these sensors. Sensors produce time series of measurements whose privacy implications are hard for individuals to comprehend as a rich array of inferences about personal behaviors can be made from those measurements, particularly when combined by information on the web and advanced analytics algorithms.</span></p>\n<p dir=\"ltr\"><span>The project focused on the privacy problem in the context of sensors that are embedded in smartphones or wirelessly connected to them. The researchers developed a novel formulation of the problem where the privacy risks of sensory data are made visible to the individual in terms of semantically meaningful inferences about their context and behaviors that are possible. The individual can designate those inferences as being in a &ldquo;whitelist&rdquo; or a &ldquo;blacklist&rdquo;. For example, instead of simply notifying the user that an application is seeking access to data from the heart rate sensor, the project&rsquo;s approach makes the user aware of the inferences that can be made from such data - both obvious ones (e.g. calories burns) and less obvious ones (e.g. existence of a cardiac disease) - and letting them express control over information sharing.</span></p>\n<p dir=\"ltr\"><span>During the project, the UCLA researchers made several contributions. Firstly, they developed a theoretical framework for reasoning about sensor data where the utility and privacy risks of sensor data being shared is expressed in terms of aforementioned white- and black- lists of inferences. Working with collaborators at UCLA they developed an information theoretic framework where the feasibility of achieving a specific combination of privacy and utility can be reasoned about, and a scheme for obfuscating the sensor data to achieve it constructed.</span></p>\n<p dir=\"ltr\"><span>Secondly, they implemented their ideas in the form of ipShield software, an enhancement to the popular Android mobile operating system. The ipShield software, which has been released in open-source form on GitHub (see </span><a href=\"http://nesl.github.io/ipShield/\"><span>http://nesl.github.io/ipShield/</span></a><span>), provide users with several benefits. Android does not require applications to seek user permission to access many forms of sensor data that present immense privacy risks. To mitigate that ipShield intercepts requests for sensor data from applications, and present them to the user via a dashboard in terms of inferences that can be made by various applications. Furthermore, ipShield lets users flag inferences as being private at the granularity of an application and in a context-sensitive manner. E.g., the user can designate accelerometer data to be shared with high-fidelity with an application monitoring her medical condition but with low-fidelity or not at all with the Uber or Facebook app.</span></p>\n<p dir=\"ltr\"><span>Thirdly, together with collaborators from the University of Memphis, the researchers investigated the privacy issues around sensor data from the perspective of users - particularly users participating in medical studies that make use of wearable sensors for 24x7 monitoring of activity and health status. &nbsp;For example, the researchers found a significant difference in privacy ratings when participants have a personal stake in the data, and yet ensuring that participants have a stake in the data requires them to actively collect all sensor data (e.g., via a study) they are asked to rate. The researchers conducted a survey of 57 participants to better understand their perception of user burden and privacy risks ...",
  "por_txt_cntn": "\n \nSensors have become ubiquitous and our society now depends on information provided by sensors for decision-making at multiple scales.  This seed project sought to explore the difficult and unique privacy challenges that are presented by these sensors. Sensors produce time series of measurements whose privacy implications are hard for individuals to comprehend as a rich array of inferences about personal behaviors can be made from those measurements, particularly when combined by information on the web and advanced analytics algorithms.\nThe project focused on the privacy problem in the context of sensors that are embedded in smartphones or wirelessly connected to them. The researchers developed a novel formulation of the problem where the privacy risks of sensory data are made visible to the individual in terms of semantically meaningful inferences about their context and behaviors that are possible. The individual can designate those inferences as being in a \"whitelist\" or a \"blacklist\". For example, instead of simply notifying the user that an application is seeking access to data from the heart rate sensor, the project\u00c6s approach makes the user aware of the inferences that can be made from such data - both obvious ones (e.g. calories burns) and less obvious ones (e.g. existence of a cardiac disease) - and letting them express control over information sharing.\nDuring the project, the UCLA researchers made several contributions. Firstly, they developed a theoretical framework for reasoning about sensor data where the utility and privacy risks of sensor data being shared is expressed in terms of aforementioned white- and black- lists of inferences. Working with collaborators at UCLA they developed an information theoretic framework where the feasibility of achieving a specific combination of privacy and utility can be reasoned about, and a scheme for obfuscating the sensor data to achieve it constructed.\nSecondly, they implemented their ideas in the form of ipShield software, an enhancement to the popular Android mobile operating system. The ipShield software, which has been released in open-source form on GitHub (see http://nesl.github.io/ipShield/), provide users with several benefits. Android does not require applications to seek user permission to access many forms of sensor data that present immense privacy risks. To mitigate that ipShield intercepts requests for sensor data from applications, and present them to the user via a dashboard in terms of inferences that can be made by various applications. Furthermore, ipShield lets users flag inferences as being private at the granularity of an application and in a context-sensitive manner. E.g., the user can designate accelerometer data to be shared with high-fidelity with an application monitoring her medical condition but with low-fidelity or not at all with the Uber or Facebook app.\nThirdly, together with collaborators from the University of Memphis, the researchers investigated the privacy issues around sensor data from the perspective of users - particularly users participating in medical studies that make use of wearable sensors for 24x7 monitoring of activity and health status.  For example, the researchers found a significant difference in privacy ratings when participants have a personal stake in the data, and yet ensuring that participants have a stake in the data requires them to actively collect all sensor data (e.g., via a study) they are asked to rate. The researchers conducted a survey of 57 participants to better understand their perception of user burden and privacy risks associated with collecting and sharing GPS, activity, physiology, and audio data  and found that users asked for 19% more in compensation to carry a smartwatch with inertial sensors, an additional 45% increase to wear a chest band with ECG and respiration sensors, and 10% more to allow audio recording.\nLastly, to further understand the privacy risks posed by seemingly innocuous sensors th..."
 }
}