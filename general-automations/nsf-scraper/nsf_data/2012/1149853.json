{
 "awd_id": "1149853",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Representing, Understanding, and Enhancing Scenes at the Internet-Scale",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-01-15",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 486222.0,
 "awd_amount": 486222.0,
 "awd_min_amd_letter_date": "2012-01-13",
 "awd_max_amd_letter_date": "2016-02-10",
 "awd_abstract_narration": "CAREER: Understanding, Representing, and Enhancing Scenes at the Internet-scale\r\n\r\nPhotography has an enormous impact on society -- it is our primary visual history and a medium for storytelling, entertainment, and art. But our visual world is extraordinarily complex which makes it difficult for computer vision to understand photos and for computer graphics to synthesize visual content. However, the emergence of Internet-scale photo collections in recent years enables new research directions. We use scene-based representations to leverage Internet-scale data. Scenes (places or environments) are the context in which all other visual phenomena exist and it seems possible to brute-force the space of scenes -- with millions of scenes, we find qualitatively similar scenes and create massively data-driven algorithms with capabilities that are complementary to typical bottom-up graphics and vision pipelines. The underlying principle of this study is that joint investigations of scene representations and large image databases will advance the state-of-the-art in graphics and vision. \r\n\r\nFirst, we are investigating detail synthesis tasks which alleviate camera shake, motion blur, defocus, atmospheric scattering, or low resolution. Scene representations are robust enough to find matching scenes in Internet-scale photo collections even in the presence of dramatic blurring. These matching scenes provide a context-specific statistical model which can be used to insert convincing texture and object detail. Second, we are studying attribute-based representations of scenes. We use crowdsourcing to discover attributes and build large databases for the community. Attributes are a powerful intermediate representation for the next generation of big data imaging research which can have broad societal impact through applications such as robotics, security, assistance to vision-impaired, and vehicle safety. The investigators also are developing a new introductory course for Brown students to explore big data computing across scientific disciplines and are creating an online community for visual computing education to benefit students interested in photography and programming.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Hays",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "James H Hays",
   "pi_email_addr": "hays@gatech.edu",
   "nsf_id": "000561883",
   "pi_start_date": "2012-01-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Brown University",
  "inst_street_address": "1 PROSPECT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PROVIDENCE",
  "inst_state_code": "RI",
  "inst_state_name": "Rhode Island",
  "inst_phone_num": "4018632777",
  "inst_zip_code": "029129100",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "RI01",
  "org_lgl_bus_name": "BROWN UNIVERSITY",
  "org_prnt_uei_num": "E3FDXZ6TBHW3",
  "org_uei_num": "E3FDXZ6TBHW3"
 },
 "perf_inst": {
  "perf_inst_name": "Brown University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "RI",
  "perf_st_name": "Rhode Island",
  "perf_zip_code": "029129002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "RI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 90757.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 93955.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 97219.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 100466.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 0.0
  }
 ],
 "por": null
}