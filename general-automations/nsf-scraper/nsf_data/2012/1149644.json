{
 "awd_id": "1149644",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER:  Harnessing Hybrid Computing Resources in PetaScale Computing and Beyond",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alan Sussman",
 "awd_eff_date": "2012-08-15",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 468182.0,
 "awd_amount": 458130.0,
 "awd_min_amd_letter_date": "2012-07-06",
 "awd_max_amd_letter_date": "2018-09-21",
 "awd_abstract_narration": "Future ExaScale computing systems are expected to exceed a hundred-thousand nodes and contain a rich mix of heterogeneous computing resources created by coupling multi-core processors with accelerator processors. However, current applications are not yet able to exploit more than a few tens of thousands of these nodes, or effectively manage this heterogeneous mix of resources to balance workloads. Moreover, this heterogeneous mixture of resources in hybrid or multi-paradigm systems presents programmers with new, but challenging opportunities for exploiting the various types of parallelism within algorithms. This CAREER research will formulate an inclusive hierarchical framework for performance modeling and analysis of hybrid computing systems that include multi-core processors and accelerators. The framework includes a coarse-grained model for rapid assessment of the fitness match between the application and the hybrid system and a fine-grained model for predicting execution time and workload balance analysis. These models will be useful for researchers and scientists developing, optimizing, and maintaining scientific codes. \r\n\r\nThe research project includes forming a taxonomy of application and architecture characteristics through a rigorous study of application optimization and execution on multi-core and accelerator processors. The study focuses on the inter-node parallelism of the applications across a mix of heterogeneous nodes and the intra-node parallelism on the multi-paradigm nodes. These hybrid system studies elucidate the application and architecture characteristics included in the coarse and fine-grained models of the hierarchical framework. The optimization methods (resource ratio optimization, load balancing and memory management) and the model framework are qualitatively assessed for other application domains not included in this study. The project also transitions this knowledge into educational modules suitable for classroom use in the undergraduate and graduate curriculum.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Melissa",
   "pi_last_name": "Smith",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Melissa C Smith",
   "pi_email_addr": "smithmc@clemson.edu",
   "nsf_id": "000266788",
   "pi_start_date": "2012-07-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Clemson University",
  "inst_street_address": "201 SIKES HALL",
  "inst_street_address_2": "",
  "inst_city_name": "CLEMSON",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8646562424",
  "inst_zip_code": "296340001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "SC03",
  "org_lgl_bus_name": "CLEMSON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "H2BMNX7DSKU8"
 },
 "perf_inst": {
  "perf_inst_name": "Clemson University",
  "perf_str_addr": "300 Brackett Hall",
  "perf_city_name": "Clemson",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "296340001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "SC03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "104500",
   "pgm_ele_name": "CAREER: FACULTY EARLY CAR DEV"
  },
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "736100",
   "pgm_ele_name": "EDUCATION AND WORKFORCE"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9151",
   "pgm_ref_txt": "EPSCOR OUTREACH"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 449166.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8962.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-922a6b7f-7fff-bcbc-8d7e-bdcbc6f187b4\"> </span></p>\n<p dir=\"ltr\"><span>In this research, we develop a body of work that performs runtime prediction and architecture selection for high-performance computing (HPC) systems. This work can be broadly divided into two sub-areas. The first focuses on modeling communication and computation times along with other metrics that describe an HPC system and uses this data to build a prediction algorithm for the optimal runtime and hardware configuration. The second area aims to solve a similar problem by leveraging modern machine learning tools for batch-job based HPC systems, i.e. systems that use a static configuration of hardware for each different instance of an experiment. This innovation marks a step towards a more cost-effective HPC workflow that utilizes information from data to produce accurate results while reducing the burden of low-level tuning for the end-user of the HPC system.</span></p>\n<p dir=\"ltr\"><span>A taxonomy for heterogeneous computing was developed for application development and education and as a basis for the Tesseract system modeling framework (Figure 1). Case studies were performed on Synchronous Iterative Algorithms (SIAs) using Spiking Neural Networks (SNN) and a Non-Linear Anisotropic Diffusion Filter. Tesseract is a framework that enables researchers in HPC to analyze how a particular distributed algorithm would perform on a supercomputing cluster. The two major goals of the project were to predict the runtime and the optimal hardware configuration given a distributed computing algorithm. The Synchronous Iterative GPGPU Execution (SIGE) model was developed that describes the execution flow of SIAs and assists with performance analysis on multi-GPGPU systems (Figure 2). Another tool called X-MAP was developed to profile the hardware counters and the associated metadata to predict the optimal hardware configuration.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Ongoing research initiated under this award aims to address the coupled goals of predicting the optimal execution time and optimal hardware configuration by developing a unified prediction interface that is algorithm and data-agnostic by leveraging advances in Machine Learning.&nbsp; The Query Based Engine (Q.B.E) shown in Figure 3 has the following main objectives:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Given profiling data from an algorithm, predict the optimal runtime by combining outputs from different models trained on the profiling data.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Given training metadata such as node configuration, GPU model, number of CPUs, etc. predict the best node configuration for the given data.&nbsp;</span></p>\n</li>\n</ul>\n<p dir=\"ltr\"><span>These objectives transform into two specific query modes in the engine: (1) produce a continuous value that corresponds to predicted runtime and (2) produce a human-readable description that corresponds to the optimal hardware configuration given the profiling data. Q.B.E. performance prediction results for the SNN Wilson Model are shown in Figure 4.&nbsp; The columns \"gt\", \"MLP\", \"Elastic\", and \"Ridge\" stand for the ground truth, MLP prediction, ElasticNet prediction, and Ridge Regression prediction respectively. It is evident from the graph that the proposed models very closely predict the actual observed run time of the algorithm on a distributed system. Additionally, the system is able to make correct run time predictions with a very low amount of data, which shows it?s capabilities to predict runtimes with very little prerequisite knowledge of the algorithm.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2019<br>\n\t\t\t\t\tModified by: Melissa&nbsp;C&nbsp;Smith</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037087371_QBE--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037087371_QBE--rgov-800width.jpg\" title=\"Q.B.E\"><img src=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037087371_QBE--rgov-66x44.jpg\" alt=\"Q.B.E\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 3. Q.B.E flow diagram</div>\n<div class=\"imageCredit\">M. Smith</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Melissa&nbsp;C&nbsp;Smith</div>\n<div class=\"imageTitle\">Q.B.E</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036967860_SIGE--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036967860_SIGE--rgov-800width.jpg\" title=\"SIGE\"><img src=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036967860_SIGE--rgov-66x44.jpg\" alt=\"SIGE\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 2. SIGE</div>\n<div class=\"imageCredit\">M. Smith</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Melissa&nbsp;C&nbsp;Smith</div>\n<div class=\"imageTitle\">SIGE</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036842173_Tesseract--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036842173_Tesseract--rgov-800width.jpg\" title=\"Tesseract\"><img src=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575036842173_Tesseract--rgov-66x44.jpg\" alt=\"Tesseract\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 1. Tesseract</div>\n<div class=\"imageCredit\">M. Smith</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Melissa&nbsp;C&nbsp;Smith</div>\n<div class=\"imageTitle\">Tesseract</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037208197_Results--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037208197_Results--rgov-800width.jpg\" title=\"Q.B.E. Results\"><img src=\"/por/images/Reports/POR/2019/1149644/1149644_10187452_1575037208197_Results--rgov-66x44.jpg\" alt=\"Q.B.E. Results\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Figure 4. Q.B.E. Predicted vs actual computation times on a SNN Wilson Model</div>\n<div class=\"imageCredit\">M. Smith</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Melissa&nbsp;C&nbsp;Smith</div>\n<div class=\"imageTitle\">Q.B.E. Results</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nIn this research, we develop a body of work that performs runtime prediction and architecture selection for high-performance computing (HPC) systems. This work can be broadly divided into two sub-areas. The first focuses on modeling communication and computation times along with other metrics that describe an HPC system and uses this data to build a prediction algorithm for the optimal runtime and hardware configuration. The second area aims to solve a similar problem by leveraging modern machine learning tools for batch-job based HPC systems, i.e. systems that use a static configuration of hardware for each different instance of an experiment. This innovation marks a step towards a more cost-effective HPC workflow that utilizes information from data to produce accurate results while reducing the burden of low-level tuning for the end-user of the HPC system.\nA taxonomy for heterogeneous computing was developed for application development and education and as a basis for the Tesseract system modeling framework (Figure 1). Case studies were performed on Synchronous Iterative Algorithms (SIAs) using Spiking Neural Networks (SNN) and a Non-Linear Anisotropic Diffusion Filter. Tesseract is a framework that enables researchers in HPC to analyze how a particular distributed algorithm would perform on a supercomputing cluster. The two major goals of the project were to predict the runtime and the optimal hardware configuration given a distributed computing algorithm. The Synchronous Iterative GPGPU Execution (SIGE) model was developed that describes the execution flow of SIAs and assists with performance analysis on multi-GPGPU systems (Figure 2). Another tool called X-MAP was developed to profile the hardware counters and the associated metadata to predict the optimal hardware configuration. \nOngoing research initiated under this award aims to address the coupled goals of predicting the optimal execution time and optimal hardware configuration by developing a unified prediction interface that is algorithm and data-agnostic by leveraging advances in Machine Learning.  The Query Based Engine (Q.B.E) shown in Figure 3 has the following main objectives:\n\n\nGiven profiling data from an algorithm, predict the optimal runtime by combining outputs from different models trained on the profiling data.\n\n\nGiven training metadata such as node configuration, GPU model, number of CPUs, etc. predict the best node configuration for the given data. \n\n\nThese objectives transform into two specific query modes in the engine: (1) produce a continuous value that corresponds to predicted runtime and (2) produce a human-readable description that corresponds to the optimal hardware configuration given the profiling data. Q.B.E. performance prediction results for the SNN Wilson Model are shown in Figure 4.  The columns \"gt\", \"MLP\", \"Elastic\", and \"Ridge\" stand for the ground truth, MLP prediction, ElasticNet prediction, and Ridge Regression prediction respectively. It is evident from the graph that the proposed models very closely predict the actual observed run time of the algorithm on a distributed system. Additionally, the system is able to make correct run time predictions with a very low amount of data, which shows it?s capabilities to predict runtimes with very little prerequisite knowledge of the algorithm.\n\n\t\t\t\t\tLast Modified: 11/29/2019\n\n\t\t\t\t\tSubmitted by: Melissa C Smith"
 }
}