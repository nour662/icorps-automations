{
 "awd_id": "1148346",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SI2-SSI: Collaborative Research: A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rajiv Ramnath",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 926667.0,
 "awd_amount": 926667.0,
 "awd_min_amd_letter_date": "2012-05-29",
 "awd_max_amd_letter_date": "2012-05-29",
 "awd_abstract_narration": "Parallel computing has entered the mainstream with increasingly large multicore processors and powerful accelerator devices. These compute engines, coupled with tighter integration of faster interconnection fabrics, are drivers for the next-generation high end computing (HEC) machines. However, the computing potential of HEC machines is delivered only through productive parallel program development and efficient parallel execution. This project enables application developers to improve performance on future HEC machines for their scientific and engineering processes. This project challenges the current model for parallel application development via \"black box\" tools and services. Instead, the project offers an open, transparent software infrastructure -- a Glass Box system -- for creating and tuning large-scale, parallel applications.  `Opening up' the tools and services used to create and evaluate peta- and exa-scale codes involves developing interfaces and methods that make tool-internal information and available for new performance management services that improve developer productivity and code efficiency.\r\n\r\nThe project will explore the information that can be shared 'across the software stack'.  Methods will be developed for analyzing program information, performance data and tool knowledge. The resulting Glass Box system will allow developers to better assess the performance of their parallel codes.  Tool creators can use the performance data to create new analysis and optimization techniques. System developers can also better manage multicore and machine resources at runtime, using JIT compilation and binary code editing to exploit the evolving hardware.  Working with the `Keeneland' NSF Track II machine and our industry partners, the project will create new performance monitoring tools, compiler methods and system-level resource management techniques. The effort is driven by the large-scale codes running on today's petascale machines.  Its broader impact is derived from the interactions with technology developers and application scientists as well as from its base in three universities with diverse student populations.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Allen",
   "pi_last_name": "Malony",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Allen D Malony",
   "pi_email_addr": "malony@cs.uoregon.edu",
   "nsf_id": "000467668",
   "pi_start_date": "2012-05-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sameer",
   "pi_last_name": "Shende",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Sameer S Shende",
   "pi_email_addr": "sameer@cs.uoregon.edu",
   "nsf_id": "000433859",
   "pi_start_date": "2012-05-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Oregon Eugene",
  "inst_street_address": "1776 E 13TH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "EUGENE",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5413465131",
  "inst_zip_code": "974031905",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "UNIVERSITY OF OREGON",
  "org_prnt_uei_num": "Z3FGN9MF92U2",
  "org_uei_num": "Z3FGN9MF92U2"
 },
 "perf_inst": {
  "perf_inst_name": "University of Oregon Eugene",
  "perf_str_addr": "",
  "perf_city_name": "Eugene",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "974033237",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8009",
   "pgm_ref_txt": "Scientifc Software Integration"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 926667.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Body\">The goals of our project - \"A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain\" (Glassbox) - were to investigate methods, techniques, heuristics and software solutions for encouraging the information sharing between different phases of computer software construction, execution, and evaluation. In the first phase of a typical High Performance Computing (HPC) software workflow, the software is designed, written as a <em>program</em> in a human-readable programming language, and subsequently <em>compiled</em> (by another program called a <em>compiler</em>) into a format that a computer can execute.&nbsp; The program is then <em>executed</em> by the computing system, using one or more runtime libraries that provide support for parallel execution, enabling multiple computer processors and/or many computers to work in concert towards completion of the program.&nbsp; In a third phase, the software execution is measured, analyzed and otherwise <em>evaluated</em> by one or more computer programs in an effort to improve performance, accuracy, energy efficiency, or some other metric.&nbsp; These phases are repeated as necessary to improve, maintain or modify the program.&nbsp; Rather than treat these phases as \"black box\" components with discrete inputs and outputs but no sharing of information, we investigated ways to increase information-sharing between these phases.</p>\n<p class=\"Body\">&nbsp;</p>\n<p class=\"Body\">Together with our colleagues at the University of Houston and the Georgia Institute of Technology, we have designed, integrated, evaluated and revised methods for providing interactions between the different phases of software construction. We have investigated a tighter integration the compilation process and the evaluation process, using the compiler to add extra instructions to the program to aid in measurement and analysis, and by providing analysis results in the form of <em>feedback</em> to the compiler to assist the code transformation and optimization stages in the compiler. We have developed greater integration between the runtime libraries that enable parallel execution and the performance measurement in order to provide an enhanced measurement context. This enhanced context assists a human or automated analyst in understanding the performance problems that may exist in the program as it is currently constructed.&nbsp; We have developed a software framework that for some cases, uses these performance measurements at execution time to help <em>guide</em> the application in order to make the program run faster and/or with better energy efficiency.&nbsp; We have published our results in academic journals and presented our results at related conferences, and provided all of our supporting software, including our source code, through publicly available websites.&nbsp; Our software is pre-installed on many HPC resources around the world, and our techniques have also been presented in tutorials and training sessions, encouraging computational scientists to adapt our ideas and potentially improve the performance of their scientific simulations.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/31/2016<br>\n\t\t\t\t\tModified by: Allen&nbsp;D&nbsp;Malony</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The goals of our project - \"A Glass Box Approach to Enabling Open, Deep Interactions in the HPC Toolchain\" (Glassbox) - were to investigate methods, techniques, heuristics and software solutions for encouraging the information sharing between different phases of computer software construction, execution, and evaluation. In the first phase of a typical High Performance Computing (HPC) software workflow, the software is designed, written as a program in a human-readable programming language, and subsequently compiled (by another program called a compiler) into a format that a computer can execute.  The program is then executed by the computing system, using one or more runtime libraries that provide support for parallel execution, enabling multiple computer processors and/or many computers to work in concert towards completion of the program.  In a third phase, the software execution is measured, analyzed and otherwise evaluated by one or more computer programs in an effort to improve performance, accuracy, energy efficiency, or some other metric.  These phases are repeated as necessary to improve, maintain or modify the program.  Rather than treat these phases as \"black box\" components with discrete inputs and outputs but no sharing of information, we investigated ways to increase information-sharing between these phases.\n \nTogether with our colleagues at the University of Houston and the Georgia Institute of Technology, we have designed, integrated, evaluated and revised methods for providing interactions between the different phases of software construction. We have investigated a tighter integration the compilation process and the evaluation process, using the compiler to add extra instructions to the program to aid in measurement and analysis, and by providing analysis results in the form of feedback to the compiler to assist the code transformation and optimization stages in the compiler. We have developed greater integration between the runtime libraries that enable parallel execution and the performance measurement in order to provide an enhanced measurement context. This enhanced context assists a human or automated analyst in understanding the performance problems that may exist in the program as it is currently constructed.  We have developed a software framework that for some cases, uses these performance measurements at execution time to help guide the application in order to make the program run faster and/or with better energy efficiency.  We have published our results in academic journals and presented our results at related conferences, and provided all of our supporting software, including our source code, through publicly available websites.  Our software is pre-installed on many HPC resources around the world, and our techniques have also been presented in tutorials and training sessions, encouraging computational scientists to adapt our ideas and potentially improve the performance of their scientific simulations.\n\n\t\t\t\t\tLast Modified: 08/31/2016\n\n\t\t\t\t\tSubmitted by: Allen D Malony"
 }
}