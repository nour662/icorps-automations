{
 "awd_id": "1148698",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "THE OPEN SCIENCE GRID  The Next Five Years: Distributed High Throughput Computing for the Nation's Scientists, Researchers, Educators, and Students",
 "cfda_num": "47.049",
 "org_code": "03010000",
 "po_phone": "7032928235",
 "po_email": "bmihaila@nsf.gov",
 "po_sign_block_name": "Bogdan Mihaila",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 18750000.0,
 "awd_amount": 24378518.0,
 "awd_min_amd_letter_date": "2012-05-16",
 "awd_max_amd_letter_date": "2021-04-20",
 "awd_abstract_narration": "The basic idea of Grid Computing is to utilize available CPU cycles and storage of many computer systems across a worldwide network so that they can function as a flexible, pervasive, and inexpensive accessible pool that could be harnessed by an individual, accredited user, similar to the way power companies and their users share the electrical grid. Grid computing can be viewed as a service for sharing computer power and data storage capacity over the Internet, simply and transparently, without having to consider where the computational facilities are located.\r\n\r\nExperiments at major centralized experimental facilities such as the Large Hadron Collider (LHC) require large amounts of computation and storage and involve hundreds of experimenters using computational facilities all over the world. These features are well suited to the capabilities of grid computing. Grid computing developments occurred in parallel to the development of the LHC experiments. The Open Science Grid (OSG) is the major facilitator of Grid Computing in the U.S. Researchers subsequently developed these ideas in many other exciting ways, producing for example, in addition to OSG,  large-scale federated systems (TeraGrid, EGEE, Earth System Grid) that provide not just computing power, but also data and software on demand. Standards organizations then developed relevant standards that led to possible interoperability of Grids. Grids define and provide a set of standard protocols, middleware, toolkits, and services built on top of these protocols. Interoperability and security are the primary concerns for the Grid infrastructure as resources may come from different administrative domains, which have both global and local usage policies, different hardware and software configurations and platforms, and vary in availability and capacity.\r\n\r\nThe Open Science Grid is a distributed computing infrastructure for large-scale scientific research. The OSG contributes to the Worldwide LHC Computing Grid as the shared distributed computing facility used by the US ATLAS and US CMS experiments. The OSG is built and operated by a consortium of 90 U.S. universities, national laboratories, scientific collaborations and software developers. It is supported by the National Science Foundation and the US Department of Energy Office of Science. The OSG supports not only physics experiments but also researchers from other fields, including astrophysics, bioinformatics and computer science. Currently the OSG has more than 60 sites in the US and five sites in Brazil, Taiwan and Mexico, supported by the host countries.\r\n \r\nAll LHC computing and storage sites in the US are members of the OSG and allow other scientific collaborations using the OSG to opportunistically use available resources. The OSG collaborates with the Enabling Grids for E-sciencE project in Europe to provide interoperating federated infrastructures which can be used transparently by the LHC experiments' software. The Large Hadron Collider, located 330 feet below the border of Switzer\u00acland and France, is the world's most powerful particle accelerator. Its very-high-energy particle collisions may yield extraordinary discoveries about the nature of the physical universe. Beyond revealing a new world of unknown particles, the LHC experiments could explain why those particles exist and behave as they do. The LHC experiments could uncover the origins of mass, shed light on dark matter, expose hidden symmetries of the universe, and possibly find extra dimensions of space. \r\n\r\nThe LHC accelerates hair-thin beams of particles to a whisker below the speed of light. Thousands of powerful superconducting magnets steer the beams around the LHC's 16.5-mile-long ring. At four points the particles collide in the hearts of the main experiments, known by their acronyms: ALICE, ATLAS, CMS and LHCb. In the data from these high-energy collisions scientists search for the tracks of particles whose existence could transform our understanding of the universe. More than 10,000 scientists, engineers and students from almost 60 nations on six continents contribute to the LHC, which is headquartered at the CERN laboratory in Geneva, Switzerland. About 1,700 come from universities and laboratories in the United States. Federal funding for US contributions to the LHC is provided by the US Department of Energy's Office of Science and the National Science Foundation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "PHY",
 "org_div_long_name": "Division Of Physics",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Miron",
   "pi_last_name": "Livny",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Miron Livny",
   "pi_email_addr": "miron@cs.wisc.edu",
   "nsf_id": "000340383",
   "pi_start_date": "2012-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Ruth",
   "pi_last_name": "Pordes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruth Pordes",
   "pi_email_addr": "ruth@fnal.gov",
   "nsf_id": "000101580",
   "pi_start_date": "2012-05-16",
   "pi_end_date": "2017-05-30"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Frank",
   "pi_last_name": "Wuerthwein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frank Wuerthwein",
   "pi_email_addr": "fkw@ucsd.edu",
   "nsf_id": "000144338",
   "pi_start_date": "2012-05-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Ernst",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Ernst",
   "pi_email_addr": "mernst@bnl.gov",
   "nsf_id": "000588705",
   "pi_start_date": "2012-05-16",
   "pi_end_date": "2017-05-30"
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 West Dayton Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "724400",
   "pgm_ele_name": "COMPUTATIONAL PHYSICS"
  },
  {
   "pgm_ele_code": "724500",
   "pgm_ele_name": "PHYSICS GRID COMPUTING"
  },
  {
   "pgm_ele_code": "747600",
   "pgm_ele_name": "XD-Extreme Digital"
  },
  {
   "pgm_ele_code": "755300",
   "pgm_ele_name": "PHYSICS AT THE INFO FRONTIER"
  },
  {
   "pgm_ele_code": "802700",
   "pgm_ele_name": "Cybersecurity Innovation"
  },
  {
   "pgm_ele_code": "808000",
   "pgm_ele_name": "Campus Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7569",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE/SCIENCE"
  },
  {
   "pgm_ref_code": "8084",
   "pgm_ref_txt": "CDS&E"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 3750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 3750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 3750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 4750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 2750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 3649980.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1000000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 978538.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-082bb3ec-7fff-aa45-9b64-d2bc1341ae8e\"> </span></p>\n<p><span id=\"docs-internal-guid-ec6206d0-7fff-33ea-dec8-0d4aa281a5a1\">&nbsp;</span></p>\n<p dir=\"ltr\"><span>The \"OSG-N5Y\" project advanced the state of the art of distributed High Throughput Computing through the design, deployment, and operation of a national fabric of services. These services, operated by </span><span>the OSG Consortium, allowed researchers with High Throughput workloads to effectively harness computing capacity located at US universities, federally funded laboratories, and international organizations.</span></p>\n<p dir=\"ltr\"><span>High Throughput Computing (HTC) is an approach to empowering researchers with computing capacity via running large numbers of independent batch jobs. Each \"job\" is typically a single computer program in a particular configuration, provided with input data and</span><span> producing output data. The philosophy behind HTC is, given a collection of computers, to maximize the number of outputs generated over time. Then distributed HTC (dHTC), which the OSG-N5Y project specialized in, applies the HTC principles over a large number of independent sources of computing capacity. By advancing the state of the art of dHTC, the OSG-N5Y project enabled researchers from a broad set of science domains to advance their science; by leveraging the OSG services, researchers were able to execute billions of jobs that utilized over 7 billion hours of computing capacity provided by organizations around the nation.</span></p>\n<p dir=\"ltr\"><span>The OSG-N5Y project provided effort to the OSG Consortium, which is governed by a Council, managed by an Executive Director, and has a Technical Director for long-term technology evolutions. The Council is responsible for governance and seting the directions of the Consortium. OSG-N5Y's contributions drove the Consortium for nearly a decade (during early years, providing the majority of the staffing and support for the Technical Director) and put it on a more sustainable footing; by the end of the OSG-N5Y project, multiple collaborating projects joined forces to contribute effort to sustain the Consortium's activities.</span></p>\n<p dir=\"ltr\"><span>The OSG-N5Y project provided services that can broadly be grouped into three categories:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Network-facing services</span><span>: These are persistent processes, operated by OSG-N5Y staff, that are exposed to the Internet and provide functionality to authorized entities. A simple use case might be a web server that serves a website; a typical OSG-N5Y network-facing service would be the \"Compute Entrypoint (CE) Collector\", which acts as a phonebook or directory service for CEs contributing capacity to the OSG fabric of services.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Software services</span><span>: The OSG-N5Y project curated software and produced the OSG Software Stack, which is an integrated, tested, documented, and supported set of externally produced computer software applications used by organzations that form&nbsp; the OSG Consortium to operate their own network-facing services.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Intellectual engagement</span><span>: The OSG facilitation team is devoted to empower users to harness the potential of dHTC to advance scientific discovery. This dedicated effort results in a better-trained software &amp; engineering community in the US, ready to leverage distributed resources for their research challenges. The Technology Investigations team collaborated with external software providers to mature and evolve technologies to meet the requirements for functionality and dependability of the OSG Software Stack.</span></p>\n</li>\n</ul>\n<p dir=\"ltr\"><span>Each of the service types has resulted in a long-lasting outcome, whether it's the network-facing services the OSG Consortium continues to serve the broad S&amp;W community, the OSG Software Stack used by science communities worldwide, or the improvements to users' and organizations' computational prowess from the engagements with researchers.</span></p>\n<p dir=\"ltr\"><span>Specific services developed by the OSG-N5Y project and remaining in use as outcomes today include:</span></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Open Science Compute Federation</span><span> (OSCF): A set of network-facing services which enable independent sites - typically universities or laboratories - to join their local computers to large \"resource pools\". These resource pools could then execute researchers' computing workloads at a global scale.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Open Science Data Federation</span><span> (OSDF): A set of services which could export scientific data to the Internet and a distribution layer, located at strategic network points around the US, that helps scale the delivery of files to resources in the OSCF.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Open Science Pool</span><span> (OSPool): A resource pool, composed of capacity donated by campuses in the US, open to use by any federally funded researcher and their collaborators.</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>OSG-Connect</span><span>: A service providing researchers with a location to place their high throughput workloads. OSG-Connect manages the workloads as ensebles of batch jobs which are executed on the OSPool.</span></p>\n</li>\n</ul>\n<p dir=\"ltr\"><span>Finally, in terms of broader impact, the project offered the annual OSG User School at the University of Wisconsin-Madison. The OSG User School is a week-long training event that covers the basic concepts of HTC and dHTC; typically, 40-60 students (a mixture of undergraduates, graduates, and cyberinfrastructure staff) attended each event. As a result, over the decade of the project, hundreds of students received in-depth training on advanced computing topics contributing to the development of the nation's workforce.</span></p>\n<p dir=\"ltr\"><span>Through its sustained services to researchers engaged in Open Science, advancement of the OSG Consortium, and facilitation of new compute intensive science, the OSG-N5Y project has a long-lasting impact on the nation's advanced cyberinfrastructure and thus on the national research capability.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/30/2022<br>\n\t\t\t\t\tModified by: Miron&nbsp;Livny</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \n\n \nThe \"OSG-N5Y\" project advanced the state of the art of distributed High Throughput Computing through the design, deployment, and operation of a national fabric of services. These services, operated by the OSG Consortium, allowed researchers with High Throughput workloads to effectively harness computing capacity located at US universities, federally funded laboratories, and international organizations.\nHigh Throughput Computing (HTC) is an approach to empowering researchers with computing capacity via running large numbers of independent batch jobs. Each \"job\" is typically a single computer program in a particular configuration, provided with input data and producing output data. The philosophy behind HTC is, given a collection of computers, to maximize the number of outputs generated over time. Then distributed HTC (dHTC), which the OSG-N5Y project specialized in, applies the HTC principles over a large number of independent sources of computing capacity. By advancing the state of the art of dHTC, the OSG-N5Y project enabled researchers from a broad set of science domains to advance their science; by leveraging the OSG services, researchers were able to execute billions of jobs that utilized over 7 billion hours of computing capacity provided by organizations around the nation.\nThe OSG-N5Y project provided effort to the OSG Consortium, which is governed by a Council, managed by an Executive Director, and has a Technical Director for long-term technology evolutions. The Council is responsible for governance and seting the directions of the Consortium. OSG-N5Y's contributions drove the Consortium for nearly a decade (during early years, providing the majority of the staffing and support for the Technical Director) and put it on a more sustainable footing; by the end of the OSG-N5Y project, multiple collaborating projects joined forces to contribute effort to sustain the Consortium's activities.\nThe OSG-N5Y project provided services that can broadly be grouped into three categories:\n\n\nNetwork-facing services: These are persistent processes, operated by OSG-N5Y staff, that are exposed to the Internet and provide functionality to authorized entities. A simple use case might be a web server that serves a website; a typical OSG-N5Y network-facing service would be the \"Compute Entrypoint (CE) Collector\", which acts as a phonebook or directory service for CEs contributing capacity to the OSG fabric of services.\n\n\nSoftware services: The OSG-N5Y project curated software and produced the OSG Software Stack, which is an integrated, tested, documented, and supported set of externally produced computer software applications used by organzations that form  the OSG Consortium to operate their own network-facing services.\n\n\nIntellectual engagement: The OSG facilitation team is devoted to empower users to harness the potential of dHTC to advance scientific discovery. This dedicated effort results in a better-trained software &amp; engineering community in the US, ready to leverage distributed resources for their research challenges. The Technology Investigations team collaborated with external software providers to mature and evolve technologies to meet the requirements for functionality and dependability of the OSG Software Stack.\n\n\nEach of the service types has resulted in a long-lasting outcome, whether it's the network-facing services the OSG Consortium continues to serve the broad S&amp;W community, the OSG Software Stack used by science communities worldwide, or the improvements to users' and organizations' computational prowess from the engagements with researchers.\nSpecific services developed by the OSG-N5Y project and remaining in use as outcomes today include:\n\n\nOpen Science Compute Federation (OSCF): A set of network-facing services which enable independent sites - typically universities or laboratories - to join their local computers to large \"resource pools\". These resource pools could then execute researchers' computing workloads at a global scale.\n\n\nOpen Science Data Federation (OSDF): A set of services which could export scientific data to the Internet and a distribution layer, located at strategic network points around the US, that helps scale the delivery of files to resources in the OSCF.\n\n\nOpen Science Pool (OSPool): A resource pool, composed of capacity donated by campuses in the US, open to use by any federally funded researcher and their collaborators.\n\n\nOSG-Connect: A service providing researchers with a location to place their high throughput workloads. OSG-Connect manages the workloads as ensebles of batch jobs which are executed on the OSPool.\n\n\nFinally, in terms of broader impact, the project offered the annual OSG User School at the University of Wisconsin-Madison. The OSG User School is a week-long training event that covers the basic concepts of HTC and dHTC; typically, 40-60 students (a mixture of undergraduates, graduates, and cyberinfrastructure staff) attended each event. As a result, over the decade of the project, hundreds of students received in-depth training on advanced computing topics contributing to the development of the nation's workforce.\nThrough its sustained services to researchers engaged in Open Science, advancement of the OSG Consortium, and facilitation of new compute intensive science, the OSG-N5Y project has a long-lasting impact on the nation's advanced cyberinfrastructure and thus on the national research capability.\n\n \n\n\t\t\t\t\tLast Modified: 09/30/2022\n\n\t\t\t\t\tSubmitted by: Miron Livny"
 }
}