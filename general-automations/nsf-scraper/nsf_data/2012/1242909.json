{
 "awd_id": "1242909",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER Collaborative Research:  Bringing Together Computational and Linguistic Methods to Extract 'Dark' Geosciences Data for the EarthCube Framework",
 "cfda_num": "47.050",
 "org_code": "06030000",
 "po_phone": "7032927792",
 "po_email": "bransom@nsf.gov",
 "po_sign_block_name": "Barbara Ransom",
 "awd_eff_date": "2012-07-15",
 "awd_exp_date": "2013-06-30",
 "tot_intn_awd_amt": 69452.0,
 "awd_amount": 69452.0,
 "awd_min_amd_letter_date": "2012-07-03",
 "awd_max_amd_letter_date": "2012-07-03",
 "awd_abstract_narration": "A large percentage of vaulable geoscience data is based on the analysis of discrete samples and is collected manually (e.g., paleontological collections, structural/tectonic data, petrographic/mineralogic data, economic data, geochemical measurements, rock mechanics, etc.) Often, these data are reported only in tables in the published literature or in .pdf or spreadsheets on individual investigator websites.  Commonly these data are not registerd on or entered into standardized, publicly accessible databases.  As a result, for this data to be discovered and used/reused, researchers or other interested parties must manually comb through the text, figures, and appendices of journal articles or websites of individual investigators, sometimes having to sift through raw experimental data. This process is extremely time intensive and slows down the time needed to make scientific discoveries or allow verification of research results.  As a result the vast amount of surface earth geoscience data is currently inaccessible. This inaccessible data is termed \"Dark Data\".  This EAGER combines the expertise of top-notch computer scientists and geoscientists whose goal is to create a search algorithm to bring this dark data to light in a way that will enable the next generation of integrative geoscience research.  The approach will involved development of an innovative search engine \"crawler\" that will comb the geoscience literature and bring dark data to light from the text and figures in this corpus. The cyberinfrastructure tool being developed will be able to interpret the semantics of English text and the concepts of geoscience. The tool will be piloted by examining entries on the Macrostrat database, a structured spatial database of  lithologic and geochronologic information, and then employing a geoscience ontology by means of the Hazy framework for information extraction.  Questions to be addressed will be to find out to what extent dark data is presently accessible and if it can be extracted and placed into an accessible format and repository where it can be discovered by web services or other search engines.  Broader impacts of the work include training of graduate students and increasing the infrastructure for science through the development of a new and much needed data search tool.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "GEO",
 "org_dir_long_name": "Directorate for Geosciences",
 "div_abbr": "EAR",
 "org_div_long_name": "Division Of Earth Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Jenkins",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher J Jenkins",
   "pi_email_addr": "chris.jenkins@colorado.edu",
   "nsf_id": "000493812",
   "pi_start_date": "2012-07-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado at Boulder",
  "perf_str_addr": "3100 Marine Street, Room 481",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803031058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "807400",
   "pgm_ele_name": "EarthCube"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "0000",
   "pgm_ref_txt": "UNASSIGNED"
  },
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "OTHR",
   "pgm_ref_txt": "OTHER RESEARCH OR EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 69452.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was focused on the 'dark data' &ndash; hidden, unused data &ndash; that exist in the sciences. It is also focused especially on ocean geological data.</p>\n<p>To locate the hidden data we can use word searches. With some special research techniques exact matches are not necessary, just parts of words or the concepts. This is done by linking the words in semantic 'meaning-nets' and by recognizing the parts (stems) of the words.</p>\n<p>Our part of the project compiled vocabularies of rock, sediment, soil, ice terms which could be used in this way. The vocabularies were written so computer programs could pick up the terms and quickly scan the web, documents, databases for hidden data resources on specialist topics such as sub-seabed ice (hydrates), or minerals.</p>\n<p>Although we worked with other high-throughput computing labs, we also applied these techniques ourselves to mapping the coastlines, harbours, reefs of all the shorelines around the world from many different hidden data resources. A surprising, huge amount of data was recovered which will be combined with existing data to map the difficult ocean zone in the surf, too shallow for ships, and muddy from rivers.</p>\n<p>Post-award the software and vocabularies will continue to be available for other groups to pick up, use and even improve. This is one way the 'dark data' problem will be reduced.</p>\n<p>CJ</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2013<br>\n\t\t\t\t\tModified by: Christopher&nbsp;J&nbsp;Jenkins</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was focused on the 'dark data' &ndash; hidden, unused data &ndash; that exist in the sciences. It is also focused especially on ocean geological data.\n\nTo locate the hidden data we can use word searches. With some special research techniques exact matches are not necessary, just parts of words or the concepts. This is done by linking the words in semantic 'meaning-nets' and by recognizing the parts (stems) of the words.\n\nOur part of the project compiled vocabularies of rock, sediment, soil, ice terms which could be used in this way. The vocabularies were written so computer programs could pick up the terms and quickly scan the web, documents, databases for hidden data resources on specialist topics such as sub-seabed ice (hydrates), or minerals.\n\nAlthough we worked with other high-throughput computing labs, we also applied these techniques ourselves to mapping the coastlines, harbours, reefs of all the shorelines around the world from many different hidden data resources. A surprising, huge amount of data was recovered which will be combined with existing data to map the difficult ocean zone in the surf, too shallow for ships, and muddy from rivers.\n\nPost-award the software and vocabularies will continue to be available for other groups to pick up, use and even improve. This is one way the 'dark data' problem will be reduced.\n\nCJ\n\n \n\n\t\t\t\t\tLast Modified: 08/30/2013\n\n\t\t\t\t\tSubmitted by: Christopher J Jenkins"
 }
}