{
 "awd_id": "1217748",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Scalable Trace-Based Tools for In-Situ Data Analysis of HPC Applications (ScalaJack)",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 457395.0,
 "awd_amount": 457395.0,
 "awd_min_amd_letter_date": "2012-05-16",
 "awd_max_amd_letter_date": "2012-07-30",
 "awd_abstract_narration": "Production codes on supercomputers are struggling to remain scalable\r\neach time the processor core count increases by a factor of 10, even\r\nthough they run efficiently at smaller scale.\r\nBut root cause diagnosis fails at petascale since (1) symptoms of\r\nperformance problems can be subtle, (2) only few\r\nmetrics can be efficiently collected and (3) tools can only feasibly record\r\na small subset of even these metrics.\r\n\r\nThis work addresses these problems by creating a framework that allows\r\napplication developers to focus on data analysis that drives customized\r\ndata extraction combined with on-the-fly analysis specifically geared\r\nto their individual problems.  This is accomplished by combining trace\r\nanalysis and in-situ data analysis techniques at runtime, thereby\r\nlifting data reduction to a new level where it IS analysis. With this\r\napproach, modular measurement and analysis components are combined to\r\nselectively extract representative data from production codes in a\r\nproblem-specific manner, which enables root cause analysis.\r\n\r\nThe work demonstrates the feasibility of customized data\r\nextraction and analysis at scale for root cause analysis on current\r\nand forthcoming multi-petascale supercomputers.  It thus contributes\r\nto sustain scalable scientific computing into the future up to the largest\r\nscales.  Results of this work will be contributed as open-source code\r\nto the research community and beyond as done, allowing other groups to\r\nnot only build tools on top of our framework but also contribute their\r\nown components.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Frank",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frank Mueller",
   "pi_email_addr": "fmuelle@ncsu.edu",
   "nsf_id": "000484031",
   "pi_start_date": "2012-05-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958206",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 457395.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This decade is projected to usher in the period of exascale computing<br />with the advent of systems with more than 500 million concurrent<br />tasks.&nbsp; Harnessing such hardware with coordinated computing in<br />software poses significant challenges.&nbsp; Production codes tend to face<br />scalability problems, but current performance analysis tools seldom<br />operate effectively beyond 10,000 cores.<br /><br />We have combined trace analysis and in-situ data analysis techniques<br />at runtime.&nbsp; Application developers thus create ultra low-overhead<br />measurement and analysis facilities on-the-fly, customized for the<br />performance problems of particular application.&nbsp; We developed an<br />analysis generator called ScalaJack for this purpose. We further<br />extended the underlying ScalaTrace infrastructure to exploit<br />statistical clustering techniques so that only one trace per cluster<br />needs to be generated, yet such traces can be replayed by all nodes of<br />a cluster without loss of events and using correct communication and<br />I/O parameters for trace events. We showed that overheads for tracing<br />remain extremely low even for large numbers of nodes, which is a<br />significant improvement over past trace consolidation, which imposed<br />exponentially increasing overheads as the number of nodes increases.</p>\n<p>Results of this work were contributed as open-source code to the<br />research community. Pluggable, customization analysis not only allows<br />other groups to build tools on top of our approach but to also<br />contribute components to our framework that will be shared in a<br />repository hosted by us.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/08/2017<br>\n\t\t\t\t\tModified by: Frank&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis decade is projected to usher in the period of exascale computing\nwith the advent of systems with more than 500 million concurrent\ntasks.  Harnessing such hardware with coordinated computing in\nsoftware poses significant challenges.  Production codes tend to face\nscalability problems, but current performance analysis tools seldom\noperate effectively beyond 10,000 cores.\n\nWe have combined trace analysis and in-situ data analysis techniques\nat runtime.  Application developers thus create ultra low-overhead\nmeasurement and analysis facilities on-the-fly, customized for the\nperformance problems of particular application.  We developed an\nanalysis generator called ScalaJack for this purpose. We further\nextended the underlying ScalaTrace infrastructure to exploit\nstatistical clustering techniques so that only one trace per cluster\nneeds to be generated, yet such traces can be replayed by all nodes of\na cluster without loss of events and using correct communication and\nI/O parameters for trace events. We showed that overheads for tracing\nremain extremely low even for large numbers of nodes, which is a\nsignificant improvement over past trace consolidation, which imposed\nexponentially increasing overheads as the number of nodes increases.\n\nResults of this work were contributed as open-source code to the\nresearch community. Pluggable, customization analysis not only allows\nother groups to build tools on top of our approach but to also\ncontribute components to our framework that will be shared in a\nrepository hosted by us.\n\n\t\t\t\t\tLast Modified: 06/08/2017\n\n\t\t\t\t\tSubmitted by: Frank Mueller"
 }
}