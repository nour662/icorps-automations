{
 "awd_id": "1209007",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  Estimation, Inference, and Computation for Finite Nonparametric Mixtures",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2012-08-15",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 23463.0,
 "awd_amount": 23463.0,
 "awd_min_amd_letter_date": "2012-08-13",
 "awd_max_amd_letter_date": "2014-08-13",
 "awd_abstract_narration": "This project aims to develop theory and methods for estimation of the functional components and weights in the nonparametric multivariate finite mixtures. These mixtures only assume that the components are drawn from some family of multivariate density functions without any parametric specification. The investigators, who are already active in this emerging area of research, adapt a number of estimation methods that are known from finite parametric mixture theory to the nonparametric context. The PI and the co-PI propose a number of practically feasible and fast algorithms that can be used to compute the resulting estimators in practice. Finally, both investigators show how to obtain large-sample asymptotic results for the proposed estimators. \r\n\r\nFinite nonparametric mixtures of distributions can provide answers to many practically important questions. As an example, they can be used to help a physician in establishing the definitive diagnosis in case of a complex medical condition with a number of possible diagnoses. An example of such a situation is a patient with a possible heart attack where other differential diagnoses are also possible. Developmental psychology provides another useful example. Indeed, study of cognitive development in children, in particular identification of strategies used by children to accomplish various tasks, can also be modeled easily using these mixtures. This has important implication for developmental psychology, providing answers to many difficult questions faced by child psychologists while helping children mature and develop in an optimal way. The PI and the co-PI propose a number of efficient algorithms to estimate these mixtures and accomplish the practical tasks mentioned above. These algorithms will be publicly available and easy to use as part of the R software package called mixtools.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Hunter",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "David R Hunter",
   "pi_email_addr": "drh20@psu.edu",
   "nsf_id": "000418997",
   "pi_start_date": "2012-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 7623.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 7821.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 8019.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This collaborative project had two centers of operation:&nbsp; Purdue University and Pennsylvania State University.&nbsp; Dr. Michael Levine, who oversaw the Purdue side, is writing a separate report; my name is David Hunter and the current report summarizes the work that was carried out at Penn State under my supervision.&nbsp; Since I worked collaboratively with Dr. Levine, there is some overlap in the two report summaries.</p>\n<p>The broad goals of this project were to advance the theory and practical applications of algorithms whose purpose is to try to \"ungroup\" sets of observations that can be categorized into a fixed, known number of subgroups but whose measurements are mixed together without any category labels.&nbsp; The statistical framework that allows for this type of ungrouping, or estimation, is called a mixture model.&nbsp; What makes our work on mixture models unusual is the fact that we do not assume that the subgroups' data takes a particular mathematical form, called a parametric model.&nbsp; A more standard approach to estimation in such situations is to assume such a parametric model, quite often a well-known type of model known as a multivariate normal model&mdash;the multivariate equivalent of the bell curve.&nbsp; Yet such a parametric assumption is quite restrictive, and recent theoretical work has demonstrated that under certain simple conditions, the assumption is mathematically unnecessary.&nbsp; This is where our work comes in, as we have developed algorithms to accomplish the estimation needed to exploit this theory.&nbsp; I co-authored a 2011 article with Dr. Levine and another colleague, Dr. Didier Chauveau of the University of Orl&eacute;ans in France, demonstrating that a slight modification to our original algorithm gave the modified algorithm appealing theoretical properties without appreciably changing the resulting estimates.&nbsp; This was the background for our original proposal to extend the earlier work.</p>\n<p>Now that the project has concluded, we can sum up the results of the Penn State efforts largely by describing the work of a PhD student, Xiaotian Zhu, who was my advisee and whose graduate studies were partially supported by the grant.&nbsp; Dr. Zhu defended his dissertation and graduated in late 2014.</p>\n<p>Dr.Zhu produced several new theoretical results regarding the algorithm. In particular, he has proved rigorously for the first time that a solution to the main optimization problem must always exist, he has developed a novel reformulation of the original model that makes the estimation more natural, and he has strengthened the so-called \"ascent property\" of the algorithm that gives the basis for its desirable numerical behavior.</p>\n<p>In addition to the theoretical results, Dr. Zhu has combined the algorithm with a<br /> well-established statistical technique called Independent Components Analysis to produce a novel algorithm for estimating mixture models that is quite distinct from standard approaches.&nbsp; He has written software that implements this new algorithm and made it publicly available to users of the popular statistical computing language called R, which is itself an open-source and well-supported program that is very popular inside and outside the statistics community. Both R itself and Dr. Zhu's software, which is in the form of a package for R called \"icamix,\" may be obtained online from the Comprehensive R Archive Network, or CRAN.&nbsp; The techniques we have developed for mixture model estimation, sometimes called model-based clustering or unsupervised learning, may thus be used by scientists in multiple fields.</p>\n<p>In addition to the icamix software, Dr. Zhu and I have co-authored two manuscripts that arose from his doctoral dissertation that are under review for publication in peer-reviewed journals as of October 2015.&nbsp; I also co-authored a journal article with Dr. Chauveau and Dr. ...",
  "por_txt_cntn": "\nThis collaborative project had two centers of operation:  Purdue University and Pennsylvania State University.  Dr. Michael Levine, who oversaw the Purdue side, is writing a separate report; my name is David Hunter and the current report summarizes the work that was carried out at Penn State under my supervision.  Since I worked collaboratively with Dr. Levine, there is some overlap in the two report summaries.\n\nThe broad goals of this project were to advance the theory and practical applications of algorithms whose purpose is to try to \"ungroup\" sets of observations that can be categorized into a fixed, known number of subgroups but whose measurements are mixed together without any category labels.  The statistical framework that allows for this type of ungrouping, or estimation, is called a mixture model.  What makes our work on mixture models unusual is the fact that we do not assume that the subgroups' data takes a particular mathematical form, called a parametric model.  A more standard approach to estimation in such situations is to assume such a parametric model, quite often a well-known type of model known as a multivariate normal model&mdash;the multivariate equivalent of the bell curve.  Yet such a parametric assumption is quite restrictive, and recent theoretical work has demonstrated that under certain simple conditions, the assumption is mathematically unnecessary.  This is where our work comes in, as we have developed algorithms to accomplish the estimation needed to exploit this theory.  I co-authored a 2011 article with Dr. Levine and another colleague, Dr. Didier Chauveau of the University of Orl&eacute;ans in France, demonstrating that a slight modification to our original algorithm gave the modified algorithm appealing theoretical properties without appreciably changing the resulting estimates.  This was the background for our original proposal to extend the earlier work.\n\nNow that the project has concluded, we can sum up the results of the Penn State efforts largely by describing the work of a PhD student, Xiaotian Zhu, who was my advisee and whose graduate studies were partially supported by the grant.  Dr. Zhu defended his dissertation and graduated in late 2014.\n\nDr.Zhu produced several new theoretical results regarding the algorithm. In particular, he has proved rigorously for the first time that a solution to the main optimization problem must always exist, he has developed a novel reformulation of the original model that makes the estimation more natural, and he has strengthened the so-called \"ascent property\" of the algorithm that gives the basis for its desirable numerical behavior.\n\nIn addition to the theoretical results, Dr. Zhu has combined the algorithm with a\n well-established statistical technique called Independent Components Analysis to produce a novel algorithm for estimating mixture models that is quite distinct from standard approaches.  He has written software that implements this new algorithm and made it publicly available to users of the popular statistical computing language called R, which is itself an open-source and well-supported program that is very popular inside and outside the statistics community. Both R itself and Dr. Zhu's software, which is in the form of a package for R called \"icamix,\" may be obtained online from the Comprehensive R Archive Network, or CRAN.  The techniques we have developed for mixture model estimation, sometimes called model-based clustering or unsupervised learning, may thus be used by scientists in multiple fields.\n\nIn addition to the icamix software, Dr. Zhu and I have co-authored two manuscripts that arose from his doctoral dissertation that are under review for publication in peer-reviewed journals as of October 2015.  I also co-authored a journal article with Dr. Chauveau and Dr. Levine about the work we have done in this area; that article appears in the 2015 volume of the journal Statistics Surveys.    Finally, I have given several talks at c..."
 }
}