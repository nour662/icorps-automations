{
 "awd_id": "1243737",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  Transforming 2D Video into an Interactive 3D Viewing Experience",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rathindra DasGupta",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2012-06-19",
 "awd_max_amd_letter_date": "2012-06-19",
 "awd_abstract_narration": "A novel method is developed to convert long video sequences from a single camera into 3D panoramic visualizations.  The approach holds the promise to work at near real-time on a laptop. The 3D content allows users to change view angles and it also supports panoramic views. The system has two real-time software components: (1) the image matcher that generates multi-view panoramic mosaics from 2D image sequences; and (2) the 3D renderer that can provide an end user a virtual fly-through or walk-through of a scene using commercially available 3D displays. The approach promises real-time 3D visualization for a broad range of camera types (high end/low end color, IR, even gamma-ray/r-ray imaging), camera motions (linear, circular), motion platforms (airborne, ground vehicle, hand-held), and scene distances (from a few inches to thousand feet). \r\n\r\nThis technology has matured from research into environmental monitoring, security and defense applications, where video was captured from a single camera on board an aircraft or ground vehicle. The system is able to produce 3D visualizations of the videos for further video data analysis, scene understanding and scientific discovery. The technology has applications not only in defense and environmental monitoring, but also in entertainment, medical imaging, inspection, real estate and land survey/development industries.  There are many 3D ready devices, from TVs, to smartphones in the consumer market already. But the content is still missing. To address this unmet need, the team is building a smartphone application to enable user-generated 3D content, without requiring a 3D camera.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhigang",
   "pi_last_name": "Zhu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhigang Zhu",
   "pi_email_addr": "zzhu@ccny.cuny.edu",
   "nsf_id": "000095302",
   "pi_start_date": "2012-06-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "CUNY City College",
  "inst_street_address": "160 CONVENT AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2126505418",
  "inst_zip_code": "100319101",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "RESEARCH FOUNDATION OF THE CITY UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "L952KGDMSLV5"
 },
 "perf_inst": {
  "perf_inst_name": "CUNY City College",
  "perf_str_addr": "160 CONVENT AVE",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100319101",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the course of our research in the past decade under the support of several NSF grants, a novel method has been developed to convert long video sequences from a single camera into 3D panoramic visualizations with our unique approach, called <em>Parallel Ray Interpolation for Stereo Mosaicing (PRISM)</em>. With this I-Corps project, our goals are to learn the type of business models that fit with our technologies and capabilities, make a go/no-go decision for technology transfer, and/or to make changes to the technological and business plans.</p>\n<p class=\"float-left\">The I-Corps project has great impact in equipping both the PI and the entrepreneurial lead (EL) with entrepreneurship mindset for bringing NSF sponsored research out of the lab. The experience of getting out of the building to talk with customers led us to meet with over 90 customers in 6 weeks. This was obviously made very plausible by the NSF I-Corps support, and through the mentoring and feedback from the teaching team and peers, we received a very rich learning experience. The EL has been better prepared to start up a business and implement entrepreneurship plans, and the PI has obtained significant hands-on experience in advising and training more students in entrepreneurship through both his senior design course and extracurricular advising.</p>\n<p>The impact of the project on technology transfer is the core of the project. The impact is not just transfer of the proposed technology of 3D viewing experience - the PRISM technology, but also other related technologies, most of them developed under NSF grant supports. In fact evaluating the readiness of the proposed technology for commercialization and making a go/no-go decision is the major goal of the program. Right now we will wait the best time for our interactive 3D viewing technology (you may watch a <a title=\"PRISM Technology\" href=\"http://www.youtube.com/watch?v=0ZF9g0GM9FY&amp;feature=youtu.be\">YouTube video</a> for the PRISM technology): we made a no go on a company, but we are open to working with partners and potentially licensing the technology. However, we have discovered that the interactive 3D experience with alternative perception for the blind &ndash; the VISTA technology, which is sponsored by an NSF EFRI grant, is more demanded by users and we have made a GO decision for this technology (please watch a <a title=\"VISTA Wearable\" href=\"http://ccvcl.org/~molina/vista/vista-prototype-pitch-aug-2013.m4v\">video </a>of the VISTA technology and a user test)<a title=\"VISTA Wearable\" href=\"http://ccvcl.org/~molina/vista/vista-prototype-pitch-aug-2013.m4v\"></a>. The EL has been starting to prepare a small business with other technological and business partners for related alternative 3D &ldquo;display&rdquo; technologies for visually impaired people, with PI as technical advisor.<strong>&nbsp;</strong></p>\n<p>This I-Corps effort has also started to produce profound impact for the PI and students in performing scientific research in the principal disciplinary fields of the project, which include machine intelligence, computer vision and human-computer interaction. The impact starts with problem definition, algorithm design principles, to usability study and customer analysis of a research project. We found that the customer discovery process was not only great at finding unaddressed customer needs, but also useful at identifying under researched problems that have real world applications. We will have a new set of perspectives to identify research problems and to perform scientific research for finding solutions.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/31/2013<br>\n\t\t\t\t\tModified by: Zhigang&nbsp;Zhu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></sp...",
  "por_txt_cntn": "\nOver the course of our research in the past decade under the support of several NSF grants, a novel method has been developed to convert long video sequences from a single camera into 3D panoramic visualizations with our unique approach, called Parallel Ray Interpolation for Stereo Mosaicing (PRISM). With this I-Corps project, our goals are to learn the type of business models that fit with our technologies and capabilities, make a go/no-go decision for technology transfer, and/or to make changes to the technological and business plans.\nThe I-Corps project has great impact in equipping both the PI and the entrepreneurial lead (EL) with entrepreneurship mindset for bringing NSF sponsored research out of the lab. The experience of getting out of the building to talk with customers led us to meet with over 90 customers in 6 weeks. This was obviously made very plausible by the NSF I-Corps support, and through the mentoring and feedback from the teaching team and peers, we received a very rich learning experience. The EL has been better prepared to start up a business and implement entrepreneurship plans, and the PI has obtained significant hands-on experience in advising and training more students in entrepreneurship through both his senior design course and extracurricular advising.\n\nThe impact of the project on technology transfer is the core of the project. The impact is not just transfer of the proposed technology of 3D viewing experience - the PRISM technology, but also other related technologies, most of them developed under NSF grant supports. In fact evaluating the readiness of the proposed technology for commercialization and making a go/no-go decision is the major goal of the program. Right now we will wait the best time for our interactive 3D viewing technology (you may watch a YouTube video for the PRISM technology): we made a no go on a company, but we are open to working with partners and potentially licensing the technology. However, we have discovered that the interactive 3D experience with alternative perception for the blind &ndash; the VISTA technology, which is sponsored by an NSF EFRI grant, is more demanded by users and we have made a GO decision for this technology (please watch a video of the VISTA technology and a user test). The EL has been starting to prepare a small business with other technological and business partners for related alternative 3D \"display\" technologies for visually impaired people, with PI as technical advisor. \n\nThis I-Corps effort has also started to produce profound impact for the PI and students in performing scientific research in the principal disciplinary fields of the project, which include machine intelligence, computer vision and human-computer interaction. The impact starts with problem definition, algorithm design principles, to usability study and customer analysis of a research project. We found that the customer discovery process was not only great at finding unaddressed customer needs, but also useful at identifying under researched problems that have real world applications. We will have a new set of perspectives to identify research problems and to perform scientific research for finding solutions.\n\n \n\n\t\t\t\t\tLast Modified: 10/31/2013\n\n\t\t\t\t\tSubmitted by: Zhigang Zhu"
 }
}