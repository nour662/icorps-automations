{
 "awd_id": "1208500",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI-Small: Spacial Primitives for Enabling Situated Human-Robot Interaction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 758000.0,
 "awd_min_amd_letter_date": "2012-07-17",
 "awd_max_amd_letter_date": "2017-06-07",
 "awd_abstract_narration": "To enable natural and productive human-robot interaction (HRI), a co-robot must both understand and control \"proxemics\" -- the social use of space -- in order to communicate in ways commonly used and understood by humans. This project focuses on answering the question: How do social (speech and gesture), environmental (loud noises and low lighting), and personal (hearing and visual impairments) factors influence positioning and communication between humans and co-robots, and how should a co-robot adjust its social behaviors to maximize human perception of its social signals?\r\n\r\nThe project will develop principled computational models for the recognition and control of proxemic co-robot behavior in HRI using both telepresence and autonomous co-robots. The research will establish a foundational component of HRI for co-robotics, with specific impact on special needs users in socially assistive contexts -- particularly the elderly, both aging in place and in institutions -- with the goal of mitigating isolation and depression, and encouraging exercise and socialization. \r\n\r\nBroader impacts: The work will inform robot design and control, and provide software and a corpus of public HRI data for use by researchers worldwide. Beyond robotics, the project promises to inform, validate, and extend longstanding research in the social sciences. This project also includes a strong public and K-12 outreach component consisting of weaving the HRI themes being developed into annual regional and international outreach events. The events feature large-scale open houses and educational workshops with interactive demonstrations and hands-on activities that highlight human factors in computational systems as an effective means of increasing interest in STEM-related activities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maja",
   "pi_last_name": "Matari\u0107",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maja J Matari\u0107",
   "pi_email_addr": "mataric@usc.edu",
   "nsf_id": "000410606",
   "pi_start_date": "2012-07-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Clifford",
   "pi_last_name": "Nass",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Clifford Nass",
   "pi_email_addr": "nass@stanford.edu",
   "nsf_id": "000192323",
   "pi_start_date": "2012-07-17",
   "pi_end_date": "2016-06-30"
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "837 Downey Way, STO 315",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 750000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Award Title</strong>: NRI-Small: Spatial Primitives for Enabling Situated Human-Robot Interaction</p>\n<p><strong>Federal Award ID</strong>: IIS-1208500</p>\n<p>As robots are being introduced into human environments, it is important to ensure that they both safe and easy to use, facilitating natural interactions.&nbsp; Sociable and socially assistive co-robots must therefore behave within the appropriate norms of human social behavior, including in how they use social space and communication: they must keep the appropriate social distance, speak and understand speech, and use and understand gesture. This NRI project addressed the following questions: how should social (auditory and visual), environmental (noisy and occluding), and personal (sensory impairment or sensitivity) stimuli influence the robot&rsquo;s behavior, and how should the robot continually adjust its communication behaviors to maximize human understanding and improve interaction.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual Merit:</strong></p>\n<p>The results of this work establish a part of the foundation for natural human-robot interaction, by enabling robots to determine how closely to approach, how to orient, and how loudly to speak, for ideal communication with people. To make the research results accessible, we produced a publicly available informative video summary:</p>\n<p><a href=\"https://www.youtube.com/channel/UCp36BiVXLqV9GiQ8e_mmSnQ\">https://www.youtube.com/channel/UCp36BiVXLqV9GiQ8e_mmSnQ</a></p>\n<p>&nbsp;</p>\n<p>The project also investigated how robots should perform different types of gestures. We studied the use of object-based gestures (e.g., round basketball) and use-based gestures (e.g., shooting a basket) to enable robots to communicate more clearly with people. This project also developed an approach to recognizing and identifying bullying behaviors in everyday environments, based on data collected from a large-scale public event. A robot capable of recognizing such behaviors can avoid situations that threaten its physical operations and integration into human environments.&nbsp; It can also provide assistance to people experiencing intimidation or other forms of social bullying. In particular, it can help children who are victims of bullying to learn how to respond as well as to help those who have bullying tendencies to recognize those, and understand why they are inappropriate.</p>\n<p>&nbsp;</p>\n<p>This project built on and contributed to multiple disciplines: contributions to robotics include both computing and engineering and open-source software, contributions to data science include novel methods, data sets, and models, and contributions to social and behavioral science include testing and validating longstanding theories on proxemics.</p>\n<p>&nbsp;</p>\n<p><strong>Broader Impacts:</strong></p>\n<p>This project trained a large group of students at all levels--from K-12 to university, to PhD and postdoc--on research methods and human participant experiments, allowing them to learn about interdisciplinary research while practicing their computing and engineering skills. &nbsp;The lead graduate student on this project started a company after finishing his PhD, transferring his expertise in software development for representing, recognizing, and generating social behaviors for autonomous sociable and socially assistive co-robots, leading to a continuing university-industry connection.</p>\n<p>&nbsp;</p>\n<p>This project included a spectrum of K-12 and public outreach activities as well. &nbsp;The project team worked with elementary and middle-school teachers to develop novel in-school and after-school science and engineering content modules. Delta Science kits were used to provide age-appropriate STEM modules as a precursor to learning robotics, Junior Botball robotics kits were used to teach students about robotics through writing code and understanding engineering principles, and Lego Education robotic kits were used to teach middle school students about robotics. &nbsp;Additionally, in each year of the project, the USC Robotics labs hosted the vastly popular USC Open House. This all-day event has been attended by up to 2,000 local K-12 students, teachers, and families. &nbsp;Additionally, our anti-bullying co-robot brought attention to bullying prevention for youth in a novel way that received both student and media attention.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/19/2018<br>\n\t\t\t\t\tModified by: Maja&nbsp;J&nbsp;Mataric</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994028638_Spatial1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994028638_Spatial1--rgov-800width.jpg\" title=\"Demonstrating the USC Viterbi Interaction Lab Anti-Bullying Robot\"><img src=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994028638_Spatial1--rgov-66x44.jpg\" alt=\"Demonstrating the USC Viterbi Interaction Lab Anti-Bullying Robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Interaction Lab Anti-Bullying Robot</div>\n<div class=\"imageCredit\">Michael Tsang</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Demonstrating the USC Viterbi Interaction Lab Anti-Bullying Robot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994375890_Spatial2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994375890_Spatial2--rgov-800width.jpg\" title=\"A Co-Robot That Knows Where to Stand to Hear and be Properly Heard\"><img src=\"/por/images/Reports/POR/2018/1208500/1208500_10191378_1539994375890_Spatial2--rgov-66x44.jpg\" alt=\"A Co-Robot That Knows Where to Stand to Hear and be Properly Heard\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A Co-Robot That Knows Where to Stand to Hear and be Properly Heard</div>\n<div class=\"imageCredit\">Ross Mead</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">A Co-Robot That Knows Where to Stand to Hear and be Properly Heard</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nAward Title: NRI-Small: Spatial Primitives for Enabling Situated Human-Robot Interaction\n\nFederal Award ID: IIS-1208500\n\nAs robots are being introduced into human environments, it is important to ensure that they both safe and easy to use, facilitating natural interactions.  Sociable and socially assistive co-robots must therefore behave within the appropriate norms of human social behavior, including in how they use social space and communication: they must keep the appropriate social distance, speak and understand speech, and use and understand gesture. This NRI project addressed the following questions: how should social (auditory and visual), environmental (noisy and occluding), and personal (sensory impairment or sensitivity) stimuli influence the robot?s behavior, and how should the robot continually adjust its communication behaviors to maximize human understanding and improve interaction.\n\n \n\nIntellectual Merit:\n\nThe results of this work establish a part of the foundation for natural human-robot interaction, by enabling robots to determine how closely to approach, how to orient, and how loudly to speak, for ideal communication with people. To make the research results accessible, we produced a publicly available informative video summary:\n\nhttps://www.youtube.com/channel/UCp36BiVXLqV9GiQ8e_mmSnQ\n\n \n\nThe project also investigated how robots should perform different types of gestures. We studied the use of object-based gestures (e.g., round basketball) and use-based gestures (e.g., shooting a basket) to enable robots to communicate more clearly with people. This project also developed an approach to recognizing and identifying bullying behaviors in everyday environments, based on data collected from a large-scale public event. A robot capable of recognizing such behaviors can avoid situations that threaten its physical operations and integration into human environments.  It can also provide assistance to people experiencing intimidation or other forms of social bullying. In particular, it can help children who are victims of bullying to learn how to respond as well as to help those who have bullying tendencies to recognize those, and understand why they are inappropriate.\n\n \n\nThis project built on and contributed to multiple disciplines: contributions to robotics include both computing and engineering and open-source software, contributions to data science include novel methods, data sets, and models, and contributions to social and behavioral science include testing and validating longstanding theories on proxemics.\n\n \n\nBroader Impacts:\n\nThis project trained a large group of students at all levels--from K-12 to university, to PhD and postdoc--on research methods and human participant experiments, allowing them to learn about interdisciplinary research while practicing their computing and engineering skills.  The lead graduate student on this project started a company after finishing his PhD, transferring his expertise in software development for representing, recognizing, and generating social behaviors for autonomous sociable and socially assistive co-robots, leading to a continuing university-industry connection.\n\n \n\nThis project included a spectrum of K-12 and public outreach activities as well.  The project team worked with elementary and middle-school teachers to develop novel in-school and after-school science and engineering content modules. Delta Science kits were used to provide age-appropriate STEM modules as a precursor to learning robotics, Junior Botball robotics kits were used to teach students about robotics through writing code and understanding engineering principles, and Lego Education robotic kits were used to teach middle school students about robotics.  Additionally, in each year of the project, the USC Robotics labs hosted the vastly popular USC Open House. This all-day event has been attended by up to 2,000 local K-12 students, teachers, and families.  Additionally, our anti-bullying co-robot brought attention to bullying prevention for youth in a novel way that received both student and media attention.\n\n\t\t\t\t\tLast Modified: 10/19/2018\n\n\t\t\t\t\tSubmitted by: Maja J Mataric"
 }
}