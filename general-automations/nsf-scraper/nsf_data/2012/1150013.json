{
 "awd_id": "1150013",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:Toward a locality-enhancing transformation framework for irregular programs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2012-02-01",
 "awd_exp_date": "2018-01-31",
 "tot_intn_awd_amt": 418786.0,
 "awd_amount": 418786.0,
 "awd_min_amd_letter_date": "2012-01-06",
 "awd_max_amd_letter_date": "2016-04-12",
 "awd_abstract_narration": "Many domains in computer science, from data-mining to simulation to computational biology, focus heavily on irregular applications, which deal with complex algorithms that manipulate complex data structures. For example, to analyze large data sets, point correlation - a data mining algorithm - organizes data in a tree-like structure that is then manipulated to extract trends and patterns. As such algorithms become more pervasive, and, more importantly, the data sets they are applied to become much larger, writing high performance irregular applications has become critically important. However, the complexity of irregular algorithms makes writing high-performance applications very difficult: simple expressions of the algorithms do not perform well, and high-performance implementations are difficult to express. An attractive solution is to develop a set of tools that could take a simple expression of an algorithm and automatically transform the program into a higher performing version. This project aims to develop automated, robust and generally-applicable performance-enhancing techniques and transformations for irregular programs.\r\n\r\nThe chief obstacle to identifying and performing performance-enhancing transformations on irregular programs is the apparent lack of principles that unify irregular applications. However, this research argues that there are, indeed, such principles that can guide the development of transformations. By leveraging high-level structural properties of irregular algorithms, it is possible to automatically transform irregular programs to significantly improve their performance. This project pursues a set of interlocking efforts to build a framework to (i) analyze irregular programs, (ii) identify profitable and legal transformations, (iii) automatically restructure programs according to those transformations, and then (iv) tune the performance of the transformed applications to best fit the target execution platform.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Milind",
   "pi_last_name": "Kulkarni",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Milind Kulkarni",
   "pi_email_addr": "milind@purdue.edu",
   "nsf_id": "000549148",
   "pi_start_date": "2012-01-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072035",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "104500",
   "pgm_ele_name": "CAREER: FACULTY EARLY CAR DEV"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7329",
   "pgm_ref_txt": "COMPILERS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 156915.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 83531.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 87208.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 91132.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many applications that drive the modern world, in fields ranging from data mining to machine learning to graphics to computational genomics, are irregular: rather than behaving in predictable manners and working with simple data structures like arrays, they behave in complex, unpredictable ways and operate over complicated data structures like trees and graphs. Most advances in the realm of compiler optimizations focus on the predictable applications rather than these emerging irregular applications. This project looked at bringing together a set of techniques to optimize irregular applications and hence improve their performance, allowing them to be deployed on larger data sets and deliver results faster.</p>\n<p><br />This project developed a series of new program transformations that apply to irregular applications like ray tracers and nearest neighbor classifiers that operate over tree data structures. These transformations -- point blocking, traversal splicing, traversal fusion, recursion twisting -- represented the first generally applicable transformations for these types of applications, generalizing the hand-written and hand-tuned optimizations that programmers had used in the past. These transformations delivered substantial performance improvements on a wide range of applications -- up to 10x in the best cases -- and often out-performed hand-tuned implementations despite being more generic and more automatic.</p>\n<p><br />This project then took those transformations and showed how they could be used to map complex applications to complex hardware, including graphics processing units (GPUs) and vector units. The optimizations enabled by this project led to the first general strategies for putting tree-based applications on GPUs and vector units, leading to speedups of up to 100x when combining all the optimizations. The project also showed how the transformations create program structures that allow irregular applications to be executed in a distributed manner, automatically scaling these applications up to hundreds of processors.</p>\n<p><br />Being able to automatically optimize programs does not help if there is no guarantee that the new program is still correct -- that it produces the same result as the original program. Compiler analyses have struggled for decades to find ways of proving that transformations on irregular programs are sound, tackling only relatively simple transformations. This project yielded several key results in this space. First, it produced the first general dependence test for scheduling transformations of tree based programs, providing an analysis that could tell whether restructuring transformations like point blocking and traversal splicing were sound. Second, it produced the first test for fusing together general traversals of trees -- this test automates the kind of careful hand tuning that, say, web browser engineers perform to speed up the rendering of web pages. Finally, this project developed the first dependence analysis framework that supports multiple transformations and provides a general dependence test to check whether any transformation on a recursive, irregular program is safe.</p>\n<p><br />The results of this project have made their way into applications in other domains. For example, the GPU transformations developed by this project have been used to speed up a state-of-the-art astrophysics simulation platform by 4-5x. The benchmarks developed as part of the experimental platform for this project have been used by external groups to drive their research. This project has led to the release of several open-source transformation and analysis frameworks. The results of this project have appeared in 15 peer-reviewed workshops and conferences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/18/2018<br>\n\t\t\t\t\tModified by: Milind&nbsp;Kulkarni</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany applications that drive the modern world, in fields ranging from data mining to machine learning to graphics to computational genomics, are irregular: rather than behaving in predictable manners and working with simple data structures like arrays, they behave in complex, unpredictable ways and operate over complicated data structures like trees and graphs. Most advances in the realm of compiler optimizations focus on the predictable applications rather than these emerging irregular applications. This project looked at bringing together a set of techniques to optimize irregular applications and hence improve their performance, allowing them to be deployed on larger data sets and deliver results faster.\n\n\nThis project developed a series of new program transformations that apply to irregular applications like ray tracers and nearest neighbor classifiers that operate over tree data structures. These transformations -- point blocking, traversal splicing, traversal fusion, recursion twisting -- represented the first generally applicable transformations for these types of applications, generalizing the hand-written and hand-tuned optimizations that programmers had used in the past. These transformations delivered substantial performance improvements on a wide range of applications -- up to 10x in the best cases -- and often out-performed hand-tuned implementations despite being more generic and more automatic.\n\n\nThis project then took those transformations and showed how they could be used to map complex applications to complex hardware, including graphics processing units (GPUs) and vector units. The optimizations enabled by this project led to the first general strategies for putting tree-based applications on GPUs and vector units, leading to speedups of up to 100x when combining all the optimizations. The project also showed how the transformations create program structures that allow irregular applications to be executed in a distributed manner, automatically scaling these applications up to hundreds of processors.\n\n\nBeing able to automatically optimize programs does not help if there is no guarantee that the new program is still correct -- that it produces the same result as the original program. Compiler analyses have struggled for decades to find ways of proving that transformations on irregular programs are sound, tackling only relatively simple transformations. This project yielded several key results in this space. First, it produced the first general dependence test for scheduling transformations of tree based programs, providing an analysis that could tell whether restructuring transformations like point blocking and traversal splicing were sound. Second, it produced the first test for fusing together general traversals of trees -- this test automates the kind of careful hand tuning that, say, web browser engineers perform to speed up the rendering of web pages. Finally, this project developed the first dependence analysis framework that supports multiple transformations and provides a general dependence test to check whether any transformation on a recursive, irregular program is safe.\n\n\nThe results of this project have made their way into applications in other domains. For example, the GPU transformations developed by this project have been used to speed up a state-of-the-art astrophysics simulation platform by 4-5x. The benchmarks developed as part of the experimental platform for this project have been used by external groups to drive their research. This project has led to the release of several open-source transformation and analysis frameworks. The results of this project have appeared in 15 peer-reviewed workshops and conferences.\n\n\t\t\t\t\tLast Modified: 07/18/2018\n\n\t\t\t\t\tSubmitted by: Milind Kulkarni"
 }
}