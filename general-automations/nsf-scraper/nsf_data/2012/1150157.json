{
 "awd_id": "1150157",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Haptic Interaction for Robotic Caregivers",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-03-01",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 499996.0,
 "awd_amount": 499996.0,
 "awd_min_amd_letter_date": "2012-01-17",
 "awd_max_amd_letter_date": "2012-01-17",
 "awd_abstract_narration": "Making contact with a person's body is critical to many of the most important caregiving tasks for people with physical disabilities.  During these tasks, the forces applied by the robot to the body of the human client (care recipient) are of central importance.  Yet robots are currently ignorant of what forces are appropriate for common tasks, and what forces are appropriate when making contact with different locations on the client's body.  In this project, the PI's goal is to endow assistive robots with the ability to use appropriate forces when haptically interacting with people.  To this end, he will capture and statistically model the forces applied when a person performs assistive tasks for him or herself, or provides care to another person.  He will enable robots to intelligently regulate the forces they apply when performing assistive tasks, so that the applied forces are comparable to those used during human-human interactions.  And he will enable clients to effectively control the forces applied by a robot during assistive tasks.  Throughout the research, the PI will conduct experiments to test relevant hypotheses: That the type of task and the pose of the tool relative to the client's body are highly predictive of the force applied by a human caregiver; That when performing tasks on a mannequin, the robot will successfully emulate the forces observed during human-human interaction; That when the robot applies force to the client's body, the client will prefer that the robot use knowledge of the task and the pose of the tool to interpret user commands rather than a constant mapping.  Because a person's ability to perform activities of daily living (ADLs) is highly predictive of his or her ability to live independently, the work will focus on four representative ADL tasks that require contact with the client's head: feeding a person yogurt, wiping a person's face, brushing a person's hair, and shaving a person with an electric razor.  Project outcomes will include a system that enables a PR2 robot from Willow Garage to assist people with severe physical disabilities with these four tasks; the PR2 will be modified to have force-torque sensors at its wrists, specialized tools, and a Kinect 3D sensor on its head.\r\n\r\nBroader Impacts:  This research will begin to endow robots with a crucial form of \"common sense\" while quantitatively analyzing and synthesizing haptic interaction in the context of humans' most basic needs.  It will also lead to a better understanding of human-robot interaction when the robot initiates contact with the user, and will contribute to data-driven methods for intelligent control.   The PI will publish extensively and will release open source code, so that the work can catalyze progress towards robots that could empower millions of people to live more independently with a higher quality of life.  The PI will directly involve people with disabilities in the research, and will actively engage the broader community by participating in events such as the RESNA conferences and the Atlanta Abilities Expo.  In addition, he will incorporate research results in his biomechanics class and graduate course on haptics, and will then adapt the material to teach people around the world about these topics and robotics using the methods and tools of Khan Academy (http://www.khanacademy.org/).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Charles",
   "pi_last_name": "Kemp",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Charles C Kemp",
   "pi_email_addr": "charlie.kemp@bme.gatech.edu",
   "nsf_id": "000367160",
   "pi_start_date": "2012-01-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue, NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 499996.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-8c47cb60-7fff-b4b4-49f1-06b2bc1ed885\"> </span></p>\n<p dir=\"ltr\"><span>Millions of people require physical assistance on a daily basis due to disabilities resulting from illnesses, injuries, aging, and other causes. Mobile robots with autonomous capabilities have the potential to provide 24/7 personalized care, dramatically improving the quality of life of people with disabilities. However, many important caregiving tasks would involve the robotic caregiver making contact with the body of the person receiving assistance. This presents numerous challenges. For example, the forces applied by the robotic caregiver should be appropriate to the task, yet robots have lacked common sense about what forces are appropriate.</span></p>\n<p dir=\"ltr\"><span>This award supported research on robotic caregivers with a focus on physical contact between robots and people. The research has resulted in new methods for assistive robot manipulation and contributions to compliant arm control, multimodal perception, and human-robot interaction. It has resulted in the quantitative characterization of the forces associated with everyday assistive tasks, such as shaving, wiping, and door opening. It has also resulted in methods that enable caregiving robots to detect anomalous situations and then take appropriate actions, such as halting. For example, these methods have enabled a robot to have the common sense to stop when it encounters unusual forces while assisting with feeding. Overall, this research has enabled robots to more intelligently regulate the forces they apply while providing assistance.</span></p>\n<p dir=\"ltr\"><span>The robotic systems developed as part of this research blend the capabilities of the person receiving care and a semi-autonomous mobile robot. This research has demonstrated that human-scale mobile manipulators can assist people in a wide variety of tasks that involve contact between the robot and the person's body, such as shaving, scratching, cleaning, and eating (see picture*). It has also shown that mobile manipulators can help a person in distinct surroundings, including when the person is in a wheelchair or in bed, and can do so in the person's home. For example, this award supported research with Henry Evans, a person with severe motor impairments due to a brainstem stroke. By using robotic systems developed as part of this research, Henry was able to perform a number of tasks for himself in his home for the first time in 10 years (see picture*).</span></p>\n<p dir=\"ltr\"><span>This work has resulted in numerous peer-reviewed publications, as well as open source software and open hardware, which the Healthcare Robotics Lab has released to the public under liberal open source licenses. This award has also helped support education by providing materials for an undergraduate class at Georgia Tech, helping with the training of undergraduate and graduate students, and producing compelling demonstrations for local junior high and high school students during tours for National Robotics Week.</span></p>\n<p dir=\"ltr\">&nbsp;</p>\n<p dir=\"ltr\">* Picture from the following article:</p>\n<p dir=\"ltr\">Grice PM, Kemp CC (2019) In-home and remote use of robotic body surrogates by people with profound motor deficits. PLoS ONE 14(3): e0212904.</p>\n<p dir=\"ltr\">Link to the article:</p>\n<p dir=\"ltr\">https://doi.org/10.1371/journal.pone.0212904</p>\n<p dir=\"ltr\">Link to the picture in the article:</p>\n<p dir=\"ltr\">https://doi.org/10.1371/journal.pone.0212904.g013</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/14/2019<br>\n\t\t\t\t\tModified by: Charles&nbsp;C&nbsp;Kemp</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1150157/1150157_10149431_1557866872335_journal.pone.0212904.g013_small--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1150157/1150157_10149431_1557866872335_journal.pone.0212904.g013_small--rgov-800width.jpg\" title=\"Robotic Caregiving\"><img src=\"/por/images/Reports/POR/2019/1150157/1150157_10149431_1557866872335_journal.pone.0212904.g013_small--rgov-66x44.jpg\" alt=\"Robotic Caregiving\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Henry Evans, a person with severe motor impairments, uses a mobile robot to perform a variety of tasks for himself in his own home.</div>\n<div class=\"imageCredit\">https://doi.org/10.1371/journal.pone.0212904.g013</div>\n<div class=\"imageSubmitted\">Charles&nbsp;C&nbsp;Kemp</div>\n<div class=\"imageTitle\">Robotic Caregiving</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nMillions of people require physical assistance on a daily basis due to disabilities resulting from illnesses, injuries, aging, and other causes. Mobile robots with autonomous capabilities have the potential to provide 24/7 personalized care, dramatically improving the quality of life of people with disabilities. However, many important caregiving tasks would involve the robotic caregiver making contact with the body of the person receiving assistance. This presents numerous challenges. For example, the forces applied by the robotic caregiver should be appropriate to the task, yet robots have lacked common sense about what forces are appropriate.\nThis award supported research on robotic caregivers with a focus on physical contact between robots and people. The research has resulted in new methods for assistive robot manipulation and contributions to compliant arm control, multimodal perception, and human-robot interaction. It has resulted in the quantitative characterization of the forces associated with everyday assistive tasks, such as shaving, wiping, and door opening. It has also resulted in methods that enable caregiving robots to detect anomalous situations and then take appropriate actions, such as halting. For example, these methods have enabled a robot to have the common sense to stop when it encounters unusual forces while assisting with feeding. Overall, this research has enabled robots to more intelligently regulate the forces they apply while providing assistance.\nThe robotic systems developed as part of this research blend the capabilities of the person receiving care and a semi-autonomous mobile robot. This research has demonstrated that human-scale mobile manipulators can assist people in a wide variety of tasks that involve contact between the robot and the person's body, such as shaving, scratching, cleaning, and eating (see picture*). It has also shown that mobile manipulators can help a person in distinct surroundings, including when the person is in a wheelchair or in bed, and can do so in the person's home. For example, this award supported research with Henry Evans, a person with severe motor impairments due to a brainstem stroke. By using robotic systems developed as part of this research, Henry was able to perform a number of tasks for himself in his home for the first time in 10 years (see picture*).\nThis work has resulted in numerous peer-reviewed publications, as well as open source software and open hardware, which the Healthcare Robotics Lab has released to the public under liberal open source licenses. This award has also helped support education by providing materials for an undergraduate class at Georgia Tech, helping with the training of undergraduate and graduate students, and producing compelling demonstrations for local junior high and high school students during tours for National Robotics Week.\n \n* Picture from the following article:\nGrice PM, Kemp CC (2019) In-home and remote use of robotic body surrogates by people with profound motor deficits. PLoS ONE 14(3): e0212904.\nLink to the article:\nhttps://doi.org/10.1371/journal.pone.0212904\nLink to the picture in the article:\nhttps://doi.org/10.1371/journal.pone.0212904.g013\n\n\t\t\t\t\tLast Modified: 05/14/2019\n\n\t\t\t\t\tSubmitted by: Charles C Kemp"
 }
}