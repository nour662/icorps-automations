{
 "awd_id": "1210235",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "NSF East Asia and Pacific Summer Institute for FY 2012 in New Zealand",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Anne Emig",
 "awd_eff_date": "2012-06-01",
 "awd_exp_date": "2013-05-31",
 "tot_intn_awd_amt": 5836.0,
 "awd_amount": 5836.0,
 "awd_min_amd_letter_date": "2012-05-18",
 "awd_max_amd_letter_date": "2012-05-18",
 "awd_abstract_narration": "This action funds Danielle Nicole Cummings of Texas A&M University to conduct a research project, entitled \"Real-time Emotion Visualization for Enhancing Human-to-Human Interaction,\" during the summer of 2012 at the University of Canterbury in Christchurch, New Zealand.  The host scientist is Dr. Mark Billinghurst.\r\n\r\nThe Intellectual Merit of the research project involves a highly interdisciplinary combination of Augmented Reality (AR) and Biological Signal Classification in order to create a real-time visualization of the human emotional state. Potentailly such a system could facilitate non-verbal communication and thereby improve human interactions.  A system that monitors and displays the emotional state of a person or group of people could have useful applications.  Providing visual cues that identify emotions can help facilitate team interaction when direct communication is not possible, or improve basic social skills for people who have difficulty reading facial expressions and/or body language. \r\n\r\nBroader Impacts of an EAPSI fellowship also include providing the Fellow a first-hand research experience outside the U.S.; an introduction to the science, science policy, and scientific infrastructure of the respective location; and an orientation to the society, culture and language.   These activities meet the NSF goal to educate for international collaborations early in the career of its scientists, engineers, and educators, thus ensuring a globally aware U.S. scientific workforce.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Danielle",
   "pi_last_name": "Cummings",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Danielle Cummings",
   "pi_email_addr": "",
   "nsf_id": "000578400",
   "pi_start_date": "2012-05-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cummings                Danielle",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "College Station",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "",
  "inst_zip_code": "778401372",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Cummings                Danielle",
  "perf_str_addr": null,
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778431372",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "731600",
   "pgm_ele_name": "EAPSI"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5941",
   "pgm_ref_txt": "NEW ZEALAND"
  },
  {
   "pgm_ref_code": "5978",
   "pgm_ref_txt": "EAST ASIA AND PACIFIC PROGRAM"
  },
  {
   "pgm_ref_code": "7316",
   "pgm_ref_txt": "EAPSI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 5836.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this research effort we explored the use of augmented reality (AR) as a medium for visualizing human biosignal data. Our ultimate goal was to create an interface that integrates seamlessly with the user&rsquo;s normal activities and facilitates social exchange, communication and team coordination.</p>\n<p>&nbsp;</p>\n<p>To address the team coordination scenario, we tested the range limits of our mobile system by converting android phones to beacons and evaluating the broadcasting functionality first with Bluetooth and then with Wi-Fi. We created a simple method for exchanging physiological status information between users using the Wi-Fi technologies in commercially available android phones. We used mobile sensors to collect heart rate, breathing rate, device temperature, posture of the wearer, acceleration, and ECG. We attempted various methods of integrating the AR technology created by the host lab in order to create a hands-free visualization of the user&rsquo;s physiological status.</p>\n<p>&nbsp;</p>\n<p>We then conducted a classification study to identify distinct events that could be used to determine if a team member was in danger or possibly in need of assistance, at which time an alert could be broadcast to teammates through the system. We evaluated a commonly used corpus of stimuli to determine its effects on a broader audience (existing data had been obtained from a test group of all students from the US).<strong> </strong>This study lead to a comparison of ratings scales for affective response to stimuli which can be used to perform evaluations in cognitive studies. &nbsp;We later conducted field evaluations with teams of participants who used the visual aids within the system to navigate to teammates who were in simulated states of distress.</p>\n<p>&nbsp;</p>\n<p>This research also lead to the development of a mobile system that connects people through the exchange of physiological signals via haptic feedback. Evaluation of this system has shown preliminary evidence that the system may elicit empathetic responses in users. These developments in AR and haptic technology allowed us to create a seamless interaction experience between users with minimal cognitive load.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/27/2012<br>\n\t\t\t\t\tModified by: Danielle&nbsp;Cummings</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this research effort we explored the use of augmented reality (AR) as a medium for visualizing human biosignal data. Our ultimate goal was to create an interface that integrates seamlessly with the user\u00c6s normal activities and facilitates social exchange, communication and team coordination.\n\n \n\nTo address the team coordination scenario, we tested the range limits of our mobile system by converting android phones to beacons and evaluating the broadcasting functionality first with Bluetooth and then with Wi-Fi. We created a simple method for exchanging physiological status information between users using the Wi-Fi technologies in commercially available android phones. We used mobile sensors to collect heart rate, breathing rate, device temperature, posture of the wearer, acceleration, and ECG. We attempted various methods of integrating the AR technology created by the host lab in order to create a hands-free visualization of the user\u00c6s physiological status.\n\n \n\nWe then conducted a classification study to identify distinct events that could be used to determine if a team member was in danger or possibly in need of assistance, at which time an alert could be broadcast to teammates through the system. We evaluated a commonly used corpus of stimuli to determine its effects on a broader audience (existing data had been obtained from a test group of all students from the US). This study lead to a comparison of ratings scales for affective response to stimuli which can be used to perform evaluations in cognitive studies.  We later conducted field evaluations with teams of participants who used the visual aids within the system to navigate to teammates who were in simulated states of distress.\n\n \n\nThis research also lead to the development of a mobile system that connects people through the exchange of physiological signals via haptic feedback. Evaluation of this system has shown preliminary evidence that the system may elicit empathetic responses in users. These developments in AR and haptic technology allowed us to create a seamless interaction experience between users with minimal cognitive load.\n\n \n\n\t\t\t\t\tLast Modified: 11/27/2012\n\n\t\t\t\t\tSubmitted by: Danielle Cummings"
 }
}