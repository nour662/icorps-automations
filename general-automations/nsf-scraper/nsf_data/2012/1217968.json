{
 "awd_id": "1217968",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Small: Collaborative Proposal: Towards Robust Uncertain Data Management",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Maria Zemankova",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 249936.0,
 "awd_amount": 265836.0,
 "awd_min_amd_letter_date": "2012-09-04",
 "awd_max_amd_letter_date": "2014-06-20",
 "awd_abstract_narration": "The goal of this project is to develop a systematic framework to enable \"robust\" query processing in presence of data uncertainties that arise naturally in a wide variety of application domains. Data uncertainties may take the form of missing or incomplete data, inherent noise in the data, trust or reputation scores assigned to data based on their sources of origin, or confidences in predictions made using automated modeling tools. The input uncertainties naturally lead to uncertainties in the results of any queries or analyses performed on such data. To enable robust and systematic reasoning over such uncertain query results, efficient algorithms and practical tools are developed to: (a) identify the input uncertainties to which query results are most sensitive, (b) decide how to use scarce resources like subject matter experts to resolve uncertainties in query results, and (c) incorporate user feedback to improve the robustness of the input uncertainty parameters themselves. The tools have the potential to make it easy and intuitive to process and analyze uncertain data and extract useful information from it in a wide range of real-world application domains including social media analysis, scientific and biological data management, sensor data management, web data integration, and information extraction. This project provides research opportunities for graduate and undergraduate students, and is aligned with several advanced graduate courses offered by the PIs. The prototype implementation of the framework, publications, and experimental data, will be disseminated via the project web site: http://www.cs.umd.edu/~amol/RPrDB.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lisa",
   "pi_last_name": "Hellerstein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lisa Hellerstein",
   "pi_email_addr": "lisa.hellerstein@nyu.edu",
   "nsf_id": "000340245",
   "pi_start_date": "2012-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "Polytechnic University of New York",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "112013840",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "NY07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 50121.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 199815.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 15900.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>People often think of data as being a collection of facts, but much of the data available today is imprecise, uncertain, or probabilistic. For example, data collected by sensors or scientific instruments is typically incomplete and \"noisy''.&nbsp; Data gathered from internet sources can be unreliable. Even when raw data is precise, using machine learning tools to extract knowledge from it can produce higher-level data that is imprecise. Faced with this abundance of uncertain data, database researchers have done extensive research to develop techniques for managing and querying probabilistic data.</p>\n<p>Much of this previous work focused on the problem of annotating data to reflect the degree of uncertainty associated with it, and propogating annotations to the results obtained from querying or analyzing the data. However, solving this problem is not sufficient. In this project, we focused on three critical challenges that need to be addressed in order to develop a \"robust'' uncertain data management system: (a) resolving uncertainties in query results by gathering more information, so that the decision-makers can have more confidence in their decisions, (b) analyzing sensitivity of the output of a specific query to the uncertainties in the input, and (c) meaningfully interpreting numeric uncertainty scores as probabilities. The goal of the project was to develop a systematic framework to address these challenges to enable robust probabilistic data management.</p>\n<p>The main outcomes of the project can be summarized as follows. It resulted in the development of a collection of algorithms and algorithmic techniques for resolving uncertainty using queries, where the goal is to choose the sequence of queries that minimizes the expected cost of determining the value of a given Boolean function on uncertain inputs. Algorithms were developed for a variety of different classes of Boolean functions: linear threshold functions (where a linear function over the uncertain inputs is compared to a threshold value), certain Boolean formulas containing conjunctions and disjunctions, and \"symmetric'' Boolean functions (where the output of the function depends only on the number of inputs set to True). These algorithms compute approximately optimal query sequences, and come with proofs guaranteeing the quality of the approximation. Some of the algorithms are designed for the \"scenario'' setting, where possible combinations of the Boolean function input values are provided. This setting does not require making strict probabilistic independence assumptions about how the uncertainties of different inputs relate to each other.</p>\n<p>Algorithms were also developed for a game theoretic formulation of a class of uncertainty resolution problems.&nbsp; In these problems, the goal is to determine the sequence of queries that resolves uncertainty, while incurring minimum cost.&nbsp; An adversary answers the queries, seeking to maximize cost, but is allowed to choose from only a limited number of combinations of query answers.&nbsp; <br /><br />The project yielded the design of a general framework to resolve uncertainty for a collection of ranking and partitioning problems, where the goal is to rank or partition a set of objects using incomplete information about user preferences.<br />Finally, the project demonstrated that the effects of \"uncalibrated\" probabilities can be significant, by showing that simple transformations of numeric uncertainty scores can result in complex transformations on the results of simple queries.</p>\n<p>Key results from this project were published in conference and journal papers in Computer Science. This project also trained several graduate and undergraduate students to do research.<br /><br />Overall this project has made significant advances in our ability to query and reason about uncertain data in a robust manner, and has thus paved the way for incorporating uncertainty in commercial database systems. More details about the project, and the publications that resulted from it, can be found at: http://www.cs.umd.edu/~amol/DBGroup/RobustPrDB.html</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/02/2018<br>\n\t\t\t\t\tModified by: Lisa&nbsp;Hellerstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nPeople often think of data as being a collection of facts, but much of the data available today is imprecise, uncertain, or probabilistic. For example, data collected by sensors or scientific instruments is typically incomplete and \"noisy''.  Data gathered from internet sources can be unreliable. Even when raw data is precise, using machine learning tools to extract knowledge from it can produce higher-level data that is imprecise. Faced with this abundance of uncertain data, database researchers have done extensive research to develop techniques for managing and querying probabilistic data.\n\nMuch of this previous work focused on the problem of annotating data to reflect the degree of uncertainty associated with it, and propogating annotations to the results obtained from querying or analyzing the data. However, solving this problem is not sufficient. In this project, we focused on three critical challenges that need to be addressed in order to develop a \"robust'' uncertain data management system: (a) resolving uncertainties in query results by gathering more information, so that the decision-makers can have more confidence in their decisions, (b) analyzing sensitivity of the output of a specific query to the uncertainties in the input, and (c) meaningfully interpreting numeric uncertainty scores as probabilities. The goal of the project was to develop a systematic framework to address these challenges to enable robust probabilistic data management.\n\nThe main outcomes of the project can be summarized as follows. It resulted in the development of a collection of algorithms and algorithmic techniques for resolving uncertainty using queries, where the goal is to choose the sequence of queries that minimizes the expected cost of determining the value of a given Boolean function on uncertain inputs. Algorithms were developed for a variety of different classes of Boolean functions: linear threshold functions (where a linear function over the uncertain inputs is compared to a threshold value), certain Boolean formulas containing conjunctions and disjunctions, and \"symmetric'' Boolean functions (where the output of the function depends only on the number of inputs set to True). These algorithms compute approximately optimal query sequences, and come with proofs guaranteeing the quality of the approximation. Some of the algorithms are designed for the \"scenario'' setting, where possible combinations of the Boolean function input values are provided. This setting does not require making strict probabilistic independence assumptions about how the uncertainties of different inputs relate to each other.\n\nAlgorithms were also developed for a game theoretic formulation of a class of uncertainty resolution problems.  In these problems, the goal is to determine the sequence of queries that resolves uncertainty, while incurring minimum cost.  An adversary answers the queries, seeking to maximize cost, but is allowed to choose from only a limited number of combinations of query answers.  \n\nThe project yielded the design of a general framework to resolve uncertainty for a collection of ranking and partitioning problems, where the goal is to rank or partition a set of objects using incomplete information about user preferences.\nFinally, the project demonstrated that the effects of \"uncalibrated\" probabilities can be significant, by showing that simple transformations of numeric uncertainty scores can result in complex transformations on the results of simple queries.\n\nKey results from this project were published in conference and journal papers in Computer Science. This project also trained several graduate and undergraduate students to do research.\n\nOverall this project has made significant advances in our ability to query and reason about uncertain data in a robust manner, and has thus paved the way for incorporating uncertainty in commercial database systems. More details about the project, and the publications that resulted from it, can be found at: http://www.cs.umd.edu/~amol/DBGroup/RobustPrDB.html\n\n\t\t\t\t\tLast Modified: 01/02/2018\n\n\t\t\t\t\tSubmitted by: Lisa Hellerstein"
 }
}