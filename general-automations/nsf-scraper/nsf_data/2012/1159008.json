{
 "awd_id": "1159008",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "IRFP: Deep Neural Networks for Perception and Action Integration in Robotic Control",
 "cfda_num": "47.079",
 "org_code": "01090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Cassandra Dudka",
 "awd_eff_date": "2013-06-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 177208.0,
 "awd_amount": 183808.0,
 "awd_min_amd_letter_date": "2012-08-02",
 "awd_max_amd_letter_date": "2015-05-27",
 "awd_abstract_narration": "The International Research Fellowship Program enables U.S. scientists and engineers to conduct nine to twenty-four months of research abroad. The program's awards provide opportunities for joint research, and the use of unique or complementary facilities, expertise and experimental conditions abroad. \r\n\r\nThis award will support a twenty-four-month research fellowship by Dr. Alan Lockett to work with Professor Juergen Schmidhuber at the Instituto dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA) in Lugano, Switzerland. \r\n\r\nThis project explores methods for training deep neural networks to control a physical robot with humanoid hands and arms. The recent development of new methods for training deep artificial neural networks has resulted in breakthroughs on a number of benchmarks in artificial intelligence. Deep neural networks currently hold the record for benchmark predictive tasks including handwriting recognition (MNIST) and object recognition (NORB, CIFAR-10). \r\n\r\nThis project is developing methods for training deep neural network controllers with thousands or millions of parameters using an array of massively multiprocessor GPUs with over 4,096 processors. Deep network controllers in this research are trained using neuroevolution, reinforcement learning, and combinations of the two. Such controllers are being used to train a humanoid iCub robot to manipulate objects for the AAAI Small-Scale Manipulation Challenge.\r\n\r\nThe research is being performed at the Instituto dalle Molle di Studi sull'Intelligenza Artificiale (IDSIA) in Lugano, Switzerland in conjunction with Professor Juergen Schmidhuber. IDSIA is a leading research institution in the study of deep neural networks, artificial evolution, reinforcement learning, and robotic control. \r\n\r\nThis research seeks to advance our understanding of robotic control in general. The focus on deep neural networks that integrate hierarchical perception and action modules has the potential to result in breakthroughs in control of complex robotic systems that would enable the deployment of computer and robotic systems that operate with greater autonomy than is currently possible.\r\n\r\nThe deployment of robotic technologies over the course of the next century is likely to mirror the rapid introduction of computer technology in the past century.  Behind the success of these robots will be deep hierarchical control systems that integrate perception and action at a high level of abstraction, as studied in this research. This research examines technologies that hold the potential to transform and improve our lives in innumerable ways. In the future, self-driving cars will co-ordinate with each other and with an active roadway to minimize accidents and improve efficiency. Advanced autopilot technology will finally make personal flying vehicles a reality. Autonomous robotic miners will reduce risk to humans while improving access to raw materials and resources. Robotic surgeons will perform complex operations with new levels of precision. Each of these technologies depends critically on the availability of deep integration of perceptual analysis and hierarchical controllers. The use of deep neural networks like the ones studied in the proposed research constitutes a promising approach to bringing these new technologies out of the lab and into our daily lives.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "O/D",
 "org_dir_long_name": "Office Of The Director",
 "div_abbr": "OISE",
 "org_div_long_name": "Office of International Science and Engineering",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alan",
   "pi_last_name": "Lockett",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Alan J Lockett",
   "pi_email_addr": "",
   "nsf_id": "000599102",
   "pi_start_date": "2012-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Lockett                 Alan           J",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Austin",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "",
  "inst_zip_code": "787490000",
  "inst_country_name": "United States",
  "cong_dist_code": null,
  "st_cong_dist_code": "TX",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "Instituto dalle Molle di Studi sull'Intelligenza Artificiale",
  "perf_str_addr": null,
  "perf_city_name": "Lugano",
  "perf_st_code": "",
  "perf_st_name": "RI REQUIRED",
  "perf_zip_code": "",
  "perf_ctry_code": "SZ",
  "perf_cong_dist": "",
  "perf_st_cong_dist": "",
  "perf_ctry_name": "Switzerland",
  "perf_ctry_flag": "0"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "595600",
   "pgm_ele_name": "IRFP-Inter Res Fellowship Prog"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5950",
   "pgm_ref_txt": "SWITZERLAND"
  },
  {
   "pgm_ref_code": "5956",
   "pgm_ref_txt": "IRFP"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 177208.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 6600.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Humanoid robots have a large number of sensors and actuators. It is a challenge to integrate high-dimensional sensor data, for example, from a stereo camera in order to control many degrees of freedom. In this project, control methodologies were studied to enable an iCub humanoid robot with 42 degrees of freedom to play the game of chess, which requires good hand-eye co-ordination. In particular, this research developed an end-to-end system comprising a convolutional neural network for initial visual filtering, a recurrent neural network sequence model to predict state transitions, and a controller to converts states into control decisions. Control methodologies explored included deep reinforcement learning with policy gradients and neuroevolution, both for the task of identifying and manipulating chess pieces.</p>\n<p>The central question for the research was whether it is better to train such a neural system end-to-end using a single error function, or to train each of the three components (filters, state transitions, and control) separately with different objectives?</p>\n<p>There are tradeoffs involved in the answer to this question. In this research and subsequent work, it has been shown that end-to-end training yields better outcomes when extensive data is available for training. However, when robot hardware is involved, extensive data is difficult and expensive to acquire, especially for control data, because it involves the risk of damaging the robot or other physical infrastructure. Additionally, data acquired from experiments in simulators may not be of high fidelity and may not generalize to real-world operation of the robot. Hence, when complex robotics are involved, it is best to consider training methodologies that either consider methods that are robust to data sparsity or to incur the capital expense of acquiring and maintaining numerous robots in order to enable training in parallel.</p>\n<p>In this work, data sparsity approaches were considered. The convolutional filters applied to vision were trained as autoencoders based on static images recorded during manual and programmatic movement of the robot in order to bootstrap learning without risking damage to the robot from controllers. A control methodology called <em>natural gradient control</em>&nbsp;was developed in partnership with other researchers that combines sampling-driven exploration with task-directed movement in order to minimize risk of damage to the robot.</p>\n<p>The combination of deep learning and robotic control is a nascent area of research that will likely yield many important developments over the next decade, transforming approaches to robotics in industrial, commercial, and domestic settings for the benefit of society as a whole. Future systems will likely be trained end-to-end based on reinforcement criteria, but the challenge that remains to be solved is how to acquire and utilize training data for humanoid robots effectively.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/28/2017<br>\n\t\t\t\t\tModified by: Alan&nbsp;J&nbsp;Lockett</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHumanoid robots have a large number of sensors and actuators. It is a challenge to integrate high-dimensional sensor data, for example, from a stereo camera in order to control many degrees of freedom. In this project, control methodologies were studied to enable an iCub humanoid robot with 42 degrees of freedom to play the game of chess, which requires good hand-eye co-ordination. In particular, this research developed an end-to-end system comprising a convolutional neural network for initial visual filtering, a recurrent neural network sequence model to predict state transitions, and a controller to converts states into control decisions. Control methodologies explored included deep reinforcement learning with policy gradients and neuroevolution, both for the task of identifying and manipulating chess pieces.\n\nThe central question for the research was whether it is better to train such a neural system end-to-end using a single error function, or to train each of the three components (filters, state transitions, and control) separately with different objectives?\n\nThere are tradeoffs involved in the answer to this question. In this research and subsequent work, it has been shown that end-to-end training yields better outcomes when extensive data is available for training. However, when robot hardware is involved, extensive data is difficult and expensive to acquire, especially for control data, because it involves the risk of damaging the robot or other physical infrastructure. Additionally, data acquired from experiments in simulators may not be of high fidelity and may not generalize to real-world operation of the robot. Hence, when complex robotics are involved, it is best to consider training methodologies that either consider methods that are robust to data sparsity or to incur the capital expense of acquiring and maintaining numerous robots in order to enable training in parallel.\n\nIn this work, data sparsity approaches were considered. The convolutional filters applied to vision were trained as autoencoders based on static images recorded during manual and programmatic movement of the robot in order to bootstrap learning without risking damage to the robot from controllers. A control methodology called natural gradient control was developed in partnership with other researchers that combines sampling-driven exploration with task-directed movement in order to minimize risk of damage to the robot.\n\nThe combination of deep learning and robotic control is a nascent area of research that will likely yield many important developments over the next decade, transforming approaches to robotics in industrial, commercial, and domestic settings for the benefit of society as a whole. Future systems will likely be trained end-to-end based on reinforcement criteria, but the challenge that remains to be solved is how to acquire and utilize training data for humanoid robots effectively.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/28/2017\n\n\t\t\t\t\tSubmitted by: Alan J Lockett"
 }
}