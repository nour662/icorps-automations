{
 "awd_id": "1221006",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC SBES: Small: Anonymity in Cyberspace",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 498097.0,
 "awd_amount": 530097.0,
 "awd_min_amd_letter_date": "2012-09-11",
 "awd_max_amd_letter_date": "2017-01-19",
 "awd_abstract_narration": "Internet users may have compelling reasons to seek anonymity online, for example, to discuss stigmatizing issues with others like themselves, or to express dissident opinions. This project studies what people believe it means to be anonymous online, how their privacy and security are affected by their strategies to achieve anonymity, and how they are likely to use new anonymity services. These questions are important because the traceability of users? actions across sites and contexts is ever greater, increasing risks for users who may misjudge their actual anonymity.  \r\nThe research involves interviews, surveys, and experimental studies to identify user motivations and practices, situational factors, and individual differences that lead people to desire anonymity. The research investigates the risks that users? perceive in their interactions, their motivations to avoid being identified, and the strategies they employ to mitigate risks they perceive to themselves and their relationships. A key component of this work is identifying cross-national and cultural differences in anonymity motivations and actions of people in countries such as China, where the government monitors and blocks Internet communications. This information will be used to design instructional materials and other tools that provide users with feedback and better strategies to protect themselves against risk. This project will inform cyberspace technical design and policy by addressing the SaTC goals of understanding, predicting and explaining prevention, attack, and defense behaviors and contributing to strategies for remediation.\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Sara",
   "pi_last_name": "Kiesler",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sara Kiesler",
   "pi_email_addr": "kiesler@cs.cmu.edu",
   "nsf_id": "000236432",
   "pi_start_date": "2012-09-11",
   "pi_end_date": "2016-07-15"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Laura",
   "pi_last_name": "Dabbish",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Laura Dabbish",
   "pi_email_addr": "dabbish@cmu.edu",
   "nsf_id": "000314694",
   "pi_start_date": "2017-01-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Laura",
   "pi_last_name": "Dabbish",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Laura Dabbish",
   "pi_email_addr": "dabbish@cmu.edu",
   "nsf_id": "000314694",
   "pi_start_date": "2012-09-11",
   "pi_end_date": "2016-07-15"
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 498097.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span><span>Internet users may have compelling reasons to seek anonymity online, for example, to discuss stigmatizing issues with others like themselves, or to express dissident opinions. This project studied what people believe it means to be anonymous online, how their privacy and security are affected by their strategies to achieve anonymity, and how they are likely to use new anonymity services. These questions are important because the traceability of users' actions across sites and contexts is ever greater, increasing risks for users who may misjudge their actual anonymity.&nbsp;</span></span></p>\n<p>Our research involved interviews, surveys, and experimental studies to identify user motivations and practices, situational factors, and individual differences that lead people to desire anonymity. The research investigated the risks that users'perceive in their interactions, their motivations to avoid being identified, and the strategies they employ to mitigate risks they perceive to themselves and their relationships.&nbsp;</p>\n<p><span><span><span>We found through surveys and interviews that many Internet users sometimes want to hide their identity or their online interactions or content. We found that p<span>eople&rsquo;s reasons for seeking anonymity range widely, from protecting family from unpleasant gossip (a relationship threat) to hiding from hackers or government surveillance (information threats). We also found that&nbsp;<span>technical knowledge and past negative experiences are two major filters determining perceptions and strategies for mitigating privacy threat.</span></span></span><br /></span></span></p>\n<p><span>We also examined how people understand the Internet and how they envision information transmission over the Internet. We found people's understanding of how information passes over the Internet is limited by their awareness of its underlying infrastructure. People with nontechnical professions or backgrounds are unaware of important entities in the network, and corresponding privacy and security threats. At the same time, technical users tend to be overconfident, leading them to potentially overlook threats to their personal information.</span></p>\n<p><span><span>People&rsquo;s technical knowledge background and awareness of personal information access (as informed by system interfaces) have mixed effects on their behavioral intentions. Our results show that an increased awareness of social privacy threats (measured by perceived access of other persons to their data) leads to a higher intention to take privacy protection actions, but this intention may not always translate into actual disclosure behavior.</span></span></p>\n<p>The findings of this project inform the design of future Internet architecture and applications to help Internet users better protect their information, and contribute to the body of research in privacy and HCI. The findings indicate that a higher level of system transparency or more user education might not be effective in influencing people to take more secure online action. Our findings suggest that many people have the desire to hide certain online information but do not have sufficient knowledge or the correct tools to do so.&nbsp;The findings also suggest more research is needed to improve policies and systems that can protect users&rsquo; privacy and security online without undue reliance on user actions.</p>\n<p>Our results can be used to design instructional materials and other tools that provide users with feedback and better strategies to protect themselves against risk. The project findings inform cyberspace technical design and policy by addressing the SaTC goals of understanding, predicting and explaining prevention, attack, and defense behaviors and contributing to strategies for remediation.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/08/2018<br>\n\t\t\t\t\tModified by: Laura&nbsp;Dabbish</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nInternet users may have compelling reasons to seek anonymity online, for example, to discuss stigmatizing issues with others like themselves, or to express dissident opinions. This project studied what people believe it means to be anonymous online, how their privacy and security are affected by their strategies to achieve anonymity, and how they are likely to use new anonymity services. These questions are important because the traceability of users' actions across sites and contexts is ever greater, increasing risks for users who may misjudge their actual anonymity. \n\nOur research involved interviews, surveys, and experimental studies to identify user motivations and practices, situational factors, and individual differences that lead people to desire anonymity. The research investigated the risks that users'perceive in their interactions, their motivations to avoid being identified, and the strategies they employ to mitigate risks they perceive to themselves and their relationships. \n\nWe found through surveys and interviews that many Internet users sometimes want to hide their identity or their online interactions or content. We found that people?s reasons for seeking anonymity range widely, from protecting family from unpleasant gossip (a relationship threat) to hiding from hackers or government surveillance (information threats). We also found that technical knowledge and past negative experiences are two major filters determining perceptions and strategies for mitigating privacy threat.\n\n\nWe also examined how people understand the Internet and how they envision information transmission over the Internet. We found people's understanding of how information passes over the Internet is limited by their awareness of its underlying infrastructure. People with nontechnical professions or backgrounds are unaware of important entities in the network, and corresponding privacy and security threats. At the same time, technical users tend to be overconfident, leading them to potentially overlook threats to their personal information.\n\nPeople?s technical knowledge background and awareness of personal information access (as informed by system interfaces) have mixed effects on their behavioral intentions. Our results show that an increased awareness of social privacy threats (measured by perceived access of other persons to their data) leads to a higher intention to take privacy protection actions, but this intention may not always translate into actual disclosure behavior.\n\nThe findings of this project inform the design of future Internet architecture and applications to help Internet users better protect their information, and contribute to the body of research in privacy and HCI. The findings indicate that a higher level of system transparency or more user education might not be effective in influencing people to take more secure online action. Our findings suggest that many people have the desire to hide certain online information but do not have sufficient knowledge or the correct tools to do so. The findings also suggest more research is needed to improve policies and systems that can protect users? privacy and security online without undue reliance on user actions.\n\nOur results can be used to design instructional materials and other tools that provide users with feedback and better strategies to protect themselves against risk. The project findings inform cyberspace technical design and policy by addressing the SaTC goals of understanding, predicting and explaining prevention, attack, and defense behaviors and contributing to strategies for remediation.\n\n\t\t\t\t\tLast Modified: 02/08/2018\n\n\t\t\t\t\tSubmitted by: Laura Dabbish"
 }
}