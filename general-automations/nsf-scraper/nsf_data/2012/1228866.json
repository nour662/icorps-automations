{
 "awd_id": "1228866",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Findings from Empirical Within Study Comparisons about the Role of Pretests and Proxy Pretests in Adjusting for Selection Bias in STEM Quasi-Experiments",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2016-09-30",
 "tot_intn_awd_amt": 790183.0,
 "awd_amount": 790183.0,
 "awd_min_amd_letter_date": "2012-09-20",
 "awd_max_amd_letter_date": "2016-01-14",
 "awd_abstract_narration": "Experimental designs in education that include treatment and control groups that are randomly assigned to different conditions of an intervention are considered the most rigorous choice to be able to evaluate causal claims. However, a randomized controlled trial (RCT) is frequently not feasible in developing evidence around the impact of many STEM practices, programs and policies. Researchers from Northwestern University examine how quasi-experimental designs that include treatment and comparison groups and outcome measures, but that do not include the random assignment to treatment and control conditions, might produce the same quality of findings as experimental designs. The researchers are also examining if pretreatment measures of study outcomes might be replaced with proxy pretests, measures in the same domain as an original pretest but in a different form, to replicate the findings from experimental studies using the original pretest. Many STEM research studies frequently have access in quasi-experimental studies for data from these proxy pretests in archival datasets, such as the state longitudinal data systems.\r\n\r\nResearchers in this project have identified a number of RCTs that they use to examine whether changing the nature of the comparison group, from the original randomly assigned group, to one that is statistically adjusted from a larger population will show similar causal estimates as the original RCT. Using a within-study comparison, the researchers determine the differences in the RCT and quasi-experimental findings. They are studying the use of proxy pretreatment tests, such as math achievement data from state longitudinal data systems, to examine the extent to which these measures replicate findings in the original RCTs. They also examine the effect that modeling with a number of pre-intervention covariates has on causal estimates. If the differences between the causal estimates in the RCT and the new quasi-experimental study are low, then the quasi-experimental design is adequate to measure impact. \r\n \r\nLarge data sets are increasingly available in education, especially with the development of district and local data systems that expand the information gathered about students, teachers and schools. These data sets provide opportunities for research and evaluation studies that can operate with population level data rather than samples of data drawn randomly from the population. The determination of the quality of quasi-experimental evaluation designs that result from this study provides information that can be used by policy makers and researchers to study questions about educational treatments, programs and policies that have been intractable to study. Removing the potential barrier of random assignment, while still maintaining the quality of an RCT, expands the methodological toolkit of evaluators.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "Cook",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas Cook",
   "pi_email_addr": "TomCook6@gwu.edu",
   "nsf_id": "000756433",
   "pi_start_date": "2012-09-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2040 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602084100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "726100",
   "pgm_ele_name": "Project & Program Evaluation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 790183.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!--  /* Font Definitions */ @font-face \t{font-family:\"Cambria Math\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1107305727 0 0 415 0;} @font-face \t{font-family:DengXian; \tpanose-1:2 1 6 0 3 1 1 1 1 1; \tmso-font-charset:134; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-1610612033 953122042 22 0 262159 0;} @font-face \t{font-family:Calibri; \tpanose-1:2 15 5 2 2 2 4 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1073786111 1 0 415 0;}  /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin:0in; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:12.0pt; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:DengXian; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p \t{mso-style-noshow:yes; \tmso-style-priority:99; \tmso-margin-top-alt:auto; \tmargin-right:0in; \tmso-margin-bottom-alt:auto; \tmargin-left:0in; \tmso-pagination:widow-orphan; \tfont-size:12.0pt; \tfont-family:\"Times New Roman\"; \tmso-fareast-font-family:DengXian; \tmso-fareast-theme-font:minor-fareast;} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-family:Calibri; \tmso-ascii-font-family:Calibri; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:DengXian; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Calibri; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} @page WordSection1 \t{size:8.5in 11.0in; \tmargin:1.0in 1.0in 1.0in 1.0in; \tmso-header-margin:.5in; \tmso-footer-margin:.5in; \tmso-paper-source:0;} div.WordSection1 \t{page:WordSection1;} -->\n<p>The outcomes in question fall into three categories- those concerning the role of the pretest in basic non-equivalent control group designs, the role of the pretest in interrupted time series designs, and the role of the pretest when added to regression discontinuity designs. All the results we report were generated from within-study comparisons that test the difference between the causal estimates from a non-experiment and a randomized experiment that share the same treatment. In this way of proceeding, the randomized experiment serves as the causal benchmark, and non-experimental estimates with pretests are evaluated relative to this benchmark. If the non-experimental and experimental estimates do not differ, there is no evidence of bias in the non-experiment. If they do differ, this is taken as evidence of bias in the non-experiment with a pretest, and the extent of bias is indicated by the size of the difference between the experimental and non-experimental estimates.</p>\n<p>a) <span><span style=\"text-decoration: underline;\">the pretest in basic non-equivalent control group designs.</span></span>&nbsp;Across all the studies we conducted and reviewed, it is clear than in education research use of a pretest measure of the study outcome almost always reduces bias. This is because the pretest is almost always correlated with the selection process into treatment and is very highly correlated with the study outcome over periods up to one year. As a result the pretest meets the theoretical requirement of being correlated with that part of the selection process that is related to the effect being examined. Sometimes, the pretest suffices to control for all of the bias in a non-experiment, but it cannot be relied upon to consistently reduce all of the bias, even if some or even much of it is reduced. In the long run, the pretest is likely to be one of several factors used to control for bias, including the use of an even richer pre-intervention covariate set and the choice of non-equivalent comparison groups that are local to the treatment groups under examination.</p>\n<p>b) <span><span style=\"text-decoration: underline;\">the pretest in the context of interrupted time series studies.</span></span></p>\n<p>The project conducted three tests of how adding up to seven pretest timepoints affected the amount of bias reduction achieved. There is a considerable literature on interrupted time series and it shows that a description of pre-intervention time trends can help in describing a large part of the selection process into treatment. The researcher can see how different the treatment and comparison groups are in their means and time trends. When time trend differences between treatment and control groups are not clear, it is common to match the two groups on their means and slopes. The studies we conducted examined both matched and unmatched time series, and they showed that adding school level data at multiple pre-intevention time points effectively reduced all of the selection bias in two of the datasets and in part of a third. In the remaining case, despite matching, much of the selection bias was not removed. Although there are only three studies to date, it seems like adding pre-intervention timepoints helps in reducing bias irrespective of the way in which treatment and comparison groups differ over time. But it also seems that adding this extra pre-intervention data cannot be relied on to reduce bias to an acceptable level.</p>\n<p>&nbsp;</p>\n<p>c) <span><span style=\"text-decoration: underline;\">adding pretest data to basic regression discontinuity studies.</span></span>Basic regression discontinuity studies suffer from lower statistical power than a randomized experiment, dependence on functional form assumptions, and a lesser causal generalization because the treatment effect in RD is estimated only at the treatment cutoff. Three studies explored whether adding the pretest could mitigate these problems. Two of them were deliberately selected to have large samples, Wing and Cook (2013) and Tang, Cook, Kisbu-Sakarya, Hock, and Chiang (in press), while the third was set up to be a deliberate small sample stress test, Kisbu-Sakarya, Cook, and Tang (in press). The first two studies showed that adding a pretest to basic RD resulted in causal generalization away from the cutoff that was similar in the randomized experiment and comparative regression discontinuity studies and that the two designs had basically similar standard errors. In each case also the regression lines were parallel, indicating no functional form complexities. The implication is that adding a pretest to basic RD mitigated two of its major problems when there were no serious functional form complexities. In the third study, the results were not similar and were not intended to be, given the deliberate choice of the small sample design. The message from the two larger size studies is that adding a pretest can have important benefits for regression discontinuity designs if the sample sizes are large and if the functional forms are clear.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/25/2017<br>\n\t\t\t\t\tModified by: Thomas&nbsp;D&nbsp;Cook</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe outcomes in question fall into three categories- those concerning the role of the pretest in basic non-equivalent control group designs, the role of the pretest in interrupted time series designs, and the role of the pretest when added to regression discontinuity designs. All the results we report were generated from within-study comparisons that test the difference between the causal estimates from a non-experiment and a randomized experiment that share the same treatment. In this way of proceeding, the randomized experiment serves as the causal benchmark, and non-experimental estimates with pretests are evaluated relative to this benchmark. If the non-experimental and experimental estimates do not differ, there is no evidence of bias in the non-experiment. If they do differ, this is taken as evidence of bias in the non-experiment with a pretest, and the extent of bias is indicated by the size of the difference between the experimental and non-experimental estimates.\n\na) the pretest in basic non-equivalent control group designs. Across all the studies we conducted and reviewed, it is clear than in education research use of a pretest measure of the study outcome almost always reduces bias. This is because the pretest is almost always correlated with the selection process into treatment and is very highly correlated with the study outcome over periods up to one year. As a result the pretest meets the theoretical requirement of being correlated with that part of the selection process that is related to the effect being examined. Sometimes, the pretest suffices to control for all of the bias in a non-experiment, but it cannot be relied upon to consistently reduce all of the bias, even if some or even much of it is reduced. In the long run, the pretest is likely to be one of several factors used to control for bias, including the use of an even richer pre-intervention covariate set and the choice of non-equivalent comparison groups that are local to the treatment groups under examination.\n\nb) the pretest in the context of interrupted time series studies.\n\nThe project conducted three tests of how adding up to seven pretest timepoints affected the amount of bias reduction achieved. There is a considerable literature on interrupted time series and it shows that a description of pre-intervention time trends can help in describing a large part of the selection process into treatment. The researcher can see how different the treatment and comparison groups are in their means and time trends. When time trend differences between treatment and control groups are not clear, it is common to match the two groups on their means and slopes. The studies we conducted examined both matched and unmatched time series, and they showed that adding school level data at multiple pre-intevention time points effectively reduced all of the selection bias in two of the datasets and in part of a third. In the remaining case, despite matching, much of the selection bias was not removed. Although there are only three studies to date, it seems like adding pre-intervention timepoints helps in reducing bias irrespective of the way in which treatment and comparison groups differ over time. But it also seems that adding this extra pre-intervention data cannot be relied on to reduce bias to an acceptable level.\n\n \n\nc) adding pretest data to basic regression discontinuity studies.Basic regression discontinuity studies suffer from lower statistical power than a randomized experiment, dependence on functional form assumptions, and a lesser causal generalization because the treatment effect in RD is estimated only at the treatment cutoff. Three studies explored whether adding the pretest could mitigate these problems. Two of them were deliberately selected to have large samples, Wing and Cook (2013) and Tang, Cook, Kisbu-Sakarya, Hock, and Chiang (in press), while the third was set up to be a deliberate small sample stress test, Kisbu-Sakarya, Cook, and Tang (in press). The first two studies showed that adding a pretest to basic RD resulted in causal generalization away from the cutoff that was similar in the randomized experiment and comparative regression discontinuity studies and that the two designs had basically similar standard errors. In each case also the regression lines were parallel, indicating no functional form complexities. The implication is that adding a pretest to basic RD mitigated two of its major problems when there were no serious functional form complexities. In the third study, the results were not similar and were not intended to be, given the deliberate choice of the small sample design. The message from the two larger size studies is that adding a pretest can have important benefits for regression discontinuity designs if the sample sizes are large and if the functional forms are clear.\n\n\t\t\t\t\tLast Modified: 01/25/2017\n\n\t\t\t\t\tSubmitted by: Thomas D Cook"
 }
}