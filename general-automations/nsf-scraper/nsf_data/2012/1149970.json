{
 "awd_id": "1149970",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Designing Socially Adept Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-01-15",
 "awd_exp_date": "2018-12-31",
 "tot_intn_awd_amt": 498245.0,
 "awd_amount": 498245.0,
 "awd_min_amd_letter_date": "2012-01-23",
 "awd_max_amd_letter_date": "2016-02-07",
 "awd_abstract_narration": "Robots hold the promise of delivering significant social contributions in such key domains as education, rehabilitation, and collaboration, but to achieve this promise they must be able to communicate effectively with people. The goal of this project is to design effective social behaviors for robots by modeling human verbal, vocal, and nonverbal behavior using computational tools, regenerating them in robots, and evaluating their effectiveness in human-robot studies in social scenarios such as storytelling, interview, conversation, instruction, and collaborative work. The research will follow an interdisciplinary approach, combining computational and social-scientific methods toward advancing the state of the art in robotic technology.\r\n\r\nIntellectual Merit: The research will create a set of design specifications that robot designers can use to create robots that effectively communicate with people. These specifications will be openly disseminated to robot designers and researchers as modules for the open-source Robot Operating System (ROS). The project will also lead to new computational tools that will enable modeling human behavior and synthesizing effective behaviors for robots. In addition, this research will contribute to social science by providing a more detailed, computational understanding of human social behavior. \r\n\r\nBroader Impacts: The research will enable robots to communicate more effectively with people in such critical domains as education, collaborative work, and health and wellbeing. The projects will also introduce computational tools into areas that have not yet substantially benefited from advancements in computer technology, such as the diagnosis and treatment of autism and traumatic brain injury. Through an integrated education and outreach program, this project will also contribute to interdisciplinary education, undergraduate and graduate curricula, K-12 and special education, public understanding of science and technology, and further inclusion of minorities and children with disabilities in scientific research and education.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bilge",
   "pi_last_name": "Mutlu",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Bilge D Mutlu",
   "pi_email_addr": "bilge@cs.wisc.edu",
   "nsf_id": "000546805",
   "pi_start_date": "2012-01-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "1210 W. Dayton St.",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537061613",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 106832.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 93537.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 96343.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 99256.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 102277.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Social robots -- robotic technologies that interact with people using human <em>social</em> norms of communication -- hold tremendous potential as intelligent assistants, companions, and collaborators for people in day-to-day tasks and environments. However, the success of these technologies will depend largely on their ability to effectively use human social norms. As \"socially adept\" technologies, they must accurately understand the social behaviors and intent of their users and effectively produce social behaviors that their users can understand. This project aimed to develop design principles, computational methods, algorithms, and technologies toward realizing such socially adept robots and unlocking their societal potential.&nbsp;</p>\n<p><br />To achieve the goal of creating social capabilities for robots, the project generated computer models of human behavior, translated these models into algorithms that robots can use to interpret or demonstrate social behavior, implemented these algorithms on robot systems, and tested their effectiveness in enabling robots to interact with people in socially adept ways. For example, the research team studied how people moved their eyes while making a selection from among many options, such as choosing toppings for a sandwich, using eye-tracking technology. The team then developed a machine-learning algorithm that predicted, based on eye-movement patterns, what people would select about two seconds before they made a selection with high accuracy. They then implemented this algorithm on a robotic assistant that predicted what users would be requesting and proactively fulfilled these requests to more quickly assist its user and to offer a more positive user experience.</p>\n<p><br />The example above illustrates the body of <em>scientific</em> and <em>practical</em> knowledge that the project generated. The scientific contributions of the project will serve as a foundation for future discovery in social robotics, and industry will build on its practical contributions to design and develop novel robotic products that will benefit society. These scientific contributions have been shared with other researchers through more than two dozen peer-review publications, three doctoral dissertations in computer science, and one master's dissertation in electrical and computer engineering. The project has also provided an interdisciplinary group of graduate and undergraduate students with opportunities for advanced research training, professional development, and career advancement in STEM fields. Finally, the project team organized a range of activities aimed at informing members of the public about social robotics. Most notably, the project team offered multiple sessions of a two-day \"Social Robotics\" summer-camp program each year of the project, enrolling nearly 200 grandparent-grandchild pairs.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/01/2019<br>\n\t\t\t\t\tModified by: Bilge&nbsp;D&nbsp;Mutlu</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686665255_Figures.001--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686665255_Figures.001--rgov-800width.jpg\" title=\"Design space for social robots\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686665255_Figures.001--rgov-66x44.jpg\" alt=\"Design space for social robots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An illustration of the design space for social robots, highlighting the behavioral elements that a robot can use to engage in social interaction with people</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Design space for social robots</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686846426_Figures.002--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686846426_Figures.002--rgov-800width.jpg\" title=\"Studying human eye movements\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686846426_Figures.002--rgov-66x44.jpg\" alt=\"Studying human eye movements\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of how people moved their eyes while making a selection from among many options using eye tracking</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Studying human eye movements</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686971371_Figures.003--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686971371_Figures.003--rgov-800width.jpg\" title=\"Proactive robotic assistant\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556686971371_Figures.003--rgov-66x44.jpg\" alt=\"Proactive robotic assistant\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The robotic assistant that predicted what its user would be requesting based on user gaze patterns and proactively fulfilled the request</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Proactive robotic assistant</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687816750_Figures.005--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687816750_Figures.005--rgov-800width.jpg\" title=\"Robot pointing toward objects\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687816750_Figures.005--rgov-66x44.jpg\" alt=\"Robot pointing toward objects\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The study of how social robots might use different kinds of human pointing gestures to effectively communicate with their users</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Robot pointing toward objects</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687992846_Figures.006--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687992846_Figures.006--rgov-800width.jpg\" title=\"Reading companion robot\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556687992846_Figures.006--rgov-66x44.jpg\" alt=\"Reading companion robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The social reading companion robot designed by the research team to improve reading interest and motivation in children</div>\n<div class=\"imageCredit\">Andy Manis</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Reading companion robot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556688454783_Figures.004--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556688454783_Figures.004--rgov-800width.jpg\" title=\"Adaptive robotic collaborator\"><img src=\"/por/images/Reports/POR/2019/1149970/1149970_10150129_1556688454783_Figures.004--rgov-66x44.jpg\" alt=\"Adaptive robotic collaborator\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A robotic collaborator that adapts its handover behavior to the task availability of its user</div>\n<div class=\"imageCredit\">Wisconsin HCI Laboratory</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Bilge&nbsp;D&nbsp;Mutlu</div>\n<div class=\"imageTitle\">Adaptive robotic collaborator</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nSocial robots -- robotic technologies that interact with people using human social norms of communication -- hold tremendous potential as intelligent assistants, companions, and collaborators for people in day-to-day tasks and environments. However, the success of these technologies will depend largely on their ability to effectively use human social norms. As \"socially adept\" technologies, they must accurately understand the social behaviors and intent of their users and effectively produce social behaviors that their users can understand. This project aimed to develop design principles, computational methods, algorithms, and technologies toward realizing such socially adept robots and unlocking their societal potential. \n\n\nTo achieve the goal of creating social capabilities for robots, the project generated computer models of human behavior, translated these models into algorithms that robots can use to interpret or demonstrate social behavior, implemented these algorithms on robot systems, and tested their effectiveness in enabling robots to interact with people in socially adept ways. For example, the research team studied how people moved their eyes while making a selection from among many options, such as choosing toppings for a sandwich, using eye-tracking technology. The team then developed a machine-learning algorithm that predicted, based on eye-movement patterns, what people would select about two seconds before they made a selection with high accuracy. They then implemented this algorithm on a robotic assistant that predicted what users would be requesting and proactively fulfilled these requests to more quickly assist its user and to offer a more positive user experience.\n\n\nThe example above illustrates the body of scientific and practical knowledge that the project generated. The scientific contributions of the project will serve as a foundation for future discovery in social robotics, and industry will build on its practical contributions to design and develop novel robotic products that will benefit society. These scientific contributions have been shared with other researchers through more than two dozen peer-review publications, three doctoral dissertations in computer science, and one master's dissertation in electrical and computer engineering. The project has also provided an interdisciplinary group of graduate and undergraduate students with opportunities for advanced research training, professional development, and career advancement in STEM fields. Finally, the project team organized a range of activities aimed at informing members of the public about social robotics. Most notably, the project team offered multiple sessions of a two-day \"Social Robotics\" summer-camp program each year of the project, enrolling nearly 200 grandparent-grandchild pairs. \n\n\t\t\t\t\tLast Modified: 05/01/2019\n\n\t\t\t\t\tSubmitted by: Bilge D Mutlu"
 }
}