{
 "awd_id": "1231620",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHB: Type I (EXP): Algorithms for Unsupervised and Online Learning of Hierarchy of Features for Tuning Cochlear Implants for the Hearing Impaired",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2016-12-31",
 "tot_intn_awd_amt": 298203.0,
 "awd_amount": 298203.0,
 "awd_min_amd_letter_date": "2012-08-31",
 "awd_max_amd_letter_date": "2012-08-31",
 "awd_abstract_narration": "Since noteworthy events happen only occasionally in any data, it is imperative for smart sensors to learn the norms in data so that authorities can be alerted and appropriate action can be taken at the occurrence of an abnormal or noteworthy event. The aim of this project is to develop algorithms that can learn the norm in terms of a hierarchy of meaningful features from data in an unsupervised and online manner. The application testbed is the problem of automatically tuning cochlear implants (CIs) of patients with severe-to-profound hearing loss by continuously monitoring their speech output. The working hypothesis is that deficiencies in hearing for people with significant hearing loss are reflected in their speech production. This project will develop and use unsupervised, online, and biologically plausible machine learning algorithms to learn feature hierarchies from the speech output data of severely-to-profoundly hearing-impaired patients. The learned feature hierarchy from the speech of a patient will be compared to those learned from the speech of a comparable normal hearing population. Deficiencies in the patient's hearing will be ascertained by identifying the missing or distorted features. Algorithms will be developed to map this information into the signal processing strategies used in CIs to enhance the audibility of speech.\r\n\r\nThe proposed project promises transformative changes to three major interdisciplinary fields: machine learning and artificial intelligence, healthcare, and sensors. It will transform the traditional ways in which the clinical needs of patients are met. For example, the results of this project will provide doctors with evidence-based practices that will better address the specific needs of individual patients by monitoring each patient around the clock at minimal effort and cost.\r\n\r\nHearing loss is the most common birth defect in the U.S. with slightly over 15,000 new pediatric cases each year and societal losses amounting to $4.6 billion over a lifetime. A proven technology for CI tuning would make a significant difference to the lives of over 1.2 million CI candidates in the U.S. and many more around the world, thereby leading to substantial health and economic benefits to society. Other than CI tuning, the proposed algorithms will be applicable to a variety of monitoring applications within healthcare, such as blood pressure, cerebrospinal fluid pressure, intracavitary pressure of the bladder, etc., and beyond healthcare, such as web, machine health, traffic, etc. Continuous monitoring with wearable and implantable body sensors will increase early detection of emergency conditions and diseases in at-risk patients and also provide a wide range of healthcare services for people with various degrees of cognitive and physical disabilities. Not only the elderly and chronically ill, but also the families in which both parents have to work will benefit from these systems to provide high-quality care services for their babies and children. Finally, the proposed project will integrate diversity by promoting teaching, learning, and interdisciplinary research among underrepresented groups.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Bonny",
   "pi_last_name": "Banerjee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Bonny Banerjee",
   "pi_email_addr": "bbnerjee@memphis.edu",
   "nsf_id": "000602614",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Lisa",
   "pi_last_name": "Mendel",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Lisa L Mendel",
   "pi_email_addr": "lmendel@memphis.edu",
   "nsf_id": "000616020",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Memphis",
  "inst_street_address": "115 JOHN WILDER TOWER",
  "inst_street_address_2": "",
  "inst_city_name": "MEMPHIS",
  "inst_state_code": "TN",
  "inst_state_name": "Tennessee",
  "inst_phone_num": "9016783251",
  "inst_zip_code": "381520001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TN09",
  "org_lgl_bus_name": "UNIVERSITY OF MEMPHIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "F2VSMAKDH8Z7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Memphis",
  "perf_str_addr": "",
  "perf_city_name": "Memphis",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "381523370",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8061",
   "pgm_ref_txt": "SCH Type I:  EXP"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 298203.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"CM12\">A cochlear implant (CI) is an electronic device that is surgically implanted into the cochlea and directly stimulates surviving auditory nerve fibers. Over 325,000 adults and children in the United States have received CIs, and these devices have provided considerable benefits to those who use them by reducing barriers to communication and restoring individuals&rsquo; ability to hear, achieving age-appropriate reading skills, and developing communication skills comparable to their hearing counterparts. Tuning a CI for each individual is challenging due to: (1) lack of adequate data to reliably estimate the nature of an individual's hearing loss, (2) heterogeneity of the hearing-impaired population, and (3) large number of adjustable CI parameters with complex inter-relations.</p>\n<p class=\"Default\">In this project, the working hypothesis was that the deficiencies in hearing for individuals with severe-to-profound hearing loss are reflected in their speech&nbsp;(Ryalls et al., 2003). It is assumed that algorithms can reside in the CI device and tune it internally, as proposed by Krause et al. (2010), thereby having continuous access to the user&rsquo;s speech. To the best of knowledge, this project was the first to investigate the nature of hearing loss of each individual&nbsp;using learned features. The features were learned from each severely-to-profoundly hearing-impaired&nbsp;individual's speech using machine learning algorithms. Using a set of neurophysiological&nbsp;metrics, the features learned from a hearing-impaired individual and those from a normal hearing individual were compared to infer the nature of hearing loss.</p>\n<p class=\"Default\">A rich set of data was collected from 40 adult individuals (30 hearing impaired, 10 normal) that will continue to facilitate algorithmic research on analyzing the nature of hearing loss and devising methods for improving hearing.&nbsp;The corpus of recordings obtained in this project represents a unique compilation of speech production output by individuals with significant hearing loss that was not available before. Acoustic analysis of the frequency, amplitude and timing components of this speech provides important information regarding the speech production characteristics of speakers who have normal speech production as well as those whose speech intelligibility varies from being highly intelligible to being unintelligible.</p>\n<p class=\"Default\">From this project, 5 journal articles, 17 conference/workshop/symposium papers and 14 extended abstracts have been published/presented. In addition, one manuscript is under review in a journal while 3 manuscripts are under preparation for submission to journals. The areas of interest of these venues include audiology, speech perception and production, computational neuroscience, data mining, Big Data, artificial intelligence, machine learning and neural networks. The PIs have been in communication with the industry (Cochlear Limited) to determine the feasibility of bringing this technology to the cochlear implant market.</p>\n<p>The potential impact of this study on the discipline of communication sciences and disorders (CSD) is substantial. It is expected that the proposed algorithms will assist audiologists in tuning CIs based on each individual&rsquo;s hearing deficiencies. That will not only provide significant hearing benefits to recipients, but economic benefits as well to both the recipients and to society at large by enabling recipients to return to work and/or enhance their productivity at work, leading to significant reduction in costs related to healthcare and other support programs. Presentation of findings to the CSD community has received positive feedback and significant interest from researchers, clinicians, and CI manufacturers who are anxious to implement the results of this work with actual CI patients.</p>\n<p>Six doctoral and four Masters students in electrical and computer engineering and CSD have been partially funded from this project.&nbsp;The students in engineering were exposed to CSD and received hands-on experience in conducting interdisciplinary research. This close interaction among computational scientists/engineers, speech and hearing scientists, and clinical audiologists helped to develop a culture disposed to interdisciplinary research in computational speech and hearing sciences at the University of Memphis. The fields of artificial intelligence, machine learning and data mining were enriched by the development of algorithms for a real-world problem that matters.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/30/2017<br>\n\t\t\t\t\tModified by: Bonny&nbsp;Banerjee</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "A cochlear implant (CI) is an electronic device that is surgically implanted into the cochlea and directly stimulates surviving auditory nerve fibers. Over 325,000 adults and children in the United States have received CIs, and these devices have provided considerable benefits to those who use them by reducing barriers to communication and restoring individuals? ability to hear, achieving age-appropriate reading skills, and developing communication skills comparable to their hearing counterparts. Tuning a CI for each individual is challenging due to: (1) lack of adequate data to reliably estimate the nature of an individual's hearing loss, (2) heterogeneity of the hearing-impaired population, and (3) large number of adjustable CI parameters with complex inter-relations.\nIn this project, the working hypothesis was that the deficiencies in hearing for individuals with severe-to-profound hearing loss are reflected in their speech (Ryalls et al., 2003). It is assumed that algorithms can reside in the CI device and tune it internally, as proposed by Krause et al. (2010), thereby having continuous access to the user?s speech. To the best of knowledge, this project was the first to investigate the nature of hearing loss of each individual using learned features. The features were learned from each severely-to-profoundly hearing-impaired individual's speech using machine learning algorithms. Using a set of neurophysiological metrics, the features learned from a hearing-impaired individual and those from a normal hearing individual were compared to infer the nature of hearing loss.\nA rich set of data was collected from 40 adult individuals (30 hearing impaired, 10 normal) that will continue to facilitate algorithmic research on analyzing the nature of hearing loss and devising methods for improving hearing. The corpus of recordings obtained in this project represents a unique compilation of speech production output by individuals with significant hearing loss that was not available before. Acoustic analysis of the frequency, amplitude and timing components of this speech provides important information regarding the speech production characteristics of speakers who have normal speech production as well as those whose speech intelligibility varies from being highly intelligible to being unintelligible.\nFrom this project, 5 journal articles, 17 conference/workshop/symposium papers and 14 extended abstracts have been published/presented. In addition, one manuscript is under review in a journal while 3 manuscripts are under preparation for submission to journals. The areas of interest of these venues include audiology, speech perception and production, computational neuroscience, data mining, Big Data, artificial intelligence, machine learning and neural networks. The PIs have been in communication with the industry (Cochlear Limited) to determine the feasibility of bringing this technology to the cochlear implant market.\n\nThe potential impact of this study on the discipline of communication sciences and disorders (CSD) is substantial. It is expected that the proposed algorithms will assist audiologists in tuning CIs based on each individual?s hearing deficiencies. That will not only provide significant hearing benefits to recipients, but economic benefits as well to both the recipients and to society at large by enabling recipients to return to work and/or enhance their productivity at work, leading to significant reduction in costs related to healthcare and other support programs. Presentation of findings to the CSD community has received positive feedback and significant interest from researchers, clinicians, and CI manufacturers who are anxious to implement the results of this work with actual CI patients.\n\nSix doctoral and four Masters students in electrical and computer engineering and CSD have been partially funded from this project. The students in engineering were exposed to CSD and received hands-on experience in conducting interdisciplinary research. This close interaction among computational scientists/engineers, speech and hearing scientists, and clinical audiologists helped to develop a culture disposed to interdisciplinary research in computational speech and hearing sciences at the University of Memphis. The fields of artificial intelligence, machine learning and data mining were enriched by the development of algorithms for a real-world problem that matters.\n\n\t\t\t\t\tLast Modified: 01/30/2017\n\n\t\t\t\t\tSubmitted by: Bonny Banerjee"
 }
}