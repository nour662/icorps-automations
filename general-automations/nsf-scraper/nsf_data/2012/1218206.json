{
 "awd_id": "1218206",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Small: Analytical Modeling and Design Methodology for Large-scale Computational Systems Employing Flexible Electronics for Extensive Physical Interfacing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2016-06-30",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2012-06-12",
 "awd_max_amd_letter_date": "2012-08-08",
 "awd_abstract_narration": "Electronics has enabled substantial computational capabilities in small-scale devices; this means that signals from physical systems can be presented to these devices to derive high-value outputs. The challenge is that although immense computational capacity can be realized in embedded devices, the ability to acquire a large number of signals that are distributed across a physical system, and to then communicate information over the associated distances, remains disproportionately small. Technologies are emerging, however, that enable transformational possibilities for creating communication channels and large-scale physical interfaces to electronics. Large-area electronics is a technology that enables the fabrication of interconnects as well as expansive arrays of diverse sensors on flexible, low-cost sheets. When combined with high-performance silicon integrated circuits (ICs), this technology can lead to systems where computation can be applied to physical signals on a much larger scale than that possible today. The resulting design space for the systems covers two technology domains. To create efficient and scalable systems, the platform components and hardware architectures must be analyzed rigorously, and methodologies for understanding and optimizing design trade-offs must be developed. The objective of this research is to analytically model the platform components and architectures for sensing and communication, and then to synthesize these into system design methodologies. The platform architectures include interfaces for digital and analog signaling, control circuits for sensing, and communication networks scalable to many nodes. The methodologies span analysis at the device, architecture, and system-protocol levels.    \r\n\r\nSome of the compelling applications that require large-scale interfacing of electronics with physical systems include detection of early-stage structural degradation in bridges and buildings through centimeter-resolution strain sensing, interactive surfaces for visually-rich computing via high-resolution displays and input sensors, etc. Large-area electronics and high-performance ICs, used synergistically, have the potential to enable such applications. By developing analytical models and methodologies for system design, this research aims to unite the efforts from both the technology-development and computer-systems domains. The outcomes of this study will help coordinate and focus research and engineering efforts in these areas towards the creation of optimal systems. This research will also engage a new generation of engineers, particularly from underrepresented groups, through the unique opportunity to develop systematic principles for the design of computing systems that interact extensively with physical systems. The broadened focus and new form-factors possible for computing systems will be illustrated to students through undergraduate projects and special-topic courses, as well as through Princeton outreach programs such as the Science and Engineering Expo for middle-school students, the Materials Camp for teachers, and the Princeton University Materials Academy for under-represented high-school students.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Naveen",
   "pi_last_name": "Verma",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Naveen Verma",
   "pi_email_addr": "nverma@princeton.edu",
   "nsf_id": "000539765",
   "pi_start_date": "2012-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sigurd",
   "pi_last_name": "Wagner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sigurd Wagner",
   "pi_email_addr": "wagner@princeton.edu",
   "nsf_id": "000269042",
   "pi_start_date": "2012-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Sturm",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "James C Sturm",
   "pi_email_addr": "sturm@Princeton.EDU",
   "nsf_id": "000201010",
   "pi_start_date": "2012-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "The Trustees Princeton University",
  "perf_str_addr": "Electrical Engineering",
  "perf_city_name": "B226 Engineering Quad B-Wi",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7938",
   "pgm_ref_txt": "SENSOR NETWORKS"
  },
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project was to create systems that exploit the large number of diverse and distributed sensors possible through Large-Area Electronics (LAE) within intelligent sensing systems. LAE is a technology based on low-temperature processing (&lt;200C) of thin films. This enables compatibility with a broad range of materials and substrates, leading to diverse sensors that can be integrated on large and flexible substrates, such as glass, plastics, paper. Intelligent sensing, however, implies the ability to extract specific inferences from the large and diverse arrays of sensors. Unfortunately, while LAE does enable the creation of thin-film transistors (TFTs), low-temperature processing leads to very low performance for computational functions, making it necessary to transfer the sensor data to a computation-rich technology, such as silicon CMOS. This raises the need for an extremely large number of interfaces, limiting the scalability of systems. Instead, the approach taken in this project is to develop computational models and architectures aligned to the characteristics of the low-performance, variation-prone TFTs that enable the raw sensor data to be aggregated and reduced to relevant information. This leads to far fewer interfaces to the silicon-CMOS domain for further processing.</p>\n<p>Canonically, systems reduce data to inferences of interest through feature-extraction and classification stages. Thus, this project explored algorithms for these operations that are amenable to TFT implementation. For feature extraction, the approach of compressive random projections was explored. Random projection involves taking random linear combinations of the sensor data. Various theoretical results have shown that, treating the data from all sensors as a vector, random projection preserves the inner products between the vectors. Further, inner products are used as a similarity metric between vectors in a number of pattern-recognition algorithms; so, such a method of compression preserves the information required for classification. Importantly, the linear combinations involved can be as simple as summation and subtraction between the sensor data, and random variations in the implementation affecting such operations are largely tolerated. Analysis based on variation and non-linearity models of the TFTs (calibrated to measured TFTs) was performed, showing that indeed high classification performance can be maintained even in the presence of severe TFT variation and large compression factors. From this, a system was demonstrated that employed an array of large-area image sensors, and a TFT block for compressive random-projection, followed by acquisition and classification. High classification performance was demonstrated for an image-recognition task classifying images of numerical digits (MNIST dataset).</p>\n<p>Taking the architectures for feature extraction further, an approach again based on random projection but in the context of compressive sensing, was explore. Typically in a system, specific feature transformations are desired, preceding classification in order to enhance performance. The approach above only performs compression, but preserves inner products of the original sensor vectors. In the next architecture investigated, analog filters and random modulators were employed to achieve the random linear combinations over the sensor data. Then, sampling at a reduced rate, possible through speed-limited TFT scanning circuits, was performed into the silicon-CMOS domain. Here, an approach to perform computationally-efficient reconstruction and then linear transformation of the features was developed and analyzed on a theoretical level. From this, a system for compressive acquisition and feature extraction of EEG signals was demonstrated, and the features were used to perform seizure detection (using analog replay of patient data from a medical dataset). High classification performance was achieved to significant compression factors.</p>\n<p>For classification, an approach known as Error-Adaptive Classifier Boosting (EACB) that extends the machine-learning algorithm of Adaptive Boosting (AdaBoost) was explored. In AdaBoost, multiple weak classifiers, which on their own are unable to fit arbitrary training data, are iteratively trained and their results are combined to form a strong classifier, which can be fit to arbitrary training data. In EACB, non-ideal implementations of weak classifiers are trained iterative, at each stage being biased to correct the errors of the previous iterations. Simple TFT based classifiers, approximating linear classifiers, but with significant non-linearity and variations, were analyzed. This showed that a strong classifier could indeed be constructed, when trained via EACB. From this, a classification system was demonstrated wherein the machine-learning model was stored using non-volatile charge trapping in the TFT classifiers. Coupling the classification system to an array of large-area image sensor, boosted classification performance at the level of an ideal implementation of a complex classifier (support-vector machine) was achieved in an image-classification application.</p>\n<p>This project demonstrated the promise of utilizing large-area sensors in intelligent sensing systems. In particular it exposed the importance of employing specialized algorithms and computational models to address the large number of interfaces from the sensors within architectures that can viably be implemented using TFTs.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/13/2016<br>\n\t\t\t\t\tModified by: Naveen&nbsp;Verma</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of this project was to create systems that exploit the large number of diverse and distributed sensors possible through Large-Area Electronics (LAE) within intelligent sensing systems. LAE is a technology based on low-temperature processing (&lt;200C) of thin films. This enables compatibility with a broad range of materials and substrates, leading to diverse sensors that can be integrated on large and flexible substrates, such as glass, plastics, paper. Intelligent sensing, however, implies the ability to extract specific inferences from the large and diverse arrays of sensors. Unfortunately, while LAE does enable the creation of thin-film transistors (TFTs), low-temperature processing leads to very low performance for computational functions, making it necessary to transfer the sensor data to a computation-rich technology, such as silicon CMOS. This raises the need for an extremely large number of interfaces, limiting the scalability of systems. Instead, the approach taken in this project is to develop computational models and architectures aligned to the characteristics of the low-performance, variation-prone TFTs that enable the raw sensor data to be aggregated and reduced to relevant information. This leads to far fewer interfaces to the silicon-CMOS domain for further processing.\n\nCanonically, systems reduce data to inferences of interest through feature-extraction and classification stages. Thus, this project explored algorithms for these operations that are amenable to TFT implementation. For feature extraction, the approach of compressive random projections was explored. Random projection involves taking random linear combinations of the sensor data. Various theoretical results have shown that, treating the data from all sensors as a vector, random projection preserves the inner products between the vectors. Further, inner products are used as a similarity metric between vectors in a number of pattern-recognition algorithms; so, such a method of compression preserves the information required for classification. Importantly, the linear combinations involved can be as simple as summation and subtraction between the sensor data, and random variations in the implementation affecting such operations are largely tolerated. Analysis based on variation and non-linearity models of the TFTs (calibrated to measured TFTs) was performed, showing that indeed high classification performance can be maintained even in the presence of severe TFT variation and large compression factors. From this, a system was demonstrated that employed an array of large-area image sensors, and a TFT block for compressive random-projection, followed by acquisition and classification. High classification performance was demonstrated for an image-recognition task classifying images of numerical digits (MNIST dataset).\n\nTaking the architectures for feature extraction further, an approach again based on random projection but in the context of compressive sensing, was explore. Typically in a system, specific feature transformations are desired, preceding classification in order to enhance performance. The approach above only performs compression, but preserves inner products of the original sensor vectors. In the next architecture investigated, analog filters and random modulators were employed to achieve the random linear combinations over the sensor data. Then, sampling at a reduced rate, possible through speed-limited TFT scanning circuits, was performed into the silicon-CMOS domain. Here, an approach to perform computationally-efficient reconstruction and then linear transformation of the features was developed and analyzed on a theoretical level. From this, a system for compressive acquisition and feature extraction of EEG signals was demonstrated, and the features were used to perform seizure detection (using analog replay of patient data from a medical dataset). High classification performance was achieved to significant compression factors.\n\nFor classification, an approach known as Error-Adaptive Classifier Boosting (EACB) that extends the machine-learning algorithm of Adaptive Boosting (AdaBoost) was explored. In AdaBoost, multiple weak classifiers, which on their own are unable to fit arbitrary training data, are iteratively trained and their results are combined to form a strong classifier, which can be fit to arbitrary training data. In EACB, non-ideal implementations of weak classifiers are trained iterative, at each stage being biased to correct the errors of the previous iterations. Simple TFT based classifiers, approximating linear classifiers, but with significant non-linearity and variations, were analyzed. This showed that a strong classifier could indeed be constructed, when trained via EACB. From this, a classification system was demonstrated wherein the machine-learning model was stored using non-volatile charge trapping in the TFT classifiers. Coupling the classification system to an array of large-area image sensor, boosted classification performance at the level of an ideal implementation of a complex classifier (support-vector machine) was achieved in an image-classification application.\n\nThis project demonstrated the promise of utilizing large-area sensors in intelligent sensing systems. In particular it exposed the importance of employing specialized algorithms and computational models to address the large number of interfaces from the sensors within architectures that can viably be implemented using TFTs.\n\n \n\n\t\t\t\t\tLast Modified: 10/13/2016\n\n\t\t\t\t\tSubmitted by: Naveen Verma"
 }
}