{
 "awd_id": "1217921",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Multicore Data-Structures: Relaxed, Flat, and Randomized",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2012-07-03",
 "awd_max_amd_letter_date": "2012-07-03",
 "awd_abstract_narration": "Most multicore data structures being designed and used in parallel software today are concurrent versions of the sequential data structures of years past.  They continue to work reasonably well because the level of parallelism offered by mainstream multicore machines is still low.  As machines grow in size, however, the limitations of these traditional structures will become clear: they have inherent sequential bottlenecks, require tight synchronization, and are not easily distributed.  This project will develop new classes of parallel data structures that combine relaxed specifications with highly decentralized randomized implementations, overcoming the drawbacks of existing structures and providing a better fit with tomorrow's massively parallel many-core machine designs. \r\n\r\nThis research will combine theoretical algorithmic work with empirical evaluation on real machines and applications, and will result in a library of concurrent data structures and a collection of design approaches and specification methodologies. Commercial software developers are in desperate need of data structures that scale while still remaining easy to understand and modify. Making this project's developed structures widely available will greatly help in making tomorrow's applications, whether they run on a cell phone or on a server in the cloud, make full use of the parallelism offered by multicore technology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nir",
   "pi_last_name": "Shavit",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nir Shavit",
   "pi_email_addr": "shanir@csail.mit.edu",
   "nsf_id": "000457678",
   "pi_start_date": "2012-07-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><dd>\n<div class=\"tinyMCEContent\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.5px Helvetica} p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 10.0px Helvetica} -->\n<p class=\"p1\">The move to multicore processors as our standard computing platform will force major changes in the way we design parallel software, and in particular in the way we design and use concurrent data structures. The goal of our research was to develop new concurrent data structures, not as lock-based or lock-free versions of sequential data structures, but rather from scratch as high throughput concurrent structures. We reevaluated the way in which concurrent data struc-tures are specied, implemented, and used in parallel programs. We then developed new types of relaxed shared concurrent objects: objects that have relaxed specications for which we then developed decentralized randomized implementations that are scalable since they have low overall communication and memory access rates.</p>\n<p>We developed a collection of data structures solving a variety of tasks. The SkipTrie, a low-depth concurrent search structure that allows fast randomized predecessor queries access without rebalancing.&nbsp;The Leaplist: a skiplist stype randomized concurrent data structrue using hardware transactions that allows efficient range queries. &nbsp;We also developed a new randomized Loose Renaming algorithm that takes only O(log log n) time to rename n items. We developed a new types of&nbsp;NUMA-aware reader-writer locks that allow for better scalaibility in concurrent data structure design. We develoepd the LevelArray: a fast, long-lived renaming algorithm. We proved mathematically that many lock-free concurrent algorithms are wait-free in practice without the need to restucture them. This introduces major potential saving in the cost of designing concurrent data structures, as programmers can avoid the overhead of wait-free algorithm design and still get all its benefits from lock-free ones. Finally, we developed the SprayList: a scalable relaxed priority queue based on randomization. For most of these data structures we provided code, available on the internet for public use.&nbsp;</p>\n</div>\n</dd><dd>\n<div class=\"tinyMCEContent\">\n<p>We belive that we have clearly shown that one can develop competitive concurrent algorithms, ones that greatly improve over traditional data structures parallelized using locks. The key techniques we developed exposed the crucial role of randomization and the use of relaxed specifications.&nbsp;</p>\n<p class=\"p2\">Commercial software developers are in desperate need of data structures that scale, and teh availability of structures and techniques developed in the project available to them will greatly help in making applications make full use of the parallelism offered by multicore machines.&nbsp;</p>\n</div>\n</dd>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/15/2016<br>\n\t\t\t\t\tModified by: Nir&nbsp;Shavit</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe move to multicore processors as our standard computing platform will force major changes in the way we design parallel software, and in particular in the way we design and use concurrent data structures. The goal of our research was to develop new concurrent data structures, not as lock-based or lock-free versions of sequential data structures, but rather from scratch as high throughput concurrent structures. We reevaluated the way in which concurrent data struc-tures are specied, implemented, and used in parallel programs. We then developed new types of relaxed shared concurrent objects: objects that have relaxed specications for which we then developed decentralized randomized implementations that are scalable since they have low overall communication and memory access rates.\n\nWe developed a collection of data structures solving a variety of tasks. The SkipTrie, a low-depth concurrent search structure that allows fast randomized predecessor queries access without rebalancing. The Leaplist: a skiplist stype randomized concurrent data structrue using hardware transactions that allows efficient range queries.  We also developed a new randomized Loose Renaming algorithm that takes only O(log log n) time to rename n items. We developed a new types of NUMA-aware reader-writer locks that allow for better scalaibility in concurrent data structure design. We develoepd the LevelArray: a fast, long-lived renaming algorithm. We proved mathematically that many lock-free concurrent algorithms are wait-free in practice without the need to restucture them. This introduces major potential saving in the cost of designing concurrent data structures, as programmers can avoid the overhead of wait-free algorithm design and still get all its benefits from lock-free ones. Finally, we developed the SprayList: a scalable relaxed priority queue based on randomization. For most of these data structures we provided code, available on the internet for public use. \n\n\n\n\nWe belive that we have clearly shown that one can develop competitive concurrent algorithms, ones that greatly improve over traditional data structures parallelized using locks. The key techniques we developed exposed the crucial role of randomization and the use of relaxed specifications. \nCommercial software developers are in desperate need of data structures that scale, and teh availability of structures and techniques developed in the project available to them will greatly help in making applications make full use of the parallelism offered by multicore machines. \n\n\n\n \n\n\t\t\t\t\tLast Modified: 11/15/2016\n\n\t\t\t\t\tSubmitted by: Nir Shavit"
 }
}