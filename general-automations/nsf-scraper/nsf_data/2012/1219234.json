{
 "awd_id": "1219234",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Graphical Approaches to Modeling High-Dimensional Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2012-08-15",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 294056.0,
 "awd_amount": 294056.0,
 "awd_min_amd_letter_date": "2012-08-15",
 "awd_max_amd_letter_date": "2012-08-15",
 "awd_abstract_narration": "This research involves theoretical and applied research on learning and representation of high-\r\ndimensional data. The term high dimensionality refers to the property that the number of variables\r\nor ?unknowns? is typically much larger than the number of observations available at hand. A key\r\nchallenge is being able to represent and learn such phenomena with sample and computational\r\nrequirements scaling favorably in the number of dimensions. This project addresses these challenges\r\nthrough a graphical approach by exploiting the inherent graphical structure present in many large\r\ndata-sets.\r\n\r\nThis research considers modeling high-dimensional data through probabilistic graphical models,\r\nalso known as Markov random fields. An important research thrust of this proposal is to develop\r\nnovel algorithms for learning and inference under the framework of graphical models. Another\r\nimportant thrust of this proposal is to develop efficient scalable models for representing high-\r\ndimensional data beyond the traditional framework of graphical models. This research establishes\r\nstrong theoretical guarantees for the developed methods, as well as applies them to real data in\r\nvarious domains, including genetic and financial data, and data from large online social networks\r\nsuch as Facebook and Twitter.\r\n\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Animashree",
   "pi_last_name": "Anandkumar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Animashree Anandkumar",
   "pi_email_addr": "anima@caltech.edu",
   "nsf_id": "000542748",
   "pi_start_date": "2012-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Irvine",
  "inst_street_address": "160 ALDRICH HALL",
  "inst_street_address_2": "",
  "inst_city_name": "IRVINE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9498247295",
  "inst_zip_code": "926970001",
  "inst_country_name": "United States",
  "cong_dist_code": "47",
  "st_cong_dist_code": "CA47",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA IRVINE",
  "org_prnt_uei_num": "MJC5FCYQTPE6",
  "org_uei_num": "MJC5FCYQTPE6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California Irvine",
  "perf_str_addr": "5171 California Ave. STE 150",
  "perf_city_name": "Irvine",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "926976000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "CA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 294056.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Research under this project involved learning and representation of high dimensional data.&nbsp;The term high dimensionality refers to the property that the number of variablesor &ldquo;unknowns&rdquo; is typically much larger than the number of observations available at hand. A key challenge is being able to represent and learn such phenomena with sample and computational requirements scaling favorably in the number of dimensions.&nbsp;This project addressed these challenges by exploiting the inherent relationships present in many large data-sets. We incorporated probabilistic graphical models with hidden variables and employed tensor factorization techniques to learn these models efficiently. In addition, we employed greedy graph-based techniques to learn challenging models such as mixtures of graphical models. We establish efficient computional and sample complexities for learning these model parameters consistently. We considered learning latent tree graphical models, which incorporate a hierarchy of latent variables, using &nbsp;divide and conquer techniques, which are used for parallelization without sacrificing on consistency guarantees. These techniques were employed in various domains such as social networks and bio-informatics, and were scalable to a large number of variables and data samples. These works have appeared in venues such as Neural Information Processing (NIPS), International Conference on Machine Learning (ICML), and Journal of Machine Learning Research (JMLR).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/13/2015<br>\n\t\t\t\t\tModified by: Animashree&nbsp;Anandkumar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nResearch under this project involved learning and representation of high dimensional data. The term high dimensionality refers to the property that the number of variablesor \"unknowns\" is typically much larger than the number of observations available at hand. A key challenge is being able to represent and learn such phenomena with sample and computational requirements scaling favorably in the number of dimensions. This project addressed these challenges by exploiting the inherent relationships present in many large data-sets. We incorporated probabilistic graphical models with hidden variables and employed tensor factorization techniques to learn these models efficiently. In addition, we employed greedy graph-based techniques to learn challenging models such as mixtures of graphical models. We establish efficient computional and sample complexities for learning these model parameters consistently. We considered learning latent tree graphical models, which incorporate a hierarchy of latent variables, using  divide and conquer techniques, which are used for parallelization without sacrificing on consistency guarantees. These techniques were employed in various domains such as social networks and bio-informatics, and were scalable to a large number of variables and data samples. These works have appeared in venues such as Neural Information Processing (NIPS), International Conference on Machine Learning (ICML), and Journal of Machine Learning Research (JMLR).\n\n\t\t\t\t\tLast Modified: 08/13/2015\n\n\t\t\t\t\tSubmitted by: Animashree Anandkumar"
 }
}