{
 "awd_id": "1207432",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: On-the-fly free energy parameterization in molecular simulations",
 "cfda_num": "47.049",
 "org_code": "03070000",
 "po_phone": "7032924942",
 "po_email": "dhess@nsf.gov",
 "po_sign_block_name": "Daryl Hess",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 198411.0,
 "awd_amount": 198411.0,
 "awd_min_amd_letter_date": "2012-08-27",
 "awd_max_amd_letter_date": "2012-08-27",
 "awd_abstract_narration": "TECHNICAL SUMMARY\r\n\r\nIn this project, funded by the Condensed Matter and Materials Theory Program, a new method is proposed for extracting free energies from molecular dynamics (MD) simulations.  The method is based on temperature-acceleration, wherein free energy gradients in some desired set of collective variables are sampled in a running MD simulation while simultaneously driving those collective variables over free energy barriers that would otherwise render traditional MD hopeless at such sampling.  These gradients are used as inputs into an optimization that minimizes the error associated with gradients of an analytical free energy by evolving that free energy?s parameters.   The method therefore takes as input an MD system, the definitions of whatever collective variables in which one would like to know the free energy, and a functional form for that free energy, and then the method produces the optimal set of parameters.  The method is formulated in a general way and is therefore expected to be applicable broadly to almost any desired collective variables.  This project will be devoted to developing this method particularly for applications involving deriving effective coarse-grained potentials for multiscale simulations and to the study of conformational statistics of large biomolecules. The project will also provide training and mentoring of underrepresented students in state of the art computational and numerical methods\r\n\r\nNON-TECHNICAL SUMMARY\r\n\r\nWhether in designing new drugs or new materials, or simply trying to understand how Nature works, computer simulations are important in understanding how matter behaves at the molecular level.  Bringing such molecular-level understanding into the realm of everyday perception requires statistical approaches that are not always straightforward and often quite expensive.  This project proposes a new statistical method for extracting information from molecular-level simulations.  The method is potentially much more efficient than existing approaches.  The research undertaken in this project will develop and apply this method to test systems relevant for biological and materials applications.   The project could significantly reduce the cost associated with obtaining high-quality information from simulations at the molecular level that at the intersections of chemistry, physics, and biology. The project will also provide training and mentoring of underrepresented students in state of the art computational and numerical methods. This work is supported by the Condensed Matter and Materials Theory Program.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMR",
 "org_div_long_name": "Division Of Materials Research",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Vanden-Eijnden",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Vanden-Eijnden",
   "pi_email_addr": "eve2@cims.nyu.edu",
   "nsf_id": "000188424",
   "pi_start_date": "2012-08-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "176500",
   "pgm_ele_name": "CONDENSED MATTER & MAT THEORY"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7569",
   "pgm_ref_txt": "CYBERINFRASTRUCTURE/SCIENCE"
  },
  {
   "pgm_ref_code": "7573",
   "pgm_ref_txt": "BIO-RELATED MATERIALS RESEARCH"
  },
  {
   "pgm_ref_code": "7574",
   "pgm_ref_txt": "CYBER INFRA FOR MATERIALS RES"
  },
  {
   "pgm_ref_code": "9161",
   "pgm_ref_txt": "SINGLE DIVISION/UNIVERSITY"
  },
  {
   "pgm_ref_code": "AMPP",
   "pgm_ref_txt": "ADVANCED MATERIALS & PROCESSING PROGRAM"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 198411.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>In recent years, Molecular Dynamics (MD) simulations have become more widespread as a tool to address</span><span>&nbsp;</span><span>problems at an atomistic level in physics, chemistry and biochemistry. As an example, the study of</span><span>&nbsp;</span><span>proteins implicated in different</span><span>&nbsp;</span><span>processes of life, is nowadays routinely performed in pharmaceutical</span><span>&nbsp;</span><span>companies. Indeed, the knowledge of the mechanism at the basis of the function (or malfunction)</span><span>&nbsp;</span><span>of proteins will guide direct intervention on them.</span></p>\n<div>Many of the phenomena that these studies address involve molecular conformational changes&nbsp;that occur on time-scales from the hundreds of nanoseconds up. Present day algorithms solve the&nbsp;equations of motion of the system&rsquo;s&nbsp;atoms with a timestep which is of the order of the femtoseconds&nbsp;(typically 1 or 2 fs). To give an example of the time required by a single-processor MD simulation, one&nbsp;step of MD for a system of a protein immersed in water (about&nbsp;16000 atoms), required .7 seconds on&nbsp;a last generation Intel computing machine, so it would take about 400 days for 100 ns. Using parallel&nbsp;architectures can help decreasing this time, and particular effort has been recently put in&nbsp;building&nbsp;specific machines and designing algorithms to perform unprecedentedly extended MD simulations. Such an approach is however focused on the idea of producing one (or very few) simulated&nbsp;trajectory of the system.&nbsp;Albeit extremely long, one single trajectory will certainly not be enough&nbsp;to describe the property of the system. In the context, the free energy is a fundamental quantity to help organize the output of MD simulations and focus on the behavior of a few collective variables of importance.&nbsp;Since the free energy is in&nbsp;essence the logarithm of the probability density function of these&nbsp;collective variables, it could in principle be calculated by histogram methods based on the binning of&nbsp;an MD trajectory. Such a direct approach, however, turns out to be&nbsp;very inefficient in general due to&nbsp;the time scale required for the trajectory to explore all the relevant regions of configuration space. To&nbsp;get around this difficulty, different techniques have been developed in the MD field. Among them&nbsp;the&nbsp;most widely used are the Umbrella Sampling/weighted histogram analysis method (WHAM)&nbsp;and the more recent metadynamics. Both such methods essentially compute the free energy&nbsp;directly by histogram&nbsp;methods, i.e. they rely on sampling the free energy space itself. This aspect&nbsp;makes them unaffordable when such space is in more than two dimensions. An alternative approach&nbsp;is also possible. Unlike the free energy which is a global&nbsp;quantity, its negative gradient (known as&nbsp;the mean force) can be expressed in terms of a local expectation, and thereby computed at a given&nbsp;point in the free energy landscape. This is the essence of the blue moon sampling strategy, and&nbsp;it offers the possibility to calculate first the mean force at a given set of locations, then use this&nbsp;information to reconstruct the free energy globally. In one dimension, this approach is known as&nbsp;thermodynamic integration and&nbsp;it goes back to Kirkwood. In higher dimensions, however, this&nbsp;way to compute free energies has been impeded by two issues. The first is where to place the points&nbsp;at which to compute the mean force, and the second is how to&nbsp;reconstruct the free energy from these&nbsp;data.</div>\n<div></div>\n<div>Temperature accelerated molecular dynamics (TAMD) is a way to address both issues. TAMD permits to accelerate the exploration of relevant but difficult-to-access&nbsp;regions in high-dimensional CV spaces.&nbsp;TAMD augments the&n...",
  "por_txt_cntn": "\nIn recent years, Molecular Dynamics (MD) simulations have become more widespread as a tool to address problems at an atomistic level in physics, chemistry and biochemistry. As an example, the study of proteins implicated in different processes of life, is nowadays routinely performed in pharmaceutical companies. Indeed, the knowledge of the mechanism at the basis of the function (or malfunction) of proteins will guide direct intervention on them.\nMany of the phenomena that these studies address involve molecular conformational changes that occur on time-scales from the hundreds of nanoseconds up. Present day algorithms solve the equations of motion of the system\u00c6s atoms with a timestep which is of the order of the femtoseconds (typically 1 or 2 fs). To give an example of the time required by a single-processor MD simulation, one step of MD for a system of a protein immersed in water (about 16000 atoms), required .7 seconds on a last generation Intel computing machine, so it would take about 400 days for 100 ns. Using parallel architectures can help decreasing this time, and particular effort has been recently put in building specific machines and designing algorithms to perform unprecedentedly extended MD simulations. Such an approach is however focused on the idea of producing one (or very few) simulated trajectory of the system. Albeit extremely long, one single trajectory will certainly not be enough to describe the property of the system. In the context, the free energy is a fundamental quantity to help organize the output of MD simulations and focus on the behavior of a few collective variables of importance. Since the free energy is in essence the logarithm of the probability density function of these collective variables, it could in principle be calculated by histogram methods based on the binning of an MD trajectory. Such a direct approach, however, turns out to be very inefficient in general due to the time scale required for the trajectory to explore all the relevant regions of configuration space. To get around this difficulty, different techniques have been developed in the MD field. Among them the most widely used are the Umbrella Sampling/weighted histogram analysis method (WHAM) and the more recent metadynamics. Both such methods essentially compute the free energy directly by histogram methods, i.e. they rely on sampling the free energy space itself. This aspect makes them unaffordable when such space is in more than two dimensions. An alternative approach is also possible. Unlike the free energy which is a global quantity, its negative gradient (known as the mean force) can be expressed in terms of a local expectation, and thereby computed at a given point in the free energy landscape. This is the essence of the blue moon sampling strategy, and it offers the possibility to calculate first the mean force at a given set of locations, then use this information to reconstruct the free energy globally. In one dimension, this approach is known as thermodynamic integration and it goes back to Kirkwood. In higher dimensions, however, this way to compute free energies has been impeded by two issues. The first is where to place the points at which to compute the mean force, and the second is how to reconstruct the free energy from these data.\n\nTemperature accelerated molecular dynamics (TAMD) is a way to address both issues. TAMD permits to accelerate the exploration of relevant but difficult-to-access regions in high-dimensional CV spaces. TAMD augments the set of independent variables with auxiliary variables that are tethered to the CV\u00c6s and evolve in lockstep with the atomic variables. A particular feature of TAMD worth mentioning here is that it uses effective time-averaging of restraining forces to compute gradients in free energy on-the-fly which govern evolution of the CVs: in other words, TAMD reports the instantaneous value of the mean force. In this project we used this property to infer the parameters of a..."
 }
}