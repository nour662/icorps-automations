{
 "awd_id": "1229222",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "The Validity of Markov Latent Class Analysis for Evaluating Measurement Errors in Complex Panel Surveys",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927269",
 "po_email": "ceavey@nsf.gov",
 "po_sign_block_name": "Cheryl Eavey",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2015-09-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2012-09-14",
 "awd_max_amd_letter_date": "2012-09-14",
 "awd_abstract_narration": "Markov latent class analysis (MLCA) comprises a broad class of models and techniques for analyzing categorical longitudinal data subject to misclassification.  An important application area is exploring data quality issues in panel surveys.  Because MLCA does not rely on gold standard or replicate measurements, it can be applied to virtually any panel survey.  For data quality evaluations, MLCA has been used to compare interview modes and alternative questionnaire designs, estimate measurement bias, investigate the causes of misclassification, and investigate many other measurement error issues.  Despite its many potential applications in survey work, MLCA has not enjoyed widespread use among survey methodologists because practical guidance on fitting MLC models to complex survey data is lacking.  This project will:  (1) evaluate the magnitude of the model bias when one or more MLCA assumptions fail when analyzing complex survey data under a wide range of conditions; (2) identify and evaluate the current strategies for diagnosing and repairing MLC model failure and misspecification; (3) address the limitations of current methods by developing improved strategies for diagnosing and repairing MLC model failure and misspecification, particularly in applications to complex surveys; and (4) apply the most effective diagnostic and remedial approaches to real panel survey data to demonstrate the range of modeling issues that can arise in practical applications as well as how to deal with them effectively.  As part of the application of these approaches, at least 10 years of data from several national panel surveys will be analyzed to identify temporal trends in measurement error for key national statistics.\r\n\r\nThis research has important implications for MLCA in all branches of science where classification error is an issue, including social science, epidemiology, clinical research, educational testing, and psychology.  The project's impact will be felt in at least four ways.  The research has particular relevance for complex survey applications because of the emphasis in this research on modeling cluster-correlated data selected with unequal probabilities and subject to nonresponse and measurement error.  It also has important implications for disadvantaged and minority populations whose data may be differentially affected by measurement error.  In addition, the evaluation of error trends will provide important information on current and historical levels of measurement error for three important federal statistical programs.  Finally, theories regarding the relationship between measurement error and survey participation will be formulated and tested.  The project is supported by the Methodology, Measurement, and Statistics Program and a consortium of federal statistical agencies as part of a joint activity to support research on survey and statistical methodology.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Biemer",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Paul P Biemer",
   "pi_email_addr": "ppb@rti.org",
   "nsf_id": "000378594",
   "pi_start_date": "2012-09-14",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marcus",
   "pi_last_name": "Berzofsky",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marcus Berzofsky",
   "pi_email_addr": "berzofsky@rti.org",
   "nsf_id": "000580626",
   "pi_start_date": "2012-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Research Triangle Institute",
  "inst_street_address": "3040 CORNWALLIS RD",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195416000",
  "inst_zip_code": "277090155",
  "inst_country_name": "United States",
  "cong_dist_code": null,
  "st_cong_dist_code": "NC",
  "org_lgl_bus_name": "RESEARCH TRIANGLE INSTITUTE",
  "org_prnt_uei_num": "JJHCMK4NT5N3",
  "org_uei_num": "JJHCMK4NT5N3"
 },
 "perf_inst": {
  "perf_inst_name": "Research Triangle Institute",
  "perf_str_addr": "3040 Cornwallis Road",
  "perf_city_name": "Research Triangle Park",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277092194",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goals for the research study The Validity of Markov Latent Class Analysis for Evaluating Measurement Errors in Complex Panel Surveys had three primary goals:</p>\n<p>1. Assess methods for measuring classification error (measurement error when all data are categorical) in longitudinal or panel data that comes from a complex survey.</p>\n<p>2. Understand how to handle missing data using full information Maximum Likelihood (FIML) in a latent class analysis (LCA) or Markov latent class analysis (MLCA).</p>\n<p>3. Understand the amount of measurement error in the National Crime Victimization Survey (NCVS) and how the inclusion of missing data impacts the findings.</p>\n<p>For the first goal, starting with the methods developed for LCA, we developed steps to assess the key MLCA assumptions when complex survey data is being analyzed. These steps assess the key MLCA assumption of local independence by looking at its various aspects independently. Namely, group homogeneity, independent classification error, time homogeneous errors, and the first-order Markov assumption are each isolated and tested in a systematic manner. Corrective steps were developed in order to ensure the validity of model assumptions. The proposed method is generalizable to any panel or longitudinal survey file.</p>\n<p>For the second goal, we examined multiple FIML methods in order to examine the impact that missing data has under each of the three potential missing data mechanism: (1) missing completely at random (MCAR), (2) missing at random (MAR), and (3) missing not at random (MNAR). In order understand the impact of these different missing data mechanisms we utilized three approaches to handle the missing data: (1) listwise or complete case deletion, Fuch&rsquo;s method, and Fay&rsquo;s method. Based on our analysis we found that (1) the selection of the grouping variables (i.e., the variables used to explain differences in classification error) does not differ regardless of the type of missing data or the FIML method used; (2) if data are MAR or MNAR then the use of FIML can greatly impact the resulting estimated classification error rates and unbiased estimates; and (3) when the amount of missing data is large &ndash; as can be the case in longitudinal data &ndash; using FIML can greatly improve standard errors, although, if data are MNAR standard errors are larger than if missing data is MAR.</p>\n<p>For the third goal, we applied our approach to the NCVS, a large nationally representative survey of households which measures crime victimization rates and characteristics of crime in the United States. The application was done in two parts. First, an assessment of the methods developed in goal 1 were tested using a complete case analysis. Second, an assessment of the impact of missing data using the methods assessed in goal 2 was conducted. The initial analysis found that measurement error in the NCVS is increasing over time for both person and household crimes (<strong>Figure 1</strong> and <strong>Figure 2</strong>). In other words, the more interview waves a respondent is in the more likely they will provide a false negative (i.e., indicate they were not a victim of a crime when in fact their true status is as a victim) response. In general, the likelihood of a false positive response (i.e., indicate that they were a victim of a crime when their true victimization status is not a victim). In addition, the analysis found that classification error rates differ within respondent or interview characteristics (e.g., respondent age, level of education, or mode of interview). For example, younger respondents (12 &ndash; 29 years old) have higher classification error rates than older respondents (50 years or older). <strong>Figure 3</strong> and <strong>Figure 4</strong> present these results. The assessment of missing data found that data were likely MAR rather than MNAR. The NCVS has a large amount of...",
  "por_txt_cntn": "\nThe goals for the research study The Validity of Markov Latent Class Analysis for Evaluating Measurement Errors in Complex Panel Surveys had three primary goals:\n\n1. Assess methods for measuring classification error (measurement error when all data are categorical) in longitudinal or panel data that comes from a complex survey.\n\n2. Understand how to handle missing data using full information Maximum Likelihood (FIML) in a latent class analysis (LCA) or Markov latent class analysis (MLCA).\n\n3. Understand the amount of measurement error in the National Crime Victimization Survey (NCVS) and how the inclusion of missing data impacts the findings.\n\nFor the first goal, starting with the methods developed for LCA, we developed steps to assess the key MLCA assumptions when complex survey data is being analyzed. These steps assess the key MLCA assumption of local independence by looking at its various aspects independently. Namely, group homogeneity, independent classification error, time homogeneous errors, and the first-order Markov assumption are each isolated and tested in a systematic manner. Corrective steps were developed in order to ensure the validity of model assumptions. The proposed method is generalizable to any panel or longitudinal survey file.\n\nFor the second goal, we examined multiple FIML methods in order to examine the impact that missing data has under each of the three potential missing data mechanism: (1) missing completely at random (MCAR), (2) missing at random (MAR), and (3) missing not at random (MNAR). In order understand the impact of these different missing data mechanisms we utilized three approaches to handle the missing data: (1) listwise or complete case deletion, Fuch\u00c6s method, and Fay\u00c6s method. Based on our analysis we found that (1) the selection of the grouping variables (i.e., the variables used to explain differences in classification error) does not differ regardless of the type of missing data or the FIML method used; (2) if data are MAR or MNAR then the use of FIML can greatly impact the resulting estimated classification error rates and unbiased estimates; and (3) when the amount of missing data is large &ndash; as can be the case in longitudinal data &ndash; using FIML can greatly improve standard errors, although, if data are MNAR standard errors are larger than if missing data is MAR.\n\nFor the third goal, we applied our approach to the NCVS, a large nationally representative survey of households which measures crime victimization rates and characteristics of crime in the United States. The application was done in two parts. First, an assessment of the methods developed in goal 1 were tested using a complete case analysis. Second, an assessment of the impact of missing data using the methods assessed in goal 2 was conducted. The initial analysis found that measurement error in the NCVS is increasing over time for both person and household crimes (Figure 1 and Figure 2). In other words, the more interview waves a respondent is in the more likely they will provide a false negative (i.e., indicate they were not a victim of a crime when in fact their true status is as a victim) response. In general, the likelihood of a false positive response (i.e., indicate that they were a victim of a crime when their true victimization status is not a victim). In addition, the analysis found that classification error rates differ within respondent or interview characteristics (e.g., respondent age, level of education, or mode of interview). For example, younger respondents (12 &ndash; 29 years old) have higher classification error rates than older respondents (50 years or older). Figure 3 and Figure 4 present these results. The assessment of missing data found that data were likely MAR rather than MNAR. The NCVS has a large amount of missingness over time. This is due to its rotating panel design and general attrition &ndash; especially by key subdomains such as younger persons and minorities. Therefore, the..."
 }
}