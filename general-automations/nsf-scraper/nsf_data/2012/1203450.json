{
 "awd_id": "1203450",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: WE FEEL SCIENCE:   We Engage with the Flexible, Experimental Environment for Learning in SCIENCE",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Julio Lopez-Ferrao",
 "awd_eff_date": "2011-08-15",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 422903.0,
 "awd_amount": 434823.0,
 "awd_min_amd_letter_date": "2011-10-26",
 "awd_max_amd_letter_date": "2014-06-09",
 "awd_abstract_narration": "This five-year CAREER proposal aims at designing, evaluating, and implementing a learning-by-collaborating system that provides haptic, visual, and auditory feedback to students with and without visual impairments to work together in hands-on science learning opportunities. The setting and sample of the proposed study includes sighted and visually impaired students (N=120) from the Arkansas School for the Blind, the Virginia School for the Deaf and Blind, the Kansas State School for the Blind, and the Fayetteville (Arkansas) High School. The hypothesis that a haptically enhanced learning-by-collaborating system may increase the science learning of both sighted and visually impaired students guides the study and its four research questions: (1) To what extent does additional haptic feedback during collaborative hands-on practice influence students' learning performance?; (2) To what extent does additional haptic feedback during collaborative hands-on practice influence students' attitudes towards science learning?; (3) How does additional haptic feedback during collaborative hands-on practice influence students' motivation to learn?; and (4) What are the relationships among learner motivation, learning attitudes, and learning performance? \r\n\r\nThe study employs a research and development design consisting of three stages. The first, Synthesis and Application, allows the PI to identify the set of points of collaboration that need to be supported haptically, audibly, or both, through two group sessions with three pairs of totally blind and partially blind students per session. The second, Development and Formative Evaluation, facilitates the development of two modules on the Nature of Light (Electromagnetic Waves, and Vibrating Charges), as well as the modification of the Molecular Properties, and Heat and Temperature modules, already designed for visually impaired students only. A Design for Co-Touch software framework is used for this purpose, and quality of the interaction techniques will be assessed using internationally established standards for usability, effectiveness, efficiency, and satisfaction. All materials that visually impaired students use are provided in Braille. \r\n\r\nThe PI will investigate the cognitive and affective impacts of shared haptic experiences on students' science learning through the third stage, Summative Evaluation of Shared Haptic Experiences. A total of 30 pairs of visually impaired and 30 pairs of sighted students participate during this stage. The study employs a two-level-between-subjects condition to manipulate sensory feedback: visual + auditory (students will receive visual and verbal instructions on science concepts) vs. visual + auditory + haptic (students will receive haptic feedback in addition to visual and verbal). This research stage utilizes Campbell & Stanley's (1966) pretest-posttest control group design in which participants are randomly assigned to one of the two groups. \r\n\r\nInstruments to be used in the study will be developed or modified and pilot-tested to determine their validity and reliability. To measure learning performance, two tests will be developed: (a) a recall and recognition test using Bloom's taxonomy, and (b) a transfer test to assess learners' ability to integrate and apply knowledge. To measure learning attitudes, the Test of Science-Related Attitudes (Fraser, 1981) will be used. To measure learning motivation, Keller's (2007) Instructional Materials Motivation Survey will be utilized. Statistical analysis (e.g., ANCOVA) will be used to control any initial differences in pretest scores between the groups. Multiple regression will be performed with the learning performance score (the sum of recall and transfer tests) as the dependent variable. Independent variables are learners' attitudes and learners' motivation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chang",
   "pi_last_name": "Nam",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Chang S Nam",
   "pi_email_addr": "csnam@niu.edu",
   "nsf_id": "000149436",
   "pi_start_date": "2011-10-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957906",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "764500",
   "pgm_ele_name": "Discovery Research K-12"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9177",
   "pgm_ref_txt": "ELEMENTARY/SECONDARY EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0110",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001011DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0411",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001112DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0413",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001314DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0414",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001415DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2010,
   "fund_oblg_amt": 15957.0
  },
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 110315.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 116402.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 116401.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 75748.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Disclaimer</p>\n<p>This Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.</p>\n<p>PI Nam received this award to investigate cognitive and affective impacts of sensory feedback in hands-on learning experiences in science education for students with and without severe visual impairments. PI and his research team maintain that collaborative hands-on practices with additional haptic sensory feedback should enhance the level of awareness (e.g., of other&rsquo;s activities), essential to coordinate joint activities, because such awareness can be transmitted through haptic senses other than vision. &nbsp;However, there has been little systematic study of how the shared haptic experiences should be designed and whether they can have the cognitive (e.g., knowledge construction and attitude toward science learning) and affective (e.g., motivation) impacts on students&rsquo; science learning.</p>\n<p>The most important and novel contributions of this work are:&nbsp;(1) A set of non-visual design principles and guidelines for the development of haptic user interfaces and haptic hands-on applications have been refined for collaborative haptic interactions. (2) PI confirmed several points of collaboration that need to be supported haptically, audibly, or both. Examples include: a) Spatial Orientation - interpreting one&rsquo;s location in relation to its surroundings, objects, and other users; b) Shared Awareness - perceiving a condition or event (e.g., location, situation); c) Co-Navigation - collaboratively moving toward a desired location or goal; d) Co-Manipulation - collaboratively changing an object; and e) Co-Selection - collaboratively initiating an environmental object and/or its key function. (3) A scenario-based observation framework was also developed to elicit and analyze user requirements for the development of collaborative haptic interaction techniques for the blind. (4) PI investigated performance and behavioral patterns of people with visual impairments in a haptically enhanced virtual environment and published the following research outcomes, which have been relatively neglected: (i) the effects of haptic assistive feedback on human performance in a haptically enhanced virtual environment, (ii) a robust stochastic modeling approach to model user behaviors (e.g., movement patterns), (iii)&nbsp; the effects of haptic feedback and visual distraction on pointing task performance in virtual environments, and (iv) human factors and ergonomics of sensory inputs and outputs of retinal microsurgery instrumentation. (5) PI found factors that can affect the use of reference frame when the users verbally express a haptically constructed mental map. (6) Nam developed a collaborative haptic system which provides a platform for students to collaborate with other students or teachers and understand the concept of electromagnetic waves, and assessed performance and behavioral patterns of students with visual impairments in the collaborative haptic system. (7) PI integrated research outcomes into existing human factors courses and taught them to both undergraduate students and graduate students.</p>\n<p>These outcomes should be beneficial for research and academic community who wants to support visually impaired students&rsquo; collaborative science learning through sensorial feedback to create appropriate approaches to support such difficulties using collaborative haptic interaction techniques.</p>\n<p>Over its duration, this grant has supported research by two postdoctoral researchers, two PhD students, three MS students, and more than dozen undergraduate researchers. Indirect...",
  "por_txt_cntn": "\nDisclaimer\n\nThis Project Outcomes Report for the General Public is displayed verbatim as submitted by the Principal Investigator (PI) for this award. Any opinions, findings, and conclusions or recommendations expressed in this Report are those of the PI and do not necessarily reflect the views of the National Science Foundation; NSF has not approved or endorsed its content.\n\nPI Nam received this award to investigate cognitive and affective impacts of sensory feedback in hands-on learning experiences in science education for students with and without severe visual impairments. PI and his research team maintain that collaborative hands-on practices with additional haptic sensory feedback should enhance the level of awareness (e.g., of other\u00c6s activities), essential to coordinate joint activities, because such awareness can be transmitted through haptic senses other than vision.  However, there has been little systematic study of how the shared haptic experiences should be designed and whether they can have the cognitive (e.g., knowledge construction and attitude toward science learning) and affective (e.g., motivation) impacts on students\u00c6 science learning.\n\nThe most important and novel contributions of this work are: (1) A set of non-visual design principles and guidelines for the development of haptic user interfaces and haptic hands-on applications have been refined for collaborative haptic interactions. (2) PI confirmed several points of collaboration that need to be supported haptically, audibly, or both. Examples include: a) Spatial Orientation - interpreting one\u00c6s location in relation to its surroundings, objects, and other users; b) Shared Awareness - perceiving a condition or event (e.g., location, situation); c) Co-Navigation - collaboratively moving toward a desired location or goal; d) Co-Manipulation - collaboratively changing an object; and e) Co-Selection - collaboratively initiating an environmental object and/or its key function. (3) A scenario-based observation framework was also developed to elicit and analyze user requirements for the development of collaborative haptic interaction techniques for the blind. (4) PI investigated performance and behavioral patterns of people with visual impairments in a haptically enhanced virtual environment and published the following research outcomes, which have been relatively neglected: (i) the effects of haptic assistive feedback on human performance in a haptically enhanced virtual environment, (ii) a robust stochastic modeling approach to model user behaviors (e.g., movement patterns), (iii)  the effects of haptic feedback and visual distraction on pointing task performance in virtual environments, and (iv) human factors and ergonomics of sensory inputs and outputs of retinal microsurgery instrumentation. (5) PI found factors that can affect the use of reference frame when the users verbally express a haptically constructed mental map. (6) Nam developed a collaborative haptic system which provides a platform for students to collaborate with other students or teachers and understand the concept of electromagnetic waves, and assessed performance and behavioral patterns of students with visual impairments in the collaborative haptic system. (7) PI integrated research outcomes into existing human factors courses and taught them to both undergraduate students and graduate students.\n\nThese outcomes should be beneficial for research and academic community who wants to support visually impaired students\u00c6 collaborative science learning through sensorial feedback to create appropriate approaches to support such difficulties using collaborative haptic interaction techniques.\n\nOver its duration, this grant has supported research by two postdoctoral researchers, two PhD students, three MS students, and more than dozen undergraduate researchers. Indirectly, this grant has enabled work by several other professors, students and researchers who co-authored several peer-reviewed journal..."
 }
}