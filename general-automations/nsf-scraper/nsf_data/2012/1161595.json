{
 "awd_id": "1161595",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "NeTS: Medium: Collaborative Research: Systematic Analysis of Protocol Implementations",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Brassil",
 "awd_eff_date": "2012-05-01",
 "awd_exp_date": "2017-04-30",
 "tot_intn_awd_amt": 446860.0,
 "awd_amount": 446860.0,
 "awd_min_amd_letter_date": "2012-04-18",
 "awd_max_amd_letter_date": "2014-09-05",
 "awd_abstract_narration": "Systematic Analysis of Protocol Implementations\r\n\r\nInternet protocol development and standardization has long been driven by the philosophy of 'rough consensus and running code.' The downside to this approach is that protocol specifications are rarely rigorously verified, even for properties that fall within the capabilities of protocol verification techniques. Further, the 'rough' nature of the approach means that some important design decisions are inevitably omitted from the specification or are defined ambiguously. Therefore, in practice the correctness, performance, and resilience of network protocols are implicitly defined by vendor and open-source implementations of the protocol specification, and these implementations are based upon the developers' varying interpretations of the standards document. This leaves developers in a bind: they are unsure of the properties of the protocol specification, and do not have tools to reason about the properties of complex protocol implementations.\r\n\r\nIntellectual Merit. This project will develop a general approach and an associated tool that will enable developers and expert users to systematically analyze a variety of properties on a range of protocol implementations. The approach builds upon recent advances in program analysis techniques in novel ways that are tailored towards the special properties and requirements of protocol implementations. Moreover, the project will instantiate the general approach with new analyses for important tasks that are largely manual and highly error-prone today, including interoperability testing and precise tracking of state changes over time (e.g., to identify anomalous state sequences or characterize protocol complexity).\r\n\r\nThe project is based on the observation that protocol implementations have an implicit internal structure, in the form of a state machine that embodies the key behavioral properties of the implementation. Due to the complexity of protocol implementations, this state machine will typically not be completely inferable by program analysis. To address this problem, the project will develop operators on a protocol implementation that allow developers to specify scalable and precise views of the underlying state machine. Developers can additionally use these views to perform a targeted concrete execution of the protocol on a real topology in order to investigate the particular property under consideration.\r\n\r\nThe outcome of the project will be a software system called Spa. Developers will provide protocol implementations and use their expertise about the protocol and its properties of interest to specify appropriate operators and guide targeted concrete execution. The project will evolve Spa operators using experiences gained from applying Spa to several protocol analyses that have not been previously considered, and will start with a set of operators that have been informed by the PIs' preliminary research.\r\n\r\nBroader Impact. The protocols that underlie access to our networked world must be reliable, robust to attacks, and must perform well over a range of conditions and in dynamic environments. This project will equip developers and experts to systematically analyze the behavior of their protocols, and will result in an overall improvement in the reliability, robustness, and performance of deployed protocols. The project will accelerate the adoption of the research by making Spa available to researchers and developers, publishing its research results in top networking and programming language conferences, and educating students on the developed research methods by incorporating them in curricula. It will also engage underrepresented groups and undergraduates in research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Todd",
   "pi_last_name": "Millstein",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Todd D Millstein",
   "pi_email_addr": "todd@cs.ucla.edu",
   "nsf_id": "000229495",
   "pi_start_date": "2012-04-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Los Angeles",
  "inst_street_address": "10889 WILSHIRE BLVD STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3107940102",
  "inst_zip_code": "900244200",
  "inst_country_name": "United States",
  "cong_dist_code": "36",
  "st_cong_dist_code": "CA36",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, LOS ANGELES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RN64EPNH8JC6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Los Angeles",
  "perf_str_addr": "4532K Boelter Hall",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900951596",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7363",
   "pgm_ref_txt": "RES IN NETWORKING TECH & SYS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 234475.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 107242.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 105143.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>All aspects of society &mdash;- communication, entertainment, finance, business, science, government &mdash;- depend on properly functioning computer networks and demand increasingly rich services that live in the cloud. As a result, both the complexity and reliability requirements of cloud networks have rapidly escalated. &nbsp;Yet by and large network engineers, operators, and protocol implementers employ the same rudimentary tools for expressing and validating network behavior that have been used for decades. &nbsp;This project has developed several approaches to enable networks to be better understood, evolved, and validated.</p>\n<p>A major focus of the project has been to improve the state of the art in <em>network configuration</em>. &nbsp;Today each router in a network is separately configured using a vendor-specific configuration language (e.g., Cisco&rsquo;s IOS language). &nbsp;It is very easy to make subtle errors in these configurations, and it is difficult to understand the ramifications of one router's configuration on the network as a whole. Currently network operators gain confidence in their configurations through simple techniques like sending test packets through the network, but these approaches are error prone and can easily miss important behaviors.</p>\n<p>We have developed two techniques to address this problem. &nbsp;First, we have created tools for automatic network configuration analysis. &nbsp;These tools accept as input the actual configuration files for each router in the network, build a model of the network behavior based on the configurations, and can then check desired correctness and security properties. &nbsp;Because the tools do not require access to the running network, they can also be used to ask \"what-if\" questions, for example to determine the impact of a proposed configuration change or a router failure. &nbsp;Our Batfish configuration analysis tool has been applied to network configurations from two university campus networks as well as several corporate networks, including the data-center networks of a major cloud provider. It has identified several configuration inconsistencies that the network engineers have subsequently fixed.</p>\n<p>Second, we have developed a correct-by-construction approach to network configuration. &nbsp;We have designed a network programming language called Propane that allows network engineers to directly express network-wide policies through a set of high-level constraints and preferences on the paths that traffic should take through the network. Our Propane compiler then automatically translates these specifications to a collection of individual router configurations. The compiler guarantees that the compiled configurations correctly implement the specified policy under all possible combinations of network failures. We have demonstrated that Propane can effectively express the policies of data-center and backbone networks of a large cloud provider; and despite its strong guarantees, our compiler scales to networks with hundreds or thousands of routers.</p>\n<p>The other major focus of the project has been to enable real-world protocol implementations to be automatically analyzed for errors. &nbsp;Nodes in distributed systems communicate using one or more <em>network protocols</em> such as HTTP and TCP. For robust operation of these system, it is critical that the implementations of these protocols be able to communicate effectively. As modern systems move towards distributed computing for scaling and reliability, our ability to provide adequate quality assurance has lagged behind.</p>\n<p>First, we developed an approach to interoperability testing of network protocols. Today, protocol developers spend significant manual effort in testing interoperability. They identify test inputs that can test specific features of theprotocol. But, because the space of test inputs is large, such manual testing is often incomplete. As a result, interoperability issues continue to frustrate developers, as well as users, even years after protocols have been fully deployed. &nbsp;Our PIC (Protocol Interoperability Checker) tool helps developers search for non-interoperabilities in protocol implementations. &nbsp;PIC leverages and extends the notion of <em>symbolic execution</em> in order to characterize the sets of messages that one protocol participant can send but another will reject as non-compliant. &nbsp;We have demonstrated that PIC is able to find multiple previously unknown noninteroperabilities in large and mature implementations of the widely used SIP and SPDY protocols, some of which have since been fixed by the respective developers.</p>\n<p>Second, we have recently generalized PIC into a framework for protocol analysis called Cat (Conversational Analysis Tool). &nbsp;Cat extends traditional symbolic execution to enable the analysis of multiple concurrent programs as a part of a distributed system. &nbsp;Through Cat we have the ability to more thoroughly explore the space of feasible outcomes of the distributed systems as a whole, considering both varying inputs from a constrained input space and network dynamics. &nbsp;We have demonstrated that Cat can analyze the widely-used Redis key-value store in order to identify complex and subtle errors.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/05/2017<br>\n\t\t\t\t\tModified by: Todd&nbsp;D&nbsp;Millstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAll aspects of society &mdash;- communication, entertainment, finance, business, science, government &mdash;- depend on properly functioning computer networks and demand increasingly rich services that live in the cloud. As a result, both the complexity and reliability requirements of cloud networks have rapidly escalated.  Yet by and large network engineers, operators, and protocol implementers employ the same rudimentary tools for expressing and validating network behavior that have been used for decades.  This project has developed several approaches to enable networks to be better understood, evolved, and validated.\n\nA major focus of the project has been to improve the state of the art in network configuration.  Today each router in a network is separately configured using a vendor-specific configuration language (e.g., Cisco?s IOS language).  It is very easy to make subtle errors in these configurations, and it is difficult to understand the ramifications of one router's configuration on the network as a whole. Currently network operators gain confidence in their configurations through simple techniques like sending test packets through the network, but these approaches are error prone and can easily miss important behaviors.\n\nWe have developed two techniques to address this problem.  First, we have created tools for automatic network configuration analysis.  These tools accept as input the actual configuration files for each router in the network, build a model of the network behavior based on the configurations, and can then check desired correctness and security properties.  Because the tools do not require access to the running network, they can also be used to ask \"what-if\" questions, for example to determine the impact of a proposed configuration change or a router failure.  Our Batfish configuration analysis tool has been applied to network configurations from two university campus networks as well as several corporate networks, including the data-center networks of a major cloud provider. It has identified several configuration inconsistencies that the network engineers have subsequently fixed.\n\nSecond, we have developed a correct-by-construction approach to network configuration.  We have designed a network programming language called Propane that allows network engineers to directly express network-wide policies through a set of high-level constraints and preferences on the paths that traffic should take through the network. Our Propane compiler then automatically translates these specifications to a collection of individual router configurations. The compiler guarantees that the compiled configurations correctly implement the specified policy under all possible combinations of network failures. We have demonstrated that Propane can effectively express the policies of data-center and backbone networks of a large cloud provider; and despite its strong guarantees, our compiler scales to networks with hundreds or thousands of routers.\n\nThe other major focus of the project has been to enable real-world protocol implementations to be automatically analyzed for errors.  Nodes in distributed systems communicate using one or more network protocols such as HTTP and TCP. For robust operation of these system, it is critical that the implementations of these protocols be able to communicate effectively. As modern systems move towards distributed computing for scaling and reliability, our ability to provide adequate quality assurance has lagged behind.\n\nFirst, we developed an approach to interoperability testing of network protocols. Today, protocol developers spend significant manual effort in testing interoperability. They identify test inputs that can test specific features of theprotocol. But, because the space of test inputs is large, such manual testing is often incomplete. As a result, interoperability issues continue to frustrate developers, as well as users, even years after protocols have been fully deployed.  Our PIC (Protocol Interoperability Checker) tool helps developers search for non-interoperabilities in protocol implementations.  PIC leverages and extends the notion of symbolic execution in order to characterize the sets of messages that one protocol participant can send but another will reject as non-compliant.  We have demonstrated that PIC is able to find multiple previously unknown noninteroperabilities in large and mature implementations of the widely used SIP and SPDY protocols, some of which have since been fixed by the respective developers.\n\nSecond, we have recently generalized PIC into a framework for protocol analysis called Cat (Conversational Analysis Tool).  Cat extends traditional symbolic execution to enable the analysis of multiple concurrent programs as a part of a distributed system.  Through Cat we have the ability to more thoroughly explore the space of feasible outcomes of the distributed systems as a whole, considering both varying inputs from a constrained input space and network dynamics.  We have demonstrated that Cat can analyze the widely-used Redis key-value store in order to identify complex and subtle errors.\n\n \n\n\t\t\t\t\tLast Modified: 05/05/2017\n\n\t\t\t\t\tSubmitted by: Todd D Millstein"
 }
}