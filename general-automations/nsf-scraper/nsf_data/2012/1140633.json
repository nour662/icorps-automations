{
 "awd_id": "1140633",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Peer Instruction in Computer Science",
 "cfda_num": "47.076",
 "org_code": "11040200",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Krupczak",
 "awd_eff_date": "2012-08-15",
 "awd_exp_date": "2015-07-31",
 "tot_intn_awd_amt": 21129.0,
 "awd_amount": 21129.0,
 "awd_min_amd_letter_date": "2012-08-16",
 "awd_max_amd_letter_date": "2012-08-16",
 "awd_abstract_narration": "This collaborative project builds on existing STEM education knowledge by examining the value, adaptability, and adoptability of Peer Instruction (PI) in the computing classroom at three different types of institutions. The work develops and disseminates curricular materials (including reading quizzes, exploratory homework, PI clicker questions with supporting meta-data) for six computer science courses at different levels in the curriculum: CS0, CS1, CS2, computer organization, computer architecture, and theory of computation. Peer Instruction materials previously developed for CS1 in media computation and the proposed AP CS Principles course (in Alice) are being expanded and disseminated along with the newly developed PI materials through a publicly available web-site, a workshop, conference presentations, and publications.\r\n\r\nThe broader impact of this work is to dramatically improve both classroom climate and learning gains by bringing a student-centered learning environment, Peer Instruction, to a range of computing courses.  The project evaluates the classroom materials, the faculty experiences, and the student learning gains. A preliminary exploration is done of supportive processes to enable PI adoption by other faculty through a variety of methods. Additionally, the project assesses and reports on various forms of learning gains and student attitudes that result from PI use in the four higher level courses using a variety of techniques including: pre- and post-tests, comparative exam performance evaluation, common clicker questions during class-time, and an attitudinal survey.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DUE",
 "org_div_long_name": "Division Of Undergraduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Glick",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "John H Glick",
   "pi_email_addr": "glick@sandiego.edu",
   "nsf_id": "000409793",
   "pi_start_date": "2012-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of San Diego",
  "inst_street_address": "5998 ALCALA PARK FRNT",
  "inst_street_address_2": "",
  "inst_city_name": "SAN DIEGO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6192606825",
  "inst_zip_code": "921102476",
  "inst_country_name": "United States",
  "cong_dist_code": "51",
  "st_cong_dist_code": "CA51",
  "org_lgl_bus_name": "UNIVERSITY OF SAN DIEGO",
  "org_prnt_uei_num": "V6S1GT51XD56",
  "org_uei_num": "V6S1GT51XD56"
 },
 "perf_inst": {
  "perf_inst_name": "University of San Diego",
  "perf_str_addr": "5998 Alcala Park",
  "perf_city_name": "San Diego",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "921102492",
  "perf_ctry_code": "US",
  "perf_cong_dist": "51",
  "perf_st_cong_dist": "CA51",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "153600",
   "pgm_ele_name": "S-STEM-Schlr Sci Tech Eng&Math"
  },
  {
   "pgm_ele_code": "751300",
   "pgm_ele_name": "TUES-Type 1 Project"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0412",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001213DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "13XX",
   "app_name": "H-1B FUND, EHR, NSF",
   "app_symb_id": "045176",
   "fund_code": "1300XXXXDB",
   "fund_name": "H-1B FUND, EDU, NSF",
   "fund_symb_id": "045176"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 21129.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Peer Instruction (PI) is a student-centric, active-learning pedagogical practice which was developed by Eric Mazur at Harvard University to address conceptual misunderstandings in physics. &nbsp;PI involves students preparing for class by reading reference material or watching online videos. &nbsp;The classroom then revolves around a series of &ldquo;ConceptTests&rdquo; which consist of (1) students being presented with a problem to solve and answering it individually (often using clickers), (2) students discussing the question in small groups and responding again (often using clickers), and (3) an instructor-led classwide discussion informed by student responses.</p>\n<p>&nbsp;</p>\n<p>At the time of the TUES grant being awarded, PI had been studied in other fields (notably physics) but little was known of its efficacy in computer science. &nbsp;Similarly, faculty adoption rates of PI were significant in physics, but few faculty had tried PI in computer science. &nbsp;The TUES grant funded research into the effectiveness of PI in computer science as well as the development of PI materials to aid faculty adoption.</p>\n<p>&nbsp;</p>\n<p>Goal #1: Research the Efficacy of Peer Instruction in Computer Science</p>\n<p>&nbsp;</p>\n<p>Three years since the award was funded, PI is now one of the most (if not the most) well studied pedagogical practices in computing. &nbsp;Research funded by this award has shown that students in a PI section do better on the final exam than students in traditional lecture section of the same course (Simon et al., SIGCSE 2013); courses at UC San Diego that have been taught with PI have, on average, failure rates that are less than half those taught using standard lecture (Porter, Lee, and Simon, SIGCSE 2013); and that PI contributed to an improvement in retention at UC San Diego by over a third, amounting to thousands more successful CS majors over a decade (Porter and Simon, SIGCSE 2013, Best Paper winner at SIGCSE 2013). &nbsp;Moreover, Students in PI classes value PI and overwhelmingly recommend other faculty adopt the practice (Porter et al., ITiCSE 2013; Porter et al., SIGCSE 2016).</p>\n<p>&nbsp;</p>\n<p>Within the classroom, research funded by this award has found measurable learning gains by students from the group discussion as well as the instructor-led classwide discussion (Zingaro and Porter 2014). &nbsp;Classroom success on PI questions is correlated with final exam outcomes (Zingaro and Porter, 2014; Zingaro and Porter, 2015). &nbsp;Moving beyond showing the efficacy of PI, recent work showed the value in clicker correctness in both predicting student&rsquo;s who will struggle in introductory courses and in identifying core concepts correlated with student success (Porter et al., ICER 2014). &nbsp;This work won the Chair&rsquo;s Award at ICER 2014.</p>\n<p>&nbsp;</p>\n<p>These studies performed above used standard graded instruments, such as exams or quizzes, rather than a formal, validated assessment, such as a Content Inventory (CI). &nbsp;Under this grant, a preliminary CI was developed for Computer Science, specifically one in computer architecture funded by this grant (Porter et al., ITiCSE 2013). &nbsp;&nbsp;However, the need for validated, full scale CIs was highlighted when pedagogical research aims to report on student learning outcomes. &nbsp;Preliminary studies examining the history of CI development in CS as well as potential development practices were explored in Porter et al., ITiCSE 2014 and Taylor et al., CSE 2014. &nbsp;One of the leads on this award (Co-PI Porter), created a team of investigators to to develop a Concept Inventory for the second programming course. &nbsp;This grant was recently funded under NSF IUSE.</p>\n<p>&nbsp;</p>\n<p>Goal #2: Support Faculty Adoption of Peer Instruction</p>\n<p>&nbsp;</p>\n<p>There were three main contributions in this area of the award. &nbsp;The first is research evidence that adopt...",
  "por_txt_cntn": "\nPeer Instruction (PI) is a student-centric, active-learning pedagogical practice which was developed by Eric Mazur at Harvard University to address conceptual misunderstandings in physics.  PI involves students preparing for class by reading reference material or watching online videos.  The classroom then revolves around a series of \"ConceptTests\" which consist of (1) students being presented with a problem to solve and answering it individually (often using clickers), (2) students discussing the question in small groups and responding again (often using clickers), and (3) an instructor-led classwide discussion informed by student responses.\n\n \n\nAt the time of the TUES grant being awarded, PI had been studied in other fields (notably physics) but little was known of its efficacy in computer science.  Similarly, faculty adoption rates of PI were significant in physics, but few faculty had tried PI in computer science.  The TUES grant funded research into the effectiveness of PI in computer science as well as the development of PI materials to aid faculty adoption.\n\n \n\nGoal #1: Research the Efficacy of Peer Instruction in Computer Science\n\n \n\nThree years since the award was funded, PI is now one of the most (if not the most) well studied pedagogical practices in computing.  Research funded by this award has shown that students in a PI section do better on the final exam than students in traditional lecture section of the same course (Simon et al., SIGCSE 2013); courses at UC San Diego that have been taught with PI have, on average, failure rates that are less than half those taught using standard lecture (Porter, Lee, and Simon, SIGCSE 2013); and that PI contributed to an improvement in retention at UC San Diego by over a third, amounting to thousands more successful CS majors over a decade (Porter and Simon, SIGCSE 2013, Best Paper winner at SIGCSE 2013).  Moreover, Students in PI classes value PI and overwhelmingly recommend other faculty adopt the practice (Porter et al., ITiCSE 2013; Porter et al., SIGCSE 2016).\n\n \n\nWithin the classroom, research funded by this award has found measurable learning gains by students from the group discussion as well as the instructor-led classwide discussion (Zingaro and Porter 2014).  Classroom success on PI questions is correlated with final exam outcomes (Zingaro and Porter, 2014; Zingaro and Porter, 2015).  Moving beyond showing the efficacy of PI, recent work showed the value in clicker correctness in both predicting student\u00c6s who will struggle in introductory courses and in identifying core concepts correlated with student success (Porter et al., ICER 2014).  This work won the Chair\u00c6s Award at ICER 2014.\n\n \n\nThese studies performed above used standard graded instruments, such as exams or quizzes, rather than a formal, validated assessment, such as a Content Inventory (CI).  Under this grant, a preliminary CI was developed for Computer Science, specifically one in computer architecture funded by this grant (Porter et al., ITiCSE 2013).   However, the need for validated, full scale CIs was highlighted when pedagogical research aims to report on student learning outcomes.  Preliminary studies examining the history of CI development in CS as well as potential development practices were explored in Porter et al., ITiCSE 2014 and Taylor et al., CSE 2014.  One of the leads on this award (Co-PI Porter), created a team of investigators to to develop a Concept Inventory for the second programming course.  This grant was recently funded under NSF IUSE.\n\n \n\nGoal #2: Support Faculty Adoption of Peer Instruction\n\n \n\nThere were three main contributions in this area of the award.  The first is research evidence that adopters of PI experience positive outcomes including similar student learning gains during peer discussion (Lee et al., TOCE 2014), similar reductions in failure rates (Porter et al., SIGCSE 2013), and similar appreciation of PI by the students (Porter et al., ITiCSE 2013; Porter et al., ..."
 }
}