{
 "awd_id": "1217353",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:Small:Collabroative Research: Elastic Fidelity: Trading off Computational Accuracy for Energy Efficiency",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 182000.0,
 "awd_amount": 182000.0,
 "awd_min_amd_letter_date": "2012-07-03",
 "awd_max_amd_letter_date": "2012-07-03",
 "awd_abstract_narration": "Energy and power consumption have become a critical issue ranging from microarchitectures to large-scale data centers and supercomputers. Conservative estimates suggest that the information technology industry world-wide energy consumption is in excess of 400 TWh and growing, generating roughly the same carbon footprint as the airline industry, accounting for 2% of global emissions. At the same time, the power constraints of chips hamper their performance, and the shrinking transistor geometries and low supply voltages increase the severity of processor variations resulting in higher timing error rates. High error rates lead to a significant drop in yield and increased manufacturing costs, calling for designs that are able to withstand them.\r\n \t\r\nThis project seeks to understand and explore the novel paradigm of elastic fidelity computing. Elastic fidelity computing capitalizes on the observation that many applications can naturally tolerate errors, and that not all of them need to run at 100% fidelity all the time. Specifically, the goal of this work is to understand the error models of various hardware components as they relate to data movement, storage, and computation, and simultaneously to understand the error resiliency of applications and re-architect them to leverage elastic fidelity.\r\n \r\nElastic fidelity offers potentially transformative effects for science and society, by challenging conventional wisdom and taking a fresh look at the interplay of errors, output quality and energy efficiency for an important class of pervasive streaming and data-intensive applications. More specifically, elastic fidelity promises significant energy savings that can put computing on an environmentally sustainable path, by lowering the operational costs in major economic sectors, and making the manufacturing of future chips cheaper by relaxing the accuracy requirements of hardware components. The results of this research will be disseminated through publications, workshops, advanced curriculum, and releases of the developed infrastructure in the public domain. To accelerate broad societal effects, the project participants will seek to foster technology transfer by promoting collaboration and industry involvement through presentations and site visit",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Srinivasan",
   "pi_last_name": "Parthasarathy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivasan Parthasarathy",
   "pi_email_addr": "srini@cse.ohio-state.edu",
   "nsf_id": "000227551",
   "pi_start_date": "2012-07-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Ohio State University",
  "inst_street_address": "1960 KENNY RD",
  "inst_street_address_2": "",
  "inst_city_name": "COLUMBUS",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "6146888735",
  "inst_zip_code": "432101016",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "OH03",
  "org_lgl_bus_name": "OHIO STATE UNIVERSITY, THE",
  "org_prnt_uei_num": "MN4MDDMN8529",
  "org_uei_num": "DLWBSLWAJWR1"
 },
 "perf_inst": {
  "perf_inst_name": "Ohio State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "432101016",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "OH03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 182000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-8a8c2084-c06f-32ec-43a0-945480ebc10b\" style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Computing consumes more than 400TWh annually and has a carbon footprint that registers as big as the carbon footprint of entire developed countries or the airline industry. The energy waste in modern processors prevents them from realizing their full potential. Even big science is constrained by computing&rsquo;s power consumption: exascale machines, required to address grand scientific challenges, need at least a 200-fold reduction in energy-per-instruction to become practical. This energy reduction cannot come from technology scaling alone. It requires sophisticated techniques to close the gap, including novel architectures, the use of emerging devices for computing, communication and/or storage, and re-evaluating some of the long-held traditionalist views of computing. </span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">The main goal of this project is to make a decisive step towards the development of power- and energy-efficient computing systems. This is accomplished by (1) transforming what has been traditionally considered a problem (computational errors) into an opportunity for lowering the energy consumption of computing: relaxing the accuracy requirements of the error-tolerant portions of a computation can lead to significantly lower energy consumption with minimal impact in the final accuracy of the result, (2) re-architecting applications to expose and treat the error-tolerant and error-sensitive portions of the computation differently, and (3) investigating novel architectures and emerging devices that lead to several times higher power and energy efficiency.</span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\"><br /></span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">During this project we worked on all these fronts. To save energy and power we propose to execute error-tolerant computations on arithmetic units that are supplied with much lower voltage than what the design of the hardware unit normally allows. This can lead to errors, but these errors have only a small impact on the accuracy of the final result as they are constrained on only the error tolerant computations. To investigate this tradeoff, we developed the most accurate and complete hardware error model to date of undervolted integer, logic and floating point arithmetic units. Our model achieves significantly higher accuracy and higher coverage than existing ones, while staying within 1-3% of the ground truth. We proposed processor architectures that increase the accuracy of undervolted arithmetic units to the point that some applications experience fully-correct results in a third of their computations, while a traditional processor under the same conditions leads to all computations being erroneous. We proposed certain ways of restructuring important applications (e.g., large-scale graph processing) to save up to 30% energy without losing much accuracy. While these techniques lead to more energy-efficient systems, which is the primary objective of Elastic Fidelity, they also lead to systems that can tolerate hardware errors. This is especially important, as devices in the deep nanoscale regime are likely to be highly error-prone due to geometry scaling, process variation and device mismatch, which necessitates techniques to absorb these errors at the architectural and software layers. </span></p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\">&nbsp;</p>\n<p style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">Simultaneously, our effort to design energy-efficient systems led to the pursuit of novel architectures, some of which utilize emerging devices. Our Galaxy architecture advocates building processors not as single monolithic chips, but as a large collection of smaller chiplets, physically distributed in space and connected through nanophotonic links to form a &ldquo;virtual macro-chip&rdquo; that can reach scales impossible to realize with conventional technologies. Galaxy achieves 7x higher performance for the same energy level, far outperforming any other alternative. Our designs on adaptive laser power gating (e.g., EcoLaser, ProLaser, SLAC, which turn off the laser in a nanophotonic interconnect when the network is idle, and predict when communication is imminent to turn the laser back on at just the right time to transmit without delay) save 42-94% of the laser power with no performance degradation; actually, performance improves by 60% when the lasers are built on chip. Our laser gating techniques are applicable even in data centers, where they can save more than half the laser energy. Our techniques for keeping the temperature of the photonic die constant so that nanophotonic devices can work correctly (e.g., Parka) reduce the energy required for thermal stability by 3.8-5.4x, and even achieve up to 34% performance improvement by eliminating the extra heating of the processor cores. Finally, we proposed two more novel architectures: (a) Dynamic Directories, which eliminate half the messages sent on on-chip interconnects and save 37% of its energy without degrading performance, and (b) SCP, which implements sophisticated data streaming techniques on the cache space saved by data compression, leading to 12% speedup with minimal hardware complexity.</span></p>\n<div style=\"line-height: 1.656; margin-top: 0pt; margin-bottom: 0pt; text-align: justify;\" dir=\"ltr\"><span style=\"font-size: 16px; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline;\">This project has led to several publications, presentations, and the public release of datasets and software artifacts. Besides its technological impact, at Ohio State University,&nbsp; this project has led to the training of two Ph.D. students, and three independent study projects. &nbsp; We also incorporated our research findings and tool chain into undergraduate and graduate-level courses, further bridging research and education.</span></div><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2016<br>\n\t\t\t\t\tModified by: Srinivasan&nbsp;Parthasarathy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Computing consumes more than 400TWh annually and has a carbon footprint that registers as big as the carbon footprint of entire developed countries or the airline industry. The energy waste in modern processors prevents them from realizing their full potential. Even big science is constrained by computing?s power consumption: exascale machines, required to address grand scientific challenges, need at least a 200-fold reduction in energy-per-instruction to become practical. This energy reduction cannot come from technology scaling alone. It requires sophisticated techniques to close the gap, including novel architectures, the use of emerging devices for computing, communication and/or storage, and re-evaluating some of the long-held traditionalist views of computing. \nThe main goal of this project is to make a decisive step towards the development of power- and energy-efficient computing systems. This is accomplished by (1) transforming what has been traditionally considered a problem (computational errors) into an opportunity for lowering the energy consumption of computing: relaxing the accuracy requirements of the error-tolerant portions of a computation can lead to significantly lower energy consumption with minimal impact in the final accuracy of the result, (2) re-architecting applications to expose and treat the error-tolerant and error-sensitive portions of the computation differently, and (3) investigating novel architectures and emerging devices that lead to several times higher power and energy efficiency.\n\n\nDuring this project we worked on all these fronts. To save energy and power we propose to execute error-tolerant computations on arithmetic units that are supplied with much lower voltage than what the design of the hardware unit normally allows. This can lead to errors, but these errors have only a small impact on the accuracy of the final result as they are constrained on only the error tolerant computations. To investigate this tradeoff, we developed the most accurate and complete hardware error model to date of undervolted integer, logic and floating point arithmetic units. Our model achieves significantly higher accuracy and higher coverage than existing ones, while staying within 1-3% of the ground truth. We proposed processor architectures that increase the accuracy of undervolted arithmetic units to the point that some applications experience fully-correct results in a third of their computations, while a traditional processor under the same conditions leads to all computations being erroneous. We proposed certain ways of restructuring important applications (e.g., large-scale graph processing) to save up to 30% energy without losing much accuracy. While these techniques lead to more energy-efficient systems, which is the primary objective of Elastic Fidelity, they also lead to systems that can tolerate hardware errors. This is especially important, as devices in the deep nanoscale regime are likely to be highly error-prone due to geometry scaling, process variation and device mismatch, which necessitates techniques to absorb these errors at the architectural and software layers. \n \nSimultaneously, our effort to design energy-efficient systems led to the pursuit of novel architectures, some of which utilize emerging devices. Our Galaxy architecture advocates building processors not as single monolithic chips, but as a large collection of smaller chiplets, physically distributed in space and connected through nanophotonic links to form a \"virtual macro-chip\" that can reach scales impossible to realize with conventional technologies. Galaxy achieves 7x higher performance for the same energy level, far outperforming any other alternative. Our designs on adaptive laser power gating (e.g., EcoLaser, ProLaser, SLAC, which turn off the laser in a nanophotonic interconnect when the network is idle, and predict when communication is imminent to turn the laser back on at just the right time to transmit without delay) save 42-94% of the laser power with no performance degradation; actually, performance improves by 60% when the lasers are built on chip. Our laser gating techniques are applicable even in data centers, where they can save more than half the laser energy. Our techniques for keeping the temperature of the photonic die constant so that nanophotonic devices can work correctly (e.g., Parka) reduce the energy required for thermal stability by 3.8-5.4x, and even achieve up to 34% performance improvement by eliminating the extra heating of the processor cores. Finally, we proposed two more novel architectures: (a) Dynamic Directories, which eliminate half the messages sent on on-chip interconnects and save 37% of its energy without degrading performance, and (b) SCP, which implements sophisticated data streaming techniques on the cache space saved by data compression, leading to 12% speedup with minimal hardware complexity.\nThis project has led to several publications, presentations, and the public release of datasets and software artifacts. Besides its technological impact, at Ohio State University,  this project has led to the training of two Ph.D. students, and three independent study projects.   We also incorporated our research findings and tool chain into undergraduate and graduate-level courses, further bridging research and education.\n\n\t\t\t\t\tLast Modified: 12/02/2016\n\n\t\t\t\t\tSubmitted by: Srinivasan Parthasarathy"
 }
}