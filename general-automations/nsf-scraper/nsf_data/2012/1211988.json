{
 "awd_id": "1211988",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Topics in Stochastic Control and Financial Mathematics",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Michael Steuerwalt",
 "awd_eff_date": "2012-09-15",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 291887.0,
 "awd_amount": 291887.0,
 "awd_min_amd_letter_date": "2012-09-11",
 "awd_max_amd_letter_date": "2014-07-20",
 "awd_abstract_narration": "Sirbu\r\nDMS-1211988\r\n\r\n     The investigator studies problems in stochastic control and financial mathematics.  The first and most important topic is a new look at the dynamic programming method in continuous-time stochastic control using a novel version of Perron's method.  Taking the supremum of stochastic sub-solutions and infimum of stochastic super-solutions, the new method provides two viscosity solutions squeezing between them the value function.  Uniqueness of the viscosity solution (in case it holds) then easily shows that the value function is the unique solution of the dynamic programming equation.  The dynamic programming principle is obtained as a conclusion using this approach, without any a priori analysis of the value function.  This amounts to verification without smoothness of the existence of a viscosity solution (similar to the verification argument in the classic case).  The second topic of the project resides in understanding the incentives of high-watermark fees on the fund manager, by modeling his/her strategic behavior.  The investigator and his colleagues study the optimal choice of the fund manager among available assets (that leads to the fund share price), such that the rational behavior of the investor (utility maximization on her side) yields maximal fees paid to the manager.  The third topic is a first step into understanding information percolation in the context of mean-field games of optimal stopping.  \r\n\r\n     Any decision under uncertainty can be modeled as a stochastic control/optimization problem.  This applies not only to finance and economics but to engineering and life sciences.  The current project mainly consists in a new technical approach to a very general class of stochastic control problems.  The new approach provides a deeper understanding of the optimization problems, and it also extends the scope of applications.  In addition, the project models and studies the strategic behavior of fund managers, as well as the percolation of information among populations that interact randomly.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mihai",
   "pi_last_name": "Sirbu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mihai Sirbu",
   "pi_email_addr": "sirbu@math.utexas.edu",
   "nsf_id": "000219317",
   "pi_start_date": "2012-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121068",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126600",
   "pgm_ele_name": "APPLIED MATHEMATICS"
  },
  {
   "pgm_ele_code": "755200",
   "pgm_ele_name": "COFFES"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 191332.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 100555.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Stochastic control problems model a wide range of decisions under uncertainty. One of the main tools to attack such problems is the dynamic programming method. In discrete models, &nbsp;the method amounts to splitting a dynamic problem into much simpler one period problems. For continuous time stochastic control, the situation is more complicated, and the method reduces to solving a partial differential equation. &nbsp;If the differential equation (called Hamilton-Jacobi-Bellman) has a smooth solution, it can be used to find the optimal controls in feedback form, and the solution of the equation is equal to the optimal payoff. &nbsp;</p>\n<p>The present award mostly focused on the dynamic programming method for situations when the Hamilton-Jacobi-Bellman equation does not have a smooth solution. One of the main outcomes is to introduce a novel method &nbsp;to &nbsp;approach dynamic programming &nbsp;and show that the non-smooth solution of the partial differential equation is equal to the optimal payoff. The method is not only a technical contribution (based on a modification of Perron's method), but brings deeper understanding into dynamic programming for continuous time stochastic control problems.</p>\n<p><br />Another very important &nbsp;outcome is the modeling and &nbsp;dynamic programming analysis of zero-sum stochastic differential games. Strategic games are well known to pose problems in both modeling strategies of individual players and the mathematical analysis of the resulting model. Using a natural framework of feedback strategies (and counter-strategies), &nbsp;different modifications of Perron's method &nbsp;relate the values of the games to the solutions of the Hamilton-Jacobi-Bellman-Isaacs equation. Most importantly, this provides a streamlined argument to showing that such games have a value, and this value can actually be attained over &nbsp; strategies/counter-strategies that take into account only the current position of the player, and not the whole past (so called, Markovian). At the technical level this requires a finer analysis than the one done above (even in the case of control problems, with one player) and the technique introduced by the PI is another novel modification of Perron's method.&nbsp;</p>\n<p><br />Overall, these sum up to more than interesting technical contributions to modeling and analysis of zero-sum games and stochastic control&nbsp;problems. The outcomes of the award bring &nbsp;a &nbsp;fresh look to important classes of models &nbsp; covering &nbsp;wide ranges of real-life situations.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/14/2016<br>\n\t\t\t\t\tModified by: Mihai&nbsp;Sirbu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nStochastic control problems model a wide range of decisions under uncertainty. One of the main tools to attack such problems is the dynamic programming method. In discrete models,  the method amounts to splitting a dynamic problem into much simpler one period problems. For continuous time stochastic control, the situation is more complicated, and the method reduces to solving a partial differential equation.  If the differential equation (called Hamilton-Jacobi-Bellman) has a smooth solution, it can be used to find the optimal controls in feedback form, and the solution of the equation is equal to the optimal payoff.  \n\nThe present award mostly focused on the dynamic programming method for situations when the Hamilton-Jacobi-Bellman equation does not have a smooth solution. One of the main outcomes is to introduce a novel method  to  approach dynamic programming  and show that the non-smooth solution of the partial differential equation is equal to the optimal payoff. The method is not only a technical contribution (based on a modification of Perron's method), but brings deeper understanding into dynamic programming for continuous time stochastic control problems.\n\n\nAnother very important  outcome is the modeling and  dynamic programming analysis of zero-sum stochastic differential games. Strategic games are well known to pose problems in both modeling strategies of individual players and the mathematical analysis of the resulting model. Using a natural framework of feedback strategies (and counter-strategies),  different modifications of Perron's method  relate the values of the games to the solutions of the Hamilton-Jacobi-Bellman-Isaacs equation. Most importantly, this provides a streamlined argument to showing that such games have a value, and this value can actually be attained over   strategies/counter-strategies that take into account only the current position of the player, and not the whole past (so called, Markovian). At the technical level this requires a finer analysis than the one done above (even in the case of control problems, with one player) and the technique introduced by the PI is another novel modification of Perron's method. \n\n\nOverall, these sum up to more than interesting technical contributions to modeling and analysis of zero-sum games and stochastic control problems. The outcomes of the award bring  a  fresh look to important classes of models   covering  wide ranges of real-life situations. \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/14/2016\n\n\t\t\t\t\tSubmitted by: Mihai Sirbu"
 }
}