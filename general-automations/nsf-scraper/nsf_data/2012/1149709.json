{
 "awd_id": "1149709",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Closed-Loop Crowd Support for People with Disabilities",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-02-15",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 500003.0,
 "awd_amount": 324509.0,
 "awd_min_amd_letter_date": "2012-02-09",
 "awd_max_amd_letter_date": "2014-02-10",
 "awd_abstract_narration": "To overcome accessibility problems, people with disabilities have traditionally relied upon the support of others in their community.  For instance, a volunteer may offer a few minutes of her time to read a blind person's mail aloud, or a fellow traveler may answer a quick question at the bus stop (e.g., \"Is that the 45 coming?\").  Professionals such as sign language interpreters and narrators of audio descriptions convert sensory information into alternative forms that enable a deaf student to participate in a conventional lecture and a blind person to enjoy a movie.  Internet connectivity has dramatically expanded the pool of potential human supporters, but finding reliable assistance on demand remains difficult.  The PI's goal in this project is to enable dynamic and diverse groups of people reachable via the Web (\"the crowd\") to interactively support people with disabilities.  The crowd is whoever happens to be available, from paid workers recruited on burgeoning micro-task marketplaces, to friends and family recruited via existing social networks, to volunteers willing to give a few minutes of their time.  While someone is always available, the crowd is dynamic and individual workers can be unreliable.  Thus, developing interactive systems to support people with disabilities presents numerous challenges, including how to enable crowd support that is real-time and high-quality, how to design interfaces that provide effective feedback even when an individual's directions may not be followed, and how to support collaboration among individual crowd workers without subverting methods of ensuring reliability.  To these ends, the PI will explore closed-loop crowd support with a number of applications.  VizWiz Stream will enable blind users to engage in an interactive conversation with the crowd about their visual environment.  AudioWiz Stream will provide nearly real-time transcription of aural speech.  And Legion and Legion VM will enable the crowd to collectively assume control of the keyboard and mouse to complete a user-specified task on existing desktop interfaces (whereas research in human-computer interaction usually assumes either a single user or a group of users collaborating in the same virtual space each in control of a personal cursor, this project will advance a new model in which a diverse and dynamic group collectively acts as a single operator).  These applications will inform a common model for closed-loop crowd support, and will be iteratively improved and evaluated in lab studies and field deployments with blind and deaf users.\r\n\r\nBroader Impacts:   Project outcomes will enable people with disabilities to overcome more accessibility problems independently and on demand.  The PI will release the software tools developed as part of this research as open source code, thereby enabling other researchers to build on his results.  Although initially intended for use by blind and deaf people, the tools will likely prove useful as well to people with other disabilities such as cognitive or motor impairments, and people without disabilities may want to outsource interactive tasks which they cannot do, do not want to do, or think the crowd may do better.  The PI will conduct annual summer programs in which blind and deaf high school students will develop tools for closed-loop crowd support, and also serve as supporters for people with different disabilities; these activities may encourage some of the participants with disabilities to pursue careers in computing, and the undergraduate students who help develop and run these activities will gain  personal exposure to accessible computing and the challenges people with disabilities face in computing that they will carry with them into their careers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jeffrey",
   "pi_last_name": "Bigham",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jeffrey Bigham",
   "pi_email_addr": "jbigham@cmu.edu",
   "nsf_id": "000541549",
   "pi_start_date": "2012-02-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 76289.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 115335.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 0.0
  }
 ],
 "por": null
}