{
 "awd_id": "1247368",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: A Research Infrastructure for Analyzing Speech-based Interfaces",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2014-01-31",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2012-07-25",
 "awd_max_amd_letter_date": "2012-09-14",
 "awd_abstract_narration": "The research community's understanding of the speech-to-text problem has reached a point at which most challenges can in principle be met, given a baseline system, enough data from the target domain, and an expert, who knows how to develop or adapt a recognizer for the target context-of-use. Unfortunately, this approach does not scale: despite the growing interest in speech-user interfaces, there are a limited number of experts equipped to analyze and develop an accurate speech recognizer.\r\n\r\nThis Early Grant for Exploratory Research explores the possibility of formalizing a speech recognition expert's implicit knowledge of the required analysis and development steps in a rule-based knowledge base, which can help a speech recognition non-expert develop a speech recognizer as part of an application, such as a dialog system in a rare dialect. Speech recognition experts adapt and improve recognizers by listening to data, aggregating error reports, and then adjusting parameters, retraining models, or applying adaptation techniques, based on their assessment of the mismatched context of use. This project extracts intuition from contextual interviews with such experts, develops a proof-of-concept expert system to predict the gains a system would see from specific adaptation techniques, and explores the factors which will make this approach feasible.\r\n\r\nThis project creates ways to make development of speech-enabled applications more accessible to a broader class of researchers, students, and practitioners, particularly from the user interface area. It will make joint development of user interface and speech recognition feasible, without requiring large teams with varied skill-sets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Florian",
   "pi_last_name": "Metze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Florian Metze",
   "pi_email_addr": "fmetze@cs.cmu.edu",
   "nsf_id": "000518948",
   "pi_start_date": "2012-07-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Kam",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Kam",
   "pi_email_addr": "mattkam@cs.cmu.edu",
   "nsf_id": "000525240",
   "pi_start_date": "2012-07-25",
   "pi_end_date": "2012-09-14"
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The research community's understanding of the speech-to-text problem has reached a point at which most challenges can in principle be met, given a baseline system, enough data from the target domain, and an expert, who knows how to develop or adapt a recognizer for the target context-of-use. Unfortunately, this approach does not scale: despite the growing interest in speech user interfaces, there are very few experts equipped to analyze a context and develop an accurate speech recognizer.&nbsp;</p>\n<p>In this project, our goal was to understand what speech experts &ldquo;intuitively&rdquo; do while building speech recognizers for a new user group, language, or an acoustic context, and formalize it, so that non-speech experts can benefit from it. The goal was not to render the speech expert superfluous, but to make it easier for non-speech experts, i.e. researchers or developers utilizing speech technology, to figure out why a speech system is failing, and guide their efforts in the right direction. More specifically, the goals were three fold: (i) to understand and formalize the tacit knowledge that speech experts employ while optimizing a recognizer for greater accuracy, (ii) support semi-automatic analysis of the errors occurring in speech recognition, and (iii) test the above rules and error analysis methodology through various experiments.</p>\n<p>In this work, we interviewed about 10 speech recognition experts and reviewed over 50 publications to formalize over 80 rules. We also developed a web-based, semi-automatic error analysis tool, which is available at&nbsp;<a href=\"http://speechkitchen.org/erroranalysis/\">http://speechkitchen.org/erroranalysis/</a>. Finally, we tested the above rules and error analysis strategy on two datasets and have demonstrated that the recommendations from the above rule-based knowledge base can lead to development of recognizers with accuracy at least as much as that from the experts&rsquo; recommendations. This shows the fundamental feasibility of the proposed approach, and helped us identify and udnerstand challenges, such as coverage of toolkit-specific techniques, while other questions could be solved, for example how to resolve conflicts between rules.&nbsp;</p>\n<p>This work has paved way for a larger research goal: how to make the task of developing speech applications more accessible to a broader class of researchers, students, and practitioners. Insights from this work will be integrated into the \"Speech Recognition Virtual Kitchen\" (<a href=\"http://www.speechkitchen.org/\">http://www.speechkitchen.org/</a>), and will such be made available to the research community, in order to enable progress towards that goal.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/05/2014<br>\n\t\t\t\t\tModified by: Florian&nbsp;Metze</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe research community's understanding of the speech-to-text problem has reached a point at which most challenges can in principle be met, given a baseline system, enough data from the target domain, and an expert, who knows how to develop or adapt a recognizer for the target context-of-use. Unfortunately, this approach does not scale: despite the growing interest in speech user interfaces, there are very few experts equipped to analyze a context and develop an accurate speech recognizer. \n\nIn this project, our goal was to understand what speech experts \"intuitively\" do while building speech recognizers for a new user group, language, or an acoustic context, and formalize it, so that non-speech experts can benefit from it. The goal was not to render the speech expert superfluous, but to make it easier for non-speech experts, i.e. researchers or developers utilizing speech technology, to figure out why a speech system is failing, and guide their efforts in the right direction. More specifically, the goals were three fold: (i) to understand and formalize the tacit knowledge that speech experts employ while optimizing a recognizer for greater accuracy, (ii) support semi-automatic analysis of the errors occurring in speech recognition, and (iii) test the above rules and error analysis methodology through various experiments.\n\nIn this work, we interviewed about 10 speech recognition experts and reviewed over 50 publications to formalize over 80 rules. We also developed a web-based, semi-automatic error analysis tool, which is available at http://speechkitchen.org/erroranalysis/. Finally, we tested the above rules and error analysis strategy on two datasets and have demonstrated that the recommendations from the above rule-based knowledge base can lead to development of recognizers with accuracy at least as much as that from the experts\u00c6 recommendations. This shows the fundamental feasibility of the proposed approach, and helped us identify and udnerstand challenges, such as coverage of toolkit-specific techniques, while other questions could be solved, for example how to resolve conflicts between rules. \n\nThis work has paved way for a larger research goal: how to make the task of developing speech applications more accessible to a broader class of researchers, students, and practitioners. Insights from this work will be integrated into the \"Speech Recognition Virtual Kitchen\" (http://www.speechkitchen.org/), and will such be made available to the research community, in order to enable progress towards that goal.\n\n \n\n\t\t\t\t\tLast Modified: 03/05/2014\n\n\t\t\t\t\tSubmitted by: Florian Metze"
 }
}