{
 "awd_id": "1250265",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  Multi-Domain, Workflow Driven Computation System for Microbial Ecology Research and Analysis",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Irene Qualters",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2014-07-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2012-08-10",
 "awd_max_amd_letter_date": "2012-08-10",
 "awd_abstract_narration": "This EAGER award to the University of California - San Diego, explores innovations to The Community Cyberinfrastructure for Advanced Microbial Ecology Research and Analysis, (CAMERA, http://camera.calit2.net/).  CAMERA is a widely used infrastructure that provides a single software system for depositing, locating, analyzing, visualization and sharing data about microbial biology.  A heavily utilized and core component of CAMERA is the workflow driven computational system for data analysis.  The award anticipates analysis needed for next generation sequence (NGS) data.  BLASTx Work flows using CAMERA's Refseq Protein database) will require nearly 2.5 Million core hours to complete analysis of a typical NGS data set, making it impractical and costly to rely on a single computational resource for an entire workflow.   The PI will prototype novel heuristic-based dynamic resource scheduling approaches to allowing distribution of workflow tasks among heterogeneous computing domains such as local systems, a variety of commercial clouds, and multiple national resources.\r\n\r\nThis research explores development of a multi-domain scheduling system where the individual component tasks of a workflow are not bound to a single computational resource or domain, but rather can be scheduled across multiple resources as well as across institutional domains.  It benefits a rapidly growing segment of the scientific community in both large and modest laboratories whose instruments now generate massive amounts of genomic data at modest expense but who have insufficient access to resources needed for processing or analyzing these data.  The cyberinfrastructure to be established will potentially be usable by other science communities facing similar computational challenges.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Ellisman",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Mark H Ellisman",
   "pi_email_addr": "mark@alex.ucsd.edu",
   "nsf_id": "000457536",
   "pi_start_date": "2012-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9145",
   "pgm_ref_txt": "SPECIAL PROGRAMS-RESERVE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Scientific data is growing at an explosive rate.&nbsp; The volume of information, in both public domain databases and private research projects, is stressing the current capacity of high-performance computational systems.&nbsp; In the field of metagenomics, this growth of data is best represented by data generated from next generation sequencing (NGS) platforms.&nbsp; Already, CRBS&rsquo;s current remote cluster execution (RCE) system enables access to several Extreme Science and Engineering Discovery Environment (XSEDE) clusters.&nbsp; Following current cluster computing usage norms, a workflow (and its component jobs) is limited to a single cluster resource for computation.&nbsp; With continually growing data sizes and resultant computational requirements, however, it has become necessary to coordinate multiple clusters for a single workflow.&nbsp; We created a software tool, Panfish, to address this need.</p>\n<p>&nbsp;</p>\n<p>Using XSEDE compute resources (or any external compute resource) typically requires the following three operations to be performed: upload data, run workflow, and copy back results.&nbsp; Panfish (semi-)automatically coordinates these operations across multiple cluster resources. Furthermore, Panfish has been expressly designed to enable job submission in a process similar to invocation of jobs on a single local cluster running Sun Grid Engine (SGE) - with the added advantage that those jobs can optionally be sent to multiple XSEDE resources.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Using Panfish, we are able to submit jobs from a single workflow across multiple and heterogeneous cluster computing systems, including local cluster, XSEDE, and commercial cloud resources.&nbsp;&nbsp; To date, Panfish has coordinated the <em><span style=\"text-decoration: underline;\">simultaneous</span></em> use of up to nine heterogeneous and geographically distributed cluster resources.</p>\n<p>&nbsp;</p>\n<p>In completing this project, we have endeavored to fulfill the following merit review criteria.&nbsp; By increasing the throughput of computationally intensive algorithms, Panfish fulfills the &ldquo;Intellectual Merit&rdquo; criteria by providing a means to accelerate the rate of scientific discovery and therefore the rate at which knowledge is advanced. &nbsp;The &ldquo;Broader Impact&rdquo; of Panfish is that it allows XSEDE, as well as local and commercial cloud resources, to be used with greater coordination and efficiency than could be run individually.&nbsp; Specifically, Panfish provides a mechanism whereby all disparate XSEDE resources, which span physical and administrative domains, can be simultaneously employed towards a common scientific question.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/05/2014<br>\n\t\t\t\t\tModified by: Mark&nbsp;H&nbsp;Ellisman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nScientific data is growing at an explosive rate.  The volume of information, in both public domain databases and private research projects, is stressing the current capacity of high-performance computational systems.  In the field of metagenomics, this growth of data is best represented by data generated from next generation sequencing (NGS) platforms.  Already, CRBS\u00c6s current remote cluster execution (RCE) system enables access to several Extreme Science and Engineering Discovery Environment (XSEDE) clusters.  Following current cluster computing usage norms, a workflow (and its component jobs) is limited to a single cluster resource for computation.  With continually growing data sizes and resultant computational requirements, however, it has become necessary to coordinate multiple clusters for a single workflow.  We created a software tool, Panfish, to address this need.\n\n \n\nUsing XSEDE compute resources (or any external compute resource) typically requires the following three operations to be performed: upload data, run workflow, and copy back results.  Panfish (semi-)automatically coordinates these operations across multiple cluster resources. Furthermore, Panfish has been expressly designed to enable job submission in a process similar to invocation of jobs on a single local cluster running Sun Grid Engine (SGE) - with the added advantage that those jobs can optionally be sent to multiple XSEDE resources. \n\n \n\nUsing Panfish, we are able to submit jobs from a single workflow across multiple and heterogeneous cluster computing systems, including local cluster, XSEDE, and commercial cloud resources.   To date, Panfish has coordinated the simultaneous use of up to nine heterogeneous and geographically distributed cluster resources.\n\n \n\nIn completing this project, we have endeavored to fulfill the following merit review criteria.  By increasing the throughput of computationally intensive algorithms, Panfish fulfills the \"Intellectual Merit\" criteria by providing a means to accelerate the rate of scientific discovery and therefore the rate at which knowledge is advanced.  The \"Broader Impact\" of Panfish is that it allows XSEDE, as well as local and commercial cloud resources, to be used with greater coordination and efficiency than could be run individually.  Specifically, Panfish provides a mechanism whereby all disparate XSEDE resources, which span physical and administrative domains, can be simultaneously employed towards a common scientific question. \n\n\t\t\t\t\tLast Modified: 08/05/2014\n\n\t\t\t\t\tSubmitted by: Mark H Ellisman"
 }
}