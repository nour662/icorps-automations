{
 "awd_id": "1246057",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CC-NIE Integration: Transforming Computational Science with ADAMANT (Adaptive Data-Aware Multi-Domain Application Network Topologies)",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2014-12-31",
 "tot_intn_awd_amt": 204070.0,
 "awd_amount": 204070.0,
 "awd_min_amd_letter_date": "2012-09-10",
 "awd_max_amd_letter_date": "2012-09-10",
 "awd_abstract_narration": "Workflows, especially data-driven workflows and workflow ensembles are becoming a centerpiece of modern computational science. However, scientists lack the tools that integrate the operation of workflow-driven science applications on top of dynamic infrastructures that link campus, institutional and national resources into connected arrangements targeted at solving a specific problem. These tools must (a) orchestrate the infrastructure in response to application demands, (b) manage application lifetime on top of the infrastructure by monitoring various workflow steps and modifying slices in response to application demands, and (c) integrate data movement with the workflows to optimize performance.\r\n \r\nProject ADAMANT (Adaptive Data-Aware Multi-domain Application Network Topologies) brings together researchers from RENCI/UNC Chapel Hill, Duke University and USC/ISI and two successful software tools to solve these problems: Pegasus workflow management system and ORCA resource control framework, developed for NSF GENI. The integration of Pegasus and ORCA enables powerful application- and data-driven virtual topology embedding into multiple institutional and national substrates (providers of cyber-resources, like computation, storage and networks). ADAMANT leverages ExoGENI - an NSF-funded GENI testbed, as well as national providers of on-demand bandwidth services (NLR, I2, ESnet) and existing OSG computational resources to create elastic, isolated environments to execute complex distributed tasks. This approach improves the performance of these applications and, by explicitly including data movement planning into the application workflow, enables new unique capabilities for distributed data-driven \"Big Science\" applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ewa",
   "pi_last_name": "Deelman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ewa Deelman",
   "pi_email_addr": "deelman@isi.edu",
   "nsf_id": "000119337",
   "pi_start_date": "2012-09-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "USC-Information Sciences Institute",
  "perf_str_addr": "4676 Admiralty Way, Suite 1001",
  "perf_city_name": "Marina del Rey",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "902926611",
  "perf_ctry_code": "US",
  "perf_cong_dist": "36",
  "perf_st_cong_dist": "CA36",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "808000",
   "pgm_ele_name": "Campus Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 204070.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-8fcaba1b-4d8c-f9d6-8702-caf1dde1f521\">\n<p dir=\"ltr\"><span>The project brought together teams of computer scientists from RENCI/UNC Chapel Hill, USC/ISI and Duke University with the purpose of studying the feasibility of complex scientific computational workflows running on dynamically provisioned cloud-like widely distributed cyber-infrastructure. The distributed cyber-infrastructure included a collection of institutional clouds, which included computational and storage resources linked with on-demand network connections that can all be provisioned together using ORCA control software, developed at Duke and RENCI and deployed in ExoGENI testbed (http://www.exogeni.net). The workflows were managed by the Pegasus workflow management system (http://pegasus.isi.edu/) designed at ISI. The project team developed software elements to tie these two systems together with a performance feedback mechanism called ShadowQ and also provide an easy-to-use portal for scientists to submit and monitor their computational workflows. </span></p>\n<br />\n<p dir=\"ltr\"><span>The main goal of the project was to prove that such a coupling between workflows and infrastructure was indeed possible, i.e. it was possible for a workflow to provision the necessary infrastructure for itself and manage it through the workflow execution process. The benefits of this approach include improved usability by domain scientists compared to existing institutional and grid resources as well better predictability and performance and security isolation, which speed up the discovery process and encourage more scientists to use existing resources. Additionally, learning how to execute workflows in distributed cyber-infrastructure represented by ExoGENI demonstrated how multiple different science domains can effectively use federated resources contributed by multiple institutions thus reducing the need for creating and maintaining separate cyber infrastructures for each science domain and improving the efficiency of investments in infrastructure build-outs. </span></p>\n<br />\n<p dir=\"ltr\"><span>The project focused on two science domains - astronomy and high-throughput gene sequencing. The two domains were chosen because on the one hand they heavily rely on workflows and workflow management systems for performing their computational tasks and on the other, of their widely differing requirements to the cyber infrastructure that must execute those workflows. The ADAMANT team successfully demonstrated both astronomy and gene sequencing applications at various venues including the premiere SuperComputing conference and generated interest among the scientists in those two domains. </span></p>\n<br /><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/02/2015<br>\n\t\t\t\t\tModified by: Ewa&nbsp;Deelman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe project brought together teams of computer scientists from RENCI/UNC Chapel Hill, USC/ISI and Duke University with the purpose of studying the feasibility of complex scientific computational workflows running on dynamically provisioned cloud-like widely distributed cyber-infrastructure. The distributed cyber-infrastructure included a collection of institutional clouds, which included computational and storage resources linked with on-demand network connections that can all be provisioned together using ORCA control software, developed at Duke and RENCI and deployed in ExoGENI testbed (http://www.exogeni.net). The workflows were managed by the Pegasus workflow management system (http://pegasus.isi.edu/) designed at ISI. The project team developed software elements to tie these two systems together with a performance feedback mechanism called ShadowQ and also provide an easy-to-use portal for scientists to submit and monitor their computational workflows. \n\n\nThe main goal of the project was to prove that such a coupling between workflows and infrastructure was indeed possible, i.e. it was possible for a workflow to provision the necessary infrastructure for itself and manage it through the workflow execution process. The benefits of this approach include improved usability by domain scientists compared to existing institutional and grid resources as well better predictability and performance and security isolation, which speed up the discovery process and encourage more scientists to use existing resources. Additionally, learning how to execute workflows in distributed cyber-infrastructure represented by ExoGENI demonstrated how multiple different science domains can effectively use federated resources contributed by multiple institutions thus reducing the need for creating and maintaining separate cyber infrastructures for each science domain and improving the efficiency of investments in infrastructure build-outs. \n\n\nThe project focused on two science domains - astronomy and high-throughput gene sequencing. The two domains were chosen because on the one hand they heavily rely on workflows and workflow management systems for performing their computational tasks and on the other, of their widely differing requirements to the cyber infrastructure that must execute those workflows. The ADAMANT team successfully demonstrated both astronomy and gene sequencing applications at various venues including the premiere SuperComputing conference and generated interest among the scientists in those two domains. \n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 02/02/2015\n\n\t\t\t\t\tSubmitted by: Ewa Deelman"
 }
}