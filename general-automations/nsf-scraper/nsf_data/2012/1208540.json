{
 "awd_id": "1208540",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI-Small: Managing Uncertainty in Human-Robot Cooperative Systems",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "jeffrey trinkle",
 "awd_eff_date": "2012-10-01",
 "awd_exp_date": "2016-09-30",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1015800.0,
 "awd_min_amd_letter_date": "2012-09-11",
 "awd_max_amd_letter_date": "2016-04-28",
 "awd_abstract_narration": "This project attempts to combine human strengths in reasoning with machine capabilities in information fusion, task planning, and simulation to manage uncertainty and achieve successful human-robot partnerships to perform complex tasks in uncertain environments that were previously considered impractical or infeasible. The approach consists of three objectives: the use of sensing and control to reduce model registration uncertainty; the definition, simulation and implementation of virtual fixtures to allow humans to intuitively constrain the task; and the development of bi-directional task planning and execution with uncertainty to allow humans and robots to request help from one another.\r\n\r\nThis research has a number of broader impacts affecting both the academic community and society at large. The work is expected to have significant appeal to those in the manufacturing and medical robotics sectors, as testbeds will impact these areas. The PIs will mentor hands-on research by undergraduate, graduate, and post-doc students and guide them in the dissemination of their research to the scientific community. The team will also provide engineering experiences for middle school girls in the Baltimore area through weekend programs on the Johns Hopkins University campus, including the \"Ready, Set, Design!\" program. Finally, the development will be made freely available as all software will be fully integrated with open-source ROS.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Kazanzides",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Peter Kazanzides",
   "pi_email_addr": "pkaz@jhu.edu",
   "nsf_id": "000582621",
   "pi_start_date": "2012-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Louis",
   "pi_last_name": "Whitcomb",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Louis L Whitcomb",
   "pi_email_addr": "llw@jhu.edu",
   "nsf_id": "000319307",
   "pi_start_date": "2012-09-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Simon",
   "pi_last_name": "Leonard",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Simon Leonard",
   "pi_email_addr": "simon.v.leonard@gmail.com",
   "nsf_id": "000606691",
   "pi_start_date": "2012-09-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "3400 North Charles Street",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 1000000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 7800.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This research investigated co-robotic interfaces that combine the experience of a human operator with the sensitivity and accuracy of a robotic system for applications in surgery and space. We focused on methods to overcome some of the uncertainty that makes these procedures more challenging.</p>\n<p>For the surgical application, we considered endoscopic brain surgery, where the surgeon drills through the sinus cavity to achieve minimally-invasive access to tumors, such as those infiltrating the pituitary gland. One risk with this surgery is accidental damage to the carotid arteries or optic nerves, which are located behind the bone being drilled. Although one can estimate their location based on other anatomical features or on preoperative images, their exact position is uncertain. We developed a real-time measurement system based on the principle of photoacoustic ultrasound. Specifically, we attach an optical fiber to the drill, though which a pulsed laser is directed in front of the cutter. As the bone thins, this laser penetrates the bone and generates an acoustic signal if it encounters a blood vessel. We use an external ultrasound probe to receive this acoustic signal. The system can then warn the surgeon about the impending danger and provide guidance to avoid accidental harm. We tested the system with synthetic materials to demonstrate the concept. The next step is to test under more realistic conditions, with the ultimate goal to help improve the safety of operations where the surgeon must cut or drill near critical anatomy that is hidden from view.</p>\n<p>The space application considered ground-based control of a servicing robot in space that could repair or refuel a satellite, thereby extending its life and preserving a large financial investment. One challenge with this procedure is the long time delay between the human operator on earth and the servicing robot in space, which is on the order of several seconds. This makes it difficult for the human operator to precisely and efficiently control the remote robot, especially when the robots must physically interact with the satellite.&nbsp; We approached this challenge by creating a model of the satellite and enabling the human operator to perform the servicing action in a simulated environment (see Figure).&nbsp; The advantage of the simulated environment is that it is not subject to time delay and servicing can always be successfully accomplished. But, servicing a simulated satellite does not help the actual satellite. The solution, however, is to transmit the results of the simulation to space and to use sensing and control on the space robot to attempt to reproduce the simulation result on the actual satellite. In many cases, the sensors on the remote robot are able to compensate for differences between the real environment and the simulated environment. But, since our model includes the normal range of expected sensor readings, the software on the remote robot is able to detect when it has failed to make reality match the simulation. In that case, the space robot stops and waits for assistance from the human operator. We successfully tested this approach on a ground-based test setup, with software-created time delays of several seconds.</p>\n<p>Both projects provided research opportunities for undergraduate, graduate, and postgraduate students. For example, seven undergraduate students participated via the NSF Research Experience for Undergraduates (REU) program and were first authors or co-authors on six conference papers and two journal papers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/02/2017<br>\n\t\t\t\t\tModified by: Peter&nbsp;Kazanzides</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1208540/1208540_10213686_1486088152242_ModelBased--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1208540/1208540_10213686_1486088152242_ModelBased--rgov-800width.jpg\" title=\"System for Satellite Servicing\"><img src=\"/por/images/Reports/POR/2017/1208540/1208540_10213686_1486088152242_ModelBased--rgov-66x44.jpg\" alt=\"System for Satellite Servicing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Model-based approach for satellite servicing. Operator on earth interacts with simulated environment. Results of simulation sent to robot in space, which uses sensing and control to reproduce simulation result on actual satellite.</div>\n<div class=\"imageCredit\">Peter Kazanzides</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Peter&nbsp;Kazanzides</div>\n<div class=\"imageTitle\">System for Satellite Servicing</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis research investigated co-robotic interfaces that combine the experience of a human operator with the sensitivity and accuracy of a robotic system for applications in surgery and space. We focused on methods to overcome some of the uncertainty that makes these procedures more challenging.\n\nFor the surgical application, we considered endoscopic brain surgery, where the surgeon drills through the sinus cavity to achieve minimally-invasive access to tumors, such as those infiltrating the pituitary gland. One risk with this surgery is accidental damage to the carotid arteries or optic nerves, which are located behind the bone being drilled. Although one can estimate their location based on other anatomical features or on preoperative images, their exact position is uncertain. We developed a real-time measurement system based on the principle of photoacoustic ultrasound. Specifically, we attach an optical fiber to the drill, though which a pulsed laser is directed in front of the cutter. As the bone thins, this laser penetrates the bone and generates an acoustic signal if it encounters a blood vessel. We use an external ultrasound probe to receive this acoustic signal. The system can then warn the surgeon about the impending danger and provide guidance to avoid accidental harm. We tested the system with synthetic materials to demonstrate the concept. The next step is to test under more realistic conditions, with the ultimate goal to help improve the safety of operations where the surgeon must cut or drill near critical anatomy that is hidden from view.\n\nThe space application considered ground-based control of a servicing robot in space that could repair or refuel a satellite, thereby extending its life and preserving a large financial investment. One challenge with this procedure is the long time delay between the human operator on earth and the servicing robot in space, which is on the order of several seconds. This makes it difficult for the human operator to precisely and efficiently control the remote robot, especially when the robots must physically interact with the satellite.  We approached this challenge by creating a model of the satellite and enabling the human operator to perform the servicing action in a simulated environment (see Figure).  The advantage of the simulated environment is that it is not subject to time delay and servicing can always be successfully accomplished. But, servicing a simulated satellite does not help the actual satellite. The solution, however, is to transmit the results of the simulation to space and to use sensing and control on the space robot to attempt to reproduce the simulation result on the actual satellite. In many cases, the sensors on the remote robot are able to compensate for differences between the real environment and the simulated environment. But, since our model includes the normal range of expected sensor readings, the software on the remote robot is able to detect when it has failed to make reality match the simulation. In that case, the space robot stops and waits for assistance from the human operator. We successfully tested this approach on a ground-based test setup, with software-created time delays of several seconds.\n\nBoth projects provided research opportunities for undergraduate, graduate, and postgraduate students. For example, seven undergraduate students participated via the NSF Research Experience for Undergraduates (REU) program and were first authors or co-authors on six conference papers and two journal papers.\n\n\t\t\t\t\tLast Modified: 02/02/2017\n\n\t\t\t\t\tSubmitted by: Peter Kazanzides"
 }
}