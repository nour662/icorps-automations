{
 "awd_id": "1246133",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CC-NIE Integration: ANSE (Advanced Network Services for Experiments)",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924220",
 "po_email": "kthompso@nsf.gov",
 "po_sign_block_name": "Kevin Thompson",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2015-12-31",
 "tot_intn_awd_amt": 800000.0,
 "awd_amount": 800000.0,
 "awd_min_amd_letter_date": "2012-09-13",
 "awd_max_amd_letter_date": "2015-01-29",
 "awd_abstract_narration": "Recent years have seen a dramatic evolution in the area of research and education networking, enabling faster data rates  and novel services to user communities. The ANSE project integrates these new services, in particular dynamic bandwidth  allocation (DYNES) and real-time network performance monitoring (perfSONAR), with the higher level workload management software deployed for the Large Hadron Collider (LHC), like PanDA and PhEDEx in the ATLAS and CMS experiments, respectively. A software defined networking approach, and in particular the use of dynamic bandwidth allocation capability, already available in ESnet and Internet2 networks, makes the network a truly manageable resource, on par with computing (CPU) and storage (disk and tape) resources. This approach enables smart optimization of resource utilization through co-scheduling and deadline scheduling algorithms within data and workload management systems. The ANSE system reacts to real-time conditions such as network events or node failure, as well as usage specific parameters like changes in data distribution priorities. Importance is given to the multi-domain aspects of networking, as required for a globally distributed system.\r\n\r\nWhile the primary target for ANSE is the LHC experiments, the ANSE project is clearly applicable to other data intensive science fields as well. Through the use of recognized standards such as the OGF NSI, ANSE is applicable beyond the use case of the LHC, and in particular to all distributed computing and data intensive applications of global scale.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Harvey",
   "pi_last_name": "Newman",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Harvey B Newman",
   "pi_email_addr": "newman@hep.caltech.edu",
   "nsf_id": "000171318",
   "pi_start_date": "2012-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Paul",
   "pi_last_name": "Sheldon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Paul Sheldon",
   "pi_email_addr": "Paul.Sheldon@Vanderbilt.edu",
   "nsf_id": "000359040",
   "pi_start_date": "2012-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kaushik",
   "pi_last_name": "De",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kaushik De",
   "pi_email_addr": "Kaushik@uta.edu",
   "nsf_id": "000177319",
   "pi_start_date": "2012-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Shawn",
   "pi_last_name": "McKee",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shawn McKee",
   "pi_email_addr": "smckee@umich.edu",
   "nsf_id": "000320041",
   "pi_start_date": "2012-09-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Artur",
   "pi_last_name": "Barczyk",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Artur Barczyk",
   "pi_email_addr": "Artur.Barczyk@cern.ch",
   "nsf_id": "000620959",
   "pi_start_date": "2012-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Institute of Technology",
  "inst_street_address": "1200 E CALIFORNIA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "PASADENA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6263956219",
  "inst_zip_code": "911250001",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "CALIFORNIA INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "U2JMKHNS5TG4"
 },
 "perf_inst": {
  "perf_inst_name": "California Institute of Technology",
  "perf_str_addr": "1200 E California Blvd MC256-48",
  "perf_city_name": "Pasadena",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "911250001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808000",
   "pgm_ele_name": "Campus Cyberinfrastructure"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 800000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Highly capable and reliable networks have been critical to the science discoveries in high energy physics for the last decades, and this has been increasingly true in other data intensive fields ranging from astrophysics and photon science to genomics in recent years. As the needs of the leading programs for acquiring, processing, distributing and analyzing globally distributed data have continued to grow exponentially in both scale and complexity, the science programs and the world&rsquo;s research and education networks that support them have been increasingly challenged. A new class of agile software driven systems coordinating network, storage and computing resources worldwide is required if these programs are to continue to realize their full potential for discoveries, now and in the coming decade.</p>\n<p>&nbsp;</p>\n<p>The ANSE (Advanced Network Services for Experiments) project, which began on January 1, 2013 and completed in the Fall of 2015, has had a pivotal role in meeting these challenges, leaving behind a strong legacy and a path forward in terms of integrating advanced network methods and services into the mainstream operations and systems of major data intensive science programs, starting with the CMS and ATLAS experiments at the LHC. The outcomes of ANSE have paved the way towards more effective and coordinated use of the world&rsquo;s research and education networks by these experiments, by other upcoming data intensive programs with needs on a similar scale such as the Large Synoptic Space Telescope (LSST), and by future programs with even greater needs such as the High Luminosity LHC (HL LHC), the Square Kilometer Array (SKA) and several projects in genomics which foresee exabyte-scale and larger datasets.</p>\n<p>&nbsp;</p>\n<p>The rise of Software Defined Networks (SDN) before and during the ANSE project enabled the team to make rapid progress in meeting its goals, while making leading edge contributions to the concept and development of SDN systems of global scope. By exploiting and contributing to this trend in the research community and industry, the ANSE team and its science, network and industry partners developed and deployed the first prototypes of a terabit/sec scale, software-driven dynamic system capable of provisioning and intelligently directing data flows, and coordinating the use of networks and storage on an unprecedented scale. This was demonstrated at the Supercomputing 2013-2015 conferences, in dedicated exercises among the US, Europe and Latin America aimed at the LSST program, and in a persistent testbed deployed in 2015 and now in operation at Caltech, the Starlight facility in Chicago, along with CERN, Fermilab, Michigan, as well as several campuses in the Pacific Research Platform.&nbsp;</p>\n<p>&nbsp;</p>\n<p>The groundbreaking progress achieved in the ANSE project was accomplished through the development and integration of several technologies, pushing forward the state of the art in many cases, including:</p>\n<p><strong>(1)</strong> The ability to allocate guaranteed bandwidth across complex networks of global extent, notably including the LHC Open Network Environment (LHCONE), using both well-established and emerging standard (NSI<span style=\"text-decoration: underline;\">)</span> methods developed by the Energy Sciences network (ESnet) and partners in the Open Grid Forum,</p>\n<p><strong>(2)</strong> The ability to construct paths supporting the dynamic circuits and other classes of flows intelligently, taking into account the available bandwidth, profiles and priorities of various transfers, as well as the network state and performance on each segment, using a Software Defined Network (SDN) controller developed by the Caltech team,</p>\n<p><strong>(3)</strong> Coupling the path selection and flow management methods of the Caltech controller with end-site services based on Open vSwitch (OVS) to provide stable protocol agnost...",
  "por_txt_cntn": "\nHighly capable and reliable networks have been critical to the science discoveries in high energy physics for the last decades, and this has been increasingly true in other data intensive fields ranging from astrophysics and photon science to genomics in recent years. As the needs of the leading programs for acquiring, processing, distributing and analyzing globally distributed data have continued to grow exponentially in both scale and complexity, the science programs and the world\u00c6s research and education networks that support them have been increasingly challenged. A new class of agile software driven systems coordinating network, storage and computing resources worldwide is required if these programs are to continue to realize their full potential for discoveries, now and in the coming decade.\n\n \n\nThe ANSE (Advanced Network Services for Experiments) project, which began on January 1, 2013 and completed in the Fall of 2015, has had a pivotal role in meeting these challenges, leaving behind a strong legacy and a path forward in terms of integrating advanced network methods and services into the mainstream operations and systems of major data intensive science programs, starting with the CMS and ATLAS experiments at the LHC. The outcomes of ANSE have paved the way towards more effective and coordinated use of the world\u00c6s research and education networks by these experiments, by other upcoming data intensive programs with needs on a similar scale such as the Large Synoptic Space Telescope (LSST), and by future programs with even greater needs such as the High Luminosity LHC (HL LHC), the Square Kilometer Array (SKA) and several projects in genomics which foresee exabyte-scale and larger datasets.\n\n \n\nThe rise of Software Defined Networks (SDN) before and during the ANSE project enabled the team to make rapid progress in meeting its goals, while making leading edge contributions to the concept and development of SDN systems of global scope. By exploiting and contributing to this trend in the research community and industry, the ANSE team and its science, network and industry partners developed and deployed the first prototypes of a terabit/sec scale, software-driven dynamic system capable of provisioning and intelligently directing data flows, and coordinating the use of networks and storage on an unprecedented scale. This was demonstrated at the Supercomputing 2013-2015 conferences, in dedicated exercises among the US, Europe and Latin America aimed at the LSST program, and in a persistent testbed deployed in 2015 and now in operation at Caltech, the Starlight facility in Chicago, along with CERN, Fermilab, Michigan, as well as several campuses in the Pacific Research Platform. \n\n \n\nThe groundbreaking progress achieved in the ANSE project was accomplished through the development and integration of several technologies, pushing forward the state of the art in many cases, including:\n\n(1) The ability to allocate guaranteed bandwidth across complex networks of global extent, notably including the LHC Open Network Environment (LHCONE), using both well-established and emerging standard (NSI) methods developed by the Energy Sciences network (ESnet) and partners in the Open Grid Forum,\n\n(2) The ability to construct paths supporting the dynamic circuits and other classes of flows intelligently, taking into account the available bandwidth, profiles and priorities of various transfers, as well as the network state and performance on each segment, using a Software Defined Network (SDN) controller developed by the Caltech team,\n\n(3) Coupling the path selection and flow management methods of the Caltech controller with end-site services based on Open vSwitch (OVS) to provide stable protocol agnostic flows end-to-end at any specified rate, up to 100 Gbps wire speed where needed,\n\n(4) Designing, developing and tuning relatively low cost data transfer nodes that, together with Caltech\u00c6s Fast Data Transfer application, that are able to provide ..."
 }
}