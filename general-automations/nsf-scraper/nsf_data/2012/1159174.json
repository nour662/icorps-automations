{
 "awd_id": "1159174",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Web corpora and computational resources for endangered languages",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Colleen M. Fitzgerald",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2015-12-31",
 "tot_intn_awd_amt": 89513.0,
 "awd_amount": 89513.0,
 "awd_min_amd_letter_date": "2012-05-23",
 "awd_max_amd_letter_date": "2012-05-23",
 "awd_abstract_narration": "Written language data play a critical role in both linguistic research and in the development of modern software tools for language processing. Traditionally, data of this kind have been expensive to produce, involving either linguistic fieldwork, digitization of printed materials, or cooperation with commercial publishers.  Over the last fifteen years, however, the vast quantities of text available on the web have made it possible to assemble \"disposable\" language databases quickly and easily for many languages. The relative ease with which indigenous and minority language groups can publish material online, through blogs, social media sites, and online newspapers, has brought the benefits of modern language processing to a much wider range of languages than was ever thought possible.\r\n\r\nThis project involves the collection and dissemination of language data (in the form of word frequency lists, sample texts, etc.) for over 1200 languages. The data are gathered by a web crawler that uses statistical methods to identify the language of documents automatically. The data will be made freely available in convenient formats to linguists, to support research on endangered languages; to software developers, to help in producing computational tools that make it easier for endangered language communities to use their languages online; and to local communities, to assist in grassroots language revitalization projects.\r\n\r\nOne of the scientific challenges will be the development of language identification techniques that scale up to thousands of languages, and that work effectively with limited training data.\r\n\r\nFinally, while the primary focus of the project is the production of useful linguistic data, it will incidentally provide the best answer to date to the fundamental question \"How many languages are represented on the web?\" which has been the subject of research by academics and public-benefit organizations like UNESCO since the early days of the web.  The project involves collaboration with local language groups to develop tools such as spell checkers and grammar checkers. The research involves collaboration with community members, with capacity building.\r\n\r\nThe Division of Information & Intelligent Systems of the Directorate for Computer & Information Science & Engineering is [co-]funding this award as part of its commitment to support the development of computational tools and methods for the documentation of endangered languages.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kevin",
   "pi_last_name": "Scannell",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Kevin P Scannell",
   "pi_email_addr": "kscanne@gmail.com",
   "nsf_id": "000261537",
   "pi_start_date": "2012-05-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Saint Louis University",
  "inst_street_address": "221 N GRAND BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3149773925",
  "inst_zip_code": "631032006",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "SAINT LOUIS UNIVERSITY",
  "org_prnt_uei_num": "JNBLLTBTLLD8",
  "org_uei_num": "JNBLLTBTLLD8"
 },
 "perf_inst": {
  "perf_inst_name": "Saint Louis University",
  "perf_str_addr": "221 N. Grand Blvd.",
  "perf_city_name": "St. Louis",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631032006",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7719",
   "pgm_ref_txt": "DEL"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 89513.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There are over 7000 languages spoken in the world today, but an increasing number of these are not spoken by younger members of their language communities, and are in danger of falling out of everyday use.&nbsp; The linguist Ken Hale famously said that \"languages embody the intellectual wealth of the people that speak them. Losing any one of them is like dropping a bomb on the Louvre.\" The aim of this project is to help address the crisis in linguistic diversity by providing data to linguists that can be used in the scientific study of languages, and by putting software tools directly in the hands of endangered language communities to make it easier for them to use their language on the computer and online.</p>\n<p>Broadly speaking, this project is a survey of language use on the web; we have collected millions of web pages over many years, identified the language that each of them is written in, and organized these into datasets that linguists and other software developers can use in their own research projects.&nbsp; To date, we have found texts in nearly 2200 different languages online; these include Bible translations, e-books, legal documents, newsgroup archives, blog posts, tweets, and much more. This is the most complete and accurate picture of the linguistic diversity of the web.</p>\n<p>What can researchers do with these datasets?&nbsp; In the field of linguistics, texts represent one form of \"raw data\" that allow linguists to study and describe the world's languages.&nbsp; Massively multilingual datasets of this kind are particularly useful for doing cross-linguistic analysis across many language families. Sociolinguists can use the data to see which domains particular languages are used in, or to study the geographical distribution of a language. Lexicographers can make use of the data to produce new dictionaries for endangered languages.</p>\n<p>Another important application of our work is in the development of computing resources for members of endangered language communities. Speakers of English often take for granted the fact that the language is ubiquitous on the computer and on the internet; we can ask our phones for directions in English, spell check our email, consult a vast online encyclopedia with around five million articles, type all the letters of the alphabet on any keyboard, and easily connect with other English speakers on social media web sites. For the vast majority of the 7000 languages in the world, most of these things are impossible, and this is one of the factors that feeds into language shift - English and other major languages become the default language of computing, the internet, education, and modernity.</p>\n<p>In order to create basic resources like spell checkers, or more advanced tools like voice recognition software, the frequencies of words and sequences of words in a given language are extremely important.&nbsp; This \"statistical\" approach to language processing on the computer is one of the great advances in the field over the last 30 years for major languages like English, French, and Chinese.&nbsp; Languages with fewer speakers and languages without an extensive written tradition have been effectively \"locked out\" of these approaches.&nbsp; A major outcome of this project has been to bring the benefits of statistical language processing to a great number of the world's languages.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/01/2016<br>\n\t\t\t\t\tModified by: Kevin&nbsp;P&nbsp;Scannell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThere are over 7000 languages spoken in the world today, but an increasing number of these are not spoken by younger members of their language communities, and are in danger of falling out of everyday use.  The linguist Ken Hale famously said that \"languages embody the intellectual wealth of the people that speak them. Losing any one of them is like dropping a bomb on the Louvre.\" The aim of this project is to help address the crisis in linguistic diversity by providing data to linguists that can be used in the scientific study of languages, and by putting software tools directly in the hands of endangered language communities to make it easier for them to use their language on the computer and online.\n\nBroadly speaking, this project is a survey of language use on the web; we have collected millions of web pages over many years, identified the language that each of them is written in, and organized these into datasets that linguists and other software developers can use in their own research projects.  To date, we have found texts in nearly 2200 different languages online; these include Bible translations, e-books, legal documents, newsgroup archives, blog posts, tweets, and much more. This is the most complete and accurate picture of the linguistic diversity of the web.\n\nWhat can researchers do with these datasets?  In the field of linguistics, texts represent one form of \"raw data\" that allow linguists to study and describe the world's languages.  Massively multilingual datasets of this kind are particularly useful for doing cross-linguistic analysis across many language families. Sociolinguists can use the data to see which domains particular languages are used in, or to study the geographical distribution of a language. Lexicographers can make use of the data to produce new dictionaries for endangered languages.\n\nAnother important application of our work is in the development of computing resources for members of endangered language communities. Speakers of English often take for granted the fact that the language is ubiquitous on the computer and on the internet; we can ask our phones for directions in English, spell check our email, consult a vast online encyclopedia with around five million articles, type all the letters of the alphabet on any keyboard, and easily connect with other English speakers on social media web sites. For the vast majority of the 7000 languages in the world, most of these things are impossible, and this is one of the factors that feeds into language shift - English and other major languages become the default language of computing, the internet, education, and modernity.\n\nIn order to create basic resources like spell checkers, or more advanced tools like voice recognition software, the frequencies of words and sequences of words in a given language are extremely important.  This \"statistical\" approach to language processing on the computer is one of the great advances in the field over the last 30 years for major languages like English, French, and Chinese.  Languages with fewer speakers and languages without an extensive written tradition have been effectively \"locked out\" of these approaches.  A major outcome of this project has been to bring the benefits of statistical language processing to a great number of the world's languages.\n\n\t\t\t\t\tLast Modified: 01/01/2016\n\n\t\t\t\t\tSubmitted by: Kevin P Scannell"
 }
}