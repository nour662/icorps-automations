{
 "awd_id": "1255314",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Characterizing and Exposing Bias in Social and Mainstream Media",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2013-08-31",
 "tot_intn_awd_amt": 185000.0,
 "awd_amount": 185000.0,
 "awd_min_amd_letter_date": "2012-08-28",
 "awd_max_amd_letter_date": "2012-08-28",
 "awd_abstract_narration": "An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries like search engines can censor or manipulate citizens' access to information.  The practices of these intermediaries can create \"filter bubbles'', whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately apparent, such as the user's geographic location or past behavior. \r\n\r\nThis project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media.  To study these effects, this project will build a large-scale, distributed monitoring system to discover and view news sources from different geographic regions, and for users with different context. The first portion of the project, which will be to characterize filter bubbles in news media, will involve two separate studies: one for information intermediaries for mainstream news media, and one for social media.  The second portion of our project will involve developing and deploying a prototype system that exposes bias in news sources, to provide users with systematic ways to observe and evaluate the extent of bias that may exist in media sources.  The last component of our project will investigate how the presenting evidence of bias or information manipulation affects users' perceptions of and attitudes towards bias in both mainstream and social media.  To do so, the project will design and instrument user studies through software distribution, recruitment, and laboratory-based studies, where cases of bias or information manipulation are presented to users through different types of interfaces.  These studies will highlight instances of bias using different visualizations and interfaces and observe how users' attitudes change depending on whether and how this information is presented.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nicholas",
   "pi_last_name": "Feamster",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Nicholas G Feamster",
   "pi_email_addr": "feamster@uchicago.edu",
   "nsf_id": "000489704",
   "pi_start_date": "2012-08-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207423275",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "MD",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8087",
   "pgm_ref_txt": "Frontiers in SaTC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 185000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries (</span><span>e.g.</span><span>, search engines) can censor or manipulate citizens&rsquo; access to information. The practices of these intermediaries can create &ldquo;filter bubbles&rdquo;, whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately ap- parent, such as the user&rsquo;s geographic location or past behavior. This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media. </span></p>\n<p><span>This project studied these effects by designing implementing, deploying, and evaluating a large-scale distributed monitoring system that measures, analyzes, and exposes how both news producers and infor- mation intermediaries represent particular entities or events differently for users in different geographic regions or with different context (</span><span>e.g.</span><span>, past search history). &nbsp;</span></p>\n<p>The project studied bias in mainstream media in two contexts:</p>\n<ul>\n<li>Differences in search results across geographic regions and user profiles as a result of profile pollution attacks.</li>\n<li>Differences in the news stories that users see at commonly used news portals, depending on profile and geography.</li>\n</ul>\n<div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p>&nbsp;</p>\n<p><strong>Pollution attacks in search engines.&nbsp;</strong>An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries (e.g., search engines) can censor or manipulate citizens&rsquo; access to information. The practices of these intermediaries can create &ldquo;filter bubbles&rdquo;, whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately ap- parent, such as the user&rsquo;s geographic location or past behavior. This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media.&nbsp;We studied these effects by designing implementing, deploying, and evaluating a large-scale distributed monitoring system that measures, analyzes, and exposes how both news producers and information intermediaries represent particular entities or events differently for users in different geographic regions or with different context (e.g., past search history). &nbsp;</p>\n</div>\n</div>\n</div>\n<div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><strong>\"Filter bubbles\"&nbsp;in Online News.&nbsp;</strong>Many organizations and information conduits, ranging from news outlets to information intermediaries (e.g., search engines) can censor or manipulate citizens&rsquo; access to information. The practices of these intermediaries can create &ldquo;filter bubbles&rdquo;, whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately apparent, such as the user&rsquo;s geographic location or past behavior. &nbsp;We study the impact of filter bubbles on the availability of news sources across different borders. Using a dataset of articles collected using two million queries of Google news, we study how coverage of a particular event or topic may differ, depending on the country where the coverage is taking place and the news outlet that is covering the topic. We reveal preliminary evidence of differing coverage across countries and regions and propose a research agenda for both studying this probl...",
  "por_txt_cntn": "\n\n\n\nAn increasing number of organizations and information conduits, ranging from news outlets to information intermediaries (e.g., search engines) can censor or manipulate citizens\u00c6 access to information. The practices of these intermediaries can create \"filter bubbles\", whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately ap- parent, such as the user\u00c6s geographic location or past behavior. This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media. \n\nThis project studied these effects by designing implementing, deploying, and evaluating a large-scale distributed monitoring system that measures, analyzes, and exposes how both news producers and infor- mation intermediaries represent particular entities or events differently for users in different geographic regions or with different context (e.g., past search history).  \n\nThe project studied bias in mainstream media in two contexts:\n\nDifferences in search results across geographic regions and user profiles as a result of profile pollution attacks.\nDifferences in the news stories that users see at commonly used news portals, depending on profile and geography.\n\n\n\n\n\n \n\nPollution attacks in search engines. An increasing number of organizations and information conduits, ranging from news outlets to information intermediaries (e.g., search engines) can censor or manipulate citizens\u00c6 access to information. The practices of these intermediaries can create \"filter bubbles\", whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately ap- parent, such as the user\u00c6s geographic location or past behavior. This project will study the effects of filter bubbles on the availability and sentiment of news sources in different geographic regions, for both social and mainstream media. We studied these effects by designing implementing, deploying, and evaluating a large-scale distributed monitoring system that measures, analyzes, and exposes how both news producers and information intermediaries represent particular entities or events differently for users in different geographic regions or with different context (e.g., past search history).  \n\n\n\n\n\n\n\n\"Filter bubbles\" in Online News. Many organizations and information conduits, ranging from news outlets to information intermediaries (e.g., search engines) can censor or manipulate citizens\u00c6 access to information. The practices of these intermediaries can create \"filter bubbles\", whereby the information any user sees is highly controlled by an information intermediary and depends largely on factors that may not be immediately apparent, such as the user\u00c6s geographic location or past behavior.  We study the impact of filter bubbles on the availability of news sources across different borders. Using a dataset of articles collected using two million queries of Google news, we study how coverage of a particular event or topic may differ, depending on the country where the coverage is taking place and the news outlet that is covering the topic. We reveal preliminary evidence of differing coverage across countries and regions and propose a research agenda for both studying this problem in greater detail and developing mechanisms for mitigating such manipulation. \n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 01/27/2014\n\n\t\t\t\t\tSubmitted by: Nicholas G Feamster"
 }
}