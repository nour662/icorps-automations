{
 "awd_id": "1216695",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Shared Memory Architectures and Microarchitectures for Heterogeneous General-Purpose Chips",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2012-07-27",
 "awd_max_amd_letter_date": "2012-07-27",
 "awd_abstract_narration": "The computing industry is currently producing and developing chips that include processor cores of different types.  The move towards heterogeneous chips is due to two trends: the ability to squeeze more transistors on each chip and the improved power-efficiency of using specific cores for specific purposes.  This research project extends the inter-core communication systems and precise specifications of homogeneous chips to heterogeneous chips.   The benefits of extending homogeneous communication paradigms include improved performance and improved power-efficiency, and preliminary results show orders of magnitude improvements in both metrics.  Society relies upon computers for ever more purposes, and qualitatively improving their performance and power-efficiency are critical to future computing platforms.  Furthermore, by extending homogeneous specification methodologies, this research project facilitates chip testing and validation for heterogeneous chips, which is a significant fraction of industry effort in chip development, and eases the programming of these chips, which is among the biggest challenges in computing today.  \r\n \r\nThis research project consists of two technical thrusts.  The first thrust is the development of memory systems for heterogeneous chips.  Rather than treat a heterogeneous chip as two distinct systems that happen to share a chip, the goal is to closely integrate the heterogeneous cores in a systematic fashion that enables most communication between cores to be performed via on-chip caches rather than via off-chip memory.   The second research thrust is to extend the notion of a computer architecture--an implementation-independent specification of a processor's behavior--from homogeneous systems to chip-wide heterogeneous systems.  This research project involves the design and experimental evaluation of heterogeneous processor chips, and the bulk of the experimental work uses full-system simulation and experiments on purchased hardware.  The contributions of this project will be heterogeneous processor chips that have significantly greater performance and power-efficiency, as well as implementation-independent architectures for heterogeneous chips.   Society will be using heterogeneous processor chips in personal computers, in smartphones, and via cloud-provided services.  Qualitatively improving these chips will enhance user computing experiences and enable new and exciting computing applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Sorin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Sorin",
   "pi_email_addr": "sorin@ee.duke.edu",
   "nsf_id": "000280417",
   "pi_start_date": "2012-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Duke University",
  "inst_street_address": "2200 W MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "DURHAM",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9196843030",
  "inst_zip_code": "277054640",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "DUKE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "TP7EK8DZV6N5"
 },
 "perf_inst": {
  "perf_inst_name": "Duke University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "277080291",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we explored how to design and program new types of<br />computer chips that contain a variety of different processor types.<br />When we began the project, there were many questions regarding how to<br />organize such chips, with the most pressing question being how the<br />processor cores should communicate with each other.&nbsp; <br /><br />In this project, we made the following intellectual contributions:<br /><br />1) Hardware: We defied conventional wisdom by showing that a chip with<br />general-purpose processor (CPU) cores and graphics processor unit<br />(GPU) cores could use a technique known as hardware cache coherence<br />for communication.&nbsp; Previous research suggested that coherence would<br />not scale to chips with many cores, particularly if some of those<br />cores are GPU cores.&nbsp; This result is important in that coherence has<br />been a mainstay of modern CPU chips and it helps to provide a simpler<br />platform for programmers who would otherwise have to worry about how<br />to move data between cores.<br /><br />2) Hardware/Software Interface: We upset conventional wisdowm by<br />showing that a chip with many GPU-like cores could present a<br />\"conservative\" interface to the software.&nbsp; This interface, called<br />sequential consistency (SC), heavily restricts how the hardware can<br />interleave memory accesses performed by the cores (which could hurt<br />performance) but it is simpler for programmers to reason about.&nbsp; Our<br />work showed that SC is a viable interface for these chips, because the<br />software that runs on these chips cannot take advantage of hardware<br />reordering accesses to memory.<br /><br />3) Software: We developed the first \"task-parallel\" runtime system for<br />chips with CPU and GPU cores.&nbsp; With this runtime system, programmers<br />can take advantage of the performance of these heterogeneous-core<br />chips while using a programming model (task-parallel) that is<br />well-suited to certain algorithms.<br /><br />In addition to our technical contributions, we had the following broader impact:<br /><br />1) We trained several PhD students, including Mr. Blake Hechtman (now<br />designing heterogeneous chips at Oracle), Ms. Meng Zhang, and<br />Mr. Weidan Wu.<br /><br />2) We trained several undergraduate research assistants, including<br />Ms. Martha Barker (now working at Oracle).<br /><br />3) The lead PhD student, Blake Hechtman, spent a 6-month internship at<br />AMD, where we achieved significant technology transfer.<br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/01/2016<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Sorin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we explored how to design and program new types of\ncomputer chips that contain a variety of different processor types.\nWhen we began the project, there were many questions regarding how to\norganize such chips, with the most pressing question being how the\nprocessor cores should communicate with each other.  \n\nIn this project, we made the following intellectual contributions:\n\n1) Hardware: We defied conventional wisdom by showing that a chip with\ngeneral-purpose processor (CPU) cores and graphics processor unit\n(GPU) cores could use a technique known as hardware cache coherence\nfor communication.  Previous research suggested that coherence would\nnot scale to chips with many cores, particularly if some of those\ncores are GPU cores.  This result is important in that coherence has\nbeen a mainstay of modern CPU chips and it helps to provide a simpler\nplatform for programmers who would otherwise have to worry about how\nto move data between cores.\n\n2) Hardware/Software Interface: We upset conventional wisdowm by\nshowing that a chip with many GPU-like cores could present a\n\"conservative\" interface to the software.  This interface, called\nsequential consistency (SC), heavily restricts how the hardware can\ninterleave memory accesses performed by the cores (which could hurt\nperformance) but it is simpler for programmers to reason about.  Our\nwork showed that SC is a viable interface for these chips, because the\nsoftware that runs on these chips cannot take advantage of hardware\nreordering accesses to memory.\n\n3) Software: We developed the first \"task-parallel\" runtime system for\nchips with CPU and GPU cores.  With this runtime system, programmers\ncan take advantage of the performance of these heterogeneous-core\nchips while using a programming model (task-parallel) that is\nwell-suited to certain algorithms.\n\nIn addition to our technical contributions, we had the following broader impact:\n\n1) We trained several PhD students, including Mr. Blake Hechtman (now\ndesigning heterogeneous chips at Oracle), Ms. Meng Zhang, and\nMr. Weidan Wu.\n\n2) We trained several undergraduate research assistants, including\nMs. Martha Barker (now working at Oracle).\n\n3) The lead PhD student, Blake Hechtman, spent a 6-month internship at\nAMD, where we achieved significant technology transfer.\n\n\n\n\t\t\t\t\tLast Modified: 08/01/2016\n\n\t\t\t\t\tSubmitted by: Daniel Sorin"
 }
}