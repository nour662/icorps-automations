{
 "awd_id": "1220311",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "ATD: Statistical methodology and algorithms for detection problems",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 471623.0,
 "awd_amount": 471623.0,
 "awd_min_amd_letter_date": "2012-08-29",
 "awd_max_amd_letter_date": "2013-09-16",
 "awd_abstract_narration": "The investigator will develop new statistical methodology and algorithms for the quick detection of the abrupt emergence of a signal which is observed by a sensor in a noisy data stream or by an array of sensors in multiple data streams. A particular emphasis will be on the construction of techniques for effectively combining the information from several sensors. Such techniques are essential when the signal is weak and observed by only a small fraction of the sensors. Part of the proposed new methodology is based on recent advances in the statistical theory of multiscale analysis. Theoretical investigations of these recent advances in the abstract Gaussian White Noise model suggest that clear improvements in detection power are possible for the problem of a quick detection of a change point, and the investigator plans to adapt these ideas for this problem, to investigate its theoretical performance, and to develop efficient algorithms for its implementation. The second main emphasis is to develop improved statistical methodology to combine the information from several data streams using a novel criterion based on the average likelihood ratio. In preliminary work the investigator has shown that this criterion results in superior detection power in a large-scale multiple testing context, and the investigator will develop corresponding methodology for the detection of a signal in multiple data streams.\r\n\r\nChange-point detection plays an important role in a range of problems such as the detection  of radioactive and biochemical threats, environmental monitoring, or the detection of recurrent DNA copy  number variants in multiple samples in high-thoughput genomics. Advances in detection methodology have thus a direct impact on important problems in national security and in high-thoughput genomics, e.g. in terms of a shorter time to the detection of chemical agents and biological threats. The investigator will adapt recent results in statistical theory to these detection problems. The theoretical results suggest that clear improvements in detection power are possible in these important problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guenther",
   "pi_last_name": "Walther",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guenther Walther",
   "pi_email_addr": "Walther@stat.stanford.edu",
   "nsf_id": "000487606",
   "pi_start_date": "2012-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "CA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "755200",
   "pgm_ele_name": "COFFES"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "6877",
   "pgm_ref_txt": "ALGORITHMS IN THREAT DETECTION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 123405.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 348218.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!--  /* Font Definitions */ @font-face \t{font-family:Times; \tpanose-1:2 0 5 0 0 0 0 0 0 0; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:3 0 0 0 1 0;} @font-face \t{font-family:\"?? ??\"; \tpanose-1:0 0 0 0 0 0 0 0 0 0; \tmso-font-charset:128; \tmso-generic-font-family:roman; \tmso-font-format:other; \tmso-font-pitch:fixed; \tmso-font-signature:1 134676480 16 0 131072 0;} @font-face \t{font-family:\"Cambria Math\"; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1107305727 0 0 415 0;} @font-face \t{font-family:Cambria; \tpanose-1:2 4 5 3 5 4 6 3 2 4; \tmso-font-charset:0; \tmso-generic-font-family:auto; \tmso-font-pitch:variable; \tmso-font-signature:-536870145 1073743103 0 0 415 0;}  /* Style Definitions */ p.MsoNormal, li.MsoNormal, div.MsoNormal \t{mso-style-unhide:no; \tmso-style-qformat:yes; \tmso-style-parent:\"\"; \tmargin:0in; \tmargin-bottom:.0001pt; \tmso-pagination:widow-orphan; \tfont-size:12.0pt; \tfont-family:Cambria; \tmso-ascii-font-family:Cambria; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:\"?? ??\"; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Cambria; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} p \t{mso-style-noshow:yes; \tmso-style-priority:99; \tmso-margin-top-alt:auto; \tmargin-right:0in; \tmso-margin-bottom-alt:auto; \tmargin-left:0in; \tmso-pagination:widow-orphan; \tfont-size:10.0pt; \tfont-family:Times; \tmso-fareast-font-family:\"?? ??\"; \tmso-fareast-theme-font:minor-fareast; \tmso-bidi-font-family:\"Times New Roman\";} .MsoChpDefault \t{mso-style-type:export-only; \tmso-default-props:yes; \tfont-family:Cambria; \tmso-ascii-font-family:Cambria; \tmso-ascii-theme-font:minor-latin; \tmso-fareast-font-family:\"?? ??\"; \tmso-fareast-theme-font:minor-fareast; \tmso-hansi-font-family:Cambria; \tmso-hansi-theme-font:minor-latin; \tmso-bidi-font-family:\"Times New Roman\"; \tmso-bidi-theme-font:minor-bidi;} @page WordSection1 \t{size:8.5in 11.0in; \tmargin:1.0in 1.25in 1.0in 1.25in; \tmso-header-margin:.5in; \tmso-footer-margin:.5in; \tmso-paper-source:0;} div.WordSection1 \t{page:WordSection1;} -->\n<p>The overall topic of the project is to develop statistical and computational methodology for the fast detection of the abrupt emergence of a signal in a noisy stream of data which is observed by a sensor, or in multiple data streams observed by an array of sensors. These problems play an important role in a range of detection problems, such as the detection of recurrent DNA copy number variants in multiple samples in high-throughput genomics.</p>\n<p>The outcomes of this project provide a precise mathematical characterization of the intensity of the signal that is required in order to detect it in multiple streams of data, when the signal may be present in only an unknown fraction of these streams. The outcomes also provide optimal statistical procedures that are able to attain these bounds, as well as algorithms for efficient computation. In particular, these results show an interplay between the scale of the sequence length to signal length ratio, and the sparseness of the signals. It is found that the difficulty of the detection problem is not noticeably affected unless this ratio grows exponentially with the number of sequences. This outcome represents a general result that contains known results about a single sequence as well as the so-called sparse mixture testing problem as special cases.</p>\n<p>A student involved in the project participated in the Hyperspectral gas-detection challange that has been organized by the sponsoring NSF program in collaboration with other federal agencies. The resulting algorithm won that challenge with a perfect peformance score.</p>\n<p>Work by a student sponsored by this project also provided a theoretical explanation of why random forests, a popular tool in statistical learning, work so well in many prediction problems. This fact had been observed in practice, but a satisfactory theoretical explanation has been outstanding for more than 20 years.</p>\n<p>Another outcome of this project has been results on the detection of faint signals whose structure is unknown. While theoretical detection limits in the literature are quite pessimistic for this case, first results obtained by this project show that it is possible to dramatically improve on these limits if there is some hidden structure in the signal, even if this structure is not known beforehand.</p>\n<p>The project also derived rules for the effective summary and graphical representation of data. These rules are based on the construction of an optimal confidence set for distribution functions. They allow a simple graphical summary (e.g. via a histogram having relatively few bins) while still allowing statistical inference that is the best possible. It is anticipated that such representations will become quite useful for high-dimensional data, where it is known that the curse of dimensionality makes statistical inference and visualization difficult.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2017<br>\n\t\t\t\t\tModified by: Guenther&nbsp;Walther</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe overall topic of the project is to develop statistical and computational methodology for the fast detection of the abrupt emergence of a signal in a noisy stream of data which is observed by a sensor, or in multiple data streams observed by an array of sensors. These problems play an important role in a range of detection problems, such as the detection of recurrent DNA copy number variants in multiple samples in high-throughput genomics.\n\nThe outcomes of this project provide a precise mathematical characterization of the intensity of the signal that is required in order to detect it in multiple streams of data, when the signal may be present in only an unknown fraction of these streams. The outcomes also provide optimal statistical procedures that are able to attain these bounds, as well as algorithms for efficient computation. In particular, these results show an interplay between the scale of the sequence length to signal length ratio, and the sparseness of the signals. It is found that the difficulty of the detection problem is not noticeably affected unless this ratio grows exponentially with the number of sequences. This outcome represents a general result that contains known results about a single sequence as well as the so-called sparse mixture testing problem as special cases.\n\nA student involved in the project participated in the Hyperspectral gas-detection challange that has been organized by the sponsoring NSF program in collaboration with other federal agencies. The resulting algorithm won that challenge with a perfect peformance score.\n\nWork by a student sponsored by this project also provided a theoretical explanation of why random forests, a popular tool in statistical learning, work so well in many prediction problems. This fact had been observed in practice, but a satisfactory theoretical explanation has been outstanding for more than 20 years.\n\nAnother outcome of this project has been results on the detection of faint signals whose structure is unknown. While theoretical detection limits in the literature are quite pessimistic for this case, first results obtained by this project show that it is possible to dramatically improve on these limits if there is some hidden structure in the signal, even if this structure is not known beforehand.\n\nThe project also derived rules for the effective summary and graphical representation of data. These rules are based on the construction of an optimal confidence set for distribution functions. They allow a simple graphical summary (e.g. via a histogram having relatively few bins) while still allowing statistical inference that is the best possible. It is anticipated that such representations will become quite useful for high-dimensional data, where it is known that the curse of dimensionality makes statistical inference and visualization difficult.\n\n\t\t\t\t\tLast Modified: 11/29/2017\n\n\t\t\t\t\tSubmitted by: Guenther Walther"
 }
}