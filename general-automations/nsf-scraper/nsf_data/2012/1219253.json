{
 "awd_id": "1219253",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Incremental Speech Processing for Rapid Dialogue",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 449984.0,
 "awd_amount": 457984.0,
 "awd_min_amd_letter_date": "2012-08-01",
 "awd_max_amd_letter_date": "2013-06-18",
 "awd_abstract_narration": "This project develops incremental language processing techniques to enable spoken dialogue systems to communicate in a way that is more highly interactive, more efficient, and more human-like.  Most previous dialogue systems have employed a strict turn-taking regime in which one person speaks at a time, no attempt is made to understand or respond to speech until the speaker finishes speaking, and the overall latency in system responses is high in comparison to human-human conversation.  This results in systems that are unable to provide a range of rapid and overlapping responses that human interlocutors frequently use to achieve an efficient and successful communication process, including back-channels, interruptions, collaborative completions, clarifications, and other rapid responses.  This project is a computational and empirical investigation into how a system's assessment of its own incremental understanding of ongoing user speech can guide its strategic decisions to initiate such rapid and overlapping responses.  The feature representations and response policies that can implement this decision-making are studied in the context of two fast-paced interactive dialogue games.  These games are carefully chosen to support objective evaluation of incremental response strategies and fun gameplay that facilitates large-scale data collection.\r\n\r\nThe resulting computational models may improve the conversational skills of a range of dialogue systems, including not only game-oriented systems but also practical applications such as intelligent tutoring and training systems, information access systems, and entertainment applications.  A second product of this project is an annotated corpus of human-human and human-system dialogue data for use by other researchers.  A third product is the incorporation of relevant software into a publicly distributed toolkit for building dialogue systems, supporting further research and education.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "DeVault",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "David J DeVault",
   "pi_email_addr": "devault@ict.usc.edu",
   "nsf_id": "000573790",
   "pi_start_date": "2012-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Traum",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "David R Traum",
   "pi_email_addr": "traum@ict.usc.edu",
   "nsf_id": "000173016",
   "pi_start_date": "2012-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kenji",
   "pi_last_name": "Sagae",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kenji Sagae",
   "pi_email_addr": "sagae@ucdavis.edu",
   "nsf_id": "000573788",
   "pi_start_date": "2012-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900891147",
  "perf_ctry_code": "US",
  "perf_cong_dist": "33",
  "perf_st_cong_dist": "CA33",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 195309.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 262675.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Today, talking to a voice-enabled computer or mobile app can be a slow<br />and frustrating experience.&nbsp; One of the reasons for this is that<br />current voice-enabled systems are relatively slow to understand and<br />respond to what a user is saying.&nbsp; While human speakers tend to<br />respond to each other very quickly, with only very short pauses<br />between one speaker and the next, typical automated systems take much<br />longer to process and respond to each new user utterance.&nbsp; This often<br />results in less natural and less efficient interactions between people<br />and automated systems.<br /><br />This research project has worked to address this limitation by<br />developing new computational techniques that can enable spoken<br />dialogue systems to understand and respond more quickly to a user's<br />speech.&nbsp; In particular, new computational techniques developed in this<br />project allow a dialogue system to understand and respond to what a<br />user is saying using real-time, \"incremental\" (word-by-word) speech<br />processing algorithms.&nbsp; These incremental speech processing algorithms<br />make it possible for a dialogue system to respond to what a user is<br />saying more quickly and to provide more efficient and natural<br />interactions with users.<br /><br />The outcomes for this project include new incremental speech<br />processing algorithms that have been implemented, optimized, and<br />evaluated in the context of fast-paced spoken dialogue interactions.<br />In one type of interaction used in this project, a user verbally<br />describes a series of pictures displayed on their computer screen to<br />an automated system.&nbsp; The automated system listens to the user's<br />spoken descriptions and tries to identify the correct pictures as<br />quickly and accurately as possible.&nbsp; This type of interaction<br />emphasizes the general capability for an automated system to<br />understand a user's referential language.&nbsp; This general capability is<br />relevant in a variety of voice-enabled systems that need to be able to<br />understand which object or image a user is referring to.&nbsp; In another<br />type of interaction used in this project, an automated system<br />participates in a word-guessing dialogue with a user.&nbsp; The system<br />decides on a specific target word or phrase, and then tries to provide<br />verbal clues that will enable a user to identify the target word or<br />phrase as quickly as possible.&nbsp; Both of these interactive tasks serve<br />as useful research testbeds for developing automated systems that can<br />sustain much faster-paced and more efficient interactions than is<br />possible in typical dialogue systems.<br /><br />One of the outcomes of this project is a new method for training<br />automated systems to make word-by-word decisions about whether they<br />have sufficiently understood what a user is saying.&nbsp; This new training<br />method produces an optimized incremental dialogue policy that governs<br />how a system reacts to each new word a user says, and makes it<br />possible for a system to react even before the user's speech<br />concludes.&nbsp; This project has evaluated a number of trained incremental<br />dialogue policies in empirical studies that evaluate their<br />effectiveness in comparison with alternative dialogue policies,<br />including policies that use less incremental speech processing.&nbsp; Our<br />results show that increased use of incremental, word-by-word speech<br />processing enables an automated system to significantly improve its<br />performance at rapidly understanding a user's descriptions of pictures<br />on a computer screen.&nbsp; Our results also show that increased use of<br />incremental speech processing leads to improved user ratings of<br />efficiency, understanding of speech, and naturalness of the<br />interaction.&...",
  "por_txt_cntn": "\nToday, talking to a voice-enabled computer or mobile app can be a slow\nand frustrating experience.  One of the reasons for this is that\ncurrent voice-enabled systems are relatively slow to understand and\nrespond to what a user is saying.  While human speakers tend to\nrespond to each other very quickly, with only very short pauses\nbetween one speaker and the next, typical automated systems take much\nlonger to process and respond to each new user utterance.  This often\nresults in less natural and less efficient interactions between people\nand automated systems.\n\nThis research project has worked to address this limitation by\ndeveloping new computational techniques that can enable spoken\ndialogue systems to understand and respond more quickly to a user's\nspeech.  In particular, new computational techniques developed in this\nproject allow a dialogue system to understand and respond to what a\nuser is saying using real-time, \"incremental\" (word-by-word) speech\nprocessing algorithms.  These incremental speech processing algorithms\nmake it possible for a dialogue system to respond to what a user is\nsaying more quickly and to provide more efficient and natural\ninteractions with users.\n\nThe outcomes for this project include new incremental speech\nprocessing algorithms that have been implemented, optimized, and\nevaluated in the context of fast-paced spoken dialogue interactions.\nIn one type of interaction used in this project, a user verbally\ndescribes a series of pictures displayed on their computer screen to\nan automated system.  The automated system listens to the user's\nspoken descriptions and tries to identify the correct pictures as\nquickly and accurately as possible.  This type of interaction\nemphasizes the general capability for an automated system to\nunderstand a user's referential language.  This general capability is\nrelevant in a variety of voice-enabled systems that need to be able to\nunderstand which object or image a user is referring to.  In another\ntype of interaction used in this project, an automated system\nparticipates in a word-guessing dialogue with a user.  The system\ndecides on a specific target word or phrase, and then tries to provide\nverbal clues that will enable a user to identify the target word or\nphrase as quickly as possible.  Both of these interactive tasks serve\nas useful research testbeds for developing automated systems that can\nsustain much faster-paced and more efficient interactions than is\npossible in typical dialogue systems.\n\nOne of the outcomes of this project is a new method for training\nautomated systems to make word-by-word decisions about whether they\nhave sufficiently understood what a user is saying.  This new training\nmethod produces an optimized incremental dialogue policy that governs\nhow a system reacts to each new word a user says, and makes it\npossible for a system to react even before the user's speech\nconcludes.  This project has evaluated a number of trained incremental\ndialogue policies in empirical studies that evaluate their\neffectiveness in comparison with alternative dialogue policies,\nincluding policies that use less incremental speech processing.  Our\nresults show that increased use of incremental, word-by-word speech\nprocessing enables an automated system to significantly improve its\nperformance at rapidly understanding a user's descriptions of pictures\non a computer screen.  Our results also show that increased use of\nincremental speech processing leads to improved user ratings of\nefficiency, understanding of speech, and naturalness of the\ninteraction.  These empirical results may help other dialogue\nresearchers and practical system builders to design and implement more\nefficient and natural spoken dialogue systems in the future.\n\nOver time, this type of research, which is developing techniques that\nenable spoken dialogue systems to understand and respond faster to\nwhat users are saying, will greatly improve the naturalness and\nacceptability of a range of dialogue system ..."
 }
}