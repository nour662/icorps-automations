{
 "awd_id": "1218709",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Structured Sparse Conditional Random Fields Models for Joint Categorization and Segmentation of Objects.",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 449794.0,
 "awd_amount": 449794.0,
 "awd_min_amd_letter_date": "2012-08-31",
 "awd_max_amd_letter_date": "2012-08-31",
 "awd_abstract_narration": "Object categorization and segmentation are arguably among the most important and challenging problems in computer vision. While these two problems are clearly related, most of the existing literature treats these tasks separately. This project bridges this gap by developing algorithms for joint categorization and segmentation of objects, which simultaneously use category-level information (top-down) and pixel-level information (bottom-up).  This project develops a novel graph-theoretic paradigm that combines principles from conditional random fields and sparse representation theory. In this framework, each semantic region is represented in terms of an over-complete dictionary of objects, object parts, subparts and superpixels. To simultaneously estimate both the segmentation and a sparse representation for each region, the research team defines an energy function for the random field, which includes new higher order potentials obtained as the output of a classifier applied to the sparse representation of a segmented region. The research team also explores methods based on structured-sparse dictionary learning and latent support vector machines for learning the dictionaries and the classifier parameters. Furthermore, the research team investigates efficient discrete optimization techniques for minimizing the new energies resulting from the combination of structured-sparse models with different classifiers.\r\n\r\nApplications of this research include image search, autonomous navigation (localization and identification of the road, street signs, pedestrians and vehicles), medical diagnostic tools (detection, localization and classification of lesions and tumors in medical images), surveillance (localization of suspicious people, weapons and vehicles) and robotics (identifying the boundaries and extent of objects to be interacted with). The project involves students of different levels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Rene",
   "pi_last_name": "Vidal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Rene Vidal",
   "pi_email_addr": "vidalr@upenn.edu",
   "nsf_id": "000486258",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "302B Clark Hall, 3400 N Charles St",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182686",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 449794.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Object categorization and segmentation are arguably among the most important and challenging problems in computer vision. While these two problems are clearly related, most of the existing literature treats these tasks separately. This project aimed to bridge this gap by developing algorithms for joint categorization and segmentation of objects, which simultaneously use category-level information (top-down) and pixel-level information (bottom-up). The proposed algorithms were based on a novel graph-theoretic framework that combines principles from conditional random fields and sparse representation theory. In this framework, each semantic region is represented in terms of an over-complete dictionary of objects, object parts, subparts and superpixels. The collection of all semantic regions of a scene was modeled with a conditional random field model whose energy function includes new higher order potentials obtained as the output of a classifier applied to the sparse representation of a segmented region. The parameters of this energy were learned using methods based on structured-sparse dictionary learning and latent support vector machines. Efficient discrete optimization techniques were used for minimizing the new energies resulting from the combination of structured-sparse models with different classifiers. Possible applications of this research include image search, autonomous navigation (localization and identification of the road, street signs, pedestrians and vehicles), medical diagnostic tools (detection, localization and classification of lesions and tumors in medical images), surveillance (localization of suspicious people, weapons and vehicles) and robotics (identifying the boundaries and extent of objects to be interacted with). This project supported the work of 3 PhD students.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/16/2017<br>\n\t\t\t\t\tModified by: Rene&nbsp;Vidal</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595861176_Outcomes-NSF-ObjRec12-2016-Figure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595861176_Outcomes-NSF-ObjRec12-2016-Figure1--rgov-800width.jpg\" title=\"Proposed approach to semantic image segmentation\"><img src=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595861176_Outcomes-NSF-ObjRec12-2016-Figure1--rgov-66x44.jpg\" alt=\"Proposed approach to semantic image segmentation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The proposed approach to semantic image segmentation integrates bottom up segmentation cues with top-down categorization cues based on structured sparse dictionary learning</div>\n<div class=\"imageCredit\">Dheeraj Singaraju, Aastha Jain, Lingling Tao, Rene Vidal</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Rene&nbsp;Vidal</div>\n<div class=\"imageTitle\">Proposed approach to semantic image segmentation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595957956_Outcomes-NSF-ObjRec12-2016-Figure2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595957956_Outcomes-NSF-ObjRec12-2016-Figure2--rgov-800width.jpg\" title=\"Segmentation results on MSRC21 Dataset\"><img src=\"/por/images/Reports/POR/2017/1218709/1218709_10209843_1484595957956_Outcomes-NSF-ObjRec12-2016-Figure2--rgov-66x44.jpg\" alt=\"Segmentation results on MSRC21 Dataset\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example segmentation results for the MSRC21 dataset using the U+P baseline and our proposed method</div>\n<div class=\"imageCredit\">Lingling Tao, Fatih Porikli, Rene Vidal</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Rene&nbsp;Vidal</div>\n<div class=\"imageTitle\">Segmentation results on MSRC21 Dataset</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nObject categorization and segmentation are arguably among the most important and challenging problems in computer vision. While these two problems are clearly related, most of the existing literature treats these tasks separately. This project aimed to bridge this gap by developing algorithms for joint categorization and segmentation of objects, which simultaneously use category-level information (top-down) and pixel-level information (bottom-up). The proposed algorithms were based on a novel graph-theoretic framework that combines principles from conditional random fields and sparse representation theory. In this framework, each semantic region is represented in terms of an over-complete dictionary of objects, object parts, subparts and superpixels. The collection of all semantic regions of a scene was modeled with a conditional random field model whose energy function includes new higher order potentials obtained as the output of a classifier applied to the sparse representation of a segmented region. The parameters of this energy were learned using methods based on structured-sparse dictionary learning and latent support vector machines. Efficient discrete optimization techniques were used for minimizing the new energies resulting from the combination of structured-sparse models with different classifiers. Possible applications of this research include image search, autonomous navigation (localization and identification of the road, street signs, pedestrians and vehicles), medical diagnostic tools (detection, localization and classification of lesions and tumors in medical images), surveillance (localization of suspicious people, weapons and vehicles) and robotics (identifying the boundaries and extent of objects to be interacted with). This project supported the work of 3 PhD students. \n\n \n\n\t\t\t\t\tLast Modified: 01/16/2017\n\n\t\t\t\t\tSubmitted by: Rene Vidal"
 }
}