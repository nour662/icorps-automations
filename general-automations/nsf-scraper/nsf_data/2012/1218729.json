{
 "awd_id": "1218729",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Distributed Combinatorial Optimization for Crowd-Scene Analysis",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2012-08-30",
 "awd_max_amd_letter_date": "2017-07-17",
 "awd_abstract_narration": "This project develops efficient computer vision algorithms based on distributed message passing for solving crowd-scene analysis tasks such as detection and tracking of closely spaced individuals. These and other vision tasks can be formulated as discrete combinatorial optimization problems, e.g., binary linear or quadratic programs, and studying their underlying mathematical structure can yield insights that allow larger and more challenging problem instances to be addressed.  Recent theoretical work proving the correctness of message passing for some classes of binary linear programming problems is being leveraged to develop practical vision algorithms for crowd scene analysis and extended to develop algorithms for finding good approximate solutions to harder problems. The project team is also exploring approximate inference methods based on randomization and on decomposition of large-scale problems into collections of interrelated subtasks that can be solved more efficiently and in parallel.  \r\n\r\nAutomated vision systems can continuously monitor crowded public spaces to provide real-time situational awareness of crowd density and to detect early signs of dangerous behavior or deviations from normal traffic flow. The ability to track individuals through a crowd and to detect the interactions of groups of people has applications in the areas of homeland security, law enforcement, and defense. Results from this project will be disseminated through collaboration with other scholars, publication of peer-reviewed articles, presentations at professional meetings, introduction of course modules into the graduate and undergraduate computer science curriculum, and through public release of source code.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Collins",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Robert T Collins",
   "pi_email_addr": "rcollins@cse.psu.edu",
   "nsf_id": "000105362",
   "pi_start_date": "2012-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "354H IST Bldg",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168027000",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7323",
   "pgm_ref_txt": "HSD - SPATIAL SOCIAL SCIENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Project Outcomes Report</strong>&nbsp;</p>\n<p>This project has developed computer vision routines for analyzing human behavior, ranging from counting and tracking people in crowd scenes to analyzing movement of a single individual performing a choreographed sports routine.&nbsp; The contributions of the project include:</p>\n<p>1) we have developed an optimization-based method for reasoning about overlapping person detections to aid detecting and counting people in crowded images.&nbsp; Our proposed approach can be used to improve the performance of any existing vision-based person detector;</p>\n<p>2) we have developed efficient algorithms for generating high-quality approximate solutions to the problem of tracking all individuals in a crowd, laying the foundation for higher-level behavioral analysis of a crowd;</p>\n<p>3) we have identified limitations in current measures for characterizing the performance of multi-target tracking algorithms and have proposed a new measure based on mean time between failures that has a clear, interpretable meaning, and that is predictive of future performance.&nbsp; A well-behaved measure such as this is essential for critical evaluation and to guide practical development efforts;</p>\n<p>4) to enable training of vision algorithms that can analyze single-individual sports performance, we have created the largest existing dataset of synchronized video, motion-capture and foot pressure data ever recorded of long, complex human movement sequences (specifically, 5-minute long, 24-form Taiji routines);</p>\n<p>5) we have developed a novel, deep convolutional residual architecture that is the first vision-based network to regress human dynamics (foot pressure) from kinematics (body pose). This is also the first work capable of computing, from single view video, the body's center of pressure and base of support, key components for analysis of human postural control and gait stability, with applications in fields such as kinesiology, biomechanics, healthcare, and robotics.</p>\n<p>6) we have quantified the difference between biomechanical joint locations suitable for kinesiology analysis and the joint locations computed by off-the-shelf computer vision pose extraction algorithms, and have found room for improvement in the vision algorithms.&nbsp; To this end, we have built a regression network that takes 2D body joints produced by an existing vision algorithm and applies computed offsets that correct the joint locations towards more accurate biomechanical locations;</p>\n<p>7) we have developed algorithms for automatically cleaning motion capture data using geometric and temporal consistency constraints, which can reduce the time needed for collecting large datasets; and</p>\n<p>8) we have developed a pose representation that decouples body pose (e.g. the rotation angles of limbs) from body shape (e.g. lengths of limb segments) and have applied it to compare Taiji performances across a populations of individuals with differences in body shape and size, as well as different speed and acceleration of movements. &nbsp;This is a step towards automated comparison of the sports performance of a novice with that of an experienced player, which could ultimately provide feedback to improve the performance of the novice.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/01/2019<br>\n\t\t\t\t\tModified by: Robert&nbsp;T&nbsp;Collins</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProject Outcomes Report \n\nThis project has developed computer vision routines for analyzing human behavior, ranging from counting and tracking people in crowd scenes to analyzing movement of a single individual performing a choreographed sports routine.  The contributions of the project include:\n\n1) we have developed an optimization-based method for reasoning about overlapping person detections to aid detecting and counting people in crowded images.  Our proposed approach can be used to improve the performance of any existing vision-based person detector;\n\n2) we have developed efficient algorithms for generating high-quality approximate solutions to the problem of tracking all individuals in a crowd, laying the foundation for higher-level behavioral analysis of a crowd;\n\n3) we have identified limitations in current measures for characterizing the performance of multi-target tracking algorithms and have proposed a new measure based on mean time between failures that has a clear, interpretable meaning, and that is predictive of future performance.  A well-behaved measure such as this is essential for critical evaluation and to guide practical development efforts;\n\n4) to enable training of vision algorithms that can analyze single-individual sports performance, we have created the largest existing dataset of synchronized video, motion-capture and foot pressure data ever recorded of long, complex human movement sequences (specifically, 5-minute long, 24-form Taiji routines);\n\n5) we have developed a novel, deep convolutional residual architecture that is the first vision-based network to regress human dynamics (foot pressure) from kinematics (body pose). This is also the first work capable of computing, from single view video, the body's center of pressure and base of support, key components for analysis of human postural control and gait stability, with applications in fields such as kinesiology, biomechanics, healthcare, and robotics.\n\n6) we have quantified the difference between biomechanical joint locations suitable for kinesiology analysis and the joint locations computed by off-the-shelf computer vision pose extraction algorithms, and have found room for improvement in the vision algorithms.  To this end, we have built a regression network that takes 2D body joints produced by an existing vision algorithm and applies computed offsets that correct the joint locations towards more accurate biomechanical locations;\n\n7) we have developed algorithms for automatically cleaning motion capture data using geometric and temporal consistency constraints, which can reduce the time needed for collecting large datasets; and\n\n8) we have developed a pose representation that decouples body pose (e.g. the rotation angles of limbs) from body shape (e.g. lengths of limb segments) and have applied it to compare Taiji performances across a populations of individuals with differences in body shape and size, as well as different speed and acceleration of movements.  This is a step towards automated comparison of the sports performance of a novice with that of an experienced player, which could ultimately provide feedback to improve the performance of the novice.\n\n \n\n\t\t\t\t\tLast Modified: 11/01/2019\n\n\t\t\t\t\tSubmitted by: Robert T Collins"
 }
}