{
 "awd_id": "1217708",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: SMALL: Collaborative Research: Data Structures for Parallel Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 138999.0,
 "awd_amount": 138999.0,
 "awd_min_amd_letter_date": "2012-07-20",
 "awd_max_amd_letter_date": "2012-07-20",
 "awd_abstract_narration": "This project develops a theory for characterizing the performance of parallel data structures and parallel algorithms that use parallel structures.  Standard metrics for parallel algorithms, such as \"work\" (total amount of computation) and \"span\" (critical-path length), do not naturally generalize in the presence of contention on shared data.  Moreover, standard approaches for analyzing sequential data structures, such as amortization, do not seem to generalize when data structures are parallel, in part because the performance depends on the properties of the underlying parallel task schedulers.\r\n\r\nThe specific research goals are as follows:  \r\n(1) Investigate a methodology for designing and analyzing parallel algorithms that use data structures, especially amortized ones. \r\n(2) Design parallel schedulers that ameliorate the contention on parallel data structures. \r\n(3) Design parallel data structures that perform provably well with these schedulers.\r\n\r\nToday parallel computing is ubiquitous.  Modern computation platforms---smartphones to network routers, personal computers to large clusters and clouds---each contain multiple processors.  Writing parallel code that provably scales well is challenging and techniques for analyzing sequential algorithms and data structures generally do not apply to parallel code.  This project will develop a theoretical foundation for characterizing the scalability of parallel programs that contend for access to shared data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Bender",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Michael A Bender",
   "pi_email_addr": "bender@cs.stonybrook.edu",
   "nsf_id": "000092778",
   "pi_start_date": "2012-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "Department of Computer Science",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117944400",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 138999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed a theory for characterizing the performance of parallel algorithms that use parallel data structures. Common metrics for parallel algorithms, such as \"work\" (total amount of computation) and \"span\" (critical-path length), do not naturally generalize when there is contention on shared data. Moreover, standard approaches for analyzing sequential data structures, such as amortization, do not seem to generalize when data structures are parallel, in part because the performance depends on the properties of the underlying parallel task schedulers.</p>\n<p>This research project resulted in the following major outcomes:&nbsp;</p>\n<p>(1) The PIs developed methodologies for designing and analyzing parallel algorithms that use data structures, including amortized data structures. &nbsp;Some of these approaches even apply to programs that store and access data from (traditional or solid state) disk.</p>\n<p>(2) The PIs implemented and published new parallel schedulers that ameliorate the contention on parallel data structures.</p>\n<p>(3) The PIs designed parallel data structures that perform provably well with these schedulers.</p>\n<p>These outcomes are significant because today parallel computing is ubiquitous. &nbsp;Modern computation platforms---smartphones to network routers, personal computers to large clusters and clouds---each contain multiple processors. &nbsp;Writing parallel code that provably scales well is challenging, however, because techniques for analyzing sequential algorithms and data structures generally do not apply to parallel code. This project helped develop theoretical techniques for accessing shared data to make it easier to write provably good scalable parallel code.<br /><br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/30/2016<br>\n\t\t\t\t\tModified by: Michael&nbsp;A&nbsp;Bender</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed a theory for characterizing the performance of parallel algorithms that use parallel data structures. Common metrics for parallel algorithms, such as \"work\" (total amount of computation) and \"span\" (critical-path length), do not naturally generalize when there is contention on shared data. Moreover, standard approaches for analyzing sequential data structures, such as amortization, do not seem to generalize when data structures are parallel, in part because the performance depends on the properties of the underlying parallel task schedulers.\n\nThis research project resulted in the following major outcomes: \n\n(1) The PIs developed methodologies for designing and analyzing parallel algorithms that use data structures, including amortized data structures.  Some of these approaches even apply to programs that store and access data from (traditional or solid state) disk.\n\n(2) The PIs implemented and published new parallel schedulers that ameliorate the contention on parallel data structures.\n\n(3) The PIs designed parallel data structures that perform provably well with these schedulers.\n\nThese outcomes are significant because today parallel computing is ubiquitous.  Modern computation platforms---smartphones to network routers, personal computers to large clusters and clouds---each contain multiple processors.  Writing parallel code that provably scales well is challenging, however, because techniques for analyzing sequential algorithms and data structures generally do not apply to parallel code. This project helped develop theoretical techniques for accessing shared data to make it easier to write provably good scalable parallel code.\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 10/30/2016\n\n\t\t\t\t\tSubmitted by: Michael A Bender"
 }
}