{
 "awd_id": "1218711",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Efficient Approximations for Dynamic Programs and Other Topics in Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rahul Shah",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2012-08-06",
 "awd_max_amd_letter_date": "2012-08-06",
 "awd_abstract_narration": "This project supports new and ongoing research on several topics in algorithms and computational complexity.  A major focus of the project will be certain combinatorical optimization problems, such as determining the longest common subsequence of two data sequences, that can be formulated as shortest path problems in special networks.  The goal is to develop algorithms that provably give close approximations to the correct answer and are significantly faster than existing algorithms.  Another goal of the project is to construct sparse spanners for networks, which are subnetworks with few edges that preserve (partially or approximately) the connectivity or distance properties of the original network.  A third part of the project will seek to establish inherent limitations on the efficiency of parallel programs in the MapReduce paradigm, which is an increasingly popular paradigm for parallel programming in which computation occurs in a sequence of precisely defined rounds.  The aim is to establish some inherent limitations on this model by proving lower bounds on the number of computation rounds needed for certain basic computational tasks.  Another part of the project will develop new algorithms and determine limits to efficiency for the file maintenance problem, in which numbers are presented in an online manner and are loaded into a linear array (possibly with gaps between items) so that the left-to-right order of the items matches the natural order. The cost is measured by the total  number of times any item is moved during the loading process.  The aim here is to obtain better algorithms than the existing ones using randomization, or to establish that randomization can not significantly improve on the best existing algorithms.\r\n\r\nBy advancing the theory of algorithms and complexity, this award will increase the set of tools available for efficient design of algorithms.  The algorithmic techniques developed for efficient estimation of dynamic programs may be useful for practitioners developing algorithms for problems such as string matching, which is a fundamental problem that arises in varied areas such as data retrieval and analysis of biological data.  Establishing inherent requirements on computational resources for solving various problems can guide the search for improved algorithms for related problems.  An important part of the project is the training of graduate students to do research in the field.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Saks",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Saks",
   "pi_email_addr": "saks@math.rutgers.edu",
   "nsf_id": "000194921",
   "pi_start_date": "2012-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "110 Frelinghuysen Rd Hill Center",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Progress was made on several problems in the theory of algorithms and&nbsp;computational complexity.<br />1. Very efficient approximation algorithms for some string problems.A string is a sequence of numbers, letters or other characters, which mightrepresent a sequence of numerical measurements, a portion of English text,or a DNA sequence. &nbsp;There are many basic algorithmic questions aboutstrings. &nbsp;Two examples are: (1) Given a string of numbers, what isthe length of the longest increasing subsequence? and (2) given two stringshow far apart are they &nbsp;(how many character changes are required toturn one string into the other). There are good standard algorithms for solvingthese problems exactly, but when one has many very large instances ofthe problem to solve, these algorithms may be too slow, or require too muchmemory. In this work, we developed new algorithms for these typesof problems that find an approximate solution (rather than an exact solution) but run much more efficiently that the standard algorithms. &nbsp;For the longest increasing subsequence problem, we develop an algorithm that makes one scan of the sequence and approximates the length of the longest increasing subsequence while using very little computer memory. For the edit distance problem we developed avery fast approximation algorithm for the special case that each of the two input strings is a string with no repeated characters.<br />2. Algorithms for file maintenance. &nbsp;Some basic problems in managing data can be modeled by the following problem, called the file maintenance problem. &nbsp;Numerical data is &nbsp;received one item at a time, and the items are to be stored in a large linear array. &nbsp;We must maintain the data in numerical order in the array, with empty locations allowed between data items. When an item arrives, we must insert this new item into the array whilemaintaining the numerical order. &nbsp;This may involve moving some of the data items already in the array. &nbsp;Each time a data item is moved within the array, we view this as having a fixed cost.The problem is to develop an algorithm that will handle any input data sequence while keeping the average cost per data item added small. &nbsp;Low cost algorithms were developed and analyzed many years ago, but it was a longstanding open problem whether there were algorithms for this problem that were substantially more efficient than the known algorithms. &nbsp;In a series of papers (begun as part of an earlier NSF project) we established that the existing algorithms are essentially best possible (up to a constant factorin the cost) for different versions of this problem.<br />3. Learning an unknown probability distribution in the presence of noise. &nbsp;Many natural and synthetic systems&nbsp;consist of a large collection (population) of objects (individuals) each of which can be classified according to certain characteristicsor measurements. &nbsp;An important step in understanding the system isto know the fraction of inviduals having certain characteristics or combination of characteristics. &nbsp;Standard techniques in statistical inference allow one to approximate these fractions from observationsof independent samples of individuals. &nbsp;The problem becomes more complex if the observations are subject to noise, so that whenobserving a given individual, some of the characteristics of that individualare incorrectly observed. &nbsp;In 2012, Dvir, Rao, Wigderson and Yehudayoff proposed a particular model of such processes and posedthe problem of efficiently estimating statistical properties ofthe population from noisy samples. &nbsp;We developed algorithms and analytical techniques which gave efficient algorithms in their model.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2016<br>\n\t\t\t\t\tModified by: Michael&nbsp;Saks</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProgress was made on several problems in the theory of algorithms and computational complexity.\n1. Very efficient approximation algorithms for some string problems.A string is a sequence of numbers, letters or other characters, which mightrepresent a sequence of numerical measurements, a portion of English text,or a DNA sequence.  There are many basic algorithmic questions aboutstrings.  Two examples are: (1) Given a string of numbers, what isthe length of the longest increasing subsequence? and (2) given two stringshow far apart are they  (how many character changes are required toturn one string into the other). There are good standard algorithms for solvingthese problems exactly, but when one has many very large instances ofthe problem to solve, these algorithms may be too slow, or require too muchmemory. In this work, we developed new algorithms for these typesof problems that find an approximate solution (rather than an exact solution) but run much more efficiently that the standard algorithms.  For the longest increasing subsequence problem, we develop an algorithm that makes one scan of the sequence and approximates the length of the longest increasing subsequence while using very little computer memory. For the edit distance problem we developed avery fast approximation algorithm for the special case that each of the two input strings is a string with no repeated characters.\n2. Algorithms for file maintenance.  Some basic problems in managing data can be modeled by the following problem, called the file maintenance problem.  Numerical data is  received one item at a time, and the items are to be stored in a large linear array.  We must maintain the data in numerical order in the array, with empty locations allowed between data items. When an item arrives, we must insert this new item into the array whilemaintaining the numerical order.  This may involve moving some of the data items already in the array.  Each time a data item is moved within the array, we view this as having a fixed cost.The problem is to develop an algorithm that will handle any input data sequence while keeping the average cost per data item added small.  Low cost algorithms were developed and analyzed many years ago, but it was a longstanding open problem whether there were algorithms for this problem that were substantially more efficient than the known algorithms.  In a series of papers (begun as part of an earlier NSF project) we established that the existing algorithms are essentially best possible (up to a constant factorin the cost) for different versions of this problem.\n3. Learning an unknown probability distribution in the presence of noise.  Many natural and synthetic systems consist of a large collection (population) of objects (individuals) each of which can be classified according to certain characteristicsor measurements.  An important step in understanding the system isto know the fraction of inviduals having certain characteristics or combination of characteristics.  Standard techniques in statistical inference allow one to approximate these fractions from observationsof independent samples of individuals.  The problem becomes more complex if the observations are subject to noise, so that whenobserving a given individual, some of the characteristics of that individualare incorrectly observed.  In 2012, Dvir, Rao, Wigderson and Yehudayoff proposed a particular model of such processes and posedthe problem of efficiently estimating statistical properties ofthe population from noisy samples.  We developed algorithms and analytical techniques which gave efficient algorithms in their model.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 12/01/2016\n\n\t\t\t\t\tSubmitted by: Michael Saks"
 }
}