{
 "awd_id": "1148359",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research SI2 SSE: Pipeline Framework for Ensemble Runs on Clouds",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Daniel Katz",
 "awd_eff_date": "2012-05-01",
 "awd_exp_date": "2014-04-30",
 "tot_intn_awd_amt": 292863.0,
 "awd_amount": 292863.0,
 "awd_min_amd_letter_date": "2012-05-07",
 "awd_max_amd_letter_date": "2012-05-07",
 "awd_abstract_narration": "Cloud computing is an attractive computational resource for e-Science because of the ease with which cores can be accessed on demand, and because the virtual machine implementation that underlies cloud computing reduces the cost of porting a numeric or analysis code to a new platform. It is difficult to use cloud computing resources for large-scale, high throughput ensemble jobs however. Additionally, the computationally oriented researcher is increasingly encouraged to make data sets available to the broader community. For the latter to be achieved, using capture tools during experimentation to harvest metadata and provenance reduces the manual burden of marking up results. Better automatic capture of metadata and provenance is the only means by which sharing of scientific data can scale to meet the burgeoning explosion of data.\r\n\r\nThis project develops a pipeline framework for running ensemble simulations on the cloud; the framework has two key components: ensemble deployment and metadata harvest. Regarding the former, on commercial cloud platforms typically a much smaller number of jobs than desired can be started at any one time. An ensemble run will need to be pipelined to a cloud resource, that is, executed in well-controlled batches over a period of time. We will use platform features of Azure, and employ machine learning techniques to continuously refine the pipeline submission strategy and workflow strategies for ensemble parameter specification, pipelined deployment, and metadata capture. Regarding the latter key component, we expect to reduce the burden of sharing scientific datasets resulting from the use of cloud resources through automatic metadata and provenance capture and representation that aligns the metadata with emerging best practices in data sharing and discovery. Ensemble simulations result in complex data sets, whose reuse could be increased by expressive, granule and collection level metadata, including the lineage of the resulting products, to contribute towards trust.\r\n\r\nIn this project we focus on a compelling and timely application from climate research: One of the more immediate and dangerous impacts of climate change could be a change in the strength of storms that form over the oceans. In addition, as sea level rises due to global warming and melting of the polar ice caps, coastal communities will become increasingly vulnerable to storm surge. There have already been indications that even modest changes in ocean surface temperature can have a disproportionate effect on hurricane strength and the damage inflicted by these storms. In an effort to understand these impacts, modelers turn to predictions generated by hydrodynamic coastal ocean models such as the Sea, Lake and Overland Surges from Hurricanes (SLOSH) model. The proposed research advances the knowledge and understanding of probabilistic storm surge products by enhancements to the SLOSH model itself and through mechanisms that take advantage of commercial cloud resources. This knowledge is expected to have application in research, the classroom, and in operational settings.\r\n\r\nThe broader significance of the project is several-fold. Cloud computing is an important economic driver but it remains difficult for use in computationally driven scientific research. This project lowers the barriers to conducting e-Science research that utilizes cloud resources, specifically Azure. It will contribute tools to help researchers share, preserve, and publicize the scientific data sets that result from their research. Because we focus on and improve an application that predicts storm surge in response to sea level changes and severe storms, our work contributes to societal responses and adaptations to climate change, including planning and building the sustainable, hazard-resilient coastal communities of the future.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Beth",
   "pi_last_name": "Plale",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Beth A Plale",
   "pi_email_addr": "plale@iu.edu",
   "nsf_id": "000334472",
   "pi_start_date": "2012-05-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "919 E. 10th St.",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474083912",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8005",
   "pgm_ref_txt": "Scientific Software Elements"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 292863.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Science paradigms have shifted through time to include a substantial portion of science that is carried out with the help of computers.&nbsp; A hundred years ago science was either empirical, describing natural phenomena, or theoretical, involving mathematical models.&nbsp;&nbsp; Today science takes two additional forms:&nbsp; computational science, which uses computers to simulate complex problems, and data exploration science, which utilizes data captured by measurement systems in the environment, and processes the data by software, storing information in a computer, and from this generating new knowledge.&nbsp;&nbsp; In this project we investigate two questions in the aid of computational science and data exploration science.&nbsp; The first is &ldquo;how can technology make it easier for scientists to take advantage of commercial cloud computing to carry out their computational science research?&rdquo; The second is &ldquo;can the software tools that researchers use help them make their results more easily reproducible?&rdquo;</p>\n<p>This project yielded several significant insights. We proposed a partitioning strategy to improve performance of the multi-job &ldquo;ensemble runs&rdquo; of a storm surge model used by the US National Hurricane Center.&nbsp; We found that in a commercial cloud environment setting, improvements gotten by intelligently packing jobs into bins yielded a small improvement in execution time, less than .01 percent. This was overshadowed by the difficulty in securing the needed compute resources on demand.</p>\n<p>Science reproducibility becomes increasingly challenging when more complex software and hardware environments are needed to carry out both computational science and data exploration science. Our work advances what we call &ldquo;multi-level provenance&rdquo; that builds capture of information about data creation and transformation into the underlying software infrastructure.&nbsp; We experimented with the WorkQueue job submission tool from Notre Dame and the Komadu provenance capture tool from Indiana University and found that &ldquo;multi-level provenance&rdquo; can be useful in reducing the manual task of documenting what happened during a computational process.</p>\n<p>The key outcomes of the project are in useful and reusable tools for provenance capture, and a careful study of commercial cloud computing that contributes additional information to the body of literature about strengths and weaknesses of commercial cloud providers for scientific ensemble computing.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/22/2014<br>\n\t\t\t\t\tModified by: Beth&nbsp;A&nbsp;Plale</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2014/1148359/1148359_10170756_1406066631046_layered_provenance--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2014/1148359/1148359_10170756_1406066631046_layered_provenance--rgov-800width.jpg\" title=\"Multi-level provenance\"><img src=\"/por/images/Reports/POR/2014/1148359/1148359_10170756_1406066631046_layered_provenance--rgov-66x44.jpg\" alt=\"Multi-level provenance\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Data provenance tells us how a data product was created so is critical to science reproducibility.  Information on the left can be captured without touching the application so reduces the manual burden of documentation.</div>\n<div class=\"imageCredit\">Quan (Gabriel) Zhou and Beth Plale</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted...",
  "por_txt_cntn": "\nScience paradigms have shifted through time to include a substantial portion of science that is carried out with the help of computers.  A hundred years ago science was either empirical, describing natural phenomena, or theoretical, involving mathematical models.   Today science takes two additional forms:  computational science, which uses computers to simulate complex problems, and data exploration science, which utilizes data captured by measurement systems in the environment, and processes the data by software, storing information in a computer, and from this generating new knowledge.   In this project we investigate two questions in the aid of computational science and data exploration science.  The first is \"how can technology make it easier for scientists to take advantage of commercial cloud computing to carry out their computational science research?\" The second is \"can the software tools that researchers use help them make their results more easily reproducible?\"\n\nThis project yielded several significant insights. We proposed a partitioning strategy to improve performance of the multi-job \"ensemble runs\" of a storm surge model used by the US National Hurricane Center.  We found that in a commercial cloud environment setting, improvements gotten by intelligently packing jobs into bins yielded a small improvement in execution time, less than .01 percent. This was overshadowed by the difficulty in securing the needed compute resources on demand.\n\nScience reproducibility becomes increasingly challenging when more complex software and hardware environments are needed to carry out both computational science and data exploration science. Our work advances what we call \"multi-level provenance\" that builds capture of information about data creation and transformation into the underlying software infrastructure.  We experimented with the WorkQueue job submission tool from Notre Dame and the Komadu provenance capture tool from Indiana University and found that \"multi-level provenance\" can be useful in reducing the manual task of documenting what happened during a computational process.\n\nThe key outcomes of the project are in useful and reusable tools for provenance capture, and a careful study of commercial cloud computing that contributes additional information to the body of literature about strengths and weaknesses of commercial cloud providers for scientific ensemble computing.\n\n\t\t\t\t\tLast Modified: 07/22/2014\n\n\t\t\t\t\tSubmitted by: Beth A Plale"
 }
}