{
 "awd_id": "1242538",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  ZeroTouch: High-Performance Sensing for Multi-Touch and Free-Air Interaction",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rathindra DasGupta",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2012-12-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2012-06-26",
 "awd_max_amd_letter_date": "2012-06-26",
 "awd_abstract_narration": "The proposed technology is a high-performance optoelectronic architecture for multi-finger interaction. As computing resources grow cheap and ubiquitous, the importance of embodying interaction grows, so that people can express themselves to computers with their bodies, in the same rich ways that we communicate with each other. Multitouch and free-air are important new sensory modalities for embodied interaction. Most multi-touch devices on the market are smartphones and tablets using capacitive multi-touch sensing technologies. However, these technologies do not scale well to large displays because of cost issues and technological challenges. They also cannot sense gloved fingers, precluding their use in many application scenarios. In contrast, the proposed effort encompasses a sensing structure that has a competitive cost structure when scaled to large displays, increasing linearly with display size, as opposed to the quadratic increase in costs exhibited by capacitive sensing. The technology does not require actual touching, only interruption of a sensing plane, enabling gloved interaction in emerging markets such as automobiles. It can work outdoors in sunlight, and in hazardous conditions. It is suitable for TV, tele-operation and 3-D scanning. Beyond multi-touch sensing, the technology enables other new modalities, such as pen+touch, haptics+touch, and free-air interaction. The range of potential markets is wide and deep. \r\n\r\nThe proposed technology can transform the impact of embodied interaction on society. Potential integration with large scale LCDs can transform users' experiences of media in living rooms and conference rooms alike. The high precision and many-finger tracking of the team?s approach in large formats in social innovation-oriented contexts will enable the development of new forms of Computer Supported Cooperative Work and Play in the information age workplace, education, and home. Integration with automobiles will first enable easier interaction by gloved hands on small control panels; more innovative solutions will use the platform for interaction across the whole dashboard, and using the windshield as a heads-up display. If successfully commercialized, the technology has the potential to open up a new broad array of industrial applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Andruid",
   "pi_last_name": "Kerne",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andruid Kerne",
   "pi_email_addr": "andruid@cs.tamu.edu",
   "nsf_id": "000234889",
   "pi_start_date": "2012-06-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University Main Campus",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"> </strong><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"> </strong></p>\n<p dir=\"ltr\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">ZeroTouch is a new technology that aims to bring &nbsp;</strong><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">multi-touch sensing to your desktop monitors, televisions and more. &nbsp;You&rsquo;re probably most familiar with multi-touch from using your tablet or smartphone; anytime you pinch or zoom an image, or try to knock out mischievous pigs in Angry Birds, the multi-touch sensor in your phone is sending the x,y coordinates of each of your fingers to it&rsquo;s internal software. However, the sensors used in phones and tablets rely on a technology that doesn&rsquo;t scale well to large screen sizes, like those used on your desktop, or in your living room. ZeroTouch aims to fill that gap.</strong></strong></p>\n<p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"> </strong></strong></p>\n<p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"><br /></strong></p>\n<p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"> <br /></strong></p>\n<p dir=\"ltr\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">Our goal in the NSF I-Corps program was to find commercialization opportunities for the ZeroTouch technology developed at the Interface Ecology Lab. During the course of the summer, the Principal Investigator and Entrepreneurial Lead teamed up with a business mentor and startup expert, and participated in an intensive crash-course in entrepreneurship. During this process, we reached out to 10+ potential customers each week, including computer manufacturers like Dell, software manufacturers like Microsoft, and other companies that we felt could benefit from the technology.</strong></p>\n<p dir=\"ltr\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\"><br /></strong></p>\n<p dir=\"ltr\"><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">During the development process of ZeroTouch, we received a lot of positive feedback from the research community regarding its potential applications and the possibilities it creates in terms of enabling human-computer interaction researchers to develop new, interesting forms of interaction. However, when we began to investigate the multi-touch marketplace, we discovered that the production costs of the sensor weren&rsquo;t as amenable to mass production and commercialization as we would have hoped. While appropriate for a research environment, where staying on the cutting edge of technology is essential, ZeroTouch simply wasn&rsquo;t ready for the mass market.</strong></p>\n<p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong id=\"docs-internal-guid-7e723a51-446b-9502-ee6d-226fd61db7fa\">Since then, we&rsquo;ve continued to use ZeroTouch as an integral part of our research into new forms of human-computer interaction, establishing a research group dedicated to investigating the &ldquo;living room of the future&rdquo;, performing basic research on simultaneous pen+touch interaction (like you do every day with a pen and paper), and further exploring ways to reduce the cost of ZeroTouch, for future commercialization. ZeroTouch is involved in research collaborations involving TEEX Urban Search and Rescue, and the University of Nottingham Mixed Reality Lab and Horizon Center of Digital Economy.</strong></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/14/2013<br>\n\t\t\t\t\tModified by: Andruid&nbsp;Kerne</p>\n</div>\n<div class=\"porSideCol\">\n<div...",
  "por_txt_cntn": "\n  \nZeroTouch is a new technology that aims to bring  multi-touch sensing to your desktop monitors, televisions and more.  You\u00c6re probably most familiar with multi-touch from using your tablet or smartphone; anytime you pinch or zoom an image, or try to knock out mischievous pigs in Angry Birds, the multi-touch sensor in your phone is sending the x,y coordinates of each of your fingers to it\u00c6s internal software. However, the sensors used in phones and tablets rely on a technology that doesn\u00c6t scale well to large screen sizes, like those used on your desktop, or in your living room. ZeroTouch aims to fill that gap.\n\n \n\n\n\n\n \n\nOur goal in the NSF I-Corps program was to find commercialization opportunities for the ZeroTouch technology developed at the Interface Ecology Lab. During the course of the summer, the Principal Investigator and Entrepreneurial Lead teamed up with a business mentor and startup expert, and participated in an intensive crash-course in entrepreneurship. During this process, we reached out to 10+ potential customers each week, including computer manufacturers like Dell, software manufacturers like Microsoft, and other companies that we felt could benefit from the technology.\n\n\nDuring the development process of ZeroTouch, we received a lot of positive feedback from the research community regarding its potential applications and the possibilities it creates in terms of enabling human-computer interaction researchers to develop new, interesting forms of interaction. However, when we began to investigate the multi-touch marketplace, we discovered that the production costs of the sensor weren\u00c6t as amenable to mass production and commercialization as we would have hoped. While appropriate for a research environment, where staying on the cutting edge of technology is essential, ZeroTouch simply wasn\u00c6t ready for the mass market.\n\n \n\n \n\n \n\n \n\nSince then, we\u00c6ve continued to use ZeroTouch as an integral part of our research into new forms of human-computer interaction, establishing a research group dedicated to investigating the \"living room of the future\", performing basic research on simultaneous pen+touch interaction (like you do every day with a pen and paper), and further exploring ways to reduce the cost of ZeroTouch, for future commercialization. ZeroTouch is involved in research collaborations involving TEEX Urban Search and Rescue, and the University of Nottingham Mixed Reality Lab and Horizon Center of Digital Economy.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/14/2013\n\n\t\t\t\t\tSubmitted by: Andruid Kerne"
 }
}