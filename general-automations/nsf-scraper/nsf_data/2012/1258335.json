{
 "awd_id": "1258335",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Data Analysis for Nursing Care Assistance",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-09-15",
 "awd_exp_date": "2015-08-31",
 "tot_intn_awd_amt": 55389.0,
 "awd_amount": 55389.0,
 "awd_min_amd_letter_date": "2012-09-12",
 "awd_max_amd_letter_date": "2012-09-12",
 "awd_abstract_narration": "The rising cost of long-term patient care, the shortage of nurses, and the increasing number of seniors in the United States make it imperative to investigate the possibility of intelligent systems for elder/patient care.  One challenge is how to prevent falls, which often result in serious injury and considerable hospital and patient costs.   In this exploratory project the PI and her team will focus on analyzing sensory data of patient actions in an effort to develop algorithms for the automatic detection and prediction of falls among elderly patients.  Their goal is to gain a good understanding of how multimodal sensory data combined with domain knowledge of falls can be used to characterize pre-fall patient actions, in order to determine the feasibility of developing automatic alert systems that incorporate machine learning algorithms to assist human nurses and robotic caregivers by warning of potential falls.  \r\n\r\nBroader Impacts:  Project outcomes will pave the way for future development of intelligent systems to reduce the incidence of patient falls, which is a major societal concern.  The project will provide a rich spectrum of interdisciplinary training for graduate student researchers, and will also strengthen UNC Charlotte's existing programs in broadening participation in computing and in research experiences for undergraduates (REU) by deepening involvement of women and minority undergraduate students in research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jing",
   "pi_last_name": "Xiao",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jing Xiao",
   "pi_email_addr": "jxiao2@wpi.edu",
   "nsf_id": "000327458",
   "pi_start_date": "2012-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Srinivas",
   "pi_last_name": "Akella",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Srinivas Akella",
   "pi_email_addr": "sakella@uncc.edu",
   "nsf_id": "000169704",
   "pi_start_date": "2012-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jianping",
   "pi_last_name": "Fan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jianping Fan",
   "pi_email_addr": "jfan@uncc.edu",
   "nsf_id": "000292039",
   "pi_start_date": "2012-09-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sonya",
   "pi_last_name": "Hardin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sonya Hardin",
   "pi_email_addr": "hardins@ecu.edu",
   "nsf_id": "000252311",
   "pi_start_date": "2012-09-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Charlotte",
  "inst_street_address": "9201 UNIVERSITY CITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "CHARLOTTE",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "7046871888",
  "inst_zip_code": "282230001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NC12",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHARLOTTE",
  "org_prnt_uei_num": "NEYCH3CVBTR6",
  "org_uei_num": "JB33DT84JNA5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Charlotte",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "282230001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NC12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 55389.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The rising cost of long-term patient care, the shortage of nursing professionals, and the growing number of seniors in the US population make it imperative to investigate intelligent sensing and robotic solutions for elder/patient care to enable a few human nurses to provide quality care to a large number of patients.</p>\n<p>In this EAGER project, we studied basic research issues inspired by the need of assisting nurses or patients with the following outcome, including a method to identify human actions, an approach to identify and localize partially occluded objects, and a model to analyze human sit-to-stand actions from a bed, with or without aid.</p>\n<p>We developed an intuitively simple method to extract action templates from 3D human joint data and trained classifiers to identify unknown actions. We tested the method on two public datasets that contained 3D human skeleton data. The experimental results show the proposed method can obtain a comparable or better performance than published state-of the-art methods.</p>\n<p>We also developed an appearance-based approach to identify partially occluded objects and estimate their positions and orientations in cluttered environments with 3D vision (such as using a Microsoft Kinect sensor). Our approach is based on segmenting an object into smooth geometrical surfaces and identifying the object using segment-based visual features rather than the usual approach of using features of the whole object. Testing shows that the approach can identify objects with partial occlusion of one another in a cluttered scene from a single image.&nbsp;</p>\n<p>We further developed a model to analyze human sit-to-stand actions from a bed,&nbsp; without or with aid (such as a supporting cane), taking into account constraints faced by motion impaired patients, for example, a maximum load on knee constraint after knee surgery. The objective was to investigate how to best enable and assist a patient to rise from a bed without falling or injury. Preliminary simulations based on the model show good promise of the approach.</p>\n<p>Three graduate students were engaged in the research and funded by this award.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/28/2015<br>\n\t\t\t\t\tModified by: Jing&nbsp;Xiao</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe rising cost of long-term patient care, the shortage of nursing professionals, and the growing number of seniors in the US population make it imperative to investigate intelligent sensing and robotic solutions for elder/patient care to enable a few human nurses to provide quality care to a large number of patients.\n\nIn this EAGER project, we studied basic research issues inspired by the need of assisting nurses or patients with the following outcome, including a method to identify human actions, an approach to identify and localize partially occluded objects, and a model to analyze human sit-to-stand actions from a bed, with or without aid.\n\nWe developed an intuitively simple method to extract action templates from 3D human joint data and trained classifiers to identify unknown actions. We tested the method on two public datasets that contained 3D human skeleton data. The experimental results show the proposed method can obtain a comparable or better performance than published state-of the-art methods.\n\nWe also developed an appearance-based approach to identify partially occluded objects and estimate their positions and orientations in cluttered environments with 3D vision (such as using a Microsoft Kinect sensor). Our approach is based on segmenting an object into smooth geometrical surfaces and identifying the object using segment-based visual features rather than the usual approach of using features of the whole object. Testing shows that the approach can identify objects with partial occlusion of one another in a cluttered scene from a single image. \n\nWe further developed a model to analyze human sit-to-stand actions from a bed,  without or with aid (such as a supporting cane), taking into account constraints faced by motion impaired patients, for example, a maximum load on knee constraint after knee surgery. The objective was to investigate how to best enable and assist a patient to rise from a bed without falling or injury. Preliminary simulations based on the model show good promise of the approach.\n\nThree graduate students were engaged in the research and funded by this award.\n\n\t\t\t\t\tLast Modified: 12/28/2015\n\n\t\t\t\t\tSubmitted by: Jing Xiao"
 }
}