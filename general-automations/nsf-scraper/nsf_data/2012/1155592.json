{
 "awd_id": "1155592",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research:Modeling temporal coordination in speech production using an artificial central pattern generator neural network",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2014-01-31",
 "tot_intn_awd_amt": 5298.0,
 "awd_amount": 5298.0,
 "awd_min_amd_letter_date": "2012-07-23",
 "awd_max_amd_letter_date": "2012-07-23",
 "awd_abstract_narration": "This project investigates how timing is coordinated in speech production and how this coordination can be computationally modeled using artificial neural networks. Research has shown that speech rhythm reflects a multi-tiered, hierarchical organization of speech units (syllables, accentual units, phrases) that are essentially cyclical in nature. One type of neural network which shares these properties, the central pattern generator (CPG), has been hypothesized to underlie speech timing. This project presents two speech production experiments designed to investigate temporal coordination within and among three levels of speech units in French and English, languages with distinct rhythm types, and to discover which timing properties they share and which are language-specific. A three-level CPG-type artificial neural network is presented which is used to model the results of both experiments in order to test the ability of such a model to simulate the timing behavior of two rhythmically distinct languages. Experiment 1 focuses on the coordination between phrases, accentual units, and syllables through a comparison of the durational effects of lengthening due to phrasal stress and phrase-final syllable lengthening in both languages. Experiment 2 compares the overall temporal coordination of spoken phrases and their constituent parts in the two languages by measuring the changes in articulatory timing of phrases which are repeated multiple times. The main goals of the proposed studies and modeling work are to investigate temporal coordination between the hierarchically structured levels of speech units, specifically how that coordination varies between languages, and to test the ability of a biologically inspired CPG-type neural network model to model this coordination and the speech patterns that result from it.\r\n\r\nThis work contributes to an understanding of the coordination and timing of rhythm units in speech and how that coordination may be generated by the brain.  In its broader impact, it will enable the integration of theories of speech production with other motor behavior in biological and cognitive models, and help to forge links between research on speech, linguistic prosody, and more broadly, neural models of animal behavior. This work will also contribute to the construction of a unified model of rhythm and prosody which is sufficient to explain both the underlying universalities and the variations of human language. The project will also enrich the training of the graduate student co-PI.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Cole",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer S Cole",
   "pi_email_addr": "jennifer.cole1@northwestern.edu",
   "nsf_id": "000383964",
   "pi_start_date": "2012-07-23",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Erin",
   "pi_last_name": "Rusaw",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Erin Rusaw",
   "pi_email_addr": "erusaw2@illinois.edu",
   "nsf_id": "000598160",
   "pi_start_date": "2012-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 5298.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The aim of this project was to gain a better understanding of the timing of syllables and words in spoken language through the development of a computational model of speech timing. &nbsp;The timing of successive syllables, words and phrases is an important aspect of speech behavior, and it is something that speakers control without conscious awareness. Different languages impose different controls on the timing of syllables and words, which result in measurable differences in speech patterns. These different timing patterns are part of what gives a language its distinctive &ldquo;rhythm&rdquo;. Incorrect timing patterns can arise in individuals with speech disorders such as dysarthria, and are also a characteristic of foreign-accented speech. In both cases, timing patterns are produced that are deviant when compared to healthy, adult native speakers, and they can cause a significant decrease in &nbsp;intelligibility, interfering with successful communication.</p>\n<p>Linguists have characterized timing patterns in terms of prosodic structures that group syllables and words and that are regulated by grammatical principles. &nbsp;In English, those structures can result in an alternating pattern of long and short syllables (stressed-unstressed), while in French the timing pattern produces phrases with syllables of roughly equal duration. &nbsp;Many other details of pronunciation are affected as a result of these timing patterns. One goal of this study was to test predictions of the linguistic model of prosody against real timing data from speech samples in different languages.</p>\n<p>&nbsp;We investigated speech timing by developing a computational model of prosodic structure using artificial neural networks that simulate the behavior of neural systems, and mathematical models of coupled oscillators, which are have been employed for modeling coordinated behavior in other types of physical activity. These computational methods were used to simulate timing patterns of syllables and words in English and in French, and the simulated timing was then compared to the actual timing patterns of sentences produced by native speakers in those languages. &nbsp;The results of the study showed that the relatively simple computational model was able to capture the timing patterns of each language with impressive accuracy. Especially interesting was the discovery that really different timing patterns in the two languages were produced by the same computational system with only a few small, but critical changes. This finding advances the scientific understanding of the mechanisms, such as prosodic structure, that are responsible for speech timing in human languages.</p>\n<p>&nbsp;The success of the neural network model of speech timing also holds promise for future research on the neural basis for speech timing in the human brain. This type of model is one that cognitive science and neuroscience researchers have used to simulate a wide variety of other patterned animal behaviors. The success of our models points to a common neural basis for speech and other neutrally controlled behaviors, in human and non-human animals.</p>\n<p>Beyond the scientific findings, this research provides a computational tool to simulate the impact of prosody on speech timing, which could be used to improve the accuracy of artificial speech recognition tools and the naturalness of synthesized speech. This tool can be used for future development of speech technologies to assist individuals with disability, by enabling synthesis of speech that is more comprehensible due to more natural sounding timing patterns. The computational model also provides a plausible model of the neural mechanisms that may underlie speech motor control, and as such may aid future research on disordered speech or delayed speech development in clinical populations.</p>\n<p>The outcomes of this project include a Ph.D. dissertation, two con...",
  "por_txt_cntn": "\nThe aim of this project was to gain a better understanding of the timing of syllables and words in spoken language through the development of a computational model of speech timing.  The timing of successive syllables, words and phrases is an important aspect of speech behavior, and it is something that speakers control without conscious awareness. Different languages impose different controls on the timing of syllables and words, which result in measurable differences in speech patterns. These different timing patterns are part of what gives a language its distinctive \"rhythm\". Incorrect timing patterns can arise in individuals with speech disorders such as dysarthria, and are also a characteristic of foreign-accented speech. In both cases, timing patterns are produced that are deviant when compared to healthy, adult native speakers, and they can cause a significant decrease in  intelligibility, interfering with successful communication.\n\nLinguists have characterized timing patterns in terms of prosodic structures that group syllables and words and that are regulated by grammatical principles.  In English, those structures can result in an alternating pattern of long and short syllables (stressed-unstressed), while in French the timing pattern produces phrases with syllables of roughly equal duration.  Many other details of pronunciation are affected as a result of these timing patterns. One goal of this study was to test predictions of the linguistic model of prosody against real timing data from speech samples in different languages.\n\n We investigated speech timing by developing a computational model of prosodic structure using artificial neural networks that simulate the behavior of neural systems, and mathematical models of coupled oscillators, which are have been employed for modeling coordinated behavior in other types of physical activity. These computational methods were used to simulate timing patterns of syllables and words in English and in French, and the simulated timing was then compared to the actual timing patterns of sentences produced by native speakers in those languages.  The results of the study showed that the relatively simple computational model was able to capture the timing patterns of each language with impressive accuracy. Especially interesting was the discovery that really different timing patterns in the two languages were produced by the same computational system with only a few small, but critical changes. This finding advances the scientific understanding of the mechanisms, such as prosodic structure, that are responsible for speech timing in human languages.\n\n The success of the neural network model of speech timing also holds promise for future research on the neural basis for speech timing in the human brain. This type of model is one that cognitive science and neuroscience researchers have used to simulate a wide variety of other patterned animal behaviors. The success of our models points to a common neural basis for speech and other neutrally controlled behaviors, in human and non-human animals.\n\nBeyond the scientific findings, this research provides a computational tool to simulate the impact of prosody on speech timing, which could be used to improve the accuracy of artificial speech recognition tools and the naturalness of synthesized speech. This tool can be used for future development of speech technologies to assist individuals with disability, by enabling synthesis of speech that is more comprehensible due to more natural sounding timing patterns. The computational model also provides a plausible model of the neural mechanisms that may underlie speech motor control, and as such may aid future research on disordered speech or delayed speech development in clinical populations.\n\nThe outcomes of this project include a Ph.D. dissertation, two conference papers, and a computational tool for simulating speech timing, all of which are available to other scientists.\n\nRusaw, Erin Christi..."
 }
}