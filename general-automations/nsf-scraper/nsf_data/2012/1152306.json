{
 "awd_id": "1152306",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "IDBR (Type A): Development of app and web interface for automated anuran recognition and mapping",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Fleischmann",
 "awd_eff_date": "2012-03-01",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 348676.0,
 "awd_amount": 368675.0,
 "awd_min_amd_letter_date": "2012-02-22",
 "awd_max_amd_letter_date": "2017-02-09",
 "awd_abstract_narration": "A synergy of disease, climate change, pollution, exotic species and habitat loss, is pressuring anuran populations worldwide. In the USA, while overall anuran population declines are clearly evident, species that will be hardest hit are hard to predict. The spatial and temporal monitoring of anuran populations needs to be improved if the signs of further population failures are to be identified and remedies sought. The ideal means to increase the coverage of data is to put out sensors that would detect frogs, or have highly trained researchers conduct surveys. However, both these options are cost-prohibitive. A more cost-effective means to gather these data is to take advantage of the many volunteers interested in the fate of anurans. The limitation to date has been the time-consuming and inherently variable success in training those volunteers to recognize anuran vocalizations. In the proposed research, machine-learning algorithms and statistical analysis of sonograms will be used to provide reproducible, standardized identification of calling anurans in real time.\r\n\tA novel use of mobile devices (e.g. iPods, phones, and tablets) is proposed to identify and map anurans. The vocal recognition software will be developed as application (app) for mobile devices. By producing an efficient and intuitive app, that integrates with an accompanying social network an army of potential volunteers can be involved in mapping the abundance and range of anurans. While this proposal takes advantage of cutting-edge technology in terms of voice recognition, connectivity and social media, its purpose is not to advance any one of those branches of technology. Rather it applies existing technology in a novel way to increase participation in this aspect of citizen science by more than an order of magnitude, and bring the cost of automated voice recognition down by almost three orders of magnitude (from close to $1000 to ~$1). In providing a standardized means to recognize anuran calls, data quality and the reliability of data gathered by volunteers will be improved.\r\n    \r\nGeneral statement of project importance\r\n\tFrogs and toads are excellent indicators of habitat quality, not just of their spawning sites, but also of adjacent uplands. These creatures are experiencing an unprecedented collapse in populations due to habitat loss, pollution, and novel diseases. As the faltering of amphibian populations may presage wider ecological problems, it is important to document where species are most affected. In the proposed research, an application (app) will be developed for smart phones and other mobile devices that will use cutting edge voice-recognition software to identify frogs and toads. Currently the average age for volunteers conducting anuran surveys is  about 50. By using modern social media and portable device technology the goal of this proposal is to engage a younger audience. The affordability of the system will make it appropriate for classroom use, and it has the potential to spur studies in ecology, physics, geography, and math, as the students consider the data, sonograms, and maps that the software will produce. Through active dissemination we believe this app could quickly be adopted by thousands, perhaps tens of thousands of users, many of whom would be new contributors to citizen science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Bush",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Mark B Bush",
   "pi_email_addr": "mbush@fit.edu",
   "nsf_id": "000286249",
   "pi_start_date": "2012-02-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ronaldo",
   "pi_last_name": "Menezes",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Ronaldo P Menezes",
   "pi_email_addr": "rmenezes@cs.fit.edu",
   "nsf_id": "000484668",
   "pi_start_date": "2012-02-22",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eraldo",
   "pi_last_name": "Ribeiro",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eraldo Ribeiro",
   "pi_email_addr": "eribeiro@cs.fit.edu",
   "nsf_id": "000495126",
   "pi_start_date": "2012-02-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Florida Institute of Technology",
  "inst_street_address": "150 W UNIVERSITY BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "MELBOURNE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3216748000",
  "inst_zip_code": "329018995",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "FL08",
  "org_lgl_bus_name": "FLORIDA INSTITUTE OF TECHNOLOGY INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNN6VH618X58"
 },
 "perf_inst": {
  "perf_inst_name": "Florida Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "329016975",
  "perf_ctry_code": "US",
  "perf_cong_dist": "08",
  "perf_st_cong_dist": "FL08",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "110800",
   "pgm_ele_name": "INSTRUMENTAT & INSTRUMENT DEVP"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7218",
   "pgm_ref_txt": "RET SUPP-Res Exp for Tchr Supp"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 368675.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we set out to provide an app for mobile devices that would provide a real-time identification of calling amphibians (frogs and toads, hereafter frogs). Frogs are very sensitive to environmental conditions and are often referred to as the 'canary in the coal-mine' for wetland habitats. They provide early warnings of deteriorating conditions caused by pollution, drainage, or loss of adjacent habitat. There are about 100 species of frog in North America, and in the app we selected the commonest 48 species for inclusion. The goal of the app is to provide a resource for someone who wants to learn more about frogs, to become a citizen scientist monitoring wetlands, or for school and college classes wanting to learn about the ecology and behavior of frogs.</p>\n<p>The app is for use on i-phones and i-pads, and features a description of each species, range maps, and photographs. It also has stock recordings of each species. Using the app is simple. A recording is made, and the app access an algorithm that finds a match for the new recording against a library of hundreds of archived frog calls. The most likely matches are show with a probability that the identification is accurate. The user can keep a profile of their recordings, sites they have visited and map their observations. The app is free and available for download from the Apple app store.</p>\n<p>The app is about 82% accurate, which is about the same as an experienced human operator. Like humans the app finds some frogs easy to distinguish based on their calls, whereas others are more problematic (often because the calls are soft or very quick). Interestingly, the species that tend to confound humans are not the same as those that confound the machine. This suggests that the app may be a significant aid even to experienced frog monitors.</p>\n<p>The average age of citizen scientists is 55, the average age of i-phone users is much less. We hope that by providing a new way for they young to interface with nature through their favorite device it will promote some new, younger, recruits to engage in citizen science.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/23/2018<br>\n\t\t\t\t\tModified by: Mark&nbsp;B&nbsp;Bush</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project we set out to provide an app for mobile devices that would provide a real-time identification of calling amphibians (frogs and toads, hereafter frogs). Frogs are very sensitive to environmental conditions and are often referred to as the 'canary in the coal-mine' for wetland habitats. They provide early warnings of deteriorating conditions caused by pollution, drainage, or loss of adjacent habitat. There are about 100 species of frog in North America, and in the app we selected the commonest 48 species for inclusion. The goal of the app is to provide a resource for someone who wants to learn more about frogs, to become a citizen scientist monitoring wetlands, or for school and college classes wanting to learn about the ecology and behavior of frogs.\n\nThe app is for use on i-phones and i-pads, and features a description of each species, range maps, and photographs. It also has stock recordings of each species. Using the app is simple. A recording is made, and the app access an algorithm that finds a match for the new recording against a library of hundreds of archived frog calls. The most likely matches are show with a probability that the identification is accurate. The user can keep a profile of their recordings, sites they have visited and map their observations. The app is free and available for download from the Apple app store.\n\nThe app is about 82% accurate, which is about the same as an experienced human operator. Like humans the app finds some frogs easy to distinguish based on their calls, whereas others are more problematic (often because the calls are soft or very quick). Interestingly, the species that tend to confound humans are not the same as those that confound the machine. This suggests that the app may be a significant aid even to experienced frog monitors.\n\nThe average age of citizen scientists is 55, the average age of i-phone users is much less. We hope that by providing a new way for they young to interface with nature through their favorite device it will promote some new, younger, recruits to engage in citizen science.\n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 05/23/2018\n\n\t\t\t\t\tSubmitted by: Mark B Bush"
 }
}