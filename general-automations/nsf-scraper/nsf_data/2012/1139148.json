{
 "awd_id": "1139148",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Socially Assistive Robots",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2012-04-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 2575000.0,
 "awd_amount": 2583000.0,
 "awd_min_amd_letter_date": "2012-04-02",
 "awd_max_amd_letter_date": "2021-03-12",
 "awd_abstract_narration": "Socially Assistive Robots\r\nLead PI/Institution: Brian Scassellati, Yale University\r\nThis Expedition will develop the fundamental computational techniques that will enable the design, implementation, and evaluation of robots that encourage social, emotional, and cognitive growth in children, including those with social or cognitive deficits.  The need for this technology is driven by critical societal problems that require sustained, personalized support that supplements the efforts of educators, parents, and clinicians.   For example, clinicians and families struggle to provide individualized educational services to children with social and cognitive deficits, whose numbers have quadrupled in the US in the last decade alone.  In many schools, educators struggle to provide language instruction for children raised in homes where a language other than English is spoken (over 20%), the fastest-growing segment of the school-age population.  This Expedition aims to support the individual needs of these children with socially assistive robots that help to guide the children toward long-term behavioral goals, that are customized to the particular needs of each child, and that develop and change as the child does.  \r\nTo achieve this vision, this Expedition will advance the state-of-the-art in socially assistive human-robot interaction from short-term interactions in structured environments to long-term interactions that are adaptive, engaging, and effective. This progress will require transformative computing research in three broad and naturally interrelated research areas. First, the Expedition will develop computational models of the dynamics of social interaction, so that robots can automatically detect, analyze, and influence agency, intention, and other social interaction primitives in dynamic environments. Second, the Expedition will develop machine learning algorithms that adapt and personalize interactions to individual physical, social, and cognitive differences, enabling robots to teach and shape behavior in ways that are tailored to the needs, preferences, and capabilities of each individual. Third, the Expedition will develop systems that guide children toward specific learning goals over periods of weeks and months, allowing for truly long-term guidance and support. Research in these three areas will be integrated into socially assistive robots that are deployed in schools and homes for durations of up to one year.  \r\nThis Expedition has the potential to substantially impact the effectiveness of education and healthcare for children, and the technological tools developed will serve as the basis for enhancing the lives of children and other groups that require specialized support and intervention. The proposed computing research is tied to a comprehensive student training program, bringing a compelling, engaging, and grounded STEM experience to K-12 students through in-school and after-school activities. It also establishes an annual training summit to provide undergraduates with the multi-disciplinary background to engage in this promising research area in graduate school. Finally, by establishing a brand name for socially assistive robotics, this effort will create a central authority for the distribution of high-quality, peer-reviewed information, providing a coherent focal point for enhancing outreach and education.\r\nFor more information visit www.yale.edu/SAR",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maja",
   "pi_last_name": "Matari\u0107",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maja J Matari\u0107",
   "pi_email_addr": "mataric@usc.edu",
   "nsf_id": "000410606",
   "pi_start_date": "2012-04-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gisele",
   "pi_last_name": "Ragusa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gisele Ragusa",
   "pi_email_addr": "ragusa@usc.edu",
   "nsf_id": "000447315",
   "pi_start_date": "2012-04-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Fei",
   "pi_last_name": "Sha",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Fei Sha",
   "pi_email_addr": "feisha@usc.edu",
   "nsf_id": "000510744",
   "pi_start_date": "2012-04-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Donna",
   "pi_last_name": "Spruijt-Metz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Donna Spruijt-Metz",
   "pi_email_addr": "dmetz@usc.edu",
   "nsf_id": "000518716",
   "pi_start_date": "2012-04-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900891143",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "772300",
   "pgm_ele_name": "Expeditions in Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7723",
   "pgm_ref_txt": "EXPERIMENTAL EXPEDITIONS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 825000.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 533000.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 1050000.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This Expedition grant explored how socially assistive robots (SAR) can aid in the social and cognitive development of children.&nbsp; We focused on three key ways of enabling such capabilities: (1) long-term adaptation: the ability to keep adapting over time so it remains effective and improves its efficacy; (2) personalization: the ability to learn about the specific needs and preferences of a user and keep adapting to those to improve their experience and outcomes; and (3) modeling social dynamics: the ability to sufficiently understand both human-human and human-robot interactions in order to intelligently adapt and help each user. &nbsp;To ensure that the Expedition research had significant practical use, we deployed SARs in complex real-world environments for extended periods of time. To make that possible, we developed the SpriteBot robot platform, a fully autonomous SAR that is affordable, compact, safe, and accessible to end-users, teachers, and families with various backgrounds. Spritebot is designed to use different ?skins? so it can be personalized and adapted for specific users and contexts.</p>\n<p>&nbsp;</p>\n<p>The work on the Expedition spanned multiple challenging real-world SAR use cases. We developed d partnerships with relevant institutions--schools, children?s hospital, parent support network-- to inform system design and recruit volunteer participants. We then deployed the robot and collected datasets that provided unprecedented amounts of new information and insights for both technology development, acceptance, and usability. We focused on multiple challenging real-world use cases: 1) learning healthy food choices by 1<sup>st</sup> grade students, in schools; 2) reducing children?s experience of pain, in hospitals; and 3) learning cognitive and social skill by 3-8 year-olds diagnosed with autism spectrum disorder (ASD), in their homes. We additionally explored facilitating group interactions and discussions involving children.&nbsp; For each use case, we focused on long-term adaptation and personalization of the SAR system to the individual needs of each child, and understanding the social dynamics of child-robot, child-caregiver/educator, and child-family interactions.</p>\n<p>&nbsp;</p>\n<p><strong>Scientific merit:</strong> In the first integration project, we deployed a Spritebot (using a dragon-like appearance) in 1<sup>st</sup> grade classrooms.&nbsp; Students interacted with the robot one-on-one, twice per week for multiple weeks, playing a ?Train Your Dragonbot? game, in which the robot asked the child to help it choose what to eat in order to train for a big dragon race.&nbsp; To maximize engagement and retention, we used tangible learning; the student chose and set a plate of physical plastic food and drink for the robot.&nbsp; The study results showed that 1<sup>st</sup> graders gained and retained new knowledge about healthy food choices, accepted the robot as a peer, and progressively shared more personal topics about school and family.</p>\n<p>&nbsp;</p>\n<p>In the child pain reduction project, we deployed a 3D-printed robot Ivey at Children?s Hospital Los Angeles to interact with children who were receiving an intravenous injection.&nbsp; Ivey helped each child to choose a coping mechanism that worked best for them, ranging from a calming breathing exercise, to an explanation of the procedure.&nbsp; The study results showed that the interaction with Ivey made children report experiencing less pain than standard distraction techniques (e.g., movies) currently used in hospitals.</p>\n<p>&nbsp;</p>\n<p>The culminating study of the Expedition was a complex month-long deployment of a Spritebot Kiwi (using an owl-like appearance) in the homes of 17 children with ASD in inner-city Los Angeles. Over a month-long deployment, each child played educational math games with Kiwi, with oversight from a parent and, in some cases, involvement from a sibling. The SAR adapted the challenge level of the math games it played based on the child?s abilities and performance, and also provided personalized social support to promote perseverance and social skill development. This first-of-its-kind study generated a novel, unique, complex, and challenging longitudinal multimodal dataset with a total of 67:51:48 hours of child-robot interaction. The data have resulted in a large number of insights, computational methods, and publications.</p>\n<p><strong>Broader impacts:&nbsp; </strong>The overarching goals of this Expedition grant aimed specifically at broad impacts for children?s development, education, and wellness.&nbsp; The work developed intelligent, adaptive, and personalized socially assistive robots for children in various settings and with a variety of needs, including those with autism spectrum disorder (ASD). &nbsp;The work also inspired multiple technology startups that have launched products.<strong>&nbsp;</strong></p>\n<p>&nbsp;</p>\n<p>K-12 STEM outreach was also a major part this Expedition. Generations of PhD, MS, and undergraduate researchers engaged in a large number of outreach activities over the lifetime of the grant.&nbsp; A major outcome was inspiring the establishment of the USC?s annual Robotics Open House, which has drawn up to 2,000 K-12 students from local underserved LA neighborhoods to see demos and talks about the work on the Expedition; this event reached over 7,000 K-12 students over the lifetime of the Expedition. Other outreach activities included annual robotics assemblies and family robotics nights at an elementary school, reaching over 800 TK-5<sup>th</sup> graders over the lifetime of the grant.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2021<br>\n\t\t\t\t\tModified by: Maja&nbsp;J&nbsp;Mataric</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009447107_kiwi-asd--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009447107_kiwi-asd--rgov-800width.jpg\" title=\"Socially assistive robot for supporting learning of children with autism spectrum disorder\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009447107_kiwi-asd--rgov-66x44.jpg\" alt=\"Socially assistive robot for supporting learning of children with autism spectrum disorder\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A child with autism spectrum disorder learning math and social skills with the help of the socially assistive robot Kiwi (mom is next to the child).</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Socially assistive robot for supporting learning of children with autism spectrum disorder</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009261311_sprite2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009261311_sprite2--rgov-800width.jpg\" title=\"Socially assistive robot Spritebot\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009261311_sprite2--rgov-66x44.jpg\" alt=\"Socially assistive robot Spritebot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Spritebot, the affordable, safe, and accessible socially assistive robot platform developed as part of the Expedition grant</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Socially assistive robot Spritebot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009347051_PainStudy--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009347051_PainStudy--rgov-800width.jpg\" title=\"Socially assistive robot for reducing children's experience of pain\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009347051_PainStudy--rgov-66x44.jpg\" alt=\"Socially assistive robot for reducing children's experience of pain\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A patient at a children\ufffds hospital interacting with the socially assistive robot Ivey to reduce his experience of pain and fear.</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Socially assistive robot for reducing children's experience of pain</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009516847_group_moderation--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009516847_group_moderation--rgov-800width.jpg\" title=\"Socially assistive robot moderates group interaction\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009516847_group_moderation--rgov-66x44.jpg\" alt=\"Socially assistive robot moderates group interaction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A discussion group being moderated by the socially assistive robot Kiwi; results show that the group feels more cohesive and selfish behaviors are reduced.</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Socially assistive robot moderates group interaction</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009643171_outreach-kiwi--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009643171_outreach-kiwi--rgov-800width.jpg\" title=\"K-12 STEM outreach with Kiwi, the socially assistive robot\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009643171_outreach-kiwi--rgov-66x44.jpg\" alt=\"K-12 STEM outreach with Kiwi, the socially assistive robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A demonstration of the socially assistive robot Kiwi during a USC Viterbi School of Engineering Robotics Open House visited by up to 2000 K-12 students from inner city schools.</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">K-12 STEM outreach with Kiwi, the socially assistive robot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009162075_food-choices-with-dragonbot--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009162075_food-choices-with-dragonbot--rgov-800width.jpg\" title=\"1st grader with Dragonbot, learning about healthy food choices\"><img src=\"/por/images/Reports/POR/2021/1139148/1139148_10161572_1641009162075_food-choices-with-dragonbot--rgov-66x44.jpg\" alt=\"1st grader with Dragonbot, learning about healthy food choices\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">1st grade student learning about healthy food choices by interacting with the socially assistive robot Dragonbot.</div>\n<div class=\"imageCredit\">Maja Mataric</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">1st grader with Dragonbot, learning about healthy food choices</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis Expedition grant explored how socially assistive robots (SAR) can aid in the social and cognitive development of children.  We focused on three key ways of enabling such capabilities: (1) long-term adaptation: the ability to keep adapting over time so it remains effective and improves its efficacy; (2) personalization: the ability to learn about the specific needs and preferences of a user and keep adapting to those to improve their experience and outcomes; and (3) modeling social dynamics: the ability to sufficiently understand both human-human and human-robot interactions in order to intelligently adapt and help each user.  To ensure that the Expedition research had significant practical use, we deployed SARs in complex real-world environments for extended periods of time. To make that possible, we developed the SpriteBot robot platform, a fully autonomous SAR that is affordable, compact, safe, and accessible to end-users, teachers, and families with various backgrounds. Spritebot is designed to use different ?skins? so it can be personalized and adapted for specific users and contexts.\n\n \n\nThe work on the Expedition spanned multiple challenging real-world SAR use cases. We developed d partnerships with relevant institutions--schools, children?s hospital, parent support network-- to inform system design and recruit volunteer participants. We then deployed the robot and collected datasets that provided unprecedented amounts of new information and insights for both technology development, acceptance, and usability. We focused on multiple challenging real-world use cases: 1) learning healthy food choices by 1st grade students, in schools; 2) reducing children?s experience of pain, in hospitals; and 3) learning cognitive and social skill by 3-8 year-olds diagnosed with autism spectrum disorder (ASD), in their homes. We additionally explored facilitating group interactions and discussions involving children.  For each use case, we focused on long-term adaptation and personalization of the SAR system to the individual needs of each child, and understanding the social dynamics of child-robot, child-caregiver/educator, and child-family interactions.\n\n \n\nScientific merit: In the first integration project, we deployed a Spritebot (using a dragon-like appearance) in 1st grade classrooms.  Students interacted with the robot one-on-one, twice per week for multiple weeks, playing a ?Train Your Dragonbot? game, in which the robot asked the child to help it choose what to eat in order to train for a big dragon race.  To maximize engagement and retention, we used tangible learning; the student chose and set a plate of physical plastic food and drink for the robot.  The study results showed that 1st graders gained and retained new knowledge about healthy food choices, accepted the robot as a peer, and progressively shared more personal topics about school and family.\n\n \n\nIn the child pain reduction project, we deployed a 3D-printed robot Ivey at Children?s Hospital Los Angeles to interact with children who were receiving an intravenous injection.  Ivey helped each child to choose a coping mechanism that worked best for them, ranging from a calming breathing exercise, to an explanation of the procedure.  The study results showed that the interaction with Ivey made children report experiencing less pain than standard distraction techniques (e.g., movies) currently used in hospitals.\n\n \n\nThe culminating study of the Expedition was a complex month-long deployment of a Spritebot Kiwi (using an owl-like appearance) in the homes of 17 children with ASD in inner-city Los Angeles. Over a month-long deployment, each child played educational math games with Kiwi, with oversight from a parent and, in some cases, involvement from a sibling. The SAR adapted the challenge level of the math games it played based on the child?s abilities and performance, and also provided personalized social support to promote perseverance and social skill development. This first-of-its-kind study generated a novel, unique, complex, and challenging longitudinal multimodal dataset with a total of 67:51:48 hours of child-robot interaction. The data have resulted in a large number of insights, computational methods, and publications.\n\nBroader impacts:  The overarching goals of this Expedition grant aimed specifically at broad impacts for children?s development, education, and wellness.  The work developed intelligent, adaptive, and personalized socially assistive robots for children in various settings and with a variety of needs, including those with autism spectrum disorder (ASD).  The work also inspired multiple technology startups that have launched products. \n\n \n\nK-12 STEM outreach was also a major part this Expedition. Generations of PhD, MS, and undergraduate researchers engaged in a large number of outreach activities over the lifetime of the grant.  A major outcome was inspiring the establishment of the USC?s annual Robotics Open House, which has drawn up to 2,000 K-12 students from local underserved LA neighborhoods to see demos and talks about the work on the Expedition; this event reached over 7,000 K-12 students over the lifetime of the Expedition. Other outreach activities included annual robotics assemblies and family robotics nights at an elementary school, reaching over 800 TK-5th graders over the lifetime of the grant. \n\n \n\n\t\t\t\t\tLast Modified: 12/31/2021\n\n\t\t\t\t\tSubmitted by: Maja J Mataric"
 }
}