{
 "awd_id": "1228976",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Workshop Proposal: Communication Theory and Signal Processing in the Cloud Era",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "John Cozzens",
 "awd_eff_date": "2012-06-15",
 "awd_exp_date": "2013-05-31",
 "tot_intn_awd_amt": 39279.0,
 "awd_amount": 39279.0,
 "awd_min_amd_letter_date": "2012-06-07",
 "awd_max_amd_letter_date": "2012-06-07",
 "awd_abstract_narration": "Workshop: Communication theory and Signal Processing in the Cloud Era\r\n\r\nAffordable virtualized computing resources have enabled storage and processing of information at a scale never previously imagined possible. Cloud computing is enabling what has been called the industrial revolution of data. Algorithms to store, process, compress and protect this information at a cloud scale are much needed. Much of this infrastructure is currently developed without a good understanding  of fundamental principles from information theory and signal processing. \r\n\r\nThe workshop `Communication theory and Signal Processing in the Cloud Era' will take place on June 25 and 26 at University of California, Berkeley. The meeting focuses on bringing together internationally known experts in academia and industry to identify new challenges in cloud computing, coding techniques and content distribution at large scale.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kannan",
   "pi_last_name": "Ramchandran",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kannan Ramchandran",
   "pi_email_addr": "kannanr@eecs.berkeley.edu",
   "nsf_id": "000173259",
   "pi_start_date": "2012-06-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Georgios-Alex",
   "pi_last_name": "Dimakis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Georgios-Alex Dimakis",
   "pi_email_addr": "dimakis@austin.utexas.edu",
   "nsf_id": "000515168",
   "pi_start_date": "2012-06-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "2150 Shattuck Ave",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947045940",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 39279.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project made possible a workshop held in Berkeley, California, in 2012 on \"Distributed Storage\" that was attended by some of the world's most renowned researchers in the field. &nbsp; A brief summary is that there are exciting challenges and opportunities for the use of coding in next-generation distributed storage systems. &nbsp;The following topics were identified:</p>\n<p>1)&nbsp;<strong>Distributed storage systems</strong> like Apache Hadoop are becoming the norm for big data analytics and storage. Many such systems deploy clusters of thousands of servers and store tens of petabytes. At this scale, several disk and node failures per day are common. Typical systems like the Google file system (GFS) and the Hadoop file system (HDFS) rely on replication strategies to provide reliable information storage. For example, the default replication value in Hadoop HDFS is 3, which means that three copies of each file are stored in different locations. Considering the massive storage scales at which these clusters operate, any small reduction the storage overhead can bring down the total storage used and thus the cost of storage considerably.&nbsp;Recently, several cloud storage systems have started using erasure coding techniques instead of replication to reduce this storage overhead. &nbsp;Research on the use of codes for these systems is a promising future direction identified by the workshop participants.</p>\n<p>2)&nbsp;<strong>Low Latency to the Cloud</strong>:&nbsp;In addition to providing reliability to the data, another important operation in any data center is to serve the user requests as fast as possible. For instance, a recent study shows that people will visit a Web site less often even if it is slower than a close competitor by just 250 milliseconds~\\cite{nytimes_impatient}. While the use of codes for providing improved reliability in archival storage systems, where the data is less frequently accessed (or so-called ``cold data''), is well understood, the role of codes in the storage of more frequently accessed and active ``hot data'' is less clear and a promising research direction.</p>\n<p>3)<strong>Image Delivery and Caching: </strong>&nbsp;Photos are initially grouped in large archive files before being encoded. This happens because current systems require files of the order of hundreds of MBs for the coding overheads to diminish. Like all content, photos are separated into `hot' and `cold' content depending on access statistics. Hot data are replicated multiple times to ensure fast delivery and cold data is protected by progressively larger codes that save storage.Optimizing delivery and caching algorithms for large image databases is going to be an important challenge.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/07/2014<br>\n\t\t\t\t\tModified by: Kannan&nbsp;Ramchandran</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project made possible a workshop held in Berkeley, California, in 2012 on \"Distributed Storage\" that was attended by some of the world's most renowned researchers in the field.   A brief summary is that there are exciting challenges and opportunities for the use of coding in next-generation distributed storage systems.  The following topics were identified:\n\n1) Distributed storage systems like Apache Hadoop are becoming the norm for big data analytics and storage. Many such systems deploy clusters of thousands of servers and store tens of petabytes. At this scale, several disk and node failures per day are common. Typical systems like the Google file system (GFS) and the Hadoop file system (HDFS) rely on replication strategies to provide reliable information storage. For example, the default replication value in Hadoop HDFS is 3, which means that three copies of each file are stored in different locations. Considering the massive storage scales at which these clusters operate, any small reduction the storage overhead can bring down the total storage used and thus the cost of storage considerably. Recently, several cloud storage systems have started using erasure coding techniques instead of replication to reduce this storage overhead.  Research on the use of codes for these systems is a promising future direction identified by the workshop participants.\n\n2) Low Latency to the Cloud: In addition to providing reliability to the data, another important operation in any data center is to serve the user requests as fast as possible. For instance, a recent study shows that people will visit a Web site less often even if it is slower than a close competitor by just 250 milliseconds~\\cite{nytimes_impatient}. While the use of codes for providing improved reliability in archival storage systems, where the data is less frequently accessed (or so-called ``cold data''), is well understood, the role of codes in the storage of more frequently accessed and active ``hot data'' is less clear and a promising research direction.\n\n3)Image Delivery and Caching:  Photos are initially grouped in large archive files before being encoded. This happens because current systems require files of the order of hundreds of MBs for the coding overheads to diminish. Like all content, photos are separated into `hot' and `cold' content depending on access statistics. Hot data are replicated multiple times to ensure fast delivery and cold data is protected by progressively larger codes that save storage.Optimizing delivery and caching algorithms for large image databases is going to be an important challenge. \n\n \n\n \n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 01/07/2014\n\n\t\t\t\t\tSubmitted by: Kannan Ramchandran"
 }
}