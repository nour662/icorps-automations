{
 "awd_id": "1219321",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "HCC: Medium: Collaborative Research: Improved Control and Sensory Feedback for Neuroprosthetics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2011-11-01",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 313050.0,
 "awd_amount": 371370.0,
 "awd_min_amd_letter_date": "2012-01-05",
 "awd_max_amd_letter_date": "2015-05-06",
 "awd_abstract_narration": "This research involves collaboration among investigators at four institutions. Recent advances in motor behavior have uncovered structure in the supporting neural control architecture, including distinctions between feed-forward and feedback control functions and learning. While the neural code has not yet been cracked, much is now known about how its foundations for sensorimotor control differ from those of even the most modern computer-based algorithms. For example, neural function must accommodate transmission and processing delays, so feedback control is subservient to feed-forward and anticipatory control. The nervous system produces exquisite, constantly and widely available predictions concerning body and environment interactions. These predictive models (also called internal models) are constructed by learning the invariants in the mapping from motor commands to sensory feedback (and inverses thereof). The PIs have developed a unique approach based upon readings from a scalp array of EEG electrodes for the construction of algorithms (decoders) which predict motor behavior (control signals) as a weighted sum of the EEG data from all electrodes at multiple time lags. The team has demonstrated two-axis control over a screen cursor using only 10 minutes of EEG and motion training data, a feat far surpassing any brain-computer interface (BCI) available to date. In the current project, the team will build upon this prior work to design and validate noninvasive neural decoders that generate agile control in upper limb prosthetics. To this end, they will investigate neural correlates of brain adaptation to multiple sources of feedback using EEG and functional near infrared spectroscopy (fNIR). An important challenge will be to provide sensory feedback appropriate to contact tasks performed with a prosthesis. Existing BCIs and neuro-prosthetic devices rely at best on vibrotactile feedback and often only on visual feedback. The PIs will add haptic and proprioceptive feedback in concert with a novel adaptation of vibrotactile, skin stretch, and arm squeeze technologies in the prosthesis interface, to provide intuitive control over contact tasks and to strengthen the motor imagery whose neural correlates are processed by the EEG decoder. To establish baseline measures, the team will compare prosthetic performance under direct brain control to myoelectric prosthetic control and direct manual control. Experiments will be performed involving both able-bodied individuals and amputees, in which real-time decoding (EEG) and analysis (EEG/fNIR) of sensorimotor control and cognitive load will be combined. \r\n\r\nBroader Impacts: This research will revolutionize the control and interface of upper limb prosthetics. The work will lead to a better understanding of the role of sensory feedback in brain-computer interfaces and will lay the foundation for restoration of motor and sensory function for amputees and individuals with neurological disease. The project will create a unique interdisciplinary environment enabling education, training, co-advising and exchange of graduate students, course development, and involvement of undergraduates in research. The PIs will also participate in outreach activities on their various campuses, targeting underrepresented groups in science and engineering.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jose",
   "pi_last_name": "Contreras-Vidal",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Jose L Contreras-Vidal",
   "pi_email_addr": "jlcontreras-vidal@uh.edu",
   "nsf_id": "000415706",
   "pi_start_date": "2012-01-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Houston",
  "inst_street_address": "4300 MARTIN LUTHER KING BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "HOUSTON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7137435773",
  "inst_zip_code": "772043067",
  "inst_country_name": "United States",
  "cong_dist_code": "18",
  "st_cong_dist_code": "TX18",
  "org_lgl_bus_name": "UNIVERSITY OF HOUSTON SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "QKWEF8XLMTT3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Houston",
  "perf_str_addr": "Electrical & Computer Eng",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "772044005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "18",
  "perf_st_cong_dist": "TX18",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0111",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001112DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2011,
   "fund_oblg_amt": 45804.0
  },
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 101062.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 195504.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 14500.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 14500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Grasping is one of the most fundamental ways humans interact with the world, allowing us to manipulate and interact with objects around us for work, play, social communication, navigation, creative art, feeding or simply taking care of ourselves. In the United States, there are approximately 2 million people living with limb loss, with 14% or 280,000 accounting for upper-limb amputations. Use of smart prostheses or artificial limbs among amputees can increase their level of independence and participation in activities of daily living. Thus, this award focused on the design and validation of noninvasive (risk-free) and intuitive human-robot interfaces based on neural activity that allow for natural control of upper limb prostheses.</p>\n<p><strong>Intellectual Merit:</strong> The primary project outcome was the development and proof-of-concept validation of a non-invasive technique, called a brain-machine interface (BMI), to allow an upper-limb amputee to use a robotic hand, powered by his/her brain activity. The novel technique is based on the use of real-time measurements of brain waves, using scalp electroencephalography (EEG) sensors, to infer the user&rsquo;s grasping intentions to control the movements of the artificial hand. Thus, for example, the BMI allowed a woman, whose right hand had been amputated in an accident, to grasp a bottle and other objects with her prosthetic hand powered only by her brain activity. The technique also allowed researchers to determine what parts of the brain, as inferred from the EEG measurements, are normally involved in grasping an object. This information may be useful in understanding the neural mechanisms involved in the control of hand movements. Another outcome of the project was the design and fabrication of a low cost 3D printed force-sensing fingertip for use in prosthetic hands, which can be used to provide force feedback to the user of the artificial hand during initial contact with an object and during object manipulation.</p>\n<p><strong>Broader impacts</strong> of the project included the development of graduate courses in advanced electroencephalography and brain-machine interfaces; the training of undergraduate, graduate, and postdoctoral students in neural engineering; and the participation in science, technology, engineering and math (STEM) outreach activities at K-12 schools in the greater Houston metropolitan area. Moreover, we developed a summer internship program to provide research experiences for selected undergraduate students from Arizona, Maryland, Massachusetts, Michigan and Texas; as well as research internships for exchange undergraduate students from the Tecnologico de Monterrey, Mexico. &nbsp;Our broader impact activities also include dissemination of our research to the general public, including presentations at the Children&rsquo;s Museum of Houston and demonstration of our neurotechnology at the Smithsonian&rsquo;s Innovation Week in Washington D.C. Research products from this award were also published on specialized peer-reviewed journals and conference publications, and reported by the science media and online at the Discovery Section of the National Science Foundation website.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/18/2016<br>\n\t\t\t\t\tModified by: Jose&nbsp;Contreras-Vidal</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2016/1219321/1219321_10096137_1471550230446_NSFOutcomesFigureHandNeuroprosthesis--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2016/1219321/1219321_10096137_1471550230446_NSFOutcomesFigureHandNeuroprosthesis--rgov-800width.jpg\" title=\"Neuroprosthesis for grasping\"><img src=\"/por/images/Reports/POR/2016/1219321/1219321_10096137_1471550230446_NSFOutcomesFigureHandNeuroprosthesis--rgov-66x44.jpg\" alt=\"Neuroprosthesis for grasping\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A woman, with a right hand amputation, demonstrates grasping movements with a bionic hand controlled by her brain waves using noninvasive scalp electroencephalography (EEG).</div>\n<div class=\"imageCredit\">University of Houston Communications Office</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Jose&nbsp;Contreras-Vidal</div>\n<div class=\"imageTitle\">Neuroprosthesis for grasping</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nGrasping is one of the most fundamental ways humans interact with the world, allowing us to manipulate and interact with objects around us for work, play, social communication, navigation, creative art, feeding or simply taking care of ourselves. In the United States, there are approximately 2 million people living with limb loss, with 14% or 280,000 accounting for upper-limb amputations. Use of smart prostheses or artificial limbs among amputees can increase their level of independence and participation in activities of daily living. Thus, this award focused on the design and validation of noninvasive (risk-free) and intuitive human-robot interfaces based on neural activity that allow for natural control of upper limb prostheses.\n\nIntellectual Merit: The primary project outcome was the development and proof-of-concept validation of a non-invasive technique, called a brain-machine interface (BMI), to allow an upper-limb amputee to use a robotic hand, powered by his/her brain activity. The novel technique is based on the use of real-time measurements of brain waves, using scalp electroencephalography (EEG) sensors, to infer the user?s grasping intentions to control the movements of the artificial hand. Thus, for example, the BMI allowed a woman, whose right hand had been amputated in an accident, to grasp a bottle and other objects with her prosthetic hand powered only by her brain activity. The technique also allowed researchers to determine what parts of the brain, as inferred from the EEG measurements, are normally involved in grasping an object. This information may be useful in understanding the neural mechanisms involved in the control of hand movements. Another outcome of the project was the design and fabrication of a low cost 3D printed force-sensing fingertip for use in prosthetic hands, which can be used to provide force feedback to the user of the artificial hand during initial contact with an object and during object manipulation.\n\nBroader impacts of the project included the development of graduate courses in advanced electroencephalography and brain-machine interfaces; the training of undergraduate, graduate, and postdoctoral students in neural engineering; and the participation in science, technology, engineering and math (STEM) outreach activities at K-12 schools in the greater Houston metropolitan area. Moreover, we developed a summer internship program to provide research experiences for selected undergraduate students from Arizona, Maryland, Massachusetts, Michigan and Texas; as well as research internships for exchange undergraduate students from the Tecnologico de Monterrey, Mexico.  Our broader impact activities also include dissemination of our research to the general public, including presentations at the Children?s Museum of Houston and demonstration of our neurotechnology at the Smithsonian?s Innovation Week in Washington D.C. Research products from this award were also published on specialized peer-reviewed journals and conference publications, and reported by the science media and online at the Discovery Section of the National Science Foundation website.\n\n \n\n\t\t\t\t\tLast Modified: 08/18/2016\n\n\t\t\t\t\tSubmitted by: Jose Contreras-Vidal"
 }
}