{
 "awd_id": "1149737",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Spectral Deformable Models: Theory and Applications",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 432371.0,
 "awd_amount": 488371.0,
 "awd_min_amd_letter_date": "2011-12-27",
 "awd_max_amd_letter_date": "2017-04-26",
 "awd_abstract_narration": "With the popularity of real-time 3D/4D data capturing capabilities, there is an emerging need to compute the deformable models over the networks. Traditional model-driven deformable models have their bottlenecks since the spatial information for large-scale datasets cannot be efficiently solved and adaptively minimized over different network conditions. This project centers on the concept of spectrum-driven deformable models. Analogous to Fourier analysis being applied to image processing, the spectral deformable models employ manifold harmonics to efficiently and effectively perform segmentation, registration, physics-based simulation, compression, and streaming of 3D deformable surfaces and volumes.\r\n\r\nIn this project, manifold harmonics are used to transform arbitrary scanned datasets into a reduced diffusion subspace, in which real-time segmentation, registration, and physics-based simulation can be performed. Besides the stretching deformations, the rotational and tensor fields are encoded with manifold harmonics, which provides a \"spectral multiresolution\" structure to compress and stream deformable models over different network conditions.\r\n\r\nThe PI works with the medical imaging experts at UT Southwestern Medical Center, to build a tele-diagnosis system for evaluating each component in the spectral deformable models. The test-bed on tele-medicine has impacts on the next-generation diagnosis and treatment services, as well as on clinical education. The theoretical and technical breakthrough can benefit our society at large, from tele-immersion, remote sensing, to speech training, through the PI?s further outreach activities. The research and education are integrated by taking research advances into existing and future courses; developing the visualization software for education; and attracting more undergraduate students into research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaohu",
   "pi_last_name": "Guo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaohu Guo",
   "pi_email_addr": "xguo@utdallas.edu",
   "nsf_id": "000178016",
   "pi_start_date": "2011-12-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "745300",
   "pgm_ele_name": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7453",
   "pgm_ref_txt": "GRAPHICS & VISUALIZATION"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 104957.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 104784.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 104631.0
  },
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 77698.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 88301.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project centers on the concept of spectrum-driven 3D/4D deformable models. When processing large-scale deformable models over the networks, traditional model-driven approaches have their bottlenecks since the spatial information cannot be efficiently solved and adaptively minimized. Analogous to Fourier analysis being applied to image processing, the spectral deformable models introduced in this project employ manifold harmonics and other geometric spectrum methods, to effectively enable the computation of segmentation, registration, physics-based simulation, compression, and streaming of 3D deformable surfaces and volumes.</p>\n<p>&nbsp;</p>\n<p>The manifold harmonics are defined as the eigenfunctions of discrete Laplace-Beltrami Operator (LBO). The PI and his students built a point-wisely defined discrete LBO on point sampled surfaces, with the symmetrizable property guaranteed and the convergence rate proved. Such discrete LBO can be also defined on the medial axis of arbitrary 3D shapes, with its spectrum shown to be a more powerful 3D shape descriptor than the use of traditional geometric spectrum.&nbsp;&nbsp;Similar to Fourier transform, the eigenfunctions of discrete LBO can be used to perform &ldquo;forward&rdquo; and &ldquo;inverse&rdquo; transforms of any square-integrable functions defined on the manifold. The PI and his students studied the spectral transform and sparse localized decomposition of rotation fields defined on manifold surfaces, for the purpose of deformable mesh compression and animation control. Except for the compression of surfaces and volumes, it was shown by the PI that the manifold harmonic transform can be used to build a blind two-way watermarking framework for textured 3D models.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Spectral transform can be used to speed-up the computation of deformable models. The PI and his students demonstrated that the deformation subspaces constructed from the elementary boundary deformations can be used for computing deformation of each sub-domain, while easily maintaining the consistency (i.e. no cracks) between two neighboring spatial sub-domains. Such subspace strategy also makes it easy to integrate FEM structural analysis and geometric design in a &ldquo;plug-and-play&rdquo; fashion, to allow agile structure analysis, i.e. a smooth design-simulation experience, for fabrication-aware shape editing. Deformable models can be interacted by using haptic devices. The spectral subspace strategy makes the streaming of deformation information adaptive over lossy networks, which can be used to support remote haptic interactions with 3D deformable models that are simulated in a collaborative virtual environment. Note that deformation not only appears in FEM simulations, but also being used for performing deformable registration of real-time captured point clouds (from RGB-D cameras) in the 3D reconstruction of dynamic human bodies.</p>\n<p>&nbsp;</p>\n<p><span>This investigation has broader impacts on an array of applications spanning from communication disorder, medical physics and radiation oncology, to tele-rehabilitation.&nbsp;</span><span>The PI has been collaborating with three partners: (1) collaborating with the Callier Center for Communication Disorders at UTD, to propose a novel visualization framework to demonstrate the human tongue deformation in real-time speech, by using our subspace FEM; the FEM tongue model is driven by the captured motion data by placing sensors on the subject&rsquo;s tongue during their speech; (2) collaborating with the medical imaging experts at UT Southwestern Medical Center, on tracking the motion of tumors and modeling the deformation of human organs through deformable registration; an adaptive meshing strategy is proposed to support 2D-2D, 3D-3D, as well as 3D-2D registrations; the patient-specific biomechanical parameters in FEM can be estimated reliably for performing biomechanical simulation of lung tumor motions; (3) collaborating with&nbsp;</span><span>a multi-disciplinary team of researchers (Drs. Balakrishnan Prabhakaran from UTD, Klara Nahrstedt from UIUC, Ruzena Bajcsy from UC-Berkeley, and Thiru Annaswamy from Dallas VA Medical Center), on developing a 3D tele-rehabilitation system with RGB-D cameras and wearable body sensors; the spectral deformable model helps the compression and streaming of real-time 3D camera data to provide the necessary high frame rates and high Quality of Experience (QoE) for the tele-immersive environments installed in geographically-distributed cities.</span></p>\n<p>&nbsp;</p>\n<p>The investigation results in this proposal have been integrated into both undergraduate and graduate curriculum that the PI is teaching at UT-Dallas. Besides the graduate students (including 1 woman PhD student) who were directly involved in this project, five undergraduate students were supported from the REU supplements and received rigorous research training in related fields of physics-based modeling, computer graphics, and virtual reality.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/28/2018<br>\n\t\t\t\t\tModified by: Xiaohu&nbsp;Guo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project centers on the concept of spectrum-driven 3D/4D deformable models. When processing large-scale deformable models over the networks, traditional model-driven approaches have their bottlenecks since the spatial information cannot be efficiently solved and adaptively minimized. Analogous to Fourier analysis being applied to image processing, the spectral deformable models introduced in this project employ manifold harmonics and other geometric spectrum methods, to effectively enable the computation of segmentation, registration, physics-based simulation, compression, and streaming of 3D deformable surfaces and volumes.\n\n \n\nThe manifold harmonics are defined as the eigenfunctions of discrete Laplace-Beltrami Operator (LBO). The PI and his students built a point-wisely defined discrete LBO on point sampled surfaces, with the symmetrizable property guaranteed and the convergence rate proved. Such discrete LBO can be also defined on the medial axis of arbitrary 3D shapes, with its spectrum shown to be a more powerful 3D shape descriptor than the use of traditional geometric spectrum.  Similar to Fourier transform, the eigenfunctions of discrete LBO can be used to perform \"forward\" and \"inverse\" transforms of any square-integrable functions defined on the manifold. The PI and his students studied the spectral transform and sparse localized decomposition of rotation fields defined on manifold surfaces, for the purpose of deformable mesh compression and animation control. Except for the compression of surfaces and volumes, it was shown by the PI that the manifold harmonic transform can be used to build a blind two-way watermarking framework for textured 3D models. \n\n \n\nSpectral transform can be used to speed-up the computation of deformable models. The PI and his students demonstrated that the deformation subspaces constructed from the elementary boundary deformations can be used for computing deformation of each sub-domain, while easily maintaining the consistency (i.e. no cracks) between two neighboring spatial sub-domains. Such subspace strategy also makes it easy to integrate FEM structural analysis and geometric design in a \"plug-and-play\" fashion, to allow agile structure analysis, i.e. a smooth design-simulation experience, for fabrication-aware shape editing. Deformable models can be interacted by using haptic devices. The spectral subspace strategy makes the streaming of deformation information adaptive over lossy networks, which can be used to support remote haptic interactions with 3D deformable models that are simulated in a collaborative virtual environment. Note that deformation not only appears in FEM simulations, but also being used for performing deformable registration of real-time captured point clouds (from RGB-D cameras) in the 3D reconstruction of dynamic human bodies.\n\n \n\nThis investigation has broader impacts on an array of applications spanning from communication disorder, medical physics and radiation oncology, to tele-rehabilitation. The PI has been collaborating with three partners: (1) collaborating with the Callier Center for Communication Disorders at UTD, to propose a novel visualization framework to demonstrate the human tongue deformation in real-time speech, by using our subspace FEM; the FEM tongue model is driven by the captured motion data by placing sensors on the subject?s tongue during their speech; (2) collaborating with the medical imaging experts at UT Southwestern Medical Center, on tracking the motion of tumors and modeling the deformation of human organs through deformable registration; an adaptive meshing strategy is proposed to support 2D-2D, 3D-3D, as well as 3D-2D registrations; the patient-specific biomechanical parameters in FEM can be estimated reliably for performing biomechanical simulation of lung tumor motions; (3) collaborating with a multi-disciplinary team of researchers (Drs. Balakrishnan Prabhakaran from UTD, Klara Nahrstedt from UIUC, Ruzena Bajcsy from UC-Berkeley, and Thiru Annaswamy from Dallas VA Medical Center), on developing a 3D tele-rehabilitation system with RGB-D cameras and wearable body sensors; the spectral deformable model helps the compression and streaming of real-time 3D camera data to provide the necessary high frame rates and high Quality of Experience (QoE) for the tele-immersive environments installed in geographically-distributed cities.\n\n \n\nThe investigation results in this proposal have been integrated into both undergraduate and graduate curriculum that the PI is teaching at UT-Dallas. Besides the graduate students (including 1 woman PhD student) who were directly involved in this project, five undergraduate students were supported from the REU supplements and received rigorous research training in related fields of physics-based modeling, computer graphics, and virtual reality.\n\n \n\n\t\t\t\t\tLast Modified: 11/28/2018\n\n\t\t\t\t\tSubmitted by: Xiaohu Guo"
 }
}