{
 "awd_id": "1216569",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: CPU-GPU Collaborative Execution in Fusion Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tao Li",
 "awd_eff_date": "2012-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 376484.0,
 "awd_amount": 376484.0,
 "awd_min_amd_letter_date": "2012-07-23",
 "awd_max_amd_letter_date": "2012-07-23",
 "awd_abstract_narration": "The most recent trend in chip design is to integrate general purpose central processing units (CPUs) with graphics processing units (GPUs) onto a single microprocessor chip. Looking beyond the obvious benefits of simply putting components closer together, such integration presents an unprecedented opportunity for the CPU and GPU to collaborate, yielding a system whose performance far exceeds the sum of its parts. Whereas, currently, the CPU and GPU are delegated different tasks that each is suited for, this project explores new ways for the CPU and GPU to tackle and collaborate on the same task. The collaboration is fundamentally different from conventional parallel processing, because the CPU and GPU have radically different architectures. In particular, the CPU performs novel meta-computation that assists a GPU task, or vice versa. This innovative approach uncovers new opportunities for emerging heterogeneous architectures. \r\n\r\nThe project investigates CPU/GPU collaborative execution paradigms to overcome fundamental limitations of both CPU and GPU computing tasks. The GPU achieves high computational throughput and energy efficiency by executing a single instruction on many data items. Its efficiency is severely degraded if some data items are not available due to long memory access latency or different data items require different operations. The CPU/GPU collaboration leverages the CPU to run far ahead of the GPU to prefetch the data and reorganize the operations needed for different data items so as to drastically improve the GPU efficiency. Conversely, on the CPU side, the CPU/GPU collaboration leverages the GPU's parallel processing power to accelerate auxiliary computations that greatly enrich the CPU program. Locality analysis, for instance, reveals the nature of memory accesses but requires high computation time when running on a CPU. GPU acceleration makes it possible to perform locality analysis simultaneously with the CPU program and adapt the memory hierarchy on-the-fly to improve CPU performance. The research cuts through software and hardware layers. From the software perspective, the project develops automated approaches to generate code for collaborative execution. From the hardware perspective, future architectures are defined to facilitate more effective CPU/GPU collaboration. The automated software approach adds value to current and upcoming microprocessors by enabling them to run more efficiently. The performance improvement and energy savings translate directly into enhanced user experience.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Huiyang",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Huiyang Zhou",
   "pi_email_addr": "hzhou@ncsu.edu",
   "nsf_id": "000250126",
   "pi_start_date": "2012-07-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 376484.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The increasing integration density, as observed in Moore&rsquo;s law, leads to fusion architecture, in which heterogeneous computing units, including CPUs, GPUs, FPGAs, and accelerators, are integrated onto the same chip. This project focuses on developing novel execution paradigms enabled by fusion architecture. This project investigates both compiler and architectural techniques to improve CPU and GPU performance as well as energy efficiency. A total of eight graduate students participated in the project and three Ph.D. dissertations and two master theses are a direct result from this project. </span><span>&nbsp;Numerous papers have been published in premium venues of the computer architecture, compiler, supercomputing and parallel processing research. A new course has been developed based on the researching findings of the project.</span></p>\n<p><span>On the CPU side,&nbsp;a new quantitative measure of locality is proposed based on conditional probability. It provides a unified definition of both temporal and spatial locality and offers insights on improving the cache performance. A spatial locality aware cache partitioning scheme is developed for the last level cache shared among multi-cores. Adaptive bypassing for inclusive last-level cache is also proposed to improve the performance of CPU memory hierarchy.</span></p>\n<p><span>On the GPU side, a CPU-GPU collaborative execution is proposed with CPUs prefetching data for GPUs to process, which significantly improves the computing efficiency. The key components in GPU architecture have been dissected and novel schemes have been proposed to improve their architecture, including warp-level processing, shared memory multiplexing, on-chip memory placement, dynamic parallelism, GPU memory hierarchy, preemption, etc. </span></p>\n<p><span>On the FPGA side, this project targets at improving the newly developed OpenCL for FPGAs framework, which aims to enable software developers to easily program FPGA devices. The project develops techniques at the OpenCL level for performance optimization, profiling, and debugging. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p><span>Besides compiler and architecture research on the fusion architectures, this project also investigates important applications, including FFT, sparse matrix-vector operations, stencil algorithms, erasure coding for software defined storage, and convolutional neural networks. Novel parallel implementations on fusion architectures have been proposed to advance the state of art performance of these important applications.</span></p>\n<p><span>Detailed research findings from this project are published in conference papers, journal papers, and theses/dissertations. Open source code is also distributed to help reproduce the experimental results and reveal the implementation details.</span><span>&nbsp;</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/03/2017<br>\n\t\t\t\t\tModified by: Huiyang&nbsp;Zhou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe increasing integration density, as observed in Moore?s law, leads to fusion architecture, in which heterogeneous computing units, including CPUs, GPUs, FPGAs, and accelerators, are integrated onto the same chip. This project focuses on developing novel execution paradigms enabled by fusion architecture. This project investigates both compiler and architectural techniques to improve CPU and GPU performance as well as energy efficiency. A total of eight graduate students participated in the project and three Ph.D. dissertations and two master theses are a direct result from this project.  Numerous papers have been published in premium venues of the computer architecture, compiler, supercomputing and parallel processing research. A new course has been developed based on the researching findings of the project.\n\nOn the CPU side, a new quantitative measure of locality is proposed based on conditional probability. It provides a unified definition of both temporal and spatial locality and offers insights on improving the cache performance. A spatial locality aware cache partitioning scheme is developed for the last level cache shared among multi-cores. Adaptive bypassing for inclusive last-level cache is also proposed to improve the performance of CPU memory hierarchy.\n\nOn the GPU side, a CPU-GPU collaborative execution is proposed with CPUs prefetching data for GPUs to process, which significantly improves the computing efficiency. The key components in GPU architecture have been dissected and novel schemes have been proposed to improve their architecture, including warp-level processing, shared memory multiplexing, on-chip memory placement, dynamic parallelism, GPU memory hierarchy, preemption, etc. \n\nOn the FPGA side, this project targets at improving the newly developed OpenCL for FPGAs framework, which aims to enable software developers to easily program FPGA devices. The project develops techniques at the OpenCL level for performance optimization, profiling, and debugging.          \n\nBesides compiler and architecture research on the fusion architectures, this project also investigates important applications, including FFT, sparse matrix-vector operations, stencil algorithms, erasure coding for software defined storage, and convolutional neural networks. Novel parallel implementations on fusion architectures have been proposed to advance the state of art performance of these important applications.\n\nDetailed research findings from this project are published in conference papers, journal papers, and theses/dissertations. Open source code is also distributed to help reproduce the experimental results and reveal the implementation details. \n\n\t\t\t\t\tLast Modified: 09/03/2017\n\n\t\t\t\t\tSubmitted by: Huiyang Zhou"
 }
}