{
 "awd_id": "1247693",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Mid-Scale: DA: Collaborative Research: Genomes Galore - Core Techniques, Libraries, and Domain Specific Languages for High-Throughput DNA Sequencing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2013-01-01",
 "awd_exp_date": "2016-12-31",
 "tot_intn_awd_amt": 350000.0,
 "awd_amount": 350000.0,
 "awd_min_amd_letter_date": "2012-09-21",
 "awd_max_amd_letter_date": "2012-09-21",
 "awd_abstract_narration": "The recent emergence of a variety of high-throughput DNA sequencing instrumentation, and the concomitant rapid decline in the cost per base, is causing severe data deluge in all areas of life sciences. The heterogeneity of sequencing instrumentation and the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever increasing data sets. The goal of the proposed project is to develop core techniques and software libraries to enable scalable, efficient, high performance computing solutions for high-throughput DNA sequencing, also known as next-generation sequencing (NGS). To empower the larger community, the project seeks to 1) identify a set of core functionalities that frequently occur in many types of high-throughput sequencing applications, 2) develop efficient parallel algorithms and high performance implementations for them, 3) pursue mapping to HPC architectures including clusters, multicores, and GPUs, 4) develop software libraries encapsulating these functionalities with the goal of enabling the bioinformatics community to exploit HPC architectures, and 5) design a domain specific language to enable bioinformatics researchers unfamiliar with parallel processing to benefit from this work through automatic generation of parallel codes. The research will be conducted in the context of challenging problems in human genetics and metagenomics, in collaboration with domain specialists.\r\n\r\nThis project is focused on a key capacity building activity to facilitate pervasive use of parallelism by NGS bioinformatics researchers and practitioners. The goal is to empower the broader community to benefit from clever parallel algorithms, highly tuned implementations, and specialized HPC hardware, without requiring expertise in any of these. The software libraries will be released as open source for use, further development, enhancements, and incorporation by the community. The project will provide opportunities for training postdoctoral and graduate students in bigdata analytics and computer science driven interdisciplinary research. Diverse existing mechanisms at the partner institutions will be leveraged to advance goals of minority and women recruitment, undergraduate participation in research, and K-12 outreach.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Wuchun",
   "pi_last_name": "Feng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Wuchun Feng",
   "pi_email_addr": "feng@cs.vt.edu",
   "nsf_id": "000066142",
   "pi_start_date": "2012-09-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute & State Univ. (Virginia Tech)",
  "perf_str_addr": "2202 Kraft Dr.",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240606356",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 350000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While DNA sequencing analysis in the biological laboratory can lead to medical and pharmaceutical breakthroughs, it is a slow, tedious, error-prone, and costly process.&nbsp;To accelerate the process, J. Craig Venter had the foresight to take such tedious sequencing analysis out of the biological laboratory and digitize it in a way that high-performance computers (or supercomputers) could perform the sequencing analysis more quickly and more efficiently. This pioneering approach led to the sequencing of the human genome by 2001, arguably a decade sooner than original projections. In short, J. Craig Venter digitized the sequencing analysis processes from the wet lab so that the computer could perform the sequencing analysis more efficiently.</p>\n<p>&nbsp;</p>\n<p>More recently, the advent of <em>high-throughput</em> DNA sequencing, also known as next-generation sequencing (NGS), is creating a massive data deluge (i.e., &ldquo;big data) in all areas of the life sciences. How massive? While Moore&rsquo;s Law continues to project a theoretical doubling in computer performance every 24 months, high-throughput DNA sequencers (or NGS) are doubling the amount of biological data that they generate every 6 to 7 months. That is, the rate at which high-throughput DNA sequencers are generating data is far outstripping our ability to compute on the data. Furthermore, the heterogeneity (and even incompatibility) of sequencing instrumentation as well as the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever-increasing data sets.&nbsp;</p>\n<p>&nbsp;</p>\n<p>To address the above challenges and create a more efficient and easier-to-use &ldquo;big data&rdquo; sequencing analysis environment that leads to faster medical and pharmaceutical breakthroughs, we achieved the following:</p>\n<p>&nbsp;</p>\n<p>1&nbsp; Efficient mapping of life-science applications onto multi-core and many-core computers (i.e., think a few multiple electronic brains to many electronic brains, e.g., 100) to deliver breakthroughs ranging from two times to thousands of times faster than ever before.</p>\n<p>2&nbsp; Analysis and decomposition of life-science applications to support the creation of reusable &ldquo;Lego-like&rdquo; building blocks (across these life-science applications) so that life scientists can easily use the building blocks to program next-generation sequencing (NGS) analysis tools to run fast on multi-core and many-core computers.</p>\n<p>3&nbsp; Creation of approaches to automate the acceleration (i.e., optimization) of the aforementioned &ldquo;Lego-like&rdquo; building blocks, which can be found in well-known algorithms in genomics, and more broadly, biocomputing.</p>\n<p>4&nbsp; Continued profiling and analysis of state-of-the-art life science applications in order to identify and add any new &ldquo;Lego-like&rdquo; building blocks for next-generation sequencing (NGS) analysis.</p>\n<p>&nbsp;</p>\n<p>In summary, with Moore&rsquo;s Law and its associated computer hardware unable to keep up with the massive data deluge from next-generation sequencers (NGS), our project sought to create a transformative software approach that accelerates the sequence analysis process to keep up with this massive data deluge, something that hardware alone cannot do.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>More recently, the advent of high-throughput DNA sequencing is creating a massive data deluge (i.e., &ldquo;big data) in all areas of the life. How massive? While Moore&rsquo;s Law continues to project a theoretical doubling in computer performance every 24 months, high-throughput DNA sequencers are doubling the amount of biological data that they generate every 6 to 7 months. In short, the rate at which high-throughput DNA sequencers are generating data is far outstripping our ability to compute on the data. Furthermore, the heterogeneity (and even incompatibility) of sequencing instrumentation as well as the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever-increasing data sets.&nbsp;</p>\n<p>&nbsp;</p>\n<p>To address the above challenges and create a more efficient and easier-to-use &ldquo;big data&rdquo; sequencing analysis environment that will lead to faster medical and pharmaceutical breakthroughs, we achieved the following:</p>\n<p>&nbsp;</p>\n<p>1&nbsp; Efficient mapping of life-science applications onto multi-core and many-core computers (i.e., think a few multiple electronic brains to many electronic brains, e.g., 100) to deliver medical and pharmaceutical breakthroughs ranging from two times to thousands of times faster than ever before.</p>\n<p>2&nbsp; Analysis and decomposition of life-science applications to support the creation of reusable &ldquo;Lego-like&rdquo; building blocks (across these life-science applications) so that life scientists can easily use the building blocks to program next-generation sequencing (NGS) analysis tools to run fast on multi-core and many-core computers.</p>\n<p>3&nbsp; Creation of approaches to automate the acceleration (i.e., optimization) of the aforementioned &ldquo;Lego-like&rdquo; building blocks, which can be found in well-known algorithms in genomics, and more broadly, biocomputing.</p>\n<p>4&nbsp; Continued profiling and analysis of state-of-the-art life science applications in order to identify and add any new &ldquo;Lego-like&rdquo; building blocks for next-generation sequencing (NGS) analysis.</p>\n<p>&nbsp;</p>\n<p>Transformative software to address the shortcomings of hardware.</p>\n<p>&nbsp;</p>\n<p>it requires supercomputing resources and Big Data storage that many researchers lack.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/12/2017<br>\n\t\t\t\t\tModified by: Wuchun&nbsp;Feng</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497287811541_100513-MissingGenes-Lab--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497287811541_100513-MissingGenes-Lab--rgov-800width.jpg\" title=\"bigdata+computing=solution\"><img src=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497287811541_100513-MissingGenes-Lab--rgov-66x44.jpg\" alt=\"bigdata+computing=solution\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A Metaphor for Analyzing Clinical \"Big Data\" with Supercomputing</div>\n<div class=\"imageCredit\">Virginia Tech</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Wuchun&nbsp;Feng</div>\n<div class=\"imageTitle\">bigdata+computing=solution</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497289083840_170612-Aalign--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497289083840_170612-Aalign--rgov-800width.jpg\" title=\"NSF_AAlign-vs-SWPS3_and_SWAPHI\"><img src=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497289083840_170612-Aalign--rgov-66x44.jpg\" alt=\"NSF_AAlign-vs-SWPS3_and_SWAPHI\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our Automatically-Generated DNA Sequence Aligner vs. the State-of-the-Art but Manually Programmed SWPS3 and SWAPHI.</div>\n<div class=\"imageCredit\">K. Hou, H. Wang, and W. Feng (Virginia Tech)</div>\n<div class=\"imagePermisssions\">Copyright owner is an institution with an existing agreement allowing use by NSF</div>\n<div class=\"imageSubmitted\">Wuchun&nbsp;Feng</div>\n<div class=\"imageTitle\">NSF_AAlign-vs-SWPS3_and_SWAPHI</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296302208_ScreenShot2017-06-12at3.36.45PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296302208_ScreenShot2017-06-12at3.36.45PM--rgov-800width.jpg\" title=\"empowering-cancer-research\"><img src=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296302208_ScreenShot2017-06-12at3.36.45PM--rgov-66x44.jpg\" alt=\"empowering-cancer-research\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Microsoft Cloud Commercial: Empowering Cancer Research</div>\n<div class=\"imageCredit\">Microsoft on YouTube</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Wuchun&nbsp;Feng</div>\n<div class=\"imageTitle\">empowering-cancer-research</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296455190_ScreenShot2017-06-12at3.39.38PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296455190_ScreenShot2017-06-12at3.39.38PM--rgov-800width.jpg\" title=\"accelerating-cancer-research\"><img src=\"/por/images/Reports/POR/2017/1247693/1247693_10217504_1497296455190_ScreenShot2017-06-12at3.39.38PM--rgov-66x44.jpg\" alt=\"accelerating-cancer-research\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Microsoft Cloud Commercial (Long): Accelerating Cancer Research</div>\n<div class=\"imageCredit\">Microsoft on YouTube</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Wuchun&nbsp;Feng</div>\n<div class=\"imageTitle\">accelerating-cancer-research</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhile DNA sequencing analysis in the biological laboratory can lead to medical and pharmaceutical breakthroughs, it is a slow, tedious, error-prone, and costly process. To accelerate the process, J. Craig Venter had the foresight to take such tedious sequencing analysis out of the biological laboratory and digitize it in a way that high-performance computers (or supercomputers) could perform the sequencing analysis more quickly and more efficiently. This pioneering approach led to the sequencing of the human genome by 2001, arguably a decade sooner than original projections. In short, J. Craig Venter digitized the sequencing analysis processes from the wet lab so that the computer could perform the sequencing analysis more efficiently.\n\n \n\nMore recently, the advent of high-throughput DNA sequencing, also known as next-generation sequencing (NGS), is creating a massive data deluge (i.e., \"big data) in all areas of the life sciences. How massive? While Moore?s Law continues to project a theoretical doubling in computer performance every 24 months, high-throughput DNA sequencers (or NGS) are doubling the amount of biological data that they generate every 6 to 7 months. That is, the rate at which high-throughput DNA sequencers are generating data is far outstripping our ability to compute on the data. Furthermore, the heterogeneity (and even incompatibility) of sequencing instrumentation as well as the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever-increasing data sets. \n\n \n\nTo address the above challenges and create a more efficient and easier-to-use \"big data\" sequencing analysis environment that leads to faster medical and pharmaceutical breakthroughs, we achieved the following:\n\n \n\n1  Efficient mapping of life-science applications onto multi-core and many-core computers (i.e., think a few multiple electronic brains to many electronic brains, e.g., 100) to deliver breakthroughs ranging from two times to thousands of times faster than ever before.\n\n2  Analysis and decomposition of life-science applications to support the creation of reusable \"Lego-like\" building blocks (across these life-science applications) so that life scientists can easily use the building blocks to program next-generation sequencing (NGS) analysis tools to run fast on multi-core and many-core computers.\n\n3  Creation of approaches to automate the acceleration (i.e., optimization) of the aforementioned \"Lego-like\" building blocks, which can be found in well-known algorithms in genomics, and more broadly, biocomputing.\n\n4  Continued profiling and analysis of state-of-the-art life science applications in order to identify and add any new \"Lego-like\" building blocks for next-generation sequencing (NGS) analysis.\n\n \n\nIn summary, with Moore?s Law and its associated computer hardware unable to keep up with the massive data deluge from next-generation sequencers (NGS), our project sought to create a transformative software approach that accelerates the sequence analysis process to keep up with this massive data deluge, something that hardware alone cannot do.\n\n \n\n \n\nMore recently, the advent of high-throughput DNA sequencing is creating a massive data deluge (i.e., \"big data) in all areas of the life. How massive? While Moore?s Law continues to project a theoretical doubling in computer performance every 24 months, high-throughput DNA sequencers are doubling the amount of biological data that they generate every 6 to 7 months. In short, the rate at which high-throughput DNA sequencers are generating data is far outstripping our ability to compute on the data. Furthermore, the heterogeneity (and even incompatibility) of sequencing instrumentation as well as the vast diversity of applications enabled by them are creating numerous analytics problems for the bioinformatics community to address. In addition, the conventional serial algorithms that have been the mainstay of bioinformatics research are severely challenged by the ever-increasing data sets. \n\n \n\nTo address the above challenges and create a more efficient and easier-to-use \"big data\" sequencing analysis environment that will lead to faster medical and pharmaceutical breakthroughs, we achieved the following:\n\n \n\n1  Efficient mapping of life-science applications onto multi-core and many-core computers (i.e., think a few multiple electronic brains to many electronic brains, e.g., 100) to deliver medical and pharmaceutical breakthroughs ranging from two times to thousands of times faster than ever before.\n\n2  Analysis and decomposition of life-science applications to support the creation of reusable \"Lego-like\" building blocks (across these life-science applications) so that life scientists can easily use the building blocks to program next-generation sequencing (NGS) analysis tools to run fast on multi-core and many-core computers.\n\n3  Creation of approaches to automate the acceleration (i.e., optimization) of the aforementioned \"Lego-like\" building blocks, which can be found in well-known algorithms in genomics, and more broadly, biocomputing.\n\n4  Continued profiling and analysis of state-of-the-art life science applications in order to identify and add any new \"Lego-like\" building blocks for next-generation sequencing (NGS) analysis.\n\n \n\nTransformative software to address the shortcomings of hardware.\n\n \n\nit requires supercomputing resources and Big Data storage that many researchers lack. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/12/2017\n\n\t\t\t\t\tSubmitted by: Wuchun Feng"
 }
}