{
 "awd_id": "1218022",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Beating Implementations of C++11 Concurrency Into Shape",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 467740.0,
 "awd_amount": 467740.0,
 "awd_min_amd_letter_date": "2012-08-13",
 "awd_max_amd_letter_date": "2017-10-03",
 "awd_abstract_narration": "The recently-ratified C and C++ standards, \"C11\" and \"C++11\"\r\nrespectively, add a concurrency model that supports writing\r\nhigh-performance, portable code for machines with multiple processors.\r\nThe concurrency model, however, is large and complicated; it is not\r\nparticularly easy for compiler and library developers to get all of\r\nits corner cases right. Errors in implementing the new model can\r\nintroduce bugs into important pieces of software, such as operating\r\nsystems, web browsers, web sites, database engines, and embedded\r\nsystems, all of which are written, at least partially, in concurrent C\r\nand C++.\r\n\r\nThe PI's previous work on randomized testing for C compilers uncovered\r\nmore than 450 bugs in production-quality compilers, most of which were\r\nfixed by compiler developers. The PI's current project extends this\r\nresearch agenda to support stress testing of implementations of the\r\nC11 and C++11 concurrency model. The intellectual merit of this work\r\nstems from the need to generate random, but standards-conforming,\r\nconcurrent code; the need to synthesize \"test oracles\" that can\r\nautomatically ascertain the success or failure of a test case; and,\r\nthe need to develop \"hostile\" simulators for flushing out errors in\r\ncompiled concurrent code.\r\n\r\nThe expected impact of the PI's work is to significantly reduce the\r\nperiod during which implementations of the C11 / C++11 concurrency\r\nmodel are flaky and immature, and to reduce the lifetime of compiler\r\nbugs that are introduced during ongoing development.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Regehr",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "John D Regehr",
   "pi_email_addr": "regehr@cs.utah.edu",
   "nsf_id": "000310362",
   "pi_start_date": "2012-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "201 PRESIDENTS CIRCLE ROOM 201",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 467740.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project focused on the LLVM compiler, which is extremely widely used in industry as well as being the basis for numberous academic projects, including many formal-methods-based ones. The work also broadened out a bit, focusing on memory models in general, instead of only on concurrency-related aspects of memory models. This refocusing had two motivations. First, some of the work that I had originally proposed got done by other people. Second, as my own research got deeper and deeper into the innards of LLVM, my colleagues and I kept running into very difficult-to-answer questions about its memory model. People in the LLVM community could not always find satisfactory answers to these questions, so we felt that it was up to us to try to figure out the solutions. LLVM is targeted by a lot of different front-ends these days, as well as quite a few formal methods-based tools (such as my group's Souper and Alive tools) and so it is really important that we know what LLVM code actually means.&nbsp;</p>\n<p>The high-level goals of this project, then, were to clarify and, if possible or necessary, fix the LLVM memory model. A major accomplishment was a body of work which resulted in this publication:</p>\n<p><a rel=\"nofollow\" href=\"http://www.cs.utah.edu/~regehr/oopsla18.pdf\">http://www.cs.utah.edu/~regehr/oopsla18.pdf</a></p>\n<p>This work came out of an effort by my group and my collaborators to understand what is superficially a really simple question: when you read from memory in LLVM code, what value should be returned? This ends up getting into very difficult territory (I consider this work to be some of the hardest material I've worked on during my career) but it is essential to be able to answer this this question if we are going to reason about what code in LLVM IR actually means.</p>\n<p>The short version of our results is this: At present, the LLVM memory model has some cases that are not specified precisely enough to tell us what some programs mean, and consequently we can get LLVM to miscompile programs (even those written in Rust, a safe and modern programming language). We developed a memory model that we believe fixes these problems without interfering with something that is very important in practice, which is allowing LLVM to perform most of the optimizations that it currently performs. This was the real trick: justifying optimizations that compiler developers intuitively \"know\" are ok, without breaking programs.</p>\n<p>The other major activity was accomplished by my PhD student Jubi Taneja.&nbsp; She has accomplished a nice piece of work that is under submission, but has not yet been published, that is part of her PhD work. The specific aim of this work was to look into the soundness and precision of dataflow analyses in LLVM. Soundness is important because LLVM can miscompile based on the results of an unsound analysis. Precision is important because imprecisiuon leads to missed optimizations. The tool that we used to look for dataflow soundness and precision bugs was a modified version of Souper, my group's formal-methods-based superoptimizer for LLVM IR.</p>\n<p>Jubi looked at 7 static analyses in LLVM and found numerous imprecisions in each of them. Some of these have resulted in patches being accepted to LLVM which inceased its static analysis precision. She did not find any unsound analyses (which is perhaps not surprising since this compiler is used on billions of lines of code in the real world).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/01/2019<br>\n\t\t\t\t\tModified by: John&nbsp;D&nbsp;Regehr</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project focused on the LLVM compiler, which is extremely widely used in industry as well as being the basis for numberous academic projects, including many formal-methods-based ones. The work also broadened out a bit, focusing on memory models in general, instead of only on concurrency-related aspects of memory models. This refocusing had two motivations. First, some of the work that I had originally proposed got done by other people. Second, as my own research got deeper and deeper into the innards of LLVM, my colleagues and I kept running into very difficult-to-answer questions about its memory model. People in the LLVM community could not always find satisfactory answers to these questions, so we felt that it was up to us to try to figure out the solutions. LLVM is targeted by a lot of different front-ends these days, as well as quite a few formal methods-based tools (such as my group's Souper and Alive tools) and so it is really important that we know what LLVM code actually means. \n\nThe high-level goals of this project, then, were to clarify and, if possible or necessary, fix the LLVM memory model. A major accomplishment was a body of work which resulted in this publication:\n\nhttp://www.cs.utah.edu/~regehr/oopsla18.pdf\n\nThis work came out of an effort by my group and my collaborators to understand what is superficially a really simple question: when you read from memory in LLVM code, what value should be returned? This ends up getting into very difficult territory (I consider this work to be some of the hardest material I've worked on during my career) but it is essential to be able to answer this this question if we are going to reason about what code in LLVM IR actually means.\n\nThe short version of our results is this: At present, the LLVM memory model has some cases that are not specified precisely enough to tell us what some programs mean, and consequently we can get LLVM to miscompile programs (even those written in Rust, a safe and modern programming language). We developed a memory model that we believe fixes these problems without interfering with something that is very important in practice, which is allowing LLVM to perform most of the optimizations that it currently performs. This was the real trick: justifying optimizations that compiler developers intuitively \"know\" are ok, without breaking programs.\n\nThe other major activity was accomplished by my PhD student Jubi Taneja.  She has accomplished a nice piece of work that is under submission, but has not yet been published, that is part of her PhD work. The specific aim of this work was to look into the soundness and precision of dataflow analyses in LLVM. Soundness is important because LLVM can miscompile based on the results of an unsound analysis. Precision is important because imprecisiuon leads to missed optimizations. The tool that we used to look for dataflow soundness and precision bugs was a modified version of Souper, my group's formal-methods-based superoptimizer for LLVM IR.\n\nJubi looked at 7 static analyses in LLVM and found numerous imprecisions in each of them. Some of these have resulted in patches being accepted to LLVM which inceased its static analysis precision. She did not find any unsound analyses (which is perhaps not surprising since this compiler is used on billions of lines of code in the real world).\n\n\t\t\t\t\tLast Modified: 07/01/2019\n\n\t\t\t\t\tSubmitted by: John D Regehr"
 }
}