{
 "awd_id": "1209136",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Numerical algebra and statistical inference",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Nandini Kannan",
 "awd_eff_date": "2012-07-01",
 "awd_exp_date": "2017-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2012-06-13",
 "awd_max_amd_letter_date": "2014-08-29",
 "awd_abstract_narration": "The investigators have two aims in this proposal that fall at the interface of numerical algebra and statistical inference. The first aim is to extend the use of randomized approximation in a variety of dimension reduction methods that rely on numerical linear algebra both supervised and unsupervised as well as linear and nonlinear and develop a statistical bases for these methods in addition to the computational motivation of being applicable to massive data. The other motivation is to extend these statistical methods for dimension reduction to multiway data using numerical multilinear algebra, a recent new development in numerical analysis. These projects will increase interaction between statistical inference and numerical analysis and benefit both fields, providing new perspectives to how we view and perform data analysis.\r\n\r\nNumerical methods with statistical implications are central to a variety of technologies used by the general population. These technologies include Google's pagerank algorithm, genetic methods used to find genetic variation related to disease, compressing of medical images for storage and treatment, as well as applications in geostatistics. In all the previous cases the fundamental idea is to condense massive data in a useful summary with respect to a desired goal. The two ideas in this proposal are (1) to study how numerical methods that scale to the massive data generated in modern scientific, engineering, and social applications impose statistical assumptions or models on the data, (2) to study more complex interactions or properties of the data than examined in current methods. The motivation behind the first aim is to understand how numerical approximations required for computational scaling as we collect more data impact the information that can be extracted from these data -- for what type of data and applications do certain numerical approximations work well. The motivation behind the second aim is to go beyond the broad category of standard statistical methods take into account the relation between pairs of objects -- two web pages that are linked for Google's pagerank, the correlation between two genes or two loci in genetics applications. The question behind this aim is whether richer sources of information can be extracted by examining the links between three web pages or three loci. The research involved in this aim consists of the development of computationally efficient algebraic methods to extract this information and understanding the statistical models implemented by these methods.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lek-Heng",
   "pi_last_name": "Lim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lek-Heng Lim",
   "pi_email_addr": "lekheng@galton.uchicago.edu",
   "nsf_id": "000150703",
   "pi_start_date": "2012-06-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5734 South University",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0113",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001314DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 56556.0
  },
  {
   "fund_oblg_fiscal_yr": 2013,
   "fund_oblg_amt": 46195.0
  },
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 47249.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we studied questions motivated by classical dimension reduction techniques: principal components analysis (PCA), linear discriminant analysis (LDA), sliced inverse regression (SIR), Laplacian and Hessian eigenmaps, locally linear embeddings (LLE), etc. The intention was to find ways of enhancing them so that they may be more effective for handling modern data sets that are (i) more complex, (ii) far larger, than what these techniques were originally developed for. We examined mainly two approaches: (i) randomized&nbsp;instead of deterministic, (ii) &nbsp;multilinear instead of linear. Our investigations led to new randomized algorithms based on diffusion Monte Carlo methods for several fundamental operations in numerical linear algebra: matrix inversion, exponentiation, eigenvalue extractions, etc. They also led to new developments in multilinear algebra including novel multilinear generalizations of linear quantities (e.g., tensor nuclear norm, symmetric multilinear rank, etc),&nbsp;better understanding of multilinear methods (e.g., homotopy groups of tensor ranks, uniqueness of nonnegative tensor approximations, etc), and even completely new notions (e.g., tensor nuclear rank, tenor network ranks, etc). A serendipitous discovery that came out of our investigations was a radically new way of defining distances between subspaces of different dimensions as distances between a point and a Schubert variety within a Grassmannian.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/02/2018<br>\n\t\t\t\t\tModified by: Lek-Heng&nbsp;Lim</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1209136/1209136_10181130_1525301941076_schubert--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1209136/1209136_10181130_1525301941076_schubert--rgov-800width.jpg\" title=\"distance between a point and a Schubert variety within the Grassmannian\"><img src=\"/por/images/Reports/POR/2018/1209136/1209136_10181130_1525301941076_schubert--rgov-66x44.jpg\" alt=\"distance between a point and a Schubert variety within the Grassmannian\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Defining distance between two subspaces of different dimensions.</div>\n<div class=\"imageCredit\">K. Ye and L.-H. Lim</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Lek-Heng&nbsp;Lim</div>\n<div class=\"imageTitle\">distance between a point and a Schubert variety within the Grassmannian</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIn this project, we studied questions motivated by classical dimension reduction techniques: principal components analysis (PCA), linear discriminant analysis (LDA), sliced inverse regression (SIR), Laplacian and Hessian eigenmaps, locally linear embeddings (LLE), etc. The intention was to find ways of enhancing them so that they may be more effective for handling modern data sets that are (i) more complex, (ii) far larger, than what these techniques were originally developed for. We examined mainly two approaches: (i) randomized instead of deterministic, (ii)  multilinear instead of linear. Our investigations led to new randomized algorithms based on diffusion Monte Carlo methods for several fundamental operations in numerical linear algebra: matrix inversion, exponentiation, eigenvalue extractions, etc. They also led to new developments in multilinear algebra including novel multilinear generalizations of linear quantities (e.g., tensor nuclear norm, symmetric multilinear rank, etc), better understanding of multilinear methods (e.g., homotopy groups of tensor ranks, uniqueness of nonnegative tensor approximations, etc), and even completely new notions (e.g., tensor nuclear rank, tenor network ranks, etc). A serendipitous discovery that came out of our investigations was a radically new way of defining distances between subspaces of different dimensions as distances between a point and a Schubert variety within a Grassmannian.\n\n\t\t\t\t\tLast Modified: 05/02/2018\n\n\t\t\t\t\tSubmitted by: Lek-Heng Lim"
 }
}