{
 "awd_id": "1147581",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "A Linguistic Taxonomy of English Web Registers",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Joan Maling",
 "awd_eff_date": "2012-09-15",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 331806.0,
 "awd_amount": 331806.0,
 "awd_min_amd_letter_date": "2012-09-19",
 "awd_max_amd_letter_date": "2012-09-19",
 "awd_abstract_narration": "For both general users and linguists, the Internet provides a massive amount of information and linguistic data, readily accessible to anyone with a computer, that has value for research in linguistics, computational linguistics and the social sciences. However, the nature of the different types of language used on the web remains unclear. To better understand the language of the internet, Drs. Biber and Davies will develop a comprehensive linguistic taxonomy of web registers. This taxonomy will be applied to a large, representative corpus of internet texts, which will be made freely available as an online resource for a range of research purposes. \r\n\r\nThe initial framework for classifying texts into register categories will be developed through hand-coding (using a rubric based on situational characteristics) and computational linguistic analysis of a sample of web sites indexed by Netscape's Open Directory Project. The resulting taxonomy will then be applied automatically to a second corpus (circa 100,000 texts) and integrated into a searchable online interface. Assuming that each web text contains an average of 1,000 words, this online searchable corpus will contain approximately 100 million words.\r\n\r\nThe linguistic descriptions resulting from this project, and the searchable online corpus, will provide the basis for more principled uses of the web as a data source, including using the web as a corpus to test hypotheses about language variation and change; using the web to identify probabilistic patterns, incorporated into tools for lexicographic research or natural language processing applications; studying ways to extract essential information on specialized topics from web documents;  and identifying examples of 'authentic' language illustrating the use of words or grammatical constructions.  The present project will provide detailed linguistic descriptions of the nature of the source documents, as well as a valuable online resource to facilitate future investigations of web-based texts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Douglas",
   "pi_last_name": "Biber",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Douglas Biber",
   "pi_email_addr": "douglas.biber@nau.edu",
   "nsf_id": "000210901",
   "pi_start_date": "2012-09-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Davies",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mark Davies",
   "pi_email_addr": "mark_davies@byu.edu",
   "nsf_id": "000586503",
   "pi_start_date": "2012-09-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northern Arizona University",
  "inst_street_address": "601 S KNOLES DR RM 220",
  "inst_street_address_2": "",
  "inst_city_name": "FLAGSTAFF",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "9285230886",
  "inst_zip_code": "86011",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "AZ02",
  "org_lgl_bus_name": "NORTHERN ARIZONA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MXHAS3AKPRN1"
 },
 "perf_inst": {
  "perf_inst_name": "Northern Arizona University",
  "perf_str_addr": "Babbitt Academic Annex",
  "perf_city_name": "Flagstaff",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "860110001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "AZ02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "SMET",
   "pgm_ref_txt": "SCIENCE, MATH, ENG & TECH EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 331806.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While there have been numerous previous studies that focus on recently-developed internet registers that especially salient (like tweets or texting), no previous study describes the full range of everyday registers found on the searchable web.&nbsp; These are the documents that readers encounter every time they do a <em>Google</em> search, representing registers like news reports, reviews, travel blogs, discussion forums, FAQs, etc.&nbsp; Based on analysis of a large, near-random corpus of web documents, the present project provides a comprehensive situational, lexical, and grammatical description of the full range of registers found on the searchable web.</p>\n<p>Linguistic interest in the World Wide Web is motivated by the desire to use the Web as a corpus that represents English generally (or any other language), pursued under the acronym WAC (Web-as-Corpus).&nbsp; One major challenge for Web-As-Corpus research is that a typical Web search provides little information about the register of the documents that are searched.&nbsp; Previous research has attempted to address this problem (e.g., through the &lsquo;Automatic Genre Identification&rsquo; initiative), but with only limited success.&nbsp; As a result, we currently know surprisingly little about the distribution of registers on the searchable web.</p>\n<p>In the present project, we tackled this problem through a bottom-up user-based investigation of a large, representative corpus of web documents.&nbsp; We based our investigation on a much larger corpus than in previous research (48,000 web documents), obtained through random sampling from across the full range of documents that are publically available on the searchable web.&nbsp; Instead of relying on individual expert coders, we recruited typical end-users of the Web for our register coding, with each document in the corpus coded by four different raters.&nbsp; End-users identified basic situational characteristics of each web document, coded in a hierarchical manner.&nbsp; Those situational characteristics lead to general register categories, which eventually lead to lists of specific sub-registers.&nbsp; By working through a hierarchical decision tree, coders were able to identify the register category of most internet texts with a high degree of reliability, including 8 general register categories (e.g., narration, opinion, and informational descriptions) and 27 specific register categories (e.g., travel blogs, product reviews, recipes).</p>\n<p>One major outcome of the project was to document the register composition of the searchable web.&nbsp; Narrative registers are found to be the most prevalent, while Opinion and Informational registers are also found to be extremely common.&nbsp; In addition, one of the major innovations of the approach is that it permits an empirical identification of &lsquo;hybrid&rsquo; documents, which integrate characteristics from multiple general register categories (e.g., opinionated-narrative).&nbsp;</p>\n<p>Other major outcomes of the project provide detailed linguistic descriptions of web registers. &nbsp;First, we carried out a Multi-Dimensional analysis to describe the overall linguistic patterns of register variation on the web.&nbsp; The central theoretical and methodological innovation of the Multi-Dimensional approach centers around the notion of linguistic co-occurrence, because lexico-grammatical features are analyzed statistically to determine the ways in which they co-occur in texts.&nbsp; Nine dimensions of variation are identified, including several oral-literate dimensions and narrative dimensions, as well as individual dimensions related to procedural/explanatory discourse and nominal/literate stance.&nbsp; The linguistic composition and the major patterns of register variation for each dimension are described and illustrated.</p>\n<p>In addition, detailed situational and linguistic descriptions were undertaken for each specific sub-register found on the web.&nbsp; These included keyword analyses (identification and interpretation of the distinctive words occurring in each register), key grammatical feature analysis (the distinctive grammatical characteristics of each register), and analysis of how stance is expressed in more or less overt ways in different registers.</p>\n<p>Finally, three major methodological innovations grew out of the research project.&nbsp; First, we explored the extent to which core lexico-grammatical features can be effectively used to automatically predict the register category of web documents.&nbsp; Second, we explored the extent to which Multi-Dimensional Analysis and Canonical Discriminant Analysis produce compatible descriptions of register variation.&nbsp; That is, although these two statistical techniques approach variation from opposite perspectives, we hypothesized that they would produce similar linguistic generalizations because both types of statistical patterns are motivated by underlying discourse functions.&nbsp; And finally, we developed a new method for identifying the salient keywords in a discourse domain, based on patterns of dispersion rather than simple frequency.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/25/2017<br>\n\t\t\t\t\tModified by: Douglas&nbsp;Biber</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile there have been numerous previous studies that focus on recently-developed internet registers that especially salient (like tweets or texting), no previous study describes the full range of everyday registers found on the searchable web.  These are the documents that readers encounter every time they do a Google search, representing registers like news reports, reviews, travel blogs, discussion forums, FAQs, etc.  Based on analysis of a large, near-random corpus of web documents, the present project provides a comprehensive situational, lexical, and grammatical description of the full range of registers found on the searchable web.\n\nLinguistic interest in the World Wide Web is motivated by the desire to use the Web as a corpus that represents English generally (or any other language), pursued under the acronym WAC (Web-as-Corpus).  One major challenge for Web-As-Corpus research is that a typical Web search provides little information about the register of the documents that are searched.  Previous research has attempted to address this problem (e.g., through the ?Automatic Genre Identification? initiative), but with only limited success.  As a result, we currently know surprisingly little about the distribution of registers on the searchable web.\n\nIn the present project, we tackled this problem through a bottom-up user-based investigation of a large, representative corpus of web documents.  We based our investigation on a much larger corpus than in previous research (48,000 web documents), obtained through random sampling from across the full range of documents that are publically available on the searchable web.  Instead of relying on individual expert coders, we recruited typical end-users of the Web for our register coding, with each document in the corpus coded by four different raters.  End-users identified basic situational characteristics of each web document, coded in a hierarchical manner.  Those situational characteristics lead to general register categories, which eventually lead to lists of specific sub-registers.  By working through a hierarchical decision tree, coders were able to identify the register category of most internet texts with a high degree of reliability, including 8 general register categories (e.g., narration, opinion, and informational descriptions) and 27 specific register categories (e.g., travel blogs, product reviews, recipes).\n\nOne major outcome of the project was to document the register composition of the searchable web.  Narrative registers are found to be the most prevalent, while Opinion and Informational registers are also found to be extremely common.  In addition, one of the major innovations of the approach is that it permits an empirical identification of ?hybrid? documents, which integrate characteristics from multiple general register categories (e.g., opinionated-narrative). \n\nOther major outcomes of the project provide detailed linguistic descriptions of web registers.  First, we carried out a Multi-Dimensional analysis to describe the overall linguistic patterns of register variation on the web.  The central theoretical and methodological innovation of the Multi-Dimensional approach centers around the notion of linguistic co-occurrence, because lexico-grammatical features are analyzed statistically to determine the ways in which they co-occur in texts.  Nine dimensions of variation are identified, including several oral-literate dimensions and narrative dimensions, as well as individual dimensions related to procedural/explanatory discourse and nominal/literate stance.  The linguistic composition and the major patterns of register variation for each dimension are described and illustrated.\n\nIn addition, detailed situational and linguistic descriptions were undertaken for each specific sub-register found on the web.  These included keyword analyses (identification and interpretation of the distinctive words occurring in each register), key grammatical feature analysis (the distinctive grammatical characteristics of each register), and analysis of how stance is expressed in more or less overt ways in different registers.\n\nFinally, three major methodological innovations grew out of the research project.  First, we explored the extent to which core lexico-grammatical features can be effectively used to automatically predict the register category of web documents.  Second, we explored the extent to which Multi-Dimensional Analysis and Canonical Discriminant Analysis produce compatible descriptions of register variation.  That is, although these two statistical techniques approach variation from opposite perspectives, we hypothesized that they would produce similar linguistic generalizations because both types of statistical patterns are motivated by underlying discourse functions.  And finally, we developed a new method for identifying the salient keywords in a discourse domain, based on patterns of dispersion rather than simple frequency.\n\n \n\n\t\t\t\t\tLast Modified: 06/25/2017\n\n\t\t\t\t\tSubmitted by: Douglas Biber"
 }
}