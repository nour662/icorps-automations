{
 "awd_id": "1162581",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Medium: Quantifying and utilizing confidence in machine learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Weng-keen Wong",
 "awd_eff_date": "2012-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2012-08-31",
 "awd_max_amd_letter_date": "2012-08-31",
 "awd_abstract_narration": "This project defines meaningful notions of confidence in prediction, designs procedures for computing such notions, and applies these procedures to core machine learning tasks such as active learning, crowd-sourced learning, and tracking. In many applications it is helpful to have classifiers that output, together with each prediction, a rating of the confidence that the prediction is in fact correct. Existing literature either provides various ad-hoc ways for computing such ratings which typically lack a rigorous mathematical footing, or provides mathematically consistent methods (in the Bayesian framework) for computing confidence ratings under very strong assumptions that are unlikely to hold in practice. The research team investigates methods of computing measures of confidence that are mathematically rigorous while making minimal assumptions on the way data is generated, and use these measures to further develop solutions to core machine learning tasks.\r\n\r\nDefining and computing mathematically sound measures of confidence lies at the heart of machine learning, pattern recognition and uncertainty in AI. Confidence-rated prediction, active learning, and tracking are fundamental tasks of machine learning and statistics that arise repeatedly in large-scale problems; this project will develop rigorous solutions to these problems. The algorithms developed in this work are tested and used in the Automatic Cameraman project, an interactive, audio-visual installation in the UCSD Computer Science department. The interactive Automatic Cameraman system are used an educational tool to be extended in many different directions, by teams of students at a variety of skill levels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yoav",
   "pi_last_name": "Freund",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Yoav S Freund",
   "pi_email_addr": "yfreund@ucsd.edu",
   "nsf_id": "000488238",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sanjoy",
   "pi_last_name": "Dasgupta",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjoy Dasgupta",
   "pi_email_addr": "dasgupta@cs.ucsd.edu",
   "nsf_id": "000188407",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kamalika",
   "pi_last_name": "Chaudhuri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kamalika Chaudhuri",
   "pi_email_addr": "kamalika@cs.ucsd.edu",
   "nsf_id": "000573596",
   "pi_start_date": "2012-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930404",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164000",
   "pgm_ele_name": "Information Technology Researc"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the research funded by this grant, we have studied the concept of confidence in the context of machine learning. Roughly speaking, a prediction is confident if it remains unchanged under small changes in the training data or the learning algorithms.&nbsp;&nbsp;</p>\n<p>Prediction confidence should not be confused with the probability of error.&nbsp; One can be very confident that an outcome of 1 is more likely than an outcome of 0 even though the difference between the probabilities is 51% to 49%</p>\n<p>In our work we have found several formulations of confidence rated prediction, some of them are based on games between nature and the learner. The relation to game theory results in a close connection with linear programming.</p>\n<p>We quantified confidence in several setups, including adversarial&nbsp;learning, learning from counter-factual information, and&nbsp;transductive learning.</p>\n<p>Confidence rated learning is closely related to active learning, where the learning algorithm queries the instructor for labels, rather than getting labels independently at random. We used our new insights into confidence-rated predictions to design new active learning algorithms.</p>\n<p>As datasets become exponentially larger, the human work required to collect labels becomes a major bottleneck in data analysis. Most existing active learning algorithms require that there is almost no noise in the labels of the training set. Active learning algorithm based on the confidence rated prediction models allow high levels of noise and thereby greatly extend the applicability of active learning.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/27/2017<br>\n\t\t\t\t\tModified by: Yoav&nbsp;S&nbsp;Freund</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn the research funded by this grant, we have studied the concept of confidence in the context of machine learning. Roughly speaking, a prediction is confident if it remains unchanged under small changes in the training data or the learning algorithms.  \n\nPrediction confidence should not be confused with the probability of error.  One can be very confident that an outcome of 1 is more likely than an outcome of 0 even though the difference between the probabilities is 51% to 49%\n\nIn our work we have found several formulations of confidence rated prediction, some of them are based on games between nature and the learner. The relation to game theory results in a close connection with linear programming.\n\nWe quantified confidence in several setups, including adversarial learning, learning from counter-factual information, and transductive learning.\n\nConfidence rated learning is closely related to active learning, where the learning algorithm queries the instructor for labels, rather than getting labels independently at random. We used our new insights into confidence-rated predictions to design new active learning algorithms.\n\nAs datasets become exponentially larger, the human work required to collect labels becomes a major bottleneck in data analysis. Most existing active learning algorithms require that there is almost no noise in the labels of the training set. Active learning algorithm based on the confidence rated prediction models allow high levels of noise and thereby greatly extend the applicability of active learning.\n\n\t\t\t\t\tLast Modified: 11/27/2017\n\n\t\t\t\t\tSubmitted by: Yoav S Freund"
 }
}